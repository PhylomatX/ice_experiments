0.764093735681684
0.7570030849527674
0.7427024199958999
0.772588455988184
0.7224970132259051
0.7318344323754367
0.7799969220455374
0.7842004647473484
0.7691490690744537
0.7434714098014621
0.740599131843668
0.7842292218751881
0.75776140274539
0.7359373959925354
0.7190825607368402
0.7691742941985438
0.7598227155839526
0.7590361837796247
0.7355949526407008
0.7555963425539698
0.7662770572612332
0.8288560701918646
0.7178392303354406
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0012809279,0.011891395,0.010877612,-0.006068995,-0.017302802,0.022659408,0.0051374114,0.0006434608,-0.020522246,-0.034523405,0.0232485,-0.0057196515,-0.011069409,0.006836182,-0.023495095,-0.012487334,0.028413309,0.007254025,0.008041761,-0.021673026,-0.0073499233,0.016617812,0.0020601018,-0.039729316,-0.017069906,0.021590827,0.028522907,-0.0153711345,0.014686147,0.005805275,0.00046022644,0.013384669,-0.023084102,-0.032742433,-0.0077198166,0.02146753,0.01096666,-0.014439551,0.0024145832,-8.147613e-06,0.032550637,0.0046681943,-0.0077883154,-0.020604445,0.009918629,0.007370473,0.011891395,-0.021234633,-0.010110426,-0.0045585963,0.020946939,0.02830371,-0.023344398,-0.0095144855,-0.011918794,0.009521335,-0.005870349,0.009528185,0.012439385,-0.0021594253,0.018179586,0.009767931,-0.01330932,0.010713215,-0.029399693,-0.0134737175,0.004288026,0.009610384,-0.023399197,0.020220852,0.049319148,0.029207896,-0.001128518,-0.01506974,0.00987068,-0.012042092,-0.011870845,-0.015754728,0.0050654877,0.009096643,0.0014170692,-0.022467611,-0.027563924,0.039427917,0.009445987,-0.03378362,0.0104597695,0.02661864,-0.018453581,0.009774781,-0.010925561,0.0174535,0.020508546,-0.0042674765,0.0052470095,0.0019881781,0.013096974,0.023851288,0.009726832,0.002344372,-0.011398204,0.009692582,-0.048414964,-0.00872675,-0.015590331,0.00027998892,0.01686441,0.00059679593,0.0120215425,-0.027399527,-0.048825957,0.04394884,0.0075691193,-0.030934066,0.011220106,-0.0048771156,-0.0017484323,-0.04345565,-0.0077403663,-0.0062744915,0.0066991844,0.030550472,0.028906502,-0.0055244295,0.019823559,-0.005976522,-0.033948015,-0.025947353,-0.024111584,-0.009158292,0.027947517,0.014179255,-0.022248415,0.03340002,-0.023056703,0.004904515,-0.005743626,0.033071227,-0.04011291,-0.015234137,0.024700673,0.0013768262,0.0063395654,0.02083734,-0.0034283658,0.020714043,0.00039558066,0.030249078,-0.0052504344,-0.010576217,-0.001477862,-0.01796039,0.020933239,0.003928407,0.017330201,0.019426264,0.008473304,-0.0019299542,-0.014960142,-0.015795827,-0.0008853472,0.005003839,0.0025361688,0.014288853,0.015946524,0.018289184,0.016110921,-0.0013879573,-0.0061100945,0.011706448,-0.010932411,0.02953669,-0.018754976,0.028742103,0.0036030377,0.013158623,0.02197442,-0.027632423,-0.004856566,-0.0006708603,-0.010528268,0.020604445,-0.0016473966,0.012233889,-0.009103493,-0.014124456,0.0010934124,-0.029098298,-0.0003756732,-0.018439882,-0.01099406,0.015480733,0.00806916,0.01274078,-0.6606574,-0.028824301,0.00087935355,-0.014466951,0.013686064,0.019193368,0.006188868,-0.019837258,-0.024454078,0.02030305,-0.019987956,0.003152658,0.016727412,-0.032550637,-0.016343817,-0.042113073,0.019946856,-0.020001655,-0.013823061,0.0153163355,-0.018796075,0.010959811,-0.014919043,0.020782541,-0.003654412,0.013213422,-0.007767766,-0.008391106,0.033564422,0.021673026,-0.002774202,0.028577706,-0.015932824,0.01045292,0.04008551,-0.016275318,-0.019453663,0.00550388,-0.012336637,0.04334605,-0.04855196,-0.0138093615,0.013994308,0.0041167787,-0.0037742849,0.0063190158,0.008959645,-0.0103501715,0.018659078,0.013220272,0.0016688025,0.026043251,0.0023940336,0.007370473,0.018974172,-0.010863912,0.014466951,-0.00811026,0.016960308,0.0007881645,0.009295289,0.003709211,-0.011836596,-0.0024728074,0.008740449,0.034907,0.014192955,0.026906336,-0.0053497576,-0.021097636,0.0044935225,0.008877447,-0.003815384,-0.010357021,-0.0008361137,-0.0031081338,0.00549703,0.0075622695,0.01680961,0.010117276,-0.0043907743,-0.022755306,0.005157961,0.011322854,-0.0069149556,0.006616986,-0.020056454,-0.009041844,0.0032160194,-0.012459935,0.01978246,0.032495838,-0.0069834543,-0.030961465,-0.012261288,0.025591157,0.0009307277,0.015535532,0.0019864656,-0.014069657,-0.012480484,0.013035325,-0.0052949586,0.007767766,0.018741276,-0.00038209496,-0.031536855,0.02838591,0.038578533,0.0031663578,-0.0019470789,0.018152187,-0.032030046,0.018919373,-0.0043291254,-0.031701252,0.006726584,-0.003130396,-0.0057676006,-0.013617565,0.027495425,-0.002774202,0.01904267,-0.014672447,0.009137742,0.02544046,0.004051705,-0.015987623,0.006846457,0.017302802,0.024645874,0.024097884,0.013953209,-0.008178758,0.022125117,0.012576383,-0.003531114,0.009082943,0.007596519,-0.010370721,-0.010569368,0.012802429,3.0235806e-05,0.010117276,-0.016289018,0.0050620628,-0.007103327,0.010631016,-0.0029608614,-0.010295372,0.008034911,-0.018206986,-0.010576217,-0.0012980526,-0.0153711345,0.0028375634,0.013103824,-0.029783286,-0.0066306856,-0.034578204,0.012535283,0.042606264,-0.024495177,0.0059525473,-0.007822565,-0.0031184086,-0.012939427,0.024947269,-0.0017706944,-0.019535862,0.0147546455,-0.029838085,-0.0039489567,0.029646289,-0.0100145275,0.0068156323,-0.00046536385,-0.019275567,-0.006503963,-0.015905425,-0.008733599,-0.019193368,0.015782127,0.008213008,0.015686229,0.011192706,0.027344728,0.0084527545,-0.032660235,0.04109929,-0.0058292495,0.007295124,-0.010110426,0.010261123,0.011774947,-0.0076102186,0.009754231,-0.003705786,0.006846457,0.0035619384,0.0053977068,0.009336389,0.026399445,-0.025988452,-0.0062881913,-0.009774781,0.008041761,-0.021042837,0.021823723,0.012295538,0.018371383,0.00039044325,-0.00809656,-0.015124539,0.00926789,-0.0028906502,0.0002894075,0.007110177,-0.009377488,0.03287943,-0.010617317,-0.013973759,0.05285369,-0.0037845597,0.013514817,0.024974668,-0.009144592,0.012316087,0.022056619,-0.029207896,-0.0016653775,0.0033530171,0.006312166,0.027139232,0.013425768,0.0031629328,-0.022796407,-0.0049524647,0.012816128,-0.012507884,0.013973759,0.015686229,-0.0045551714,-0.011747547,0.038030542,0.0048942403,0.032742433,0.01967286,0.0014401877,-0.01045292,-0.011905095,0.0013417206,-0.017385,-0.0050106887,0.007980112,-0.002959149,0.012590082,-0.0032297194,0.018179586,0.021823723,0.017289102,0.022714207,0.018850874,-0.03419461,0.032249242,0.005863499,-0.009630933,-0.02608435,-0.021494929,-0.0289887,-0.022632008,0.0045551714,0.016508214,-0.04219527,0.03712636,0.0053052334,0.019563261,0.012377736,0.037783947,0.014110756,-0.021796323,-0.01801519,0.0036030377,0.014398451,0.004853141,0.0021491505,-0.010932411,0.004938765,-0.008569202,-0.0014213504,0.003709211,0.019549562,-0.0038119592,-0.002923187,-0.007651318,0.014206654,0.01391896,-0.0052367346,-0.011726998,-0.01274763,-0.012946277,0.0069663296,-0.01904267,-0.030824468,0.03761955,0.007254025,0.015713628,-0.016480815,-0.008856897,-0.02670084,0.0064388886,-0.018878274,-0.0025567184,-0.021823723,0.01616572,0.0040619797,-0.028659904,0.016905509,0.028413309,-0.0029916859,-0.0030242228,0.0011473552,-0.0021388757,0.0065142377,0.03359182,0.027152931,0.0034386406,0.010130975,-0.040469103,0.003366717,0.0035208391,-0.005969672,0.0026474793,0.018275484,-0.0004666482,0.01098721,-0.0027433776,-0.0042709014,0.0006858444,0.014371051,0.026303547,-0.023330698,-0.00872675,-0.015028641,0.003305068,-0.011144757,0.019234467,0.025344562,0.013199722,0.0021748375,0.008397955,0.0070827776,0.002114901,-0.017686395,0.004565446,0.014658747,0.018330283,0.019809859,0.007808865,0.02144013,-0.014932742,-0.012843528,0.013788812,0.0073773228,0.012042092,-0.0023101226,0.0116858985,-0.007062228,-0.0071923756,-0.013453168,0.018850874,-0.010028227,0.009404887,-0.0004666482,-0.0045620212,-0.011829746,-0.041044492,-0.008671951,0.0053429077,0.011658499,-0.009103493,-0.00044567042,0.009034994,-0.021125035,-0.025563758,-0.008521253,0.012651731,-0.011672199,0.014234054,-0.0019025546,-0.0033975414,-0.0031081338,-0.0003382129,-0.0010309072,0.0023974585,-0.04866156,-0.03871553,-0.0115215015,0.021234633,0.030194279,0.008582902,0.0014992679,-0.027084433,0.001390526,-0.021275733,-0.009493936,-0.0032913683,-0.014412151,0.0077129668,0.014795745,-0.0025310314,-0.0034814524,-0.0029728487,0.013631265,-0.010706365,0.03364662,0.0077129668,-0.021536028,-0.0006340422,0.0091788415,8.3964565e-05,0.021179834,0.0054251063,-0.022289515,0.027550224,-0.023577293,-0.014165555,-0.007000579,-0.012542133,-0.00695948,0.0107406145,0.0075143203,0.0044421484,-0.008432205,0.011384503,-0.014562849,0.008808948,-0.017809693,0.00047863548,0.0008091423,0.021522328,0.01620682,-0.007980112,0.025878854,0.01679591,-0.041400686,0.016658911,0.010041927,-0.015891725,0.008740449,-0.021015437,0.011295455,-0.024440378,0.016357517,-5.2390893e-05,0.025097966,-0.007596519,-0.0056477273,-0.027920118,-0.005339483,-0.027618723,-0.014727246,-0.010569368,-0.011028309,0.011918794,-0.003527689,-0.017508298,-0.007110177,0.007986962,-0.022673108,-0.010083026,0.014453251,-0.0072882744,0.04008551,-0.0012209914,-0.002722828,-0.014809445,-0.027728321,-0.0022244991,-0.028879102,-0.0025892553,0.0021320258,0.021125035,0.0153163355,0.031454656,0.017645296,0.031646453,-0.0056271777,-0.01979616,-0.0065245125,0.012487334,-0.004397624,-0.009377488,0.016384916,0.00012864934,-0.029755887,0.0077403663,0.0049284897,0.0058087,0.011240656,-0.026303547,-0.017467199,-0.017385,-0.022138817,0.00065459183,0.022796407,-0.021234633,-0.006295041,-0.030495673,0.015809527,-0.0031646453,-0.003938682,0.021166135,0.0024984945,0.012966827,-0.0048805405,0.022440212,-0.0004109929,-0.0016645213,-0.010802263,-0.030988865,-0.010487169,0.0021337382,0.03655097,-0.019522162,0.015768427,0.016056122,0.000953846,-0.012528433,-0.023906088,0.0088979965,-0.017563097,0.0022484737,-0.0062916162,-0.009548735,-0.025741855,-0.012096891,-0.013932659,0.0012912027,0.006623836,-0.018275484,0.002923187,0.006716309,-0.021371631,0.02427598,-0.009672033,0.026207648,0.016069822,0.025851455,0.0029351744,0.0016593839,0.008165059,-0.012007843,-0.0058737737,0.010384421,0.011336554,-0.0126380315,0.015795827,-0.03375622,0.008589752,-0.00075263076,-0.013453168,-0.007767766,0.00979533,0.013281921,-0.0095144855,-0.007486921,-0.025865154,-0.011562601,0.0007209501,-0.008747299,-0.015028641,0.010117276,-0.0077198166,0.0014932742,0.009384338,0.015768427,0.028221512,0.0063258656,0.000607927,0.021042837,-0.0016482528,0.009562435,0.019905757,0.0016542465,0.008521253,0.024673274,0.008418505,-0.004620245,-0.0022673109,0.008637701,-0.0025858304,-0.0012680844,0.028933901,-0.011048859,0.00040992262,0.0007556276,0.010829663,0.0020155776,-0.0057607507,-0.014110756,0.003013948,-0.007829415,0.008651401,0.009308989,0.007589669,-0.030386075,-0.008185608,0.002205662,-0.0045414716,0.005603203,-0.0021645627,0.0051785107,-0.03227664,-0.014987541,-0.0018289185,0.014549149,0.026495343,-0.013692914,0.00753487,0.024138983,0.0031612203,-0.017878192,-0.007993812,0.021179834,-0.007247175,-0.021837423,0.022042919,-0.0072129257,-0.027536524,0.029098298,-0.0009478524,-0.029509291,-0.02372799,0.0041167787,-0.019576961,-0.00068027887,-0.040469103,-0.015151938,0.0048325914,0.01271338,0.010288523,0.009315839,-0.0012826404,0.015220437,-0.00048334477,0.0043531,0.007473221,-0.008733599,-0.013727163,0.01391211,-0.0026286421,-0.03759215,-0.012322937,0.0019676285,0.0015557794,0.01098036,-0.013466868,-0.014343652,0.005846374,-0.009692582,0.033372622,0.007863664,-0.016535614,-0.019275567,-0.006236817,0.005161386,0.026783038,-0.0289613,-0.008870597,-0.0023940336,-0.005329208,-0.033235624,-0.041921277,-0.01975506,0.03701676,0.019494763,-0.0100145275,0.0006156331,-0.01619312,-0.020124953,-0.012192789,0.010555668,-0.007069078,-0.0076102186,0.004681894,-0.0065964363,0.018316584,0.002558431,-0.018357683,0.002263886,0.010494019,-0.012576383,-0.022960804,0.016631512,0.03698936,-0.022234716,-0.01450805,0.0044352985,-0.01330932,0.022262115,0.0012346912,-0.002835851,-0.015480733,0.014590248,0.019576961,0.026289847,0.02381019,0.018412482,-0.01388471,0.0036920863,0.014631348,-0.017302802,-0.026276147,-0.014316252,0.009747381,-0.0077335164,0.0040688296,-0.011795497,-0.017494598,-0.0085623525,-0.0016131471,0.021714125,-0.0012817841,-0.00046836067,0.02719403,0.0031338208,-0.021700425,-0.001794669,0.02661864,-0.024960969,-0.018809775,0.02374169,-0.039866313,0.0051442613,-0.0023683466,-0.019481063,-0.020220852,-0.002179975,-0.004229802,-0.006247092,-0.0051819356,0.009630933,0.0075622695,-0.017206904,0.02033045,-0.0043770745,-0.014055957,-0.016302718,0.0028427008,0.026878936,0.0044866726,-0.013268221,-0.0015703354,-0.018686477,-0.019974256,0.02667344,0.025618557,0.014740946,0.032660235,0.24637654,-0.017521998,-0.013186023,0.011261205,0.015247837,0.005959397,1.8315406e-05,0.032057445,-0.021042837,-0.012953127,0.016686311,0.0063327155,0.004620245,0.00202414,0.0014213504,-0.009993978,-0.021001738,-0.008576052,0.0015669104,0.013035325,0.013576466,0.0028940751,0.0005064631,-0.02027565,0.045318816,0.011158457,0.002722828,0.019289266,-0.014316252,-0.0107406145,0.0066443854,0.0026115174,0.0080623105,0.020494847,-0.016521914,-0.00806916,-0.006024471,-0.016713712,0.025824055,0.014713546,0.020974338,-0.009672033,-0.011555751,-0.010857062,0.0092884395,0.0031732076,-0.011363953,-0.012562683,0.009966578,0.0071307267,-0.023138901,-0.01617942,0.017138405,0.0289613,-0.0015232424,-0.010768014,0.0018186437,-0.004044855,0.034687802,0.014151855,-0.035591986,0.010891312,-0.029235296,0.018453581,-0.005216185,-0.00067985075,-0.0029403118,-0.0103501715,0.026563842,-0.026166549,-0.014453251,0.007870514,-0.00201729,-0.0011405053,-0.025755554,-0.0057059517,0.033454824,0.01959066,0.020029055,0.02318,-0.015905425,9.873462e-05,-0.002089214,-0.010624167,-0.016110921,-0.00983643,0.024015686,-0.016001323,0.008151359,0.006664935,3.9868453e-05,0.0005295815,-0.013090124,-0.007651318,0.0012971964,0.004418174,0.0048702657,0.025207564,-0.010185774,0.00064046396,-0.031043664,0.05605943,0.010315922,0.0030892966,0.015439633,0.016124621,0.024399279,0.015138239,0.008493854,-0.015905425,-0.002799889,-0.050634325,-2.2128328e-05,-0.0073430734,-0.007418422,0.0058292495,0.0015780415,-0.0035413888,0.03359182,-0.010672116,-0.0060552955,-0.014919043,-0.0023358096,0.009754231,0.011802346,-0.021330532,-0.020248251,-0.0015497857,-0.0154259335,0.007123877,-0.0011661923,0.017467199,0.0022107994,0.027728321,-0.009952879,-0.019850958,-0.01794669,-0.040962294,0.0034934396,0.0091788415,-0.00073507795,0.017289102,0.016576713,-0.016316418,0.0018939923,-0.011528351,0.012131141,0.009726832,-0.015782127,-0.015343735,-0.0051442613,-0.0038564834,-0.015768427,-0.025111666,0.020549646,-0.012494184,-0.012644881,-0.017001407,0.010288523,-0.00808286,-0.011555751,0.0044763978,0.008165059,-0.031372458,-0.013144923,-0.007473221,-0.17656255,-0.006507388,0.022755306,-0.043592647,0.018179586,0.021714125,0.012535283,0.0038667582,-0.03370142,0.015220437,0.008254107,-0.01387101,-0.020974338,0.004945615,0.004356525,-0.0029779861,-0.030057281,0.016097222,0.0043188506,0.02667344,0.026920035,-0.019522162,0.005209335,-0.00078431144,-0.016439715,-0.004527772,-0.0031886199,0.011761247,0.011932494,-0.02202922,0.01853578,-0.011795497,0.010548818,0.0074389717,-0.004945615,-0.010117276,0.0017569946,-0.020727742,-0.0052470095,0.01271338,0.025851455,0.010644716,-0.018028889,0.029235296,-0.0012261288,0.018837174,0.021097636,0.0026594666,0.009973428,-0.023358097,0.006315591,-0.011781797,-0.00052786904,-0.0018409058,0.017837092,0.020809941,0.016782211,-0.009767931,-0.013679214,-0.029317494,-0.01961806,-0.0065758866,0.019987956,-0.0032382817,-0.003418091,-0.00435995,-0.0030790218,0.027111832,-0.053182483,0.006949205,-0.02034415,0.003120121,0.005596353,-0.003126971,-0.005260709,0.021673026,-0.016535614,0.005216185,0.018864574,-0.012569533,-0.009473386,0.046716195,-0.0042537767,0.016782211,-0.014864244,0.017206904,0.004109929,0.036167376,-0.013795662,-0.010083026,0.010267973,-0.038331937,-0.0013802511,-0.012384586,0.026015852,0.02491987,0.010939261,-0.013960059,0.011165307,0.00067000405,-0.002693716,-0.0029711362,-0.028742103,0.017467199,0.02087844,0.003305068,0.0039660814,0.021768924,0.027933817,0.0017758318,-0.03657837,-0.010521418,-0.009582984,-0.012877777,-0.0023563593,0.02959149,0.0058840485,0.00017456495,-0.03134506,0.006068995,0.06756724,-0.017700095,0.0029659988,0.0010077888,-0.0024796573,-0.03068747,-0.123078674,-0.025152765,0.0042674765,-0.0024625324,0.009439137,0.0035653634,-0.009165142,-0.00983643,-0.025330862,0.017878192,-0.05038773,-0.028139314,-0.0008600883,-0.009329539,-0.015110839,-0.0027108407,0.0056374525,-0.004288026,-0.020618144,0.019700259,-0.034002814,-0.030797068,-0.015549231,0.0023649216,0.018234385,0.0055210046,-0.018864574,-0.00247452,-0.0044763978,-0.0013194585,0.027481725,-0.02202922,-0.019193368,-0.0030242228,-0.014001158,-0.011268055,0.005918298,-0.009500786,0.024248581,-0.036852363,0.014357352,-0.02087844,-0.011651649,-0.020097554,-0.01159685,0.0036098878,-0.0289613,0.029892884,0.0074458215,-0.00872675,-0.020426348,0.0040311553,-0.028659904,0.007980112,0.008795248,0.0070964773,0.0036338624,0.014836844,-0.008754149,0.01682331,-0.015384834,0.017165804,0.010041927,-0.004808617,0.032687634,-0.017837092,-0.020974338,-0.019481063,0.006298466,-0.032797232,-0.00752802,-0.0012792154,-0.009576134,0.020097554,-0.02250871,-0.010226874,0.0020446896,0.0040722545,-0.0072060754,-0.016590413,-0.006253942,-0.007582819,0.018152187,-0.020796241,0.003385554,0.0072129257,-0.009719982,-0.017617896,-0.017234303,-0.013206572,-0.017343901,0.04704499,0.018837174,-0.029920284,0.0032417066,0.006658085,0.00057239324,0.002959149,0.0006156331,0.009555585,-0.03301643,-0.009521335,-0.039756715,0.018823475,-0.016069822,-0.01852208,-0.010706365,-0.01974136,0.0051853606,-0.0058155498,0.0048188916,-0.011466702,-0.012987376,0.012274988,-0.031016264,0.0033684294,-0.021494929,3.0316078e-05,0.010466619,-0.014987541,0.016905509,-0.009487086,-0.0077335164,-0.016357517,-0.001143074,-0.013021626,-0.010898162,-0.004507222,-0.0076581677,0.024399279,-0.022755306,-0.01617942,0.0042674765,-0.0232348,0.0027964641,0.036633167,0.013144923,-0.009158292,0.007904763,0.017658995,0.037318155,-0.023111502,6.5823086e-05,-0.04123629,-0.00927474,-0.0131380735,0.017741194,0.004192128,-0.0038975826,-0.00809656,-0.0096240835,-0.0020378397,0.019535862,0.022810107,-0.010925561,-0.028139314,-0.016590413,-0.01564513,-0.0006015052,-0.019974256,-0.023015603,-0.017152105,0.03531799,-0.0075554196,0.022207316,-0.011124208,0.014288853,0.0068053575,-0.0027365277,0.016124621,-0.002580693,-0.02613915,-0.0027827644,0.0014564561,-0.003716061,-0.0016910646,-9.857408e-05,0.01620682,-0.020508546,0.0062881913,-0.0011045435,0.04115409,-0.0021851123,-0.011740698,-0.02833111,0.011898245,0.024481477,-0.0019573537,-0.014439551,0.0035687883,0.0043907743,-0.015864326,0.001911117,0.008569202,0.010329622,0.00035405325,0.0004961883,-0.0034557653,0.0065416372,-0.010500869,0.0005347189,0.015782127,0.0063395654,0.007973262,-0.009582984,-0.021494929,-0.041510284,0.017343901,-0.024481477,-0.050223332,0.013227122,0.0060552955,0.018686477,-0.018439882,0.02028935,0.008904846,-0.006140919,0.024015686,-0.016069822,-0.0348522,-0.036687966,0.022782708,0.004044855,-0.023125201,-0.013021626,0.008404805,0.024823971,0.02835851,0.0174398,-0.024988368,0.0232485,0.015727328,0.0015857476,0.0022296365,-0.0015780415,-0.018823475,-0.019330366,-0.017576797,0.009199391,0.0154259335,-0.0064834133,0.069814,0.013829911,0.006726584,-0.010500869,-0.002577268,0.02838591,0.022906005,-5.038409e-05,-0.020645544,-0.025892554,-0.0065861614,0.008158209,-0.029235296,-0.0154259335,-0.009774781,0.0002769921,-0.011870845,0.00115763,-0.023289599,-0.0043257005,0.024152683,-0.0004812042,0.010850213,0.008404805,0.0037366105,0.0035139893,0.002690291,-0.0026269297,0.020796241,-0.015850626,-0.002395746,0.014069657,-0.02835851,-0.027125532,0.0055895033,0.01391211,-0.0060484456,-0.01615202,-0.0050346632,0.0011550613,-0.0017407262,0.01561773,-0.016672611,-0.011268055,-0.027426926,0.016398616,0.01622052,-0.022810107,-0.0028666756]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0012692019,0.011907545,0.010879852,-0.0060976497,-0.017333768,0.02270518,0.0050939354,0.0006697138,-0.020567577,-0.03453051,0.023212178,-0.0057448084,-0.011119647,0.0069300816,-0.023472525,-0.012496756,0.028446564,0.007207559,0.007995457,-0.021608975,-0.00737199,0.016648639,0.0020177055,-0.039792303,-0.017073419,0.021567866,0.02852878,-0.015442812,0.014661765,0.0057687876,0.00048044685,0.0133394655,-0.023116259,-0.032749176,-0.0076597445,0.021499354,0.011003175,-0.014387713,0.0024253572,9.634629e-06,0.03250253,0.0046862834,-0.0078036212,-0.020636091,0.009906968,0.00731718,0.011914397,-0.02126641,-0.010098804,-0.004573237,0.02100606,0.028309537,-0.023321798,-0.009509593,-0.011900694,0.009475336,-0.005837301,0.009530147,0.012469351,-0.002178711,0.018128518,0.009776793,-0.013380573,0.010756528,-0.02937834,-0.0134901935,0.0042615035,0.009626065,-0.023362905,0.020279825,0.049384113,0.029186504,-0.0011347452,-0.01505914,0.009859009,-0.0120103145,-0.011852735,-0.015771674,0.0051590228,0.009146474,0.0013522737,-0.022472238,-0.027569598,0.039490845,0.009447931,-0.033900194,0.010407113,0.026637822,-0.018429976,0.009797348,-0.010955215,0.017429687,0.020444255,-0.0042375242,0.0052309614,0.001983449,0.013051711,0.023856198,0.00975624,0.0023105983,-0.0113457395,0.009680876,-0.04847974,-0.008728546,-0.015662054,0.0002614196,0.016895285,0.0005977752,0.011928099,-0.027405167,-0.048863415,0.043985292,0.0075706774,-0.030885624,0.01124297,-0.0048507145,-0.0017693461,-0.04343719,-0.007728257,-0.006217547,0.0066902866,0.030529356,0.028885046,-0.005484459,0.019841341,-0.0059846034,-0.033955004,-0.025925288,-0.02413025,-0.009180731,0.02789846,0.014168471,-0.02232151,0.0334069,-0.02307515,0.0049123764,-0.005734531,0.03305063,-0.04014857,-0.015237273,0.024705758,0.0013514173,0.0063717016,0.020814225,-0.003471892,0.020704605,0.0003873121,0.0302279,-0.005234387,-0.0106195025,-0.0015346893,-0.017991493,0.020910142,0.003936067,0.017333768,0.019375453,0.008509304,-0.0019132233,-0.014976924,-0.01575797,-0.00085341407,0.0049877404,0.0025109984,0.0143054975,0.015949808,0.018238138,0.016059428,-0.0013873866,-0.006162737,0.01172256,-0.010914108,0.02954277,-0.018758837,0.028830236,0.0035798,0.013229844,0.022020051,-0.02762441,-0.0049020993,-0.0006842728,-0.010516733,0.020649794,-0.0016631511,0.012270664,-0.009112218,-0.014141066,0.001063663,-0.029104289,-0.0003875262,-0.018525893,-0.010996323,0.0154839195,0.00806397,0.012750254,-0.6603549,-0.02885764,0.0008140191,-0.014483631,0.013661476,0.019224726,0.0061867167,-0.019855043,-0.02455503,0.020279825,-0.019923557,0.0031687224,0.016689748,-0.032529935,-0.016319778,-0.04209434,0.020005772,-0.020033177,-0.013798501,0.015278381,-0.018786242,0.01092781,-0.014949519,0.020827927,-0.0036620155,0.013298358,-0.0077556623,-0.008372279,0.03357133,0.02169119,-0.0027507937,0.02858359,-0.0159087,0.010523585,0.040121164,-0.016196454,-0.019430263,0.005505013,-0.012332326,0.04338238,-0.048561957,-0.013777948,0.014024595,0.0041073496,-0.00379219,0.006279209,0.008934084,-0.010413963,0.018662918,0.013202439,0.0017436538,0.026062313,0.0023568445,0.007324031,0.019005483,-0.010893554,0.014442523,-0.008105079,0.017004907,0.00079517806,0.0092903515,0.003685995,-0.011852735,-0.0024613265,0.008755951,0.034914184,0.014236985,0.026925577,-0.0053337305,-0.021129385,0.004460191,0.008886126,-0.0037305285,-0.010386558,-0.00079517806,-0.0030933584,0.0055015874,0.0075432723,0.016785664,0.010146763,-0.0044464883,-0.022787396,0.0051042126,0.011373145,-0.0069129537,0.006625199,-0.020060582,-0.009057408,0.0032286714,-0.012441946,0.019786531,0.03250253,-0.006984892,-0.030940434,-0.012209002,0.025637534,0.0009463347,0.015497622,0.0019183618,-0.014058851,-0.012517311,0.0130380085,-0.0053679873,0.007831027,0.018745134,-0.00039780315,-0.03159816,0.028336942,0.038586475,0.0031550198,-0.0019714592,0.018128518,-0.03203664,0.018991781,-0.004384827,-0.03170778,0.006703989,-0.003175574,-0.005833875,-0.013565558,0.027487382,-0.0027936143,0.019073997,-0.01468917,0.009167029,0.025486806,0.004093647,-0.01601832,0.0068444405,0.017251553,0.024623543,0.024048034,0.013962933,-0.008159889,0.022184484,0.012565269,-0.0035147127,0.009064259,0.0075227185,-0.010400261,-0.010612651,0.012743403,6.16081e-05,0.010146763,-0.016347183,0.0050768075,-0.0070568305,0.010592097,-0.0029255017,-0.010242681,0.008016012,-0.018210733,-0.010633205,-0.001292325,-0.015388002,0.0028946707,0.01309967,-0.029789416,-0.006693712,-0.034612726,0.012517311,0.042615034,-0.024527624,0.0059743263,-0.007831027,-0.0031104865,-0.012942091,0.024938703,-0.0017693461,-0.019553587,0.014771385,-0.029816821,-0.0039223647,0.02965239,-0.010057696,0.006806758,-0.00045561092,-0.019265832,-0.006405958,-0.015894998,-0.008680587,-0.01925213,0.015771674,0.008214699,0.015662054,0.011263524,0.02736406,0.008447642,-0.032639556,0.041135155,-0.005813321,0.0073103285,-0.010057696,0.010311195,0.0117979245,-0.0076254876,0.009776793,-0.003617482,0.0069061024,0.0035181383,0.0053679873,0.009345162,0.026418582,-0.025993802,-0.006296337,-0.00975624,0.008016012,-0.021060871,0.02185562,0.01230492,0.018388867,0.0003588364,-0.0081119295,-0.01511395,0.009262946,-0.0028724042,0.0002612055,0.0071253437,-0.009393121,0.0328862,-0.010592097,-0.0140040405,0.052891973,-0.0037784874,0.013613516,0.02497981,-0.009173879,0.012291217,0.022074861,-0.029186504,-0.0016785664,0.0033125996,0.0063066143,0.027117413,0.013421681,0.0031276147,-0.022828504,-0.004980889,0.012811916,-0.012496756,0.01394923,0.015675755,-0.004549258,-0.01166775,0.038038373,0.0048541403,0.032749176,0.01967691,0.0014507611,-0.01049618,-0.011914397,0.0013419968,-0.017347472,-0.0050082942,0.00800916,-0.002932353,0.012626931,-0.0032372354,0.018169627,0.021841919,0.017333768,0.022773694,0.018868458,-0.034174245,0.03225588,0.00586128,-0.009591809,-0.026103422,-0.021458246,-0.028967261,-0.022664074,0.004525278,0.016511614,-0.04225877,0.037188813,0.0053371564,0.019580992,0.012352879,0.037819132,0.014141066,-0.021814514,-0.018046303,0.0036106308,0.014401415,0.0048712683,0.00214788,-0.010907257,0.004922653,-0.008618925,-0.0014233559,0.0036928463,0.01951248,-0.003802467,-0.0028741169,-0.007700852,0.01420958,0.013887568,-0.005254941,-0.011763668,-0.012695444,-0.01288728,0.0069232304,-0.019060293,-0.030830814,0.037627295,0.0072829234,0.015675755,-0.01649791,-0.008892977,-0.026692633,0.0064470656,-0.018923268,-0.0025332652,-0.02180081,0.016210157,0.004014857,-0.028610995,0.016936393,0.028446564,-0.003000866,-0.0030128555,0.0010987759,-0.0021324647,0.0065053017,0.033379495,0.027144818,0.0034290715,0.010119358,-0.040422622,0.0033622715,0.003552395,-0.005950347,0.0026737167,0.018265544,-0.00047316734,0.011023728,-0.0027062602,-0.0042649293,0.0006748522,0.01437401,0.026336366,-0.0233355,-0.008666884,-0.014990627,0.0032920458,-0.0111333495,0.019265832,0.025322374,0.013181886,0.002206116,0.008447642,0.0070842355,0.002099921,-0.017703738,0.004573237,0.014675467,0.018361462,0.019813936,0.007844729,0.021513056,-0.014963222,-0.012866726,0.013798501,0.007392544,0.01203772,-0.0023260135,0.011640345,-0.007070533,-0.007228113,-0.013545004,0.018923268,-0.010043994,0.009406824,-0.00043462883,-0.0045835143,-0.011743114,-0.04105294,-0.008618925,0.0053748386,0.011633494,-0.009077962,-0.00041578777,0.009084813,-0.021197896,-0.025555318,-0.008557264,0.012668039,-0.011654047,0.014182175,-0.0019080847,-0.0034479126,-0.0030882198,-0.00028047475,-0.0010670887,0.0023756854,-0.048671577,-0.038750906,-0.011571832,0.021225302,0.030255305,0.008557264,0.0015458227,-0.027090007,0.0013908122,-0.02137603,-0.009447931,-0.003309174,-0.014442523,0.0076665957,0.014812493,-0.0025521063,-0.0035249896,-0.0029734606,0.013654625,-0.010790785,0.033708356,0.0077077034,-0.021513056,-0.00063160347,0.009235541,9.152898e-05,0.021115681,0.0054433513,-0.02233521,0.027514787,-0.023582147,-0.014223282,-0.007043128,-0.012558418,-0.006974615,0.010722272,0.0074953134,0.0044773193,-0.008481899,0.0114074005,-0.014593252,0.008831315,-0.017799657,0.00048215967,0.0008050268,0.021499354,0.016223859,-0.00795435,0.025856776,0.016895285,-0.04140921,0.016717153,0.010091953,-0.0159087,0.008673736,-0.021060871,0.011332037,-0.024418004,0.01633348,-4.1241565e-05,0.025089432,-0.0076665957,-0.0056454646,-0.027939567,-0.00524809,-0.027651815,-0.014716575,-0.010612651,-0.01108539,0.011948653,-0.003552395,-0.017511902,-0.007111641,0.008098227,-0.022636669,-0.010112506,0.014442523,-0.007262369,0.04014857,-0.0011801351,-0.0027439424,-0.014839898,-0.02773403,-0.0021975518,-0.028939856,-0.0025315525,0.0021838492,0.021129385,0.015305786,0.03151594,0.017566713,0.03162556,-0.0056454646,-0.019827638,-0.006539558,0.012469351,-0.004401955,-0.009406824,0.016456803,0.00011111939,-0.0297072,0.007728257,0.0048883967,0.0058510033,0.011249822,-0.026240448,-0.017457092,-0.017415984,-0.022102268,0.0006731394,0.022787396,-0.021197896,-0.0062620807,-0.030474545,0.015771674,-0.0031841379,-0.0039634723,0.021184195,0.0024904446,0.012928388,-0.0049123764,0.02243113,-0.00041450316,-0.0017059717,-0.010811338,-0.030995244,-0.010509882,0.0021050593,0.036613304,-0.01956729,0.015785376,0.016169049,0.0010054271,-0.012558418,-0.023952117,0.0089272335,-0.017621523,0.0022677777,-0.0063305935,-0.009605511,-0.025747154,-0.012051422,-0.013867015,0.0012974634,0.0066800094,-0.018251842,0.002903235,0.0066834353,-0.021362329,0.024390599,-0.0097151315,0.02619934,0.016086834,0.025870478,0.0028843938,0.0016391716,0.00816674,-0.0120103145,-0.00594007,0.010372856,0.011373145,-0.012640634,0.015826484,-0.03379057,0.00859152,-0.0007377985,-0.013428532,-0.0077556623,0.009783645,0.013270953,-0.009495891,-0.0075158672,-0.025870478,-0.011544427,0.0007300908,-0.008749099,-0.015004329,0.010146763,-0.0076391906,0.0015115662,0.0093520135,0.015730565,0.028172512,0.006279209,0.00061704445,0.020964952,-0.0016571563,0.00959866,0.01993726,0.0016220433,0.008570966,0.024774272,0.0084133865,-0.004672581,-0.0022677777,0.008660033,-0.0025949269,-0.0012477916,0.028967261,-0.011064837,0.00038303004,0.00080802426,0.010838743,0.0019868747,-0.0057242545,-0.014099958,0.0029426299,-0.0078036212,0.008653182,0.009304054,0.0075912313,-0.03039233,-0.008207847,0.0022181058,-0.004528704,0.0055975053,-0.0022095416,0.0052069817,-0.032283287,-0.014976924,-0.0018327206,0.014565847,0.026459688,-0.013675178,0.0074679083,0.02418506,0.0031995533,-0.017854467,-0.007981755,0.02115679,-0.00721441,-0.02185562,0.022047456,-0.00721441,-0.027501086,0.029131694,-0.00094376545,-0.029515365,-0.023773983,0.0041347547,-0.019594695,-0.0007091087,-0.04050484,-0.01516876,0.0048301606,0.012681741,0.010311195,0.009338311,-0.0012323761,0.015237273,-0.00050913665,0.004364273,0.0074405028,-0.008783356,-0.013743691,0.01389442,-0.0025983525,-0.03759989,-0.012366582,0.001974885,0.0015980639,0.010996323,-0.013538153,-0.0143192,0.0058578546,-0.009721983,0.033434305,0.007844729,-0.016525315,-0.01925213,-0.0063340194,0.005165874,0.026761146,-0.028939856,-0.008831315,-0.0023654085,-0.0053371564,-0.033215065,-0.0419025,-0.019759126,0.036996976,0.019539885,-0.010002886,0.00059820345,-0.016251264,-0.020115392,-0.01225011,0.010571543,-0.0070842355,-0.0076391906,0.0046588783,-0.006597794,0.018320354,0.0025315525,-0.018347759,0.002264352,0.0105304355,-0.012572121,-0.022938125,0.016648639,0.037024383,-0.02222559,-0.014524738,0.004439637,-0.013305209,0.022307806,0.0012306633,-0.0028467118,-0.015470217,0.014579549,0.019608397,0.026295258,0.02381509,0.018402569,-0.013860163,0.0037168257,0.0146069545,-0.017306363,-0.026295258,-0.014278092,0.009783645,-0.007748811,0.004066242,-0.011791074,-0.017511902,-0.008577817,-0.0016434536,0.021718595,-0.0012666326,-0.00043056087,0.027144818,0.0031498815,-0.021677487,-0.001829295,0.026596716,-0.02497981,-0.018841052,0.023746578,-0.039792303,0.0051693,-0.0023243008,-0.019498777,-0.020183906,-0.0021735723,-0.004199842,-0.0062655066,-0.0051555973,0.009584958,0.007604934,-0.017320067,0.020293526,-0.004408806,-0.014113661,-0.016347183,0.0028330092,0.026925577,0.004521853,-0.013291506,-0.0015843612,-0.018717729,-0.019964665,0.026651526,0.025623832,0.01474398,0.032639556,0.24642727,-0.017484497,-0.013202439,0.011236119,0.015250975,0.0059811776,1.1173494e-06,0.03203664,-0.021019764,-0.012942091,0.016717153,0.006296337,0.0046760067,0.00206909,0.0014096533,-0.010009738,-0.02099236,-0.008557264,0.0015903561,0.013044859,0.013579261,0.0029357786,0.00045818015,-0.020293526,0.045382958,0.011181308,0.0027062602,0.019279536,-0.014291795,-0.01071542,0.006638902,0.0026154807,0.0080228625,0.02052647,-0.016511614,-0.008050268,-0.0059948806,-0.016730854,0.025829371,0.014702872,0.02100606,-0.009605511,-0.011544427,-0.01081819,0.009262946,0.0032389483,-0.01135259,-0.012572121,0.0100165885,0.0071664513,-0.023212178,-0.016155345,0.017100824,0.028994666,-0.0015560996,-0.010749677,0.0018241565,-0.0040114312,0.03458532,0.014113661,-0.035654124,0.010859298,-0.029213909,0.018498488,-0.005234387,-0.00075064466,-0.0029494811,-0.010366005,0.026528202,-0.026185637,-0.014442523,0.00790639,-0.0020177055,-0.0010996324,-0.025733452,-0.005700275,0.033489116,0.0196221,0.020060582,0.02322588,-0.015949808,0.00011111939,-0.0020827928,-0.010640056,-0.016169049,-0.009886414,0.023952117,-0.016032023,0.008118781,0.0066902866,2.265476e-05,0.00059092394,-0.013072265,-0.007673447,0.001296607,0.004422509,0.004898674,0.025130538,-0.010153615,0.0005883547,-0.03107746,0.05609838,0.010297491,0.0030693787,0.015415407,0.016141644,0.024390599,0.015100247,0.00843394,-0.015922403,-0.00278505,-0.050617345,6.908163e-07,-0.00737199,-0.007447354,0.005840726,0.0015852177,-0.003483882,0.03362614,-0.010681164,-0.005970901,-0.014935817,-0.002303747,0.009728834,0.0117979245,-0.021362329,-0.02025242,-0.0015261252,-0.015388002,0.007139046,-0.0011664324,0.017457092,0.0022557878,0.027747732,-0.009913819,-0.019855043,-0.017991493,-0.04099813,0.0035078614,0.0092012845,-0.0006483035,0.017306363,0.016648639,-0.016264968,0.0019012335,-0.01156498,0.012113084,0.009721983,-0.01575797,-0.015360597,-0.005080233,-0.0038470004,-0.01581278,-0.025226457,0.020540172,-0.012435094,-0.0126748895,-0.016991204,0.010352302,-0.00806397,-0.011599237,0.0045355554,0.008228402,-0.0312967,-0.013161331,-0.007447354,-0.17659889,-0.0064984504,0.0228011,-0.043629028,0.018197032,0.021773405,0.012558418,0.0038367235,-0.03368095,0.015250975,0.008351725,-0.013908123,-0.021033466,0.004946633,0.0043505705,-0.0029443426,-0.03011828,0.016100535,0.00429576,0.026747443,0.026911875,-0.019457668,0.005272069,-0.00078147545,-0.016470505,-0.004576663,-0.003175574,0.011743114,0.01193495,-0.021978945,0.018594407,-0.011832181,0.010564692,0.007419949,-0.0049363556,-0.010153615,0.0017505051,-0.020773116,-0.0052652177,0.012709146,0.025925288,0.010653758,-0.018018898,0.029296124,-0.0011912683,0.018813647,0.021143086,0.0026274705,0.0099549275,-0.023362905,0.0063374448,-0.011893842,-0.00051213405,-0.0018755412,0.017799657,0.02084163,0.01675826,-0.0098041985,-0.013695733,-0.029350935,-0.0196221,-0.006532707,0.020019475,-0.0032389483,-0.003405092,-0.0043951035,-0.0030436865,0.02710371,-0.053166024,0.0069883177,-0.020403147,0.0031515942,0.0055838027,-0.0030899327,-0.005251515,0.02163638,-0.016484208,0.005244664,0.018841052,-0.012537864,-0.009530147,0.046698406,-0.0042683547,0.016799368,-0.014839898,0.01718304,0.0041039237,0.036202226,-0.013777948,-0.010043994,0.010222128,-0.038367234,-0.001340284,-0.012421392,0.025980098,0.024870189,0.010955215,-0.01399719,0.011153903,0.00068470096,-0.0026771424,-0.0029957274,-0.02874802,0.017429687,0.020882737,0.0033040354,0.003966898,0.021787109,0.027925866,0.0017864744,-0.036585897,-0.010585246,-0.009591809,-0.012894131,-0.0024116547,0.029570175,0.0058749826,0.00014473354,-0.031433728,0.0061182035,0.06758114,-0.017717442,0.0030299837,0.00092920644,-0.002449337,-0.030693788,-0.123323254,-0.025212754,0.0042991857,-0.0024716035,0.009495891,0.0035558206,-0.009160177,-0.009886414,-0.025418293,0.017909277,-0.050398104,-0.028172512,-0.00089495,-0.009345162,-0.01516876,-0.0026874193,0.005659167,-0.0042991857,-0.020594982,0.019718017,-0.034009814,-0.030748598,-0.015566135,0.002466465,0.018265544,0.005467331,-0.01882735,-0.0025195626,-0.004518427,-0.0013222994,0.02747368,-0.022020051,-0.019183617,-0.0030419736,-0.013983486,-0.011318334,0.0059263674,-0.009475336,0.024280978,-0.036832545,0.014387713,-0.020855332,-0.011619791,-0.02010169,-0.011606089,0.0035935026,-0.028967261,0.029926443,0.0074542053,-0.008721694,-0.020444255,0.004042262,-0.0286384,0.00806397,0.008831315,0.007111641,0.0035832257,0.014826195,-0.008735397,0.016785664,-0.015388002,0.01718304,0.009975481,-0.004816458,0.032749176,-0.017854467,-0.020964952,-0.019471372,0.0063100397,-0.032858796,-0.0075227185,-0.0013017454,-0.009557552,0.020060582,-0.022472238,-0.010249533,0.0020279824,0.0040867957,-0.0072007077,-0.016634937,-0.006268932,-0.007604934,0.018210733,-0.02078682,0.003482169,0.007234964,-0.009728834,-0.017594118,-0.01718304,-0.013195588,-0.01729266,0.04705467,0.018799946,-0.029981254,0.0032098303,0.006625199,0.0005438213,0.0029494811,0.00065515476,0.009578106,-0.033023227,-0.009543849,-0.0397649,0.01882735,-0.016114239,-0.018525893,-0.010735975,-0.019718017,0.0052104075,-0.005844152,0.004819884,-0.0114348065,-0.012996901,0.012332326,-0.030995244,0.0033331534,-0.021540461,1.24714925e-05,0.010468774,-0.014990627,0.01692269,-0.009495891,-0.007721406,-0.016347183,-0.00107394,-0.013079116,-0.010845595,-0.004460191,-0.007652893,0.024390599,-0.0228011,-0.016210157,0.0042649293,-0.023253284,0.0027919014,0.036613304,0.0131270755,-0.009125921,0.007892688,0.017648928,0.037325837,-0.02307515,7.049337e-05,-0.04124478,-0.009276649,-0.013154481,0.017744847,0.0042032674,-0.003929216,-0.008050268,-0.0096534705,-0.0020759415,0.019526182,0.022842208,-0.010907257,-0.028199917,-0.01655272,-0.015662054,-0.0005742239,-0.019978367,-0.023047745,-0.017169338,0.03532526,-0.0075706774,0.022211889,-0.011147052,0.0143192,0.00681361,-0.0027422295,0.016155345,-0.0026360345,-0.026117124,-0.0028724042,0.0014216431,-0.0037339542,-0.0017093973,-0.00015286946,0.016196454,-0.020457957,0.006299763,-0.0011210426,0.04121737,-0.002245511,-0.011743114,-0.02836435,0.011928099,0.024459112,-0.0019509053,-0.014415118,0.003648313,0.004391678,-0.01585389,0.001962895,0.008612074,0.010366005,0.00034748897,0.000507852,-0.0034324971,0.006539558,-0.0105304355,0.000551529,0.015744269,0.006354573,0.007968052,-0.009550701,-0.02152676,-0.04151883,0.017347472,-0.02450022,-0.050178863,0.013216142,0.0061490345,0.018758837,-0.018402569,0.020279825,0.008906679,-0.0062072705,0.023993224,-0.016045725,-0.034859374,-0.036668114,0.02274629,0.0040491135,-0.023157366,-0.013024306,0.008392832,0.024787974,0.02841916,0.017388579,-0.025007214,0.02328069,0.015744269,0.0015466792,0.0022369467,-0.001587787,-0.01882735,-0.019334346,-0.017566713,0.009153326,0.015388002,-0.006453917,0.06982837,0.013832758,0.0067485226,-0.01050303,-0.0025606703,0.028391754,0.022828504,-4.1964162e-05,-0.020649794,-0.025925288,-0.0065840916,0.008200997,-0.029296124,-0.015470217,-0.009735686,0.0002693414,-0.011893842,0.0011390273,-0.023266988,-0.0043163137,0.02418506,-0.00047359554,0.010859298,0.008420237,0.0037065488,0.0034890203,0.0026771424,-0.00265145,0.020827927,-0.015881294,-0.0024510496,0.014045148,-0.02836435,-0.027172223,0.0056043565,0.013956081,-0.0060633933,-0.016169049,-0.0050185714,0.0011869863,-0.0017642076,0.01559354,-0.016648639,-0.011229267,-0.027446276,0.01638829,0.016292373,-0.022773694,-0.0029083735]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
0.7460664427733196
0.7462382711361816
0.7562957520201781
0.7333181684701596
0.70427419065181
0.7291395693181544
0.7224415325745757
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0012538448,0.011928654,0.010873507,-0.006073953,-0.017279763,0.022678832,0.0051181535,0.0006277789,-0.02054113,-0.03453212,0.023254367,-0.005775908,-0.011120165,0.0069064237,-0.023514729,-0.012517893,0.028475296,0.007235301,0.008030088,-0.021664795,-0.0073517784,0.016663117,0.002062335,-0.03976675,-0.017087918,0.021596277,0.028530108,-0.015429827,0.014689853,0.005772482,0.00046077083,0.013360641,-0.023089929,-0.0327507,-0.0076875077,0.021527762,0.010989984,-0.014443195,0.002392925,2.9547573e-05,0.03250404,0.0047002053,-0.0077902814,-0.020623349,0.009907429,0.0073449267,0.011962913,-0.021239994,-0.010119829,-0.004597431,0.020897413,0.028256044,-0.02330918,-0.009516887,-0.011887545,0.009503184,-0.005840998,0.009544294,0.01242197,-0.0021959413,0.018211583,0.009736139,-0.013333235,0.010770733,-0.029379707,-0.013511376,0.004261702,0.009626513,-0.02330918,0.020225955,0.049359005,0.029160457,-0.001163061,-0.015046137,0.009873171,-0.011983467,-0.011887545,-0.015772408,0.0050838953,0.00905783,0.001417427,-0.022486987,-0.027570883,0.03943787,0.009468926,-0.033819553,0.0104213,0.026639063,-0.018430833,0.009832062,-0.010955726,0.017457904,0.020472614,-0.0042171665,0.0052003725,0.001969838,0.013038616,0.023912122,0.009742991,0.002305567,-0.011359971,0.009681326,-0.048481997,-0.008687843,-0.015635377,0.00026635636,0.016854962,0.0006320611,0.011997171,-0.027379038,-0.04886569,0.04398734,0.007550475,-0.030941876,0.011229791,-0.0048680697,-0.0017625769,-0.043439213,-0.0077217654,-0.006255521,0.0067282817,0.030530779,0.028968612,-0.0054881405,0.019801155,-0.00595405,-0.03398399,-0.025967605,-0.024090264,-0.009181159,0.02785865,0.014114318,-0.022322549,0.033408456,-0.023076225,0.004898902,-0.005673134,0.033052173,-0.040123034,-0.015237982,0.024720613,0.001356619,0.0063000564,0.0208426,-0.0034532119,0.020705568,0.0004286539,0.03028412,-0.0053065727,-0.010606294,-0.0015022157,-0.01799233,0.02096593,0.003946528,0.017389389,0.019376356,0.008489146,-0.0019218769,-0.014963918,-0.015827222,-0.00084788684,0.0050119534,0.0025145411,0.014278757,0.01595055,0.018266395,0.016087582,-0.0013668963,-0.006142469,0.011688848,-0.01092832,0.029571552,-0.018746007,0.02874936,0.0035251537,0.013196203,0.022021078,-0.027653102,-0.004864644,-0.00067145785,-0.010524075,0.020637052,-0.001654664,0.0122232735,-0.00909894,-0.014128022,0.0010842674,-0.02913305,-0.00037940795,-0.018444536,-0.010948874,0.015470938,0.008050643,0.012764551,-0.66038567,-0.02888639,0.00081448525,-0.014456899,0.013696371,0.019198215,0.006159598,-0.019855969,-0.024515064,0.02029447,-0.01991078,0.0031191958,0.016731635,-0.03258626,-0.016334241,-0.0420963,0.019924484,-0.020006703,-0.013799144,0.015306499,-0.018800821,0.010907765,-0.014950215,0.020815194,-0.0036724634,0.013285274,-0.0077765784,-0.00837952,0.033545487,0.0216922,-0.0027783283,0.028612327,-0.015936848,0.010489816,0.04015044,-0.016224615,-0.019444872,0.0055018435,-0.01229179,0.043356992,-0.04853681,-0.01377859,0.014025248,0.00412467,-0.0037649602,0.0063103335,0.008907095,-0.010387043,0.018663788,0.013223609,0.0017034818,0.026036121,0.0023843606,0.007365482,0.019033775,-0.010907765,0.014498008,-0.008105456,0.016964588,0.0007823683,0.009283933,0.003682741,-0.0118669905,-0.0024768573,0.0087221,0.034943216,0.014223944,0.026885722,-0.0053271274,-0.021116665,0.0044432697,0.008941352,-0.003747831,-0.010339081,-0.0008508844,-0.0031072055,0.005525824,0.007557327,0.016827557,0.010174642,-0.004422715,-0.022774754,0.0051352824,0.011359971,-0.0069304043,0.006618656,-0.020102626,-0.009071533,0.0032134056,-0.012463081,0.019828562,0.032531448,-0.006992069,-0.030941876,-0.012243829,0.025638727,0.0009301062,0.01548464,0.0019766898,-0.014114318,-0.012517893,0.013038616,-0.00535796,0.007845094,0.018746007,-0.00043636197,-0.03159963,0.028338263,0.038615678,0.0031294732,-0.0019869672,0.018129362,-0.03206554,0.019006368,-0.0043267924,-0.031709254,0.006711153,-0.0031277605,-0.0057519274,-0.013600447,0.027488664,-0.0027868927,0.019047478,-0.014648744,0.009146901,0.02547429,0.004066431,-0.01595055,0.0068379077,0.01726606,0.024652096,0.02407656,0.013963583,-0.008146565,0.022171812,0.012565854,-0.0034857572,0.009078384,0.0076326947,-0.010441855,-0.01059259,0.012702887,3.463275e-05,0.010106126,-0.016320538,0.0050838953,-0.0070914174,0.010606294,-0.0029273508,-0.010256861,0.008002682,-0.018211583,-0.010640551,-0.0012803947,-0.015416125,0.0028057348,0.013113983,-0.029763399,-0.006673469,-0.034586933,0.012559003,0.04261702,-0.024515064,0.0060020112,-0.007879352,-0.0031174829,-0.012976951,0.024939863,-0.0018242414,-0.019540794,0.014785776,-0.02981821,-0.003932825,0.029708585,-0.010023907,0.0068379077,-0.0004237293,-0.019239323,-0.006395979,-0.01590944,-0.0087221,-0.01926673,0.015772408,0.008242488,0.015717596,0.0112709,0.027392741,0.008434333,-0.032668483,0.041137073,-0.005844424,0.0072969655,-0.01007872,0.010277417,0.011832732,-0.007660101,0.009756694,-0.0036656118,0.00686874,0.003502886,0.0053785145,0.009338746,0.02640611,-0.025967605,-0.0062623722,-0.009804655,0.008043791,-0.021034446,0.02181553,0.0123328995,0.018403428,0.00036805996,-0.008112308,-0.015114654,0.009249675,-0.0028999443,0.00026614225,0.0071393787,-0.009366152,0.03288773,-0.010626849,-0.013929325,0.052921843,-0.0037820893,0.013614151,0.024953566,-0.009174307,0.012264384,0.022034781,-0.029215269,-0.0016623721,0.0033196055,0.006320611,0.027132379,0.013429157,0.0031157702,-0.022870677,-0.004929734,0.0127577,-0.0124973385,0.013929325,0.015690189,-0.0045803017,-0.011709403,0.03806755,0.0048509403,0.0327507,0.019664124,0.001489369,-0.010469262,-0.011921803,0.0013694657,-0.017375685,-0.005001676,0.00799583,-0.002975312,0.012627519,-0.0032442377,0.018170472,0.021829233,0.017348278,0.022774754,0.018855633,-0.03414843,0.03228479,0.005899237,-0.009585404,-0.026104638,-0.021418136,-0.029023424,-0.022678832,0.004563173,0.016471272,-0.042260736,0.037108324,0.0053202757,0.019540794,0.012374009,0.03790311,0.014155428,-0.021788122,-0.018047143,0.0036039473,0.014456899,0.004847515,0.0021411285,-0.010914616,0.0049400115,-0.00859192,-0.001443977,0.0036895925,0.019540794,-0.0038334762,-0.0029119346,-0.0077080624,0.014223944,0.013922473,-0.005289444,-0.011764216,-0.012737145,-0.012935841,0.006988643,-0.019061182,-0.03083225,0.037656453,0.0072627077,0.015717596,-0.01649868,-0.00884543,-0.026680173,0.006426811,-0.018951556,-0.0025128282,-0.021829233,0.016210912,0.0040390245,-0.02866714,0.016909776,0.028447889,-0.0030010056,-0.0029496185,0.00110054,-0.002130851,0.006498753,0.03351808,0.027159786,0.0034412215,0.010133533,-0.04045191,0.003382983,0.0035628376,-0.0059609013,0.0026378701,0.018266395,-0.0004286539,0.011003687,-0.0026824058,-0.0042719794,0.0007057159,0.014360976,0.02628278,-0.023336587,-0.008708398,-0.015005028,0.0032630798,-0.011161274,0.019253027,0.02535096,0.013189351,0.0022062187,0.008406927,0.007111972,0.002115435,-0.01769086,0.004559747,0.014662447,0.01837602,0.019814858,0.0077765784,0.021541465,-0.014936511,-0.012860473,0.013812847,0.0073380754,0.012051984,-0.002326122,0.0116477385,-0.0070914174,-0.0072627077,-0.013497674,0.01888304,-0.010017055,0.009462074,-0.0004335785,-0.00461456,-0.0118121775,-0.041109666,-0.008687843,0.005371663,0.01165459,-0.009092088,-0.00039932044,0.009085236,-0.021130368,-0.025556508,-0.008585068,0.012661777,-0.011675145,0.014223944,-0.0018910447,-0.003432657,-0.0030832249,-0.00030168498,-0.0010697078,0.002392925,-0.048673842,-0.038752712,-0.011517558,0.02122629,0.03028412,0.008585068,0.0015364737,-0.027063863,0.0013523367,-0.021363324,-0.009489481,-0.0032887734,-0.014456899,0.007680656,0.01475837,-0.0025607895,-0.0034634892,-0.0029735991,0.013634706,-0.010777584,0.033709925,0.0077217654,-0.021514058,-0.00065775466,0.009208565,0.00011615622,0.021171479,0.0054127728,-0.022363657,0.027570883,-0.023624355,-0.014182835,-0.007009198,-0.012552151,-0.0069989203,0.010770733,0.007488811,0.004432992,-0.008441185,0.011421636,-0.014580228,0.008824875,-0.01782789,0.00049117487,0.0007853659,0.021514058,0.016156098,-0.007934165,0.025844276,0.016841259,-0.041438542,0.016745336,0.010071868,-0.015895737,0.008735804,-0.021034446,0.011346268,-0.024446547,0.016361646,-7.483244e-05,0.0250906,-0.00761214,-0.0056251725,-0.027927166,-0.005303147,-0.027625695,-0.01475837,-0.01059259,-0.011037945,0.011921803,-0.0035491344,-0.017512718,-0.007077714,0.008057495,-0.022651426,-0.010133533,0.014470602,-0.0072832624,0.04023266,-0.0011733384,-0.0027166638,-0.014826886,-0.027790135,-0.00220108,-0.028913798,-0.002589909,0.0021702477,0.021130368,0.015279092,0.0314626,0.017622344,0.03159963,-0.005584063,-0.019842265,-0.006529585,0.012449377,-0.0043918826,-0.009468926,0.016443865,0.00010421943,-0.029735992,0.007735469,0.0048920503,0.0058375723,0.011216087,-0.026186857,-0.017485311,-0.017375685,-0.022089593,0.00062264013,0.02276105,-0.021239994,-0.0063103335,-0.030558184,0.015799815,-0.0031568797,-0.0039705085,0.021171479,0.0025333832,0.012942693,-0.0049023274,0.022445878,-0.00045049342,-0.001688922,-0.01080499,-0.031024095,-0.010482965,0.00214798,0.03661501,-0.019554498,0.015827222,0.016087582,0.00099434,-0.012531596,-0.02393953,0.008913945,-0.01764975,0.002252467,-0.0063308887,-0.009578552,-0.02573465,-0.012093093,-0.013915622,0.0012786819,0.006690598,-0.018252691,0.0028999443,0.0067385593,-0.021363324,0.024350625,-0.009681326,0.02624167,0.016046472,0.02589909,0.0028811025,0.0016092721,0.008167121,-0.0119766155,-0.0058889594,0.010359636,0.011366823,-0.012641222,0.015786111,-0.033792146,0.008585068,-0.0007605288,-0.013401751,-0.007797133,0.009784101,0.013244164,-0.009551146,-0.0075436234,-0.02585798,-0.011538113,0.0006902998,-0.008770062,-0.015005028,0.010140385,-0.007680656,0.0014859431,0.009345598,0.015745003,0.028173825,0.0063103335,0.000593949,0.021061853,-0.0016512382,0.009592256,0.019938188,0.0016503818,0.008557662,0.024720613,0.008454888,-0.004648818,-0.002274735,0.008646733,-0.0025813445,-0.0012547013,0.028968612,-0.011085906,0.00040638619,0.0007695216,0.010798139,0.0020503446,-0.0057142433,-0.014100615,0.0029701733,-0.007803985,0.008667287,0.009311339,0.007605288,-0.03044856,-0.008215082,0.002219922,-0.0045117857,0.0056080436,-0.0021976542,0.0052003725,-0.032312196,-0.014963918,-0.0018208156,0.014593931,0.026474625,-0.013668964,0.0074614044,0.024117671,0.003223683,-0.017869001,-0.007934165,0.021157775,-0.0071941917,-0.021870341,0.02199367,-0.007201043,-0.027488664,0.029160457,-0.0009686465,-0.029544147,-0.02377509,0.004117818,-0.019581905,-0.000686874,-0.04045191,-0.015155763,0.0048132567,0.0127165895,0.010311674,0.009331894,-0.0012478497,0.015292795,-0.0004868926,0.0043267924,0.0074751074,-0.008770062,-0.013758034,0.013922473,-0.002571067,-0.037629046,-0.012360306,0.0019681253,0.0015835785,0.010948874,-0.013497674,-0.014319867,0.005830721,-0.009708732,0.03346327,0.007831391,-0.016539788,-0.019280434,-0.0062966305,0.0051352824,0.0267898,-0.028968612,-0.008865984,-0.0023483897,-0.0053202757,-0.03321661,-0.041877046,-0.019746343,0.037026104,0.01952709,-0.010044462,0.0006149321,-0.016224615,-0.02011633,-0.012189016,0.010572036,-0.0070708627,-0.007618991,0.004683076,-0.0065981015,0.018362317,0.0025419476,-0.018362317,0.0022644575,0.010503519,-0.012572706,-0.02292549,0.016649414,0.0369987,-0.022212923,-0.014484306,0.004415863,-0.013305828,0.022254033,0.0012547013,-0.0028742508,-0.015429827,0.014621338,0.019636717,0.02628278,0.02377509,0.018403428,-0.013833403,0.0036416312,0.014635041,-0.017279763,-0.026269076,-0.014278757,0.00969503,-0.007749172,0.004049302,-0.0117573645,-0.017485311,-0.008543959,-0.0015964253,0.021705903,-0.0012341464,-0.0004247999,0.027214598,0.0031551667,-0.021678496,-0.0018019737,0.026652766,-0.024994677,-0.018814523,0.023720277,-0.03982156,0.0051935213,-0.0023535283,-0.019444872,-0.020239659,-0.002180525,-0.004237721,-0.0062452434,-0.0051900954,0.009626513,0.0075778817,-0.017279763,0.020321878,-0.004419289,-0.014086912,-0.016361646,0.0028125863,0.026913127,0.004474102,-0.013333235,-0.0015870044,-0.018704899,-0.019951891,0.02666647,0.025597619,0.014744666,0.032641076,0.24621949,-0.017485311,-0.013182499,0.011257197,0.01522428,0.005964327,-2.3753144e-07,0.03206554,-0.020979632,-0.012970099,0.016704228,0.0063685724,0.004628263,0.0020469187,0.0014336996,-0.009962242,-0.02096593,-0.008612475,0.0015518898,0.01305917,0.013573041,0.0029136476,0.00045134986,-0.02028077,0.045330256,0.011140719,0.0026841187,0.019280434,-0.014265054,-0.010736475,0.006622082,0.0026549993,0.008050643,0.020472614,-0.016471272,-0.008064346,-0.0060568242,-0.016717931,0.025844276,0.014730964,0.021020742,-0.009681326,-0.011517558,-0.010832397,0.009270229,0.0031979894,-0.011421636,-0.012586409,0.010010203,0.0070982687,-0.023185851,-0.016156098,0.01714273,0.028968612,-0.0015287657,-0.010750177,0.001796835,-0.003997915,0.03461434,0.014141725,-0.03565578,0.010894061,-0.029160457,0.018485647,-0.005244908,-0.0007421151,-0.002942767,-0.010380191,0.026529437,-0.026173154,-0.014456899,0.007893056,-0.002058909,-0.0010996836,-0.025720946,-0.005710818,0.03346327,0.019636717,0.020061517,0.023213258,-0.015936848,0.000112837464,-0.0021034447,-0.0106337005,-0.016142394,-0.00982521,0.024021748,-0.01603277,0.008139714,0.00669745,1.4920988e-05,0.000536995,-0.013079725,-0.0076669524,0.0012898158,0.0044432697,0.004861218,0.025186522,-0.010195197,0.00062435307,-0.0310515,0.056073584,0.010318526,0.0030558184,0.015388718,0.016156098,0.024350625,0.01510095,0.008454888,-0.015923144,-0.0027937444,-0.050674513,-4.5070752e-05,-0.0073449267,-0.0074202945,0.00584785,0.0015784398,-0.0035285796,0.033682518,-0.010681662,-0.0060465466,-0.014895402,-0.0022970026,0.009736139,0.011771068,-0.02134962,-0.020267066,-0.0015339043,-0.015388718,0.0071736365,-0.0011853287,0.017471608,0.0022473284,0.02773532,-0.00995539,-0.019869672,-0.01795122,-0.04100004,0.0035320055,0.009174307,-0.00069115625,0.017279763,0.016608305,-0.016265724,0.0019167381,-0.01152441,0.012106797,0.009770397,-0.015758704,-0.015347608,-0.0050736177,-0.0038574568,-0.015786111,-0.025118006,0.02054113,-0.012463081,-0.012620667,-0.016978292,0.010339081,-0.008064346,-0.011572371,0.004539192,0.008187675,-0.031380378,-0.01314139,-0.0074614044,-0.17660712,-0.006498753,0.022774754,-0.04363106,0.018156769,0.021747014,0.012552151,0.0038506053,-0.033682518,0.015210576,0.008304153,-0.01390877,-0.021007039,0.0049537146,0.004364476,-0.0029359153,-0.030064868,0.016101286,0.0042685536,0.026721282,0.02692683,-0.019485982,0.005224353,-0.0007558183,-0.016457569,-0.0045152116,-0.0031534538,0.011771068,0.0119492095,-0.022007374,0.01858157,-0.0118395835,0.01059259,0.0074202945,-0.0049605663,-0.010126681,0.001777993,-0.020774085,-0.005286018,0.01267548,0.02589909,0.010661107,-0.018006034,0.029324895,-0.0012195867,0.018814523,0.021130368,0.002622454,0.009982797,-0.023363993,0.0062795016,-0.011832732,-0.0005194378,-0.0018619252,0.017841594,0.0208426,0.016772743,-0.009797804,-0.013668964,-0.029352302,-0.019636717,-0.006563843,0.020020407,-0.0032528022,-0.0033915474,-0.0043987343,-0.0030626701,0.02717349,-0.053223312,0.0069715143,-0.0204178,0.0031534538,0.005601192,-0.0031277605,-0.0052586114,0.021678496,-0.016512383,0.00521065,0.01888304,-0.012552151,-0.009496333,0.046727985,-0.004247999,0.01680015,-0.014840589,0.017197544,0.0040835603,0.036176506,-0.013847105,-0.010085572,0.010215752,-0.03831421,-0.0013523367,-0.012490487,0.025967605,0.024912458,0.010983133,-0.014011544,0.011120165,0.0006817353,-0.0027080993,-0.0030198474,-0.028776767,0.017416796,0.020911116,0.0032819216,0.0039705085,0.021801826,0.027913462,0.0017848447,-0.03653279,-0.010558332,-0.0095717,-0.0128810285,-0.0023826477,0.029598959,0.0058684046,0.00015127072,-0.03143519,0.0061150626,0.067639105,-0.01769086,0.0030147089,0.0010268852,-0.0024357478,-0.030722624,-0.12321937,-0.025172818,0.004292534,-0.0024785702,0.009489481,0.0035765409,-0.009194862,-0.009859468,-0.025405774,0.017910112,-0.050427858,-0.028173825,-0.0008864272,-0.009345598,-0.015128357,-0.0026806928,0.00563545,-0.0043370696,-0.020568537,0.01973264,-0.034011398,-0.03083225,-0.01556686,0.0024203316,0.018252691,0.005460734,-0.018869337,-0.0024905605,-0.0045186374,-0.0013155093,0.027488664,-0.022021078,-0.019184511,-0.0030900766,-0.013963583,-0.011346268,0.0059848824,-0.009475778,0.024282109,-0.03683426,0.014360976,-0.020856304,-0.011668294,-0.020088924,-0.011627183,0.0035868182,-0.028996017,0.029927837,0.007433998,-0.008728952,-0.020486316,0.0040390245,-0.02866714,0.008030088,0.008776913,0.0071051205,0.0036073732,0.014867996,-0.008749507,0.01680015,-0.015361312,0.017170137,0.010030759,-0.004806405,0.032723293,-0.017841594,-0.021020742,-0.019485982,0.0063308887,-0.03283292,-0.0075299204,-0.001275256,-0.009564849,0.020088924,-0.022486987,-0.010229455,0.0020126607,0.004114392,-0.0071941917,-0.01663571,-0.0062760757,-0.0075778817,0.01819788,-0.020774085,0.003451499,0.007235301,-0.009749842,-0.01760864,-0.01718384,-0.013223609,-0.017293466,0.047056865,0.018800821,-0.02990043,0.0032425248,0.006622082,0.0005451313,0.002975312,0.0006200708,0.0095717,-0.03299736,-0.009551146,-0.03976675,0.018855633,-0.01611499,-0.018513052,-0.010688513,-0.019705232,0.0051969467,-0.0058238693,0.0048509403,-0.011421636,-0.0129632475,0.012319196,-0.031024095,0.0033315958,-0.021582574,3.441864e-05,0.010489816,-0.015018731,0.016909776,-0.009516887,-0.00774232,-0.016347943,-0.001108248,-0.013066022,-0.010859803,-0.004474102,-0.007694359,0.024378031,-0.022774754,-0.016156098,0.004224018,-0.023254367,0.002766338,0.03661501,0.013134538,-0.009174307,0.007899907,0.017677156,0.037354983,-0.023076225,5.9898066e-05,-0.041274104,-0.009277081,-0.013155093,0.017718267,0.0041486504,-0.0039533796,-0.008050643,-0.009667623,-0.0020503446,0.019513387,0.022774754,-0.010955726,-0.028173825,-0.016594602,-0.015621673,-0.00056140387,-0.019979298,-0.023035116,-0.01718384,0.0352995,-0.0075915847,0.022226626,-0.011174978,0.014306163,0.006834482,-0.0027492088,0.016169801,-0.0025744927,-0.02611834,-0.002833141,0.001443977,-0.0037101472,-0.0016854963,-0.00012911005,0.016169801,-0.020554833,0.0063171852,-0.0011202383,0.041137073,-0.0022233478,-0.0117573645,-0.028338263,0.011942358,0.02446025,-0.0019578477,-0.014429493,0.0035833926,0.0044124373,-0.01586833,0.0019338672,0.008619326,0.010380191,0.00032802086,0.0005322845,-0.0034789054,0.0065261596,-0.010524075,0.0005618321,0.015786111,0.0063548693,0.007941017,-0.009557997,-0.021514058,-0.041520763,0.017334575,-0.024501361,-0.050208606,0.013264718,0.006077379,0.018732304,-0.018430833,0.02029447,0.008913945,-0.006159598,0.023980638,-0.016060175,-0.034943216,-0.036724634,0.02276105,0.004049302,-0.023158444,-0.013066022,0.008441185,0.024802832,0.028393075,0.017416796,-0.024994677,0.023226961,0.015717596,0.0015630238,0.0022062187,-0.0015784398,-0.018800821,-0.01934895,-0.01760864,0.009181159,0.015416125,-0.006464495,0.06983162,0.013799144,0.006707727,-0.010489816,-0.0025590768,0.02836567,0.022911787,-4.10829e-05,-0.020609645,-0.02589909,-0.006587824,0.008221933,-0.029324895,-0.015429827,-0.009742991,0.00025372373,-0.0118669905,0.0011313723,-0.023336587,-0.0043404954,0.024186186,-0.00049074664,0.010859803,0.008372668,0.0037238505,0.0034960345,0.0027029605,-0.0026344445,0.020856304,-0.015840925,-0.002428896,0.014059505,-0.02836567,-0.027146082,0.0056217466,0.013943029,-0.0060568242,-0.016197208,-0.005018805,0.0011604916,-0.0017557252,0.015621673,-0.01663571,-0.011236642,-0.027406443,0.016402757,0.016265724,-0.022815865,-0.002942767]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
0.7136026935116674
0.7785785057923886
0.7231044840862928
0.7650518860213186
0.7150392264535101
0.725688915474423
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.001268853,0.011801532,0.010904259,-0.006024055,-0.017315306,0.02269894,0.0050925356,0.0006502658,-0.020616721,-0.034466226,0.023233196,-0.005756928,-0.011137139,0.006911054,-0.023479775,-0.012479623,0.028438745,0.0072261263,0.008013808,-0.021589337,-0.007335717,0.016589269,0.0019966026,-0.039808765,-0.017164618,0.02154824,0.028520938,-0.015452267,0.014685133,0.0057877507,0.00052483595,0.013383745,-0.02306881,-0.032740176,-0.007657639,0.02156194,0.010979602,-0.014438554,0.0024452389,-1.5702136e-06,0.03254839,0.0046541733,-0.007801477,-0.020671517,0.009876847,0.007322018,0.011897423,-0.02121947,-0.010130276,-0.004589104,0.020986589,0.028246962,-0.023356484,-0.009561775,-0.011904272,0.009520679,-0.005935013,0.009527528,0.01240428,-0.0021712626,0.018137235,0.009739859,-0.0133631965,0.010739873,-0.029342867,-0.013520733,0.0042706067,0.009589173,-0.023287991,0.02027425,0.04937054,0.029178482,-0.0011096043,-0.0150687,0.009863148,-0.012007014,-0.011835778,-0.015739942,0.0051404815,0.009075467,0.0013733065,-0.022411266,-0.02757572,0.039479993,0.009438486,-0.033808682,0.010417951,0.026603105,-0.018452307,0.009828902,-0.010986452,0.017452294,0.020534528,-0.0042671817,0.0052192495,0.0019760544,0.013075521,0.023890737,0.009739859,0.0023116756,-0.011383718,0.009698763,-0.048411623,-0.008780942,-0.015616653,0.00024764895,0.016863246,0.0006211558,0.011993315,-0.027411334,-0.04887738,0.044028,0.007554898,-0.030877136,0.011315224,-0.004852806,-0.0018082439,-0.04342525,-0.007705585,-0.006232962,0.0066815983,0.030548364,0.028931903,-0.005506925,0.019876985,-0.0059932326,-0.033945672,-0.025945561,-0.024137316,-0.0091576595,0.02791819,0.014164577,-0.022287976,0.03339772,-0.02305511,0.004934999,-0.005726106,0.032986753,-0.040164933,-0.015246784,0.024726367,0.0013262169,0.0063767997,0.020808505,-0.0035240208,0.020685215,0.00040753983,0.030301785,-0.0052706203,-0.010623434,-0.0014940273,-0.017986547,0.020904396,0.003952109,0.017397499,0.019397525,0.008465869,-0.0019263963,-0.014986507,-0.015726242,-0.00082278525,0.0049726707,0.0024880478,0.014287867,0.015918026,0.018287921,0.016150907,-0.0013947109,-0.006095974,0.01171249,-0.010965903,0.029507253,-0.018822176,0.028822312,0.0036096384,0.013239907,0.022014,-0.027616818,-0.0049281497,-0.00067209825,-0.010527542,0.020603022,-0.0016104672,0.012253593,-0.009130262,-0.014150878,0.0011301525,-0.029123686,-0.00034739345,-0.018520802,-0.011020699,0.015493363,0.008082302,0.01274675,-0.6606118,-0.02884971,0.0008544638,-0.01447965,0.013657722,0.019178346,0.0061576185,-0.019794792,-0.024507185,0.020370143,-0.019972876,0.0031370292,0.01668516,-0.03257579,-0.016246798,-0.042137563,0.019945478,-0.020055069,-0.0138289565,0.015287881,-0.018753681,0.010924807,-0.014931711,0.020781107,-0.0036747078,0.013308401,-0.00776723,-0.008390526,0.03350731,0.02165783,-0.0027654488,0.028603131,-0.015849533,0.010445349,0.040027946,-0.016246798,-0.019424923,0.0055206236,-0.012342635,0.043370456,-0.04854861,-0.013781011,0.0140686855,0.00411307,-0.0038151208,0.006335703,0.008917931,-0.010383704,0.018602995,0.013233058,0.0017243387,0.026000356,0.0023407855,0.0073631145,0.018972863,-0.010876861,0.014452253,-0.00811655,0.016931739,0.0007718428,0.00926725,0.0037158043,-0.011774134,-0.0024538008,0.008719297,0.034931984,0.014191975,0.026931876,-0.0053562378,-0.02109618,0.004554857,0.008904232,-0.0036918314,-0.010383704,-0.000870303,-0.0030873711,0.005493226,0.007623392,0.01680845,0.010109727,-0.0044212933,-0.02271264,0.0051028095,0.0114111155,-0.006911054,0.0065994053,-0.02004137,-0.009006972,0.003208948,-0.012459075,0.01982219,0.032520995,-0.0069521503,-0.030959329,-0.012219345,0.02561679,0.0009991575,0.015493363,0.0019657803,-0.0140686855,-0.012520719,0.013075521,-0.0053356895,0.007787778,0.01865779,-0.0003976938,-0.031589475,0.02838395,0.03857587,0.0031421664,-0.0019709175,0.018123535,-0.032027837,0.018986562,-0.004380197,-0.031699065,0.0066576255,-0.003082234,-0.005770627,-0.013602926,0.027520925,-0.00278086,0.019068755,-0.01471253,0.009102864,0.0254935,0.004078823,-0.016013918,0.0068357103,0.017233113,0.024603076,0.024068823,0.013924848,-0.008198743,0.022164688,0.012548117,-0.0035068973,0.009048069,0.0075754463,-0.010404252,-0.010561788,0.012726202,3.7939302e-05,0.010075481,-0.01632899,0.005075412,-0.0070959874,0.010609735,-0.0029075742,-0.010205619,0.008048056,-0.01819203,-0.010630283,-0.0013373471,-0.015397471,0.0028647652,0.013102919,-0.02978123,-0.006678174,-0.034603212,0.012548117,0.04263072,-0.024507185,0.0059452867,-0.007849422,-0.0031181935,-0.012952232,0.024972945,-0.0017234825,-0.019548213,0.0147673255,-0.02978123,-0.003941835,0.029616844,-0.0100891795,0.0069007794,-0.0004321549,-0.019274237,-0.006479541,-0.01587693,-0.008678201,-0.019246839,0.015808435,0.008267237,0.015616653,0.011233031,0.027260648,0.008486418,-0.032740176,0.041123852,-0.005808299,0.007356265,-0.010068631,0.010328908,0.011746736,-0.0076918863,0.009774107,-0.0036747078,0.006945301,0.0034931984,0.0053699366,0.009376841,0.026329128,-0.025972959,-0.006301456,-0.0097809555,0.0080617545,-0.021109879,0.021835916,0.012335786,0.018356416,0.00039341292,-0.008130249,-0.015082398,0.009164509,-0.0028767518,0.0002806117,0.0070959874,-0.0093905395,0.03290456,-0.010623434,-0.013959095,0.052904833,-0.003777449,0.013500185,0.024972945,-0.009143961,0.012253593,0.0220277,-0.029233277,-0.0016618378,0.0032860038,0.0063425526,0.02710996,0.013479637,0.0032072358,-0.022863327,-0.0049555474,0.012801546,-0.012445376,0.013952246,0.015698845,-0.004554857,-0.01170564,0.038055316,0.00486308,0.03268538,0.0196989,0.0014554994,-0.010493294,-0.011986465,0.0012765586,-0.017315306,-0.005041165,0.00799326,-0.0029829175,0.0125823645,-0.0032209344,0.018150933,0.021822216,0.017329004,0.022726338,0.018863272,-0.03419225,0.03232921,0.0059110397,-0.009575474,-0.02608255,-0.021438649,-0.029014096,-0.022657845,0.0045103356,0.016520774,-0.04219236,0.037151195,0.005298018,0.019561911,0.012342635,0.03778134,0.014123481,-0.021863313,-0.01806874,0.003592515,0.01447965,0.004832258,0.002167838,-0.0108700115,0.0049384236,-0.008561761,-0.0014366636,0.003719229,0.019520815,-0.003801422,-0.0028493542,-0.0076644886,0.014205674,0.013883752,-0.0052569215,-0.011678242,-0.012726202,-0.012911135,0.0069521503,-0.019082453,-0.030794943,0.037616953,0.007287771,0.015739942,-0.016534474,-0.008869984,-0.026698995,0.006476116,-0.01889067,-0.0025000342,-0.021726325,0.016205702,0.0040616994,-0.028603131,0.016945438,0.02838395,-0.0030411375,-0.0029880546,0.001137858,-0.0020976316,0.0065206373,0.033233333,0.027164755,0.003378471,0.010157674,-0.040411513,0.0033527857,0.003544569,-0.0059589855,0.0026472965,0.018219428,-0.00044563966,0.011082344,-0.002727777,-0.0042945794,0.00068194425,0.014438554,0.02628803,-0.023315389,-0.008671352,-0.014986507,0.003214085,-0.011096043,0.019274237,0.025315415,0.013198811,0.0021644132,0.008431623,0.007089138,0.0020993438,-0.01771257,0.004554857,0.014698831,0.018383814,0.01980849,0.0077809286,0.021520842,-0.014931711,-0.0128152445,0.013801559,0.00741791,0.01193852,-0.0023784572,0.011637146,-0.007075439,-0.00718503,-0.01355498,0.018835874,-0.010000137,0.009438486,-0.00044521157,-0.004568556,-0.011739887,-0.041069057,-0.008678201,0.0053528133,0.011623447,-0.009068618,-0.00036152036,0.009068618,-0.021082481,-0.025589392,-0.0085275145,0.01263031,-0.011671393,0.014233071,-0.0019229716,-0.0034521022,-0.0030514116,-0.00025021748,-0.001035117,0.0023955808,-0.048740394,-0.038740255,-0.01158235,0.021178372,0.03024699,0.008589159,0.0015428293,-0.02710996,0.0013664571,-0.02132906,-0.009479582,-0.0032928532,-0.014452253,0.0077603804,0.0147673255,-0.0025205824,-0.0034538144,-0.0029966163,0.013637173,-0.010719324,0.033644296,0.0077261333,-0.021520842,-0.0006566871,0.009185057,0.00011943657,0.021192072,0.0054281563,-0.022301676,0.027562022,-0.023575665,-0.014150878,-0.0070274933,-0.012541268,-0.0069795474,0.010753572,0.007506952,0.004424718,-0.008424773,0.011376868,-0.014644036,0.0087672435,-0.017767366,0.0004987226,0.00084076496,0.021507144,0.0162331,-0.007965863,0.025890766,0.016876943,-0.041452624,0.016657762,0.010048083,-0.01587693,0.008705598,-0.021013986,0.011294675,-0.024466088,0.01632899,-5.68822e-05,0.025068836,-0.0076165427,-0.0056336387,-0.02791819,-0.005345964,-0.02757572,-0.014739928,-0.010589186,-0.011082344,0.01193167,-0.0034777874,-0.017534487,-0.007089138,0.008041206,-0.022671543,-0.0100891795,0.014438554,-0.0072946204,0.04008274,-0.0011849478,-0.0027397636,-0.014876916,-0.02769901,-0.0022209208,-0.028931903,-0.0025788024,0.0021918109,0.021109879,0.015260483,0.03150728,0.017589282,0.03161687,-0.00561994,-0.019794792,-0.006534336,0.012411129,-0.004390471,-0.009438486,0.016397486,6.362459e-05,-0.029753832,0.0077261333,0.0048870533,0.0058117234,0.011253579,-0.026205838,-0.017438594,-0.017370101,-0.02212359,0.00069649925,0.022835929,-0.021233167,-0.0062774834,-0.030548364,0.015794737,-0.0031866876,-0.0039212867,0.021192072,0.0025359937,0.012917985,-0.0049726707,0.02247976,-0.00046790024,-0.0016969411,-0.01078097,-0.030931931,-0.010486445,0.0021335909,0.036603242,-0.019548213,0.015781038,0.016082412,0.00097432843,-0.012520719,-0.024014028,0.008904232,-0.017671475,0.002251743,-0.006315155,-0.009602872,-0.02572638,-0.0120412605,-0.013856354,0.0013048124,0.006695297,-0.018260524,0.002902437,0.0066439267,-0.021356458,0.02421951,-0.009698763,0.02619214,0.016027616,0.025890766,0.0028801765,0.0016926602,0.008171345,-0.011986465,-0.0059041902,0.010356306,0.011390567,-0.01263716,0.015781038,-0.033781286,0.008589159,-0.00071790366,-0.013465938,-0.007705585,0.009760408,0.013281004,-0.009575474,-0.0075138016,-0.025904464,-0.0114933085,0.00069692737,-0.008760394,-0.015013904,0.010102878,-0.007671338,0.0015111509,0.009335744,0.015739942,0.028246962,0.006335703,0.00065112195,0.020959191,-0.0017046466,0.009609721,0.01991808,0.0016447143,0.008554912,0.024753764,0.008424773,-0.0046644476,-0.0022294826,0.008650803,-0.0025942137,-0.0012757024,0.0289593,-0.011027548,0.00040753983,0.00071148237,0.010808367,0.002046261,-0.0056678858,-0.014054987,0.0029041495,-0.0077261333,0.008650803,0.009315196,0.007568597,-0.030411376,-0.008212442,0.002226058,-0.0045480076,0.00556172,-0.0022688666,0.0051850025,-0.032247018,-0.014959109,-0.001818518,0.014616638,0.026520912,-0.0136714205,0.0074795545,0.024137316,0.003222647,-0.017904354,-0.007972712,0.021164674,-0.007219277,-0.021835916,0.0220277,-0.0072329757,-0.027534625,0.029096289,-0.0009460746,-0.029534651,-0.023740051,0.004092522,-0.019603008,-0.0007020644,-0.04046631,-0.015137194,0.0048699295,0.012657708,0.010267264,0.009322045,-0.001239743,0.015205688,-0.00052055507,0.004366498,0.0074932533,-0.008787791,-0.013739915,0.013890602,-0.0026918177,-0.037589557,-0.012363183,0.0019674927,0.0016019056,0.011007,-0.013507035,-0.014356361,0.0058117234,-0.009685064,0.033425115,0.007849422,-0.016479678,-0.019260539,-0.0062774834,0.0052055507,0.02676749,-0.028931903,-0.008869984,-0.0024144165,-0.00538706,-0.033233333,-0.041863587,-0.019767394,0.037069,0.01946602,-0.010006987,0.000636995,-0.016246798,-0.020096166,-0.012212496,0.010582337,-0.0070959874,-0.007602844,0.004633625,-0.006640502,0.018329019,0.002582227,-0.018301621,0.002270579,0.010561788,-0.012568666,-0.022931822,0.016671462,0.036932014,-0.022205783,-0.014493349,0.004448691,-0.013287853,0.02224688,0.0012517294,-0.0028459295,-0.0154659655,0.01460294,0.019603008,0.026205838,0.023808545,0.018383814,-0.013808409,0.0037397773,0.014589241,-0.017274208,-0.02628803,-0.01424677,0.009787805,-0.0077946275,0.004068549,-0.011746736,-0.01750709,-0.008602858,-0.0016258784,0.021685228,-0.0013227921,-0.00046704407,0.027178455,0.0031216182,-0.021616735,-0.0018099563,0.026616802,-0.024972945,-0.018822176,0.023767449,-0.039781366,0.005147331,-0.0023698956,-0.019520815,-0.02016466,-0.0022055097,-0.0042021126,-0.006256935,-0.005157605,0.009596022,0.0075822957,-0.017274208,0.020301647,-0.0044075944,-0.014041288,-0.016397486,0.0028031205,0.026945574,0.004486363,-0.013253606,-0.0016096111,-0.01865779,-0.01993178,0.026603105,0.025685284,0.014671434,0.032603186,0.24635954,-0.01749339,-0.013178263,0.01123988,0.015246784,0.0060069314,9.491515e-06,0.03197304,-0.021000288,-0.012965931,0.016753655,0.006315155,0.0046096523,0.0020548226,0.001381012,-0.010034384,-0.021013986,-0.008596008,0.0016233099,0.013041275,0.013582378,0.0029349718,0.00044264304,-0.02027425,0.04539788,0.011150838,0.0027209276,0.01935643,-0.014315264,-0.010733023,0.0066096797,0.0025976384,0.008034357,0.020466033,-0.016493376,-0.008000109,-0.0059624105,-0.01669886,0.025781175,0.014726229,0.020986589,-0.0096234195,-0.011548104,-0.010856313,0.009294648,0.0032517568,-0.011397417,-0.012548117,0.010020685,0.007137084,-0.023137303,-0.016137207,0.01713722,0.028931903,-0.0015967685,-0.0107124755,0.0018219427,-0.0040377267,0.034603212,0.014109782,-0.035616927,0.01089056,-0.029123686,0.018493405,-0.005246647,-0.00075429113,-0.003000041,-0.010349457,0.026479814,-0.026151042,-0.014438554,0.007856272,-0.002056535,-0.0010530966,-0.025671585,-0.0056952834,0.033534706,0.019603008,0.020055069,0.023260593,-0.015945423,1.850143e-05,-0.0020633845,-0.010643981,-0.016123509,-0.009924794,0.023945533,-0.016027616,0.008191893,0.006685023,6.8975685e-05,0.00058305595,-0.013137166,-0.007637091,0.0013116618,0.0044589653,0.0049213003,0.025164729,-0.010178221,0.000554374,-0.031014124,0.05616515,0.010308361,0.0031284676,0.015452267,0.016123509,0.024356497,0.015055001,0.008431623,-0.015972821,-0.002762024,-0.05065823,-1.2842642e-05,-0.0073768133,-0.007438458,0.005828847,0.0016301593,-0.003544569,0.03369909,-0.01066453,-0.0059829587,-0.014863217,-0.0022962643,0.00973301,0.01181523,-0.021370156,-0.020329045,-0.0014726229,-0.015383773,0.007157632,-0.0011584063,0.017438594,0.0022243455,0.027671613,-0.009972739,-0.01982219,-0.01795915,-0.040959466,0.0034692257,0.009143961,-0.00062543666,0.017233113,0.01668516,-0.0162194,0.0018818751,-0.01147961,0.01204811,0.00973301,-0.015739942,-0.015383773,-0.0051028095,-0.003883615,-0.015808435,-0.025109934,0.020520829,-0.012390581,-0.01263716,-0.016972836,0.010301511,-0.008068603,-0.011507007,0.004534309,0.008239839,-0.031370293,-0.013178263,-0.0075138016,-0.17655036,-0.0065206373,0.022781134,-0.04356224,0.01819203,0.021726325,0.012527569,0.0037808737,-0.033671696,0.0152330855,0.008356279,-0.0139043005,-0.021013986,0.004958972,0.004369923,-0.0029401088,-0.030055206,0.016137207,0.004352799,0.026685297,0.026890779,-0.01945232,0.0051610298,-0.0008043774,-0.016383786,-0.004506911,-0.0031815504,0.011787833,0.01193167,-0.021918109,0.0185482,-0.011780983,0.010486445,0.007356265,-0.004945273,-0.010150824,0.0017791339,-0.020767407,-0.005280894,0.012712503,0.025863368,0.010650831,-0.018013945,0.029260674,-0.0011977904,0.018753681,0.021082481,0.0026421596,0.00995904,-0.023370184,0.0062946067,-0.011794682,-0.0005278326,-0.0019041357,0.017890656,0.020794805,0.016781053,-0.009767257,-0.013726216,-0.029342867,-0.019603008,-0.006534336,0.020013973,-0.0032637434,-0.0034212798,-0.0043630735,-0.0030702476,0.02712366,-0.05320621,0.0069795474,-0.020370143,0.0031267551,0.005595967,-0.0030942205,-0.005260346,0.021644132,-0.016383786,0.005181578,0.018822176,-0.012568666,-0.009541227,0.046740368,-0.00428773,0.016822148,-0.014808422,0.017109824,0.004092522,0.036192276,-0.013870053,-0.010020685,0.010274113,-0.038301896,-0.0013441965,-0.012417979,0.026055152,0.02491815,0.011007,-0.013993342,0.011061795,0.0006451287,-0.002679831,-0.0030205892,-0.02874012,0.017397499,0.020904396,0.003349361,0.003986356,0.02178112,0.027904492,0.0017979698,-0.036521047,-0.010486445,-0.009561775,-0.012849491,-0.0023835944,0.029562049,0.0058904914,0.00016770349,-0.03142509,0.006116522,0.06767216,-0.017630378,0.0030051782,0.0010008699,-0.0024246906,-0.030657955,-0.12317977,-0.025164729,0.004256908,-0.0024777737,0.009486431,0.0035856655,-0.009137112,-0.0098562995,-0.025329115,0.017876957,-0.050384253,-0.028219564,-0.000831347,-0.009335744,-0.0150687,-0.0027260648,0.005585693,-0.0043425253,-0.020548226,0.019726297,-0.033945672,-0.030740147,-0.015520761,0.0024024302,0.01817833,0.005489801,-0.018863272,-0.0025274318,-0.0045274594,-0.00127399,0.027397636,-0.0220277,-0.019150948,-0.0030445622,-0.013952246,-0.011322073,0.005907615,-0.009513829,0.024192112,-0.036822423,0.014342662,-0.020890698,-0.011664543,-0.020137262,-0.011548104,0.0035856655,-0.0289593,0.02989082,0.0073836627,-0.008746695,-0.020479733,0.004068549,-0.028603131,0.008020658,0.008787791,0.00706859,0.003568542,0.0147673255,-0.008760394,0.01679475,-0.015383773,0.017219413,0.010006987,-0.004774038,0.032712776,-0.017835861,-0.02097289,-0.019493418,0.0062980317,-0.032849766,-0.007506952,-0.001297963,-0.009575474,0.020068768,-0.022507157,-0.01019877,0.0019811916,0.0041096453,-0.0071987286,-0.016657762,-0.0062432364,-0.007602844,0.018219428,-0.020781107,0.0034349787,0.0072672227,-0.009746709,-0.017534487,-0.017192015,-0.013212509,-0.017329004,0.04706914,0.018753681,-0.029945616,0.0032055234,0.0066336524,0.00058305595,0.002960657,0.00064298825,0.009575474,-0.033014152,-0.00950013,-0.039781366,0.018808477,-0.016068714,-0.0185482,-0.010698777,-0.019657804,0.0052192495,-0.005842546,0.004914451,-0.011452212,-0.012965931,0.012328936,-0.03106892,0.0033373744,-0.021534542,5.682869e-05,0.0104248,-0.014986507,0.01691804,-0.00950698,-0.007753531,-0.01634269,-0.001069364,-0.013007027,-0.010904259,-0.0044281427,-0.007671338,0.024356497,-0.022808531,-0.016192002,0.004274031,-0.023260593,0.0027911342,0.036685433,0.0131303165,-0.009137112,0.007917916,0.017657775,0.03731558,-0.023096208,0.00013827244,-0.04126084,-0.0092741,-0.013164564,0.017767366,0.004219236,-0.003941835,-0.008054905,-0.009602872,-0.0020753709,0.01945232,0.022794833,-0.010911108,-0.028164769,-0.016507076,-0.015602954,-0.0006177311,-0.020013973,-0.02305511,-0.017219413,0.03534295,-0.007520651,0.022164688,-0.011157687,0.014328963,0.006845984,-0.0027380511,0.016150907,-0.0026233236,-0.026164742,-0.0028305182,0.001468342,-0.0037226537,-0.0017517363,-0.0001720914,0.0162194,-0.020493431,0.0063322787,-0.001059946,0.041178647,-0.002138728,-0.011767285,-0.028411347,0.011924821,0.024424993,-0.0019418075,-0.014452253,0.003637036,0.004434992,-0.01587693,0.0019332457,0.008623405,0.010363156,0.00032342054,0.00047988672,-0.0034178551,0.006510363,-0.010520692,0.0005265483,0.015726242,0.006335703,0.007952164,-0.009554925,-0.021493444,-0.04150742,0.017329004,-0.024493486,-0.050247263,0.013212509,0.0060857,0.018739983,-0.018397512,0.020233154,0.008863135,-0.006150769,0.023959232,-0.016013918,-0.03487719,-0.036712833,0.022794833,0.0040719737,-0.023137303,-0.013061822,0.008411074,0.024822257,0.028411347,0.017397499,-0.024986643,0.023260593,0.015781038,0.0015659461,0.0022277702,-0.0015950562,-0.018822176,-0.019315332,-0.017575582,0.009212455,0.015397471,-0.0064384444,0.06986397,0.0138289565,0.006712421,-0.010513843,-0.0025462678,0.028329154,0.022849629,-8.6420274e-05,-0.020657817,-0.025877066,-0.00654461,0.008198743,-0.029260674,-0.0154659655,-0.009760408,0.00034118618,-0.011897423,0.0011489884,-0.023274291,-0.004308278,0.024192112,-0.0004696126,0.010835765,0.008397375,0.0037295031,0.0034606638,0.0026815436,-0.0026198989,0.0208496,-0.01586323,-0.0024144165,0.014054987,-0.02838395,-0.027205853,0.0056370636,0.013938547,-0.0060651517,-0.016178304,-0.004993219,0.0011301525,-0.0017568733,0.015602954,-0.016657762,-0.011253579,-0.027438732,0.016397486,0.016260497,-0.022781134,-0.0029520951]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0013346411,0.011841409,0.010896288,-0.0061158924,-0.017286127,0.022682907,0.0051057087,0.00063992577,-0.020546112,-0.03446268,0.0232445,-0.0057529113,-0.011074354,0.00686925,-0.023463659,-0.012464641,0.028435819,0.007259626,0.008019832,-0.021628207,-0.007355508,0.016601259,0.002044338,-0.039695088,-0.017108062,0.021600813,0.028463213,-0.015395886,0.014669923,0.00578373,0.0004661399,0.013389216,-0.02303904,-0.03270941,-0.007697943,0.021436444,0.010944229,-0.0144096725,0.0024158803,-2.6702587e-06,0.032517646,0.004670816,-0.0078075225,-0.020600902,0.009882679,0.007376054,0.011882501,-0.021258377,-0.010094989,-0.004592056,0.020943336,0.028244054,-0.02335408,-0.009540244,-0.01188935,0.009526547,-0.005889885,0.009547093,0.012396154,-0.0022018582,0.018162763,0.009786798,-0.013354972,0.010738768,-0.029339846,-0.013450854,0.0042598937,0.0096429745,-0.023312988,0.020231072,0.049283274,0.029175479,-0.0011497261,-0.015067148,0.009848436,-0.011998929,-0.011861955,-0.015793111,0.0051057087,0.00908823,0.0014219622,-0.022436354,-0.027518092,0.039448533,0.009396422,-0.033777807,0.010464819,0.026641458,-0.018450407,0.009834738,-0.010951078,0.017450497,0.020505019,-0.0042701666,0.0052495315,0.002004958,0.013039932,0.023860885,0.009711462,0.0023696516,-0.011361999,0.009677218,-0.04840664,-0.008732097,-0.015628742,0.0002899998,0.016888903,0.000652339,0.01199208,-0.027408512,-0.04881756,0.043996073,0.0075267255,-0.030901352,0.011211328,-0.0048591555,-0.0017652534,-0.043448176,-0.0077116406,-0.0062802616,0.006725427,0.03049043,0.028874135,-0.0054823873,0.019792754,-0.0059480993,-0.033942174,-0.02594289,-0.02403895,-0.009177263,0.027833132,0.0142042115,-0.02224459,0.033366885,-0.023107527,0.0048899744,-0.005722092,0.03301075,-0.04010601,-0.015176727,0.024737518,0.001353475,0.006348748,0.02076527,-0.0034363372,0.02071048,0.00040985213,0.030243875,-0.0052118637,-0.010574399,-0.001487881,-0.017943604,0.020902244,0.003931156,0.017327221,0.019340739,0.00845815,-0.0019090762,-0.0149712665,-0.015793111,-0.0008834828,0.0049961293,0.0024826552,0.014300093,0.01590269,0.018272342,0.016080756,-0.0013594677,-0.0061056195,0.0117181325,-0.010903137,0.029504215,-0.018751752,0.028764555,0.0036058426,0.013163209,0.02202543,-0.027613973,-0.0049105207,-0.0007092689,-0.010505912,0.020600902,-0.0016411206,0.012211239,-0.009095078,-0.014135725,0.0011137704,-0.0290659,-0.00041605876,-0.018450407,-0.010999018,0.015478071,0.00803353,0.012738589,-0.6609821,-0.028819345,0.0008826267,-0.014491857,0.0137385,0.019203765,0.0061569847,-0.019888636,-0.024477268,0.020313255,-0.019943425,0.0031675254,0.01669714,-0.03254504,-0.016299915,-0.042133227,0.019998215,-0.020011913,-0.013800138,0.015286307,-0.018779146,0.010930532,-0.014957569,0.02076527,-0.0036469349,0.013300182,-0.007745884,-0.008375965,0.03350386,0.021682996,-0.002724072,0.028518002,-0.015888993,0.010505912,0.04010601,-0.016231429,-0.019450318,0.005475539,-0.012327666,0.043338597,-0.048571005,-0.013813836,0.013978205,0.0041023735,-0.003735968,0.0063213534,0.008992348,-0.010382635,0.018628474,0.0132590905,0.001673652,0.026038771,0.0023987584,0.007355508,0.018957213,-0.010889439,0.014437067,-0.0081088655,0.016984785,0.000797874,0.009293691,0.0036914514,-0.011841409,-0.0024449872,0.008725248,0.034846205,0.014176817,0.026888011,-0.005304321,-0.0211351,0.004475628,0.008862223,-0.003756514,-0.010341543,-0.00082569686,-0.0030802046,0.0054960847,0.0075198766,0.016820416,0.010094989,-0.004458506,-0.02276509,0.0051433765,0.011334605,-0.006886372,0.006667213,-0.020066703,-0.009040289,0.003239437,-0.012478339,0.019751662,0.03254504,-0.006941161,-0.030956142,-0.012211239,0.025710033,0.0009613868,0.015491768,0.0019433197,-0.01405354,-0.012512581,0.013033084,-0.0053282916,0.0078006736,0.018779146,-0.0004175569,-0.031586222,0.02832624,0.038571898,0.0031486915,-0.0019724267,0.018135367,-0.031997144,0.01891612,-0.0043249563,-0.0316958,0.006701457,-0.0031572524,-0.005739214,-0.013594677,0.027504394,-0.0027600275,0.019107884,-0.014669923,0.009129322,0.02546348,0.004047584,-0.01601227,0.0068178847,0.017286127,0.024655333,0.024052648,0.013971356,-0.008122562,0.02213501,0.012567371,-0.0035168093,0.009108776,0.007602061,-0.010437424,-0.010588096,0.01273174,6.458114e-05,0.010108687,-0.016299915,0.0050851624,-0.0070884083,0.0105812475,-0.0029329574,-0.010300451,0.008019832,-0.018244946,-0.010608642,-0.0012815637,-0.015382188,0.002852485,0.013081024,-0.02980556,-0.006646667,-0.034572255,0.012539976,0.042516753,-0.02451836,0.005954948,-0.007855463,-0.0030733559,-0.012930353,0.02494298,-0.0017507,-0.019532504,0.014752108,-0.02986035,-0.003931156,0.02964119,-0.00998541,0.006831582,-0.0004417414,-0.019272253,-0.0064754495,-0.015930085,-0.008745795,-0.019203765,0.015820505,0.008266386,0.01564244,0.01119763,0.027326329,0.008485544,-0.03265462,0.041092224,-0.0058042766,0.007300718,-0.010040199,0.010259358,0.0117181325,-0.007602061,0.009738857,-0.0036914514,0.0068555526,0.0035202338,0.0054344465,0.009334783,0.026394904,-0.025970284,-0.006297383,-0.009759403,0.008047227,-0.021052916,0.02181997,0.0123071205,0.018381922,0.00036383737,-0.008047227,-0.015135636,0.009218356,-0.0029158357,0.00032552745,0.00708156,-0.009382724,0.03287378,-0.010588096,-0.013978205,0.0528446,-0.0037633628,0.013553585,0.024970373,-0.009136171,0.0123071205,0.022011735,-0.029175479,-0.0016710837,0.00328909,0.006324778,0.02710717,0.013409762,0.0031572524,-0.022847276,-0.004917369,0.012807076,-0.012485187,0.013957658,0.015656136,-0.004537266,-0.011697586,0.038051397,0.0048797014,0.032736804,0.019655779,0.0014536374,-0.010471668,-0.011875653,0.0013663165,-0.017368313,-0.0050200997,0.008006135,-0.0029124112,0.012587918,-0.0032240273,0.018135367,0.021847365,0.017327221,0.02276509,0.018861331,-0.03413394,0.0322437,0.0058350954,-0.009636126,-0.026038771,-0.021491233,-0.02895632,-0.022628117,0.0045201443,0.01649168,-0.04221541,0.037119973,0.0053282916,0.019546201,0.012375608,0.03777745,0.014135725,-0.021806274,-0.017984696,0.0036537836,0.0143959755,0.004838609,0.00214022,-0.010909985,0.004955037,-0.008595123,-0.0014039843,0.0037119975,0.019532504,-0.0038489716,-0.0029175477,-0.007656851,0.014149422,0.013902869,-0.00525638,-0.0117318295,-0.012718043,-0.012923504,0.0069103423,-0.019080488,-0.030846562,0.037640475,0.007259626,0.01569723,-0.01649168,-0.008855374,-0.02668255,0.00642066,-0.018833935,-0.002569976,-0.02176518,0.01617664,0.0040133405,-0.028600186,0.016888903,0.028408423,-0.0030305514,-0.00299802,0.0011026413,-0.0021333713,0.006489147,0.03350386,0.02710717,0.0034722928,0.01014293,-0.040407352,0.0032959387,0.003523658,-0.005985767,0.0026641458,0.018286038,-0.00043425063,0.01098532,-0.00274633,-0.0042667426,0.0006998519,0.014354883,0.026285324,-0.023367777,-0.008704702,-0.014998661,0.00328909,-0.01114969,0.019244857,0.025353901,0.01321115,0.0022001462,0.008417057,0.0070952573,0.0020871426,-0.017710747,0.004537266,0.014642528,0.018354526,0.019779056,0.0077801277,0.02145014,-0.014930175,-0.012834471,0.01379329,0.0073623564,0.012019475,-0.0022840428,0.011663343,-0.00708156,-0.0071979878,-0.013457703,0.018875027,-0.010047048,0.009396422,-0.0004417414,-0.004585207,-0.011800316,-0.041010037,-0.008649913,0.0053556864,0.011663343,-0.009115625,-0.00038117316,0.009101927,-0.021121403,-0.025559362,-0.008540333,0.012635859,-0.011642796,0.014190515,-0.001907364,-0.0034072301,-0.0030921898,-0.0002998448,-0.001051276,0.002366227,-0.048653193,-0.038681477,-0.011492125,0.021258377,0.030216482,0.008588275,0.0015495192,-0.027066078,0.0013389216,-0.02128577,-0.009464908,-0.0032873778,-0.014382278,0.0077116406,0.014765806,-0.0025579908,-0.003474005,-0.0029860348,0.013622072,-0.010697675,0.03361344,0.0077116406,-0.021546023,-0.00065447926,0.009163566,0.00014510691,0.021176193,0.005448144,-0.02229938,0.027545488,-0.023586936,-0.0142042115,-0.0070336186,-0.012587918,-0.006968556,0.010711373,0.007506179,0.0044105654,-0.00845815,0.01140994,-0.014601436,0.008827979,-0.01780663,0.00046357163,0.0008025825,0.021491233,0.016217731,-0.00797874,0.025847008,0.01680672,-0.04136617,0.01664235,0.0100128045,-0.015916388,0.008738946,-0.021011824,0.011314059,-0.024422478,0.01632731,-3.2370826e-05,0.025107348,-0.00760891,-0.0056501804,-0.027942711,-0.0053282916,-0.027641369,-0.014738411,-0.01056755,-0.011019564,0.011971534,-0.00354078,-0.0174368,-0.0071021058,0.008026681,-0.022682907,-0.010108687,0.014437067,-0.007287021,0.040078614,-0.0011942427,-0.0027360572,-0.014861687,-0.027709855,-0.0022412383,-0.028874135,-0.0025716883,0.0021573417,0.0211351,0.015300004,0.031476643,0.017573774,0.03164101,-0.0056364834,-0.019779056,-0.0065542096,0.012464641,-0.0044311113,-0.009389573,0.016423192,8.8016546e-05,-0.02969598,0.007725338,0.0048899744,0.0058350954,0.011218177,-0.026244232,-0.0174368,-0.017409405,-0.022093918,0.0006865825,0.022833578,-0.021203587,-0.0062562907,-0.030517824,0.015779413,-0.0031863595,-0.0039585507,0.021176193,0.002491216,0.012923504,-0.004855731,0.022463748,-0.00046057533,-0.0017010468,-0.010793557,-0.030983536,-0.010464819,0.0020974155,0.036599472,-0.019546201,0.015738321,0.016053362,0.0009391285,-0.012553674,-0.02392937,0.00893071,-0.017532682,0.0022737696,-0.006276837,-0.009574488,-0.025737429,-0.012019475,-0.013875474,0.0012892685,0.0066535156,-0.01823125,0.0029175477,0.0066980324,-0.021354258,0.024271807,-0.009725159,0.026189443,0.016080756,0.025860706,0.0029021383,0.0016864933,0.008184201,-0.012026324,-0.005907007,0.010348392,0.011334605,-0.012676951,0.01575202,-0.033805203,0.008554031,-0.0007319552,-0.01342346,-0.0077595813,0.009766252,0.013279636,-0.009533396,-0.0074924817,-0.025847008,-0.0115469145,0.0007525013,-0.008691005,-0.014998661,0.010156628,-0.0076705483,0.0014784639,0.009382724,0.015738321,0.02816187,0.0062631397,0.00061039074,0.020984428,-0.0016496815,0.009526547,0.019861242,0.0016317037,0.008519787,0.024682729,0.008423906,-0.004592056,-0.0022703453,0.008663611,-0.0025271717,-0.0012627298,0.02895632,-0.011026413,0.00036148314,0.0007910253,0.010848347,0.0019844119,-0.0057563353,-0.014122027,0.00295864,-0.0077732787,0.008629367,0.009321086,0.0075541204,-0.03043564,-0.00819105,0.0021761756,-0.004506447,0.0055577233,-0.0022104192,0.0052015907,-0.032298487,-0.014984963,-0.0018354526,0.014574042,0.026490787,-0.013663164,0.007533574,0.024189621,0.0031949203,-0.01786142,-0.007944496,0.021162495,-0.0071774414,-0.021861063,0.02202543,-0.007211685,-0.027504394,0.029093293,-0.00096481113,-0.029504215,-0.023737608,0.004098949,-0.019587293,-0.00066432427,-0.040489536,-0.015121938,0.004818063,0.012697496,0.010327845,0.009327934,-0.0012721467,0.01521782,-0.00049738714,0.004369473,0.0074308435,-0.0087184,-0.01368371,0.013923415,-0.0026350387,-0.037530895,-0.012327666,0.0019878363,0.0015127074,0.010999018,-0.013464551,-0.014313791,0.0058522173,-0.009718311,0.033421673,0.00787601,-0.016519073,-0.019272253,-0.006331627,0.0052015907,0.026751038,-0.02895632,-0.008862223,-0.0023901977,-0.0053180186,-0.03322991,-0.041831885,-0.019696873,0.037010394,0.019491412,-0.009999108,0.00064848666,-0.016245125,-0.020094097,-0.0121496,0.010560702,-0.007074711,-0.0076431534,0.0046468456,-0.006588453,0.018327132,0.00254943,-0.018354526,0.0022806183,0.010478517,-0.012581069,-0.022997947,0.016614955,0.036983002,-0.022217195,-0.014464462,0.004424263,-0.013307031,0.022285681,0.0012413276,-0.0028336511,-0.015436978,0.014615134,0.019628385,0.026271628,0.023751305,0.018368224,-0.013868625,0.003688027,0.014601436,-0.017313523,-0.02631272,-0.014313791,0.009704613,-0.007745884,0.0040852516,-0.011772922,-0.017477892,-0.008567728,-0.0015709214,0.021682996,-0.0012832759,-0.0004545827,0.027175657,0.0031075994,-0.021669298,-0.0018354526,0.02657297,-0.024970373,-0.018792843,0.023696516,-0.039804667,0.005136528,-0.0023508177,-0.019450318,-0.020176282,-0.0022104192,-0.0041982555,-0.006218623,-0.0051878933,0.0096292775,0.007567818,-0.01723134,0.020299558,-0.004458506,-0.014039842,-0.016299915,0.0028439243,0.026901709,0.004458506,-0.0132590905,-0.0015632167,-0.018683264,-0.019984517,0.026668852,0.025600454,0.014738411,0.032682013,0.24611501,-0.01749159,-0.013163209,0.011225025,0.015204122,0.0059720697,-1.5851005e-05,0.03202454,-0.021011824,-0.012978294,0.01669714,0.0063282023,0.004660543,0.002044338,0.0013842942,-0.009992259,-0.021011824,-0.008554031,0.0015983162,0.012978294,0.013567282,0.002908987,0.0004995273,-0.020258466,0.045311023,0.011183933,0.0027086623,0.019285949,-0.014245304,-0.010731919,0.0066295452,0.002626478,0.008026681,0.020463927,-0.01649168,-0.008060925,-0.0059789186,-0.016683443,0.025805917,0.014669923,0.02097073,-0.009636126,-0.0115400655,-0.010855195,0.009307388,0.0031897838,-0.011368848,-0.012615313,0.009992259,0.007115803,-0.023176014,-0.01617664,0.017135456,0.028983714,-0.001567497,-0.010745617,0.0018183308,-0.0040133405,0.034544863,0.014135725,-0.035585865,0.010896288,-0.029202873,0.018450407,-0.005174196,-0.0007439405,-0.0029415183,-0.010348392,0.026545577,-0.026175747,-0.014437067,0.007848615,-0.0020374893,-0.0011411653,-0.025710033,-0.0057083946,0.03344907,0.019587293,0.020039307,0.023217106,-0.01590269,7.8225035e-05,-0.0020683086,-0.010629188,-0.016108152,-0.009848436,0.023997858,-0.016025966,0.0081088655,0.0066877594,5.021491e-05,0.0005234978,-0.013108419,-0.0076773968,0.0013312168,0.004390019,0.0048625795,0.025189532,-0.010184023,0.00063778553,-0.031010931,0.05610458,0.010300451,0.0030425366,0.015368491,0.016162941,0.02435399,0.015094543,0.008471847,-0.015875295,-0.0028045443,-0.050598223,-4.0022114e-05,-0.0073692054,-0.0074376925,0.0058522173,0.0015777701,-0.0035579016,0.03361344,-0.010663432,-0.0060474053,-0.014930175,-0.002354242,0.009773101,0.011759224,-0.02134056,-0.020258466,-0.0015187,-0.015423281,0.0071500465,-0.0011831135,0.017505286,0.0021967217,0.027696159,-0.009971713,-0.019874938,-0.017929906,-0.041010037,0.0034877025,0.009197809,-0.00070199213,0.017245036,0.016587561,-0.016286217,0.0019022275,-0.011560612,0.0121085085,0.009711462,-0.01575202,-0.015368491,-0.005095436,-0.0038523958,-0.015834203,-0.025134742,0.020491323,-0.012464641,-0.012615313,-0.016971087,0.010341543,-0.008054076,-0.011560612,0.004503023,0.008177352,-0.031339668,-0.013128965,-0.007444541,-0.17664176,-0.006482298,0.022778789,-0.04358515,0.018190157,0.021724088,0.012567371,0.003920883,-0.033668227,0.015231517,0.008259537,-0.013861776,-0.020998126,0.0049413396,0.004379746,-0.0029329574,-0.030052112,0.016135545,0.004321532,0.026696248,0.026901709,-0.019491412,0.005218712,-0.0007567818,-0.016423192,-0.0045338417,-0.0031863595,0.0117318295,0.011957837,-0.022011735,0.018573685,-0.011793468,0.010526458,0.0073897513,-0.0049481886,-0.010136082,0.0017584047,-0.02076527,-0.0052392585,0.012711194,0.025915496,0.010663432,-0.018012092,0.029202873,-0.0012053718,0.018806541,0.021094007,0.0026418874,0.009958016,-0.02340887,0.006276837,-0.011800316,-0.000564162,-0.0018628475,0.017779235,0.02076527,0.016738232,-0.009732008,-0.0136426175,-0.029312452,-0.019587293,-0.006567907,0.020011913,-0.0032137542,-0.003386684,-0.0043763216,-0.0030391123,0.027120868,-0.05314594,0.006958283,-0.020354347,0.0031315698,0.005588542,-0.0030990385,-0.0052700774,0.021682996,-0.016532771,0.0052118637,0.018861331,-0.012567371,-0.009485454,0.046680763,-0.004242772,0.016779324,-0.014861687,0.017190246,0.004095525,0.036161155,-0.013800138,-0.010081292,0.010225114,-0.03829795,-0.0014185378,-0.012382456,0.025970284,0.024901887,0.010951078,-0.013943961,0.011170235,0.00066603645,-0.0026795554,-0.002987747,-0.028737161,0.0174368,0.020902244,0.0033027874,0.003999643,0.02176518,0.027887922,0.001780663,-0.036572076,-0.010574399,-0.009581337,-0.0128687145,-0.0023388322,0.029559005,0.005886461,0.00015345377,-0.03139446,0.0060953465,0.067555614,-0.017655957,0.0029843226,0.0010007669,-0.0024603968,-0.030682193,-0.12305751,-0.02514844,0.004290713,-0.002489504,0.009478606,0.003581872,-0.009170414,-0.009848436,-0.025326507,0.017902512,-0.050351672,-0.028134475,-0.0008920437,-0.009307388,-0.015121938,-0.0027206475,0.0056022396,-0.004311259,-0.020532414,0.019724267,-0.033942174,-0.030764377,-0.0155328605,0.0023987584,0.018244946,0.00546869,-0.018861331,-0.002491216,-0.004513296,-0.001313239,0.027435908,-0.021998037,-0.019148976,-0.0029997323,-0.013985053,-0.01130721,0.005965221,-0.009512849,0.024230715,-0.03681863,0.014354883,-0.020847455,-0.011642796,-0.020066703,-0.011608553,0.003571599,-0.02895632,0.029887743,0.007423995,-0.008745795,-0.020409137,0.0040133405,-0.028654976,0.008006135,0.008800585,0.007054165,0.0036229643,0.014834292,-0.008780038,0.016779324,-0.015382188,0.017190246,0.0100196535,-0.0047906684,0.03270941,-0.01780663,-0.020957034,-0.019464016,0.0062905345,-0.032791592,-0.007533574,-0.0012764272,-0.009622429,0.020080399,-0.022491144,-0.010238812,0.0020460503,0.0040921005,-0.0071979878,-0.016573863,-0.0062734126,-0.007567818,0.018149065,-0.020806363,0.0034585954,0.0072048362,-0.009759403,-0.01760117,-0.017162852,-0.013197452,-0.017327221,0.0470095,0.018751752,-0.029915137,0.0032274516,0.0066192723,0.0005538889,0.0029740497,0.0006493427,0.009540244,-0.03298336,-0.009526547,-0.03977727,0.018820237,-0.01606706,-0.018532593,-0.010677129,-0.019669477,0.005273502,-0.0057974276,0.0048351847,-0.011430487,-0.013005689,0.012313969,-0.031010931,0.0033541527,-0.021546023,3.552765e-05,0.010451122,-0.0149712665,0.0169163,-0.009471757,-0.0077595813,-0.016368402,-0.0011326044,-0.01305363,-0.010834649,-0.0044995984,-0.0076226075,0.024436176,-0.022778789,-0.01617664,0.0042975615,-0.023176014,0.0027925589,0.036626868,0.013163209,-0.009149868,0.007848615,0.017655957,0.037311736,-0.023011645,7.351655e-05,-0.04125659,-0.009279993,-0.013176906,0.017683353,0.0041982555,-0.003914034,-0.008081471,-0.009581337,-0.0020100945,0.019491412,0.02281988,-0.010916834,-0.02816187,-0.016587561,-0.015628742,-0.0005637339,-0.01997082,-0.022997947,-0.017162852,0.035284523,-0.0075815152,0.0221898,-0.011101749,0.014245304,0.0068281577,-0.002732633,0.016135545,-0.0026127805,-0.02614835,-0.0027839981,0.0014639104,-0.0037599383,-0.0017267294,-0.00013087445,0.016204033,-0.020505019,0.0062562907,-0.0011308922,0.041119616,-0.0021950095,-0.011772922,-0.028298844,0.0119235935,0.024477268,-0.0019142127,-0.0144096725,0.0036024181,0.004407141,-0.0158479,0.0019244858,0.00856088,0.010314148,0.00040899604,0.0005136528,-0.0033815475,0.0065131173,-0.010519609,0.0005624498,0.015710926,0.0063795676,0.007958194,-0.009581337,-0.02150493,-0.041448355,0.017327221,-0.024504662,-0.050242092,0.013252242,0.006085073,0.018724356,-0.018436711,0.020272164,0.008882768,-0.0061775306,0.023970462,-0.016094454,-0.034791414,-0.036681656,0.022778789,0.004016765,-0.023107527,-0.013026235,0.008396511,0.024792308,0.02838103,0.017409405,-0.024997769,0.023230804,0.015738321,0.0015846188,0.002208707,-0.0016128698,-0.018820237,-0.019313345,-0.017587472,0.009156717,0.015368491,-0.006451479,0.069801986,0.013800138,0.006763095,-0.010492214,-0.0025853857,0.02832624,0.022847276,-6.821951e-05,-0.020641994,-0.025901798,-0.0065918774,0.00813626,-0.029285057,-0.015450676,-0.009732008,0.00029813263,-0.01183456,0.0011625675,-0.02329929,-0.0043489267,0.024107438,-0.00044816206,0.010855195,0.008389662,0.0037119975,0.0035202338,0.0026829797,-0.0026778432,0.020820059,-0.0158479,-0.0024107436,0.014094632,-0.028353633,-0.027148262,0.0056125126,0.013971356,-0.0060439813,-0.01617664,-0.005013251,0.0011839697,-0.0017121759,0.01564244,-0.016669745,-0.011211328,-0.027435908,0.016395796,0.016217731,-0.022778789,-0.0029243964]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
0.6820650027239067
0.6763415895692027
0.7047837273021036
0.7748578800779097
0.7546785759055026
0.751793371462621
0.6839710742378938
0.7228732594238143
0.7653159846234671
0.6960198031431534
0.7299178681460138
0.7263767112615971
0.735939939186916
0.7606101907711289
0.713901989529165
0.6966207430944948
0.6972019870372815
0.6764750093510549
0.750557932798413
0.7987147373739567
0.7484232330219142
0.748000073324641
0.6842498041141591
0.7508345276356558
0.7708142705988741
0.7717083655855929
0.6746693993063738
0.7564110600583012
0.7706479105478041
0.7113918921280061
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0013040254,0.011891205,0.010897988,-0.0060928725,-0.017261427,0.022672746,0.0051373295,0.00062803854,-0.020535618,-0.034522854,0.023248129,-0.0057264096,-0.011069233,0.006897721,-0.02349472,-0.012487135,0.028440256,0.007267609,0.008021084,-0.021686379,-0.007404604,0.01657645,0.0020686314,-0.03972868,-0.017110731,0.021563083,0.028495053,-0.015425688,0.014699612,0.005777783,0.0004161237,0.013357056,-0.023070034,-0.03274191,-0.007705994,0.021453487,0.010925387,-0.01443932,0.0024042702,-1.5585909e-05,0.03249532,0.0046818196,-0.007795041,-0.020590415,0.00993217,0.007370355,0.011863806,-0.021179497,-0.010117114,-0.0045961975,0.020987703,0.02830326,-0.023302926,-0.009493785,-0.011891205,0.009493785,-0.0058497055,0.009575982,0.012439187,-0.002229601,0.018151898,0.009802025,-0.013343357,0.010740443,-0.029344425,-0.013487202,0.004277683,0.009651329,-0.023357725,0.020234227,0.049290963,0.029262228,-0.0011413434,-0.015096898,0.009877372,-0.012007651,-0.011898055,-0.015768176,0.0050996556,0.009062249,0.0014101969,-0.022480953,-0.027549785,0.03945469,0.0094047375,-0.03378308,0.010445903,0.026659315,-0.018439587,0.009815724,-0.010939087,0.01743952,0.020494519,-0.0042057605,0.0052298014,0.0019727345,0.013035117,0.023905706,0.009726677,0.0023597467,-0.011363773,0.009747227,-0.048386794,-0.00872661,-0.01564488,0.00031080842,0.016823042,0.0006515846,0.011980252,-0.027440188,-0.048852578,0.04400294,0.007548449,-0.030906174,0.011206227,-0.0049181366,-0.001746692,-0.043454956,-0.0077539426,-0.0062812413,0.006726477,0.030522587,0.02887864,-0.005541466,0.019809542,-0.0059764264,-0.03400227,-0.025974337,-0.024015302,-0.009158146,0.027864875,0.01416533,-0.022261761,0.033344693,-0.023111133,0.004907862,-0.0057435343,0.033070702,-0.04008487,-0.015233894,0.02471398,0.0013485489,0.00632919,0.020837007,-0.0034248861,0.02072741,0.00042875294,0.030303394,-0.0052640503,-0.010576049,-0.0014889693,-0.017946403,0.020919206,0.003935194,0.017357323,0.019384855,0.008452619,-0.0019025243,-0.014959903,-0.015809275,-0.00086478377,0.0049934844,0.0025258537,0.014261226,0.01594627,0.018288892,0.016096964,-0.0013956411,-0.006144246,0.011706261,-0.010932237,0.02953622,-0.018740978,0.028714247,0.003579006,0.013158413,0.02201517,-0.027618283,-0.004907862,-0.0006982487,-0.010500701,0.020590415,-0.0016353832,0.012219994,-0.009151296,-0.01413793,0.0010933949,-0.029070435,-0.00040948796,-0.018480686,-0.011007585,0.015466786,0.008096431,0.012767976,-0.66064686,-0.02887864,0.0008634995,-0.01445302,0.013699545,0.019247862,0.0061545204,-0.019850641,-0.024481086,0.020289026,-0.019973937,0.0031423331,0.016699746,-0.03257752,-0.016329858,-0.042085003,0.019946538,-0.020001335,-0.013795442,0.015302392,-0.018782075,0.010925387,-0.014905105,0.02079591,-0.003637229,0.013281709,-0.0077813417,-0.008390971,0.033509087,0.021672681,-0.0027810077,0.02860465,-0.015918871,0.010500701,0.04008487,-0.01624766,-0.019494453,0.0054866676,-0.012274792,0.043345362,-0.048551187,-0.0138228405,0.014021484,0.004154387,-0.0037502504,0.0063326145,0.008980052,-0.010384255,0.01868618,0.013220061,0.0016995998,0.026015436,0.0024094074,0.007384055,0.01896017,-0.010891139,0.01443932,-0.008075882,0.016960036,0.00077316805,0.009301991,0.0036851775,-0.0118501065,-0.0024710554,0.00871976,0.03487904,0.01416533,0.026878508,-0.0053017237,-0.021110998,0.004452352,0.008891005,-0.0037399759,-0.010370555,-0.0008129824,-0.00308411,0.0055140667,0.007562149,0.016768243,0.010110265,-0.004424953,-0.022782343,0.0051270546,0.011322674,-0.0069114203,0.006651129,-0.020056134,-0.0089869015,0.003253642,-0.012439187,0.019768443,0.03255012,-0.006959369,-0.030960971,-0.012226844,0.025618149,0.00093242526,0.015480486,0.001959035,-0.014069432,-0.012480286,0.013041967,-0.0053188484,0.007795041,0.018795775,-0.0004204048,-0.031536352,0.02833066,0.03852312,0.0031560326,-0.0019538975,0.018179296,-0.032002136,0.01894647,-0.0042948076,-0.031728145,0.006709352,-0.0031320585,-0.0057264096,-0.013583099,0.027522385,-0.0027638832,0.019083466,-0.0146585135,0.009137597,0.025481153,0.004027666,-0.01595997,0.0068223733,0.017275127,0.024618082,0.0240975,0.013980386,-0.008158079,0.022179563,0.012562483,-0.0035070835,0.009062249,0.007596398,-0.010432203,-0.010610297,0.012761126,3.871727e-05,0.010130813,-0.016316159,0.0050619817,-0.007103214,0.0105965985,-0.0029847883,-0.010281509,0.008041633,-0.018261494,-0.010582899,-0.0012415212,-0.015411988,0.0028666297,0.013103615,-0.029782811,-0.006654554,-0.034605052,0.012535084,0.042605586,-0.024522185,0.005962727,-0.007870388,-0.0031234962,-0.01293922,0.024960572,-0.0017706662,-0.019494453,0.01474071,-0.02981021,-0.003914645,0.029700613,-0.009986969,0.006836073,-0.00044651955,-0.01926156,-0.006418237,-0.015891472,-0.00874031,-0.019234162,0.015768176,0.008274525,0.015699679,0.011247327,0.027316893,0.00842522,-0.032687113,0.041153435,-0.0058565554,0.007315557,-0.010096565,0.010281509,0.011788459,-0.007616947,0.009719827,-0.003668053,0.006897721,0.003527633,0.0054215947,0.00932939,0.026399024,-0.025946938,-0.0062778164,-0.009774625,0.008041633,-0.021042502,0.021823375,0.0123295905,0.01838479,0.00038636997,-0.008062182,-0.015151697,0.0092266435,-0.0028871791,0.00025472592,0.007116914,-0.009363639,0.03285151,-0.010630847,-0.013959836,0.052907642,-0.0037879243,0.013514601,0.02498797,-0.009130747,0.012302191,0.022069966,-0.02920743,-0.0017090183,0.003361526,0.0063120653,0.0271114,0.013446104,0.003130346,-0.022796042,-0.0049592354,0.012802225,-0.012493985,0.013959836,0.01567228,-0.004548249,-0.01174736,0.038057335,0.0048736134,0.032714512,0.019631447,0.0014555766,-0.010466453,-0.011898055,0.0013768043,-0.017357323,-0.0049934844,0.007986834,-0.0029967756,0.012589882,-0.0032365175,0.018165596,0.021850774,0.017316224,0.022754945,0.018877974,-0.034194063,0.03222133,0.005839431,-0.0095828315,-0.026029136,-0.021494586,-0.029015636,-0.022645349,0.0045242747,0.016466852,-0.042194597,0.037098367,0.0053188484,0.01953555,0.012363839,0.037755948,0.01415163,-0.021768577,-0.0180423,0.003582431,0.014411922,0.004877038,0.002118292,-0.010945937,0.0049626604,-0.008596464,-0.001422184,0.003647504,0.01956295,-0.0038324478,-0.0029385523,-0.007651196,0.014206428,0.013939287,-0.0052743247,-0.01174051,-0.012713178,-0.01295292,0.006928545,-0.019056067,-0.030796576,0.03767375,0.007247059,0.015713379,-0.016480552,-0.008849906,-0.026659315,0.006449061,-0.018877974,-0.0025618149,-0.021795977,0.01623396,0.004037941,-0.028659448,0.016918939,0.028440256,-0.0030156123,-0.002983076,0.0011233627,-0.0021354165,0.0065209833,0.033536486,0.027152497,0.0034676974,0.010151363,-0.04044106,0.003330702,0.003551607,-0.005966152,0.0026354499,0.018275194,-0.00042254533,0.011007585,-0.0027279218,-0.0042879577,0.0007320694,0.014329724,0.026234629,-0.023371425,-0.008706061,-0.015001002,0.00330844,-0.011158279,0.01927526,0.025330458,0.0132269105,0.0021850774,0.008377272,0.007103214,0.0021234294,-0.017686112,0.00452085,0.014644814,0.018329991,0.019836942,0.007795041,0.021453487,-0.014905105,-0.012836474,0.01383654,0.007349806,0.012069299,-0.002257,0.011665163,-0.007116914,-0.00722651,-0.013494052,0.018864274,-0.010048617,0.009411587,-0.00041912045,-0.0045824978,-0.011809008,-0.041071236,-0.008671812,0.0053599468,0.011706261,-0.009082798,-0.00042404374,0.009082798,-0.021165797,-0.025522253,-0.008527967,0.01265838,-0.011665163,0.014206428,-0.0018939622,-0.003447148,-0.0030926722,-0.0003311437,-0.0010514401,0.0023580343,-0.048660785,-0.038714916,-0.011514467,0.021234294,0.030221196,0.008562216,0.0015129435,-0.027084,0.0013519739,-0.021261694,-0.009507484,-0.003311865,-0.014398222,0.0077196937,0.014795508,-0.0025344158,-0.003474547,-0.0029505396,0.013631048,-0.010713045,0.033646084,0.007685445,-0.021494586,-0.0006678528,0.009185545,0.00018205411,0.021179497,0.0054558436,-0.022302859,0.027577184,-0.023631714,-0.0141790295,-0.007055266,-0.012548783,-0.006990193,0.010754143,0.00752105,0.004431803,-0.008370422,0.011404871,-0.014576316,0.008815657,-0.017795708,0.00048333706,0.00078344275,0.021467187,0.016192863,-0.007945736,0.02587844,0.016795643,-0.041400027,0.016713444,0.010048617,-0.01594627,0.008760859,-0.021056201,0.011295275,-0.024467388,0.016316159,-2.1579459e-05,0.025070168,-0.007616947,-0.0055962643,-0.027933372,-0.0053222734,-0.027631983,-0.014727011,-0.010569199,-0.011028133,0.011952853,-0.003558457,-0.01745322,-0.007116914,0.008000534,-0.022686446,-0.010089715,0.01446672,-0.007308707,0.04008487,-0.0012012789,-0.0027621707,-0.014850306,-0.02772788,-0.0022193263,-0.02890604,-0.002573802,0.0021628158,0.021179497,0.015261293,0.031481553,0.017617615,0.03164595,-0.0056133885,-0.019795842,-0.0065518073,0.012452886,-0.004448927,-0.009377339,0.016439455,0.00013667437,-0.029755412,0.0077196937,0.0048701884,0.0058531305,0.011233627,-0.026262028,-0.01745322,-0.017384723,-0.022097366,0.0006824086,0.022782343,-0.021247994,-0.0063017905,-0.030495187,0.015795575,-0.003188569,-0.003976293,0.021152098,0.0024470813,0.01293237,-0.0048599136,0.022439854,-0.00042168912,-0.0016636385,-0.010795241,-0.030988371,-0.010487001,0.002125142,0.036550388,-0.019508151,0.015795575,0.016042167,0.0010060603,-0.012541934,-0.023933105,0.008945803,-0.017617615,0.0022638498,-0.006260692,-0.009575982,-0.025741445,-0.012082999,-0.01387764,0.0012903259,0.006654554,-0.018261494,0.0029505396,0.006716202,-0.02137129,0.024275593,-0.009678729,0.02617983,0.016042167,0.025851041,0.0029162907,0.0016670633,0.008178628,-0.011987102,-0.005901079,0.010350007,0.011350073,-0.012672079,0.015781876,-0.03378308,0.008555366,-0.0007620372,-0.013411854,-0.0078087407,0.009781475,0.01326116,-0.009562283,-0.00752105,-0.02586474,-0.011555566,0.00073635054,-0.00874031,-0.0150421,0.0101239635,-0.007678595,0.0014821196,0.009384188,0.015727079,0.028221063,0.006325765,0.0005860837,0.021042502,-0.0016233961,0.009534883,0.019891739,0.001634527,0.0085074175,0.024727678,0.00842522,-0.004609897,-0.0022587124,0.008637563,-0.0025412657,-0.0012654954,0.02893344,-0.011034983,0.00039899925,0.0008211165,0.010829491,0.0019932839,-0.0057469592,-0.014096832,0.0030207497,-0.0077813417,0.008637563,0.009315691,0.007562149,-0.030440388,-0.008206028,0.0022124765,-0.004544824,0.0056270882,-0.0021919273,0.0051613036,-0.032303527,-0.014987302,-0.0018066275,0.014590016,0.02649492,-0.013665296,0.007555299,0.024152298,0.0031851442,-0.017891606,-0.007945736,0.021138398,-0.00721966,-0.021850774,0.02200147,-0.00721281,-0.027494987,0.029125232,-0.0009486935,-0.02950882,-0.023727613,0.0041372627,-0.01959035,-0.00066528417,-0.04041366,-0.015137997,0.0048222397,0.012706328,0.010288359,0.009315691,-0.0012749139,0.015233894,-0.00050602696,0.0043461807,0.007438853,-0.00874031,-0.013692696,0.013925588,-0.002589214,-0.03761895,-0.01235014,0.001983009,0.0015411988,0.010945937,-0.013487202,-0.014316024,0.005842856,-0.009712977,0.033399493,0.0078498395,-0.016507952,-0.01926156,-0.0062743914,0.0051373295,0.02679631,-0.02893344,-0.008856756,-0.0023837208,-0.0052982992,-0.033235095,-0.04186581,-0.019713646,0.03704357,0.019494453,-0.010014367,0.0006306072,-0.01623396,-0.020124631,-0.012144647,0.010617147,-0.007068965,-0.0076580457,0.004698944,-0.00661688,0.018316291,0.0025378407,-0.01834369,0.0022398755,0.010452753,-0.0125693325,-0.022946738,0.016603848,0.037016172,-0.022261761,-0.014507818,0.004448927,-0.013322808,0.02228916,0.0012732014,-0.0028409432,-0.015466786,0.014590016,0.019617748,0.026275728,0.02378241,0.018425887,-0.01386394,0.0036612034,0.014631114,-0.017288826,-0.026316825,-0.014329724,0.009740377,-0.007774492,0.00406534,-0.011795308,-0.017521719,-0.008562216,-0.0016319583,0.021713778,-0.0012509397,-0.0004356027,0.027193597,0.0031389082,-0.021672681,-0.0018151897,0.026618216,-0.02497427,-0.018823175,0.023713913,-0.039810877,0.0051852777,-0.002361459,-0.019439654,-0.02022053,-0.0021816525,-0.004236584,-0.006257267,-0.0051750033,0.00963763,0.00753475,-0.017234027,0.020289026,-0.004421528,-0.014069432,-0.016316159,0.0028272436,0.026878508,0.0044729016,-0.013295408,-0.0015848661,-0.018699879,-0.019987635,0.026700413,0.025631849,0.014713312,0.032604918,0.24637261,-0.017494319,-0.013172112,0.011226777,0.015220194,0.0059764264,2.0910536e-05,0.032002136,-0.021015102,-0.013000868,0.016699746,0.006346314,0.004637296,0.0020429445,0.0014067721,-0.009980119,-0.020974003,-0.008589615,0.0015677417,0.013035117,0.01353515,0.0029128657,0.0005026021,-0.020261627,0.045318093,0.011124031,0.0027227846,0.019288959,-0.014274926,-0.0107198935,0.006664829,0.0026388748,0.008048482,0.020494519,-0.016507952,-0.008075882,-0.006055199,-0.016727144,0.025823642,0.014699612,0.020987703,-0.009651329,-0.011541867,-0.010884289,0.009288291,0.0031663072,-0.011356923,-0.012583032,0.009993818,0.007158012,-0.02315223,-0.016165463,0.017110731,0.02893344,-0.0015531859,-0.010740443,0.0018306017,-0.004034516,0.034632448,0.01415163,-0.035591416,0.010870589,-0.029234828,0.018412188,-0.0052126767,-0.0007106639,-0.0029265652,-0.010329457,0.02653602,-0.02617983,-0.01445302,0.007863539,-0.002051507,-0.0011370622,-0.025714045,-0.0057127103,0.033509087,0.01959035,0.019987635,0.02319333,-0.015877772,0.00016182587,-0.0020806184,-0.010610297,-0.016124364,-0.009815724,0.023987904,-0.016014768,0.008103281,0.006695653,5.305898e-05,0.00048975874,-0.013076216,-0.0076648956,0.0013279996,0.0044181035,0.00481539,0.025193464,-0.010185611,0.0006207606,-0.031043168,0.056058537,0.010350007,0.0030704106,0.015425688,0.016151763,0.02435779,0.015151697,0.008473168,-0.015864072,-0.0027878573,-0.05057872,-2.5512727e-05,-0.007342956,-0.007425153,0.0058360063,0.0015189371,-0.003524208,0.03370088,-0.010658246,-0.006024375,-0.014905105,-0.002303236,0.009767775,0.011774759,-0.02134389,-0.020316426,-0.0015163684,-0.015411988,0.007144313,-0.0011738797,0.017535418,0.0022176139,0.02771418,-0.009925321,-0.01986434,-0.017932704,-0.040989038,0.003453998,0.009192395,-0.0007003892,0.017275127,0.016590148,-0.01628876,0.0019076617,-0.011562416,0.012117247,0.009692428,-0.015754476,-0.01535719,-0.0051407544,-0.0038632718,-0.015781876,-0.025083868,0.020535618,-0.012487135,-0.01263783,-0.017001135,0.010315757,-0.008062182,-0.011555566,0.004486601,0.008199178,-0.03134456,-0.013124164,-0.007466252,-0.17655973,-0.006503859,0.022782343,-0.043564554,0.018165596,0.021700079,0.0125693325,0.0038906708,-0.03367348,0.015206495,0.008295074,-0.013918738,-0.020974003,0.0049455357,0.0043564555,-0.0029591017,-0.030056803,0.016110664,0.004332481,0.026700413,0.026905907,-0.019508151,0.0052229515,-0.0007954298,-0.016425755,-0.00452085,-0.0031834317,0.01174736,0.011932304,-0.022042569,0.018562883,-0.011802158,0.010589749,0.0074525527,-0.0049592354,-0.010117114,0.0017569667,-0.020713711,-0.0052366513,0.012699478,0.025851041,0.010637697,-0.0180423,0.029234828,-0.0012089849,0.018768376,0.021110998,0.0026200379,0.009986969,-0.023385122,0.0062778164,-0.011856956,-0.0005591127,-0.0018734128,0.01778201,0.02078221,0.016740844,-0.009747227,-0.013685846,-0.029344425,-0.019658847,-0.006592906,0.020015035,-0.0032450797,-0.003346114,-0.004394129,-0.0030549986,0.0270977,-0.053181633,0.006966219,-0.020316426,0.0031371957,0.0055894144,-0.003157745,-0.0052503506,0.021617882,-0.01654905,0.0052024024,0.018864274,-0.012576182,-0.009480085,0.04668805,-0.004216035,0.016768243,-0.014850306,0.017220328,0.004103014,0.036248997,-0.013809142,-0.010130813,0.010219861,-0.038331326,-0.0014076283,-0.012425487,0.026015436,0.024919473,0.010952787,-0.013952986,0.011165129,0.00070167356,-0.0026970978,-0.0030207497,-0.028741645,0.01748062,0.020905506,0.0032827535,0.003996842,0.021795977,0.027919672,0.0017997777,-0.03652299,-0.010521251,-0.009589681,-0.012877572,-0.0023254978,0.029591016,0.0058805295,0.0001789503,-0.03137196,0.0060928725,0.067620955,-0.017658714,0.0029745137,0.0009889359,-0.0024710554,-0.03068698,-0.1232959,-0.025111265,0.0042537088,-0.0024933172,0.009486935,0.0035653065,-0.009151296,-0.009829423,-0.02531676,0.017864207,-0.050386928,-0.028138865,-0.00084466254,-0.009349939,-0.015124298,-0.0026936731,0.005630513,-0.0043187817,-0.020563018,0.019686246,-0.03397487,-0.030769179,-0.015576383,0.0023957079,0.018192995,0.0055140667,-0.018864274,-0.0024505062,-0.0044934507,-0.0012886134,0.027467588,-0.02201517,-0.019206762,-0.0030002003,-0.013980386,-0.011295275,0.005966152,-0.009480085,0.024248194,-0.036851775,0.014343424,-0.020837007,-0.011644613,-0.020042434,-0.011589815,0.00361668,-0.028960839,0.029892407,0.007425153,-0.008788258,-0.020480819,0.0039865677,-0.028686848,0.008021084,0.008788258,0.0070895148,0.0036235296,0.0148366075,-0.008767709,0.016809342,-0.015384589,0.01715183,0.009980119,-0.0047434676,0.032687113,-0.017864207,-0.021001402,-0.019467054,0.0062812413,-0.03279671,-0.007500501,-0.0012860448,-0.009596531,0.020097233,-0.02253575,-0.010213011,0.002029245,0.00407219,-0.007164862,-0.016590148,-0.006291516,-0.0075758486,0.018192995,-0.02078221,0.003419749,0.007253909,-0.009726677,-0.017617615,-0.01716553,-0.013185812,-0.017316224,0.047044236,0.018809475,-0.029919807,0.003293028,0.006596331,0.0005646781,0.0029539643,0.0006361726,0.009575982,-0.032988504,-0.009555433,-0.039783478,0.018850574,-0.016069567,-0.018521786,-0.010699345,-0.019699946,0.0052263765,-0.0058497055,0.0048325146,-0.011466519,-0.012994018,0.012281642,-0.031043168,0.003400912,-0.021535685,3.2215336e-05,0.010466453,-0.014959903,0.01689154,-0.009480085,-0.007795041,-0.016329858,-0.0011507617,-0.0130488165,-0.010863739,-0.0045037256,-0.0076580457,0.024426289,-0.022768645,-0.016151763,0.004240009,-0.023234429,0.0027775827,0.036632583,0.013158413,-0.009151296,0.007877238,0.017686112,0.037290163,-0.023070034,8.722757e-05,-0.04126303,-0.009274592,-0.013124164,0.01774091,0.004216035,-0.0038975205,-0.008027934,-0.009603381,-0.002013833,0.019467054,0.022809742,-0.010918537,-0.028166264,-0.016603848,-0.01564488,-0.0005689592,-0.019973937,-0.022960437,-0.01716553,0.035344828,-0.007562149,0.022206962,-0.01113773,0.014288626,0.0068223733,-0.0027450463,0.016083267,-0.0025840767,-0.026070233,-0.002786145,0.0014598578,-0.00376395,-0.0017021685,-0.00013271434,0.016192863,-0.020494519,0.006298366,-0.0011344936,0.041126035,-0.002214189,-0.0117336605,-0.028358059,0.011939153,0.024467388,-0.001924786,-0.014411922,0.003579006,0.004397554,-0.015864072,0.001928211,0.008562216,0.010370555,0.00033242803,0.0005085956,-0.003453998,0.0065483823,-0.010528101,0.00058908045,0.015768176,0.0063326145,0.007918337,-0.009603381,-0.021535685,-0.04148222,0.017343624,-0.024494786,-0.05027733,0.01325431,0.0060620485,0.01867248,-0.018412188,0.020302726,0.008884155,-0.006171645,0.023987904,-0.016069567,-0.03487904,-0.03668738,0.022796042,0.004031091,-0.023111133,-0.013021418,0.008404671,0.024768777,0.028358059,0.01743952,-0.02497427,0.02317963,0.015713379,0.0015857223,0.0022381633,-0.0015934283,-0.018864274,-0.019343758,-0.017603915,0.009178695,0.015384589,-0.006449061,0.06981288,0.013802292,0.006716202,-0.010528101,-0.0025960638,0.028358059,0.022850841,-5.2068975e-05,-0.020631514,-0.02589214,-0.0066066054,0.008164929,-0.029289627,-0.015466786,-0.009760926,0.000293684,-0.011877505,0.0011473369,-0.023289226,-0.0043187817,0.024165997,-0.00050217396,0.010850039,0.008390971,0.003767375,0.003493384,0.0026885357,-0.0026611367,0.02078221,-0.015850374,-0.0023854333,0.014110532,-0.028385457,-0.0271251,0.0056373626,0.013905038,-0.0060757482,-0.016165463,-0.0050243083,0.0011550429,-0.0017098745,0.01565858,-0.016658647,-0.011226777,-0.027412789,0.016494252,0.016206563,-0.022782343,-0.0029094408]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0013022454,0.011876889,0.010897422,-0.006106255,-0.017301627,0.022671571,0.0051062405,0.00062800595,-0.020507155,-0.034575857,0.023233222,-0.0057500857,-0.011068658,0.0068733897,-0.023466103,-0.012486487,0.028466176,0.007260382,0.008000119,-0.021657856,-0.0073973704,0.016602987,0.0020342767,-0.039754014,-0.017123543,0.02161676,0.028493574,-0.015411188,0.014698849,0.0057946066,0.0004606233,0.013404309,-0.023055138,-0.032740213,-0.0077124434,0.021466073,0.0109522175,-0.014411173,0.0024349678,-1.9491406e-05,0.03252103,0.0046815765,-0.007787787,-0.020616746,0.009897407,0.007356274,0.011883738,-0.021205794,-0.01010289,-0.004571986,0.020986613,0.028274393,-0.023301717,-0.009541238,-0.011904286,0.009493292,-0.0058802245,0.009554937,0.012404294,-0.0021781146,0.018150955,0.009760419,-0.013363212,0.010753585,-0.0293703,-0.01350705,0.0042808857,0.009657678,-0.023315415,0.020274274,0.0493432,0.029178517,-0.0011181673,-0.015082416,0.009883708,-0.012007028,-0.011883738,-0.015753658,0.0050891167,0.009068628,0.0014392338,-0.022493485,-0.027562054,0.039507437,0.009459045,-0.033781324,0.01045221,0.026657932,-0.01843863,0.009835763,-0.0109522175,0.017438615,0.020493455,-0.0042363643,0.0052535026,0.0020103038,0.013048139,0.02386337,0.009739871,0.0023116781,-0.0113357855,0.009678226,-0.048466474,-0.008726157,-0.01563037,0.0002654149,0.016863264,0.00068665406,0.011965931,-0.027425066,-0.04885004,0.04402805,0.0075617563,-0.030931966,0.0112604415,-0.0048699356,-0.0017534507,-0.043425303,-0.007726142,-0.006260367,0.0067021544,0.030575797,0.02890454,-0.005517205,0.019835912,-0.0059658424,-0.03397311,-0.025972988,-0.024055153,-0.009185068,0.027904525,0.014164594,-0.022301702,0.03337036,-0.023109933,0.0048836344,-0.005708989,0.032986794,-0.040110186,-0.015219404,0.024712697,0.0013604654,0.0063391356,0.020822227,-0.0034555309,0.020712636,0.00041653018,0.030247025,-0.0052706264,-0.010561801,-0.001493173,-0.017959172,0.020945517,0.003945264,0.017356422,0.019370152,0.008472729,-0.0019109873,-0.014945428,-0.015808454,-0.00089470507,0.004979526,0.0025359967,0.014301582,0.015931744,0.018301642,0.01608243,-0.001348479,-0.0061370777,0.011691955,-0.01093167,0.029507289,-0.018781101,0.028740153,0.0035616967,0.013185128,0.022014026,-0.027630549,-0.00487336,-0.000729891,-0.010520704,0.020644143,-0.0016318735,0.01221936,-0.009116574,-0.014150895,0.0010882011,-0.029123722,-0.0003829252,-0.018493425,-0.011054959,0.01550708,0.008048065,0.012760464,-0.6606126,-0.028849743,0.00086345465,-0.014438571,0.013698834,0.019219464,0.0061507765,-0.019890707,-0.024479816,0.020301672,-0.0199592,0.0031438824,0.016726276,-0.032575827,-0.016315311,-0.042082816,0.020000298,-0.020027695,-0.013787876,0.0152878985,-0.018808499,0.010917971,-0.014931729,0.020781131,-0.0036507393,0.013294718,-0.007739841,-0.008376837,0.033562142,0.021657856,-0.002765452,0.028603164,-0.015890647,0.010465909,0.040082786,-0.016233118,-0.019424947,0.005486383,-0.0123358,0.043343112,-0.048576064,-0.013828973,0.013959112,0.0041062254,-0.0037329323,0.006311738,0.008993285,-0.010404265,0.018685209,0.013219375,0.0016763948,0.026082579,0.0024161318,0.007356274,0.018972885,-0.010870025,0.014424872,-0.00809601,0.016959157,0.0007748403,0.009308358,0.00370211,-0.011815244,-0.002460653,0.008733006,0.03490463,0.014150895,0.026849715,-0.0053185723,-0.021109903,0.004476094,0.008869995,-0.003770604,-0.01033577,-0.0008206458,-0.0031062106,0.0055035064,0.0075343587,0.016808469,0.01010289,-0.0044452716,-0.022767462,0.0051199393,0.011349484,-0.0069590076,0.006650784,-0.020055093,-0.00904808,0.0032312125,-0.012459089,0.019753719,0.032548428,-0.0069829808,-0.030959364,-0.012239908,0.025657916,0.0009751857,0.015493381,0.0019400973,-0.014068702,-0.012486487,0.013061838,-0.005349395,0.007808335,0.018753704,-0.00039705215,-0.031562112,0.028329188,0.038575917,0.0031438824,-0.001962358,0.018137256,-0.03205527,0.018945487,-0.004301434,-0.031699102,0.0067124288,-0.0031507318,-0.0057398113,-0.0135823935,0.027534656,-0.0027671645,0.019082475,-0.014671451,0.009157671,0.025438735,0.00405143,-0.016013937,0.0068288688,0.017274229,0.024630504,0.024068851,0.0139728105,-0.008157656,0.022151014,0.012596078,-0.003500052,0.009089177,0.0075960034,-0.010424812,-0.010616596,0.012712518,6.6139684e-05,0.010130288,-0.016287914,0.005061719,-0.007095996,0.010602897,-0.00296751,-0.010267276,0.008034366,-0.018233148,-0.010589198,-0.0012671421,-0.015397489,0.002866481,0.013089236,-0.029781265,-0.0066439346,-0.034603253,0.012541282,0.042603374,-0.024534611,0.0059487186,-0.007849432,-0.0030634017,-0.01292485,0.024945576,-0.0017603001,-0.019534538,0.014767343,-0.029863458,-0.0039212913,0.029699072,-0.010013848,0.0068185944,-0.00043108518,-0.019287959,-0.006448726,-0.015918044,-0.008739856,-0.019233163,0.015781056,0.008253547,0.015685165,0.011219345,0.027288077,0.008479578,-0.032658022,0.041151296,-0.00581858,0.007322027,-0.010089192,0.010280975,0.011815244,-0.007623401,0.009719322,-0.0036678629,0.0068528415,0.003489778,0.0054213135,0.0093289055,0.02642505,-0.025972988,-0.0063185873,-0.009760419,0.008027516,-0.02102771,0.02184964,0.012287854,0.018370137,0.00041053692,-0.008075463,-0.015137211,0.009219315,-0.0028990158,0.00027397668,0.0071096946,-0.009335755,0.0329046,-0.010602897,-0.013959112,0.0528775,-0.0037808781,0.013561846,0.024959275,-0.009130273,0.012301553,0.02206882,-0.029178517,-0.0016875251,0.0033322414,0.006298039,0.027123692,0.013438556,0.0031404577,-0.022863355,-0.004924731,0.012794711,-0.0125001855,0.0139728105,0.015671466,-0.0045480127,-0.011691955,0.03805536,0.004887059,0.032740213,0.019698923,0.0014221102,-0.010465909,-0.011904286,0.001353616,-0.01739752,-0.0050377464,0.008006969,-0.0029383998,0.012589228,-0.003205527,0.018137256,0.021835942,0.017287929,0.022767462,0.018876994,-0.03416489,0.03227445,0.005849402,-0.009630281,-0.026041484,-0.021479772,-0.028986733,-0.022657871,0.0045171906,0.016507095,-0.042219806,0.03712384,0.0053219968,0.019561935,0.012397445,0.037781384,0.0141234975,-0.021808544,-0.018013967,0.0036233417,0.014411173,0.004852812,0.0021472923,-0.010917971,0.004945279,-0.008589169,-0.0014032742,0.0036747123,0.019575633,-0.00381855,-0.0028836045,-0.0076850457,0.014191992,0.013904316,-0.005263777,-0.0117399,-0.012739915,-0.012945398,0.0069487337,-0.019082475,-0.030822376,0.037671793,0.0072192857,0.015712563,-0.016507095,-0.008869995,-0.026699027,0.006428178,-0.01891809,-0.002547983,-0.021808544,0.016178323,0.0040377313,-0.028603164,0.01693176,0.028438779,-0.0030188805,-0.0029949076,0.0011155988,-0.0021353057,0.006482973,0.033534747,0.027164787,0.0034366949,0.010123438,-0.04041156,0.0033459403,0.0035753956,-0.0059658424,0.0026507243,0.018287944,-0.0004171723,0.010965916,-0.0027517532,-0.0042466386,0.00068665406,0.014356378,0.02630176,-0.023342812,-0.008712458,-0.01504132,0.0032620349,-0.011130302,0.019233163,0.025329145,0.013198826,0.0021866763,0.008438482,0.0071028452,0.0021301687,-0.017698893,0.0045411633,0.01468515,0.018356437,0.019808514,0.0077946363,0.021452375,-0.014945428,-0.012835807,0.013828973,0.0073699728,0.012041275,-0.002325377,0.011650858,-0.0071096946,-0.007198737,-0.013513899,0.018863294,-0.010048095,0.009417948,-0.0004199549,-0.00458226,-0.011815244,-0.0410965,-0.008664512,0.0053562443,0.011671406,-0.009075478,-0.0004126774,0.009075478,-0.0211373,-0.025589421,-0.008506976,0.0126508735,-0.011650858,0.014219389,-0.001885302,-0.003412722,-0.00311306,-0.0002938828,-0.0010710775,0.002373323,-0.048685655,-0.038712904,-0.011534418,0.021246891,0.030219628,0.008561771,0.0015282761,-0.027055196,0.0013673148,-0.021287987,-0.009500141,-0.0033082685,-0.014411173,0.0076987445,0.014767343,-0.0025394214,-0.0034795038,-0.0029880581,0.013609791,-0.010712489,0.033671733,0.0077329916,-0.021534568,-0.00066953053,0.009205616,0.00012821253,0.021150999,0.0054692593,-0.0223154,0.027548354,-0.023616789,-0.0142056905,-0.0070206523,-0.012568681,-0.006979556,0.010753585,0.007506961,0.0044486965,-0.008438482,0.011424827,-0.014602957,0.008822049,-0.017808484,0.00049144565,0.0008095155,0.021466073,0.016246816,-0.00799327,0.025877098,0.016849566,-0.041425273,0.01668518,0.010054944,-0.015918044,0.008726157,-0.02102771,0.011315237,-0.02443872,0.016356409,-2.0682028e-05,0.025082564,-0.007623401,-0.005616522,-0.02795932,-0.005308298,-0.027671644,-0.01468515,-0.010561801,-0.011075507,0.011965931,-0.0035103261,-0.01750711,-0.0071233935,0.0080138175,-0.022657871,-0.010109739,0.014438571,-0.007274081,0.04013758,-0.00118923,-0.0027534657,-0.0148221385,-0.027712742,-0.0022551706,-0.02890454,-0.0025428461,0.0021627033,0.021164699,0.0152878985,0.03147992,0.017589303,0.031644307,-0.0056199464,-0.019794814,-0.0065377685,0.012472788,-0.004417874,-0.0094042495,0.016438602,9.102233e-05,-0.029753868,0.007705594,0.004890484,0.005815155,0.011239893,-0.026233267,-0.01749341,-0.01739752,-0.022096219,0.000662253,0.022781162,-0.02126059,-0.0062843403,-0.030521002,0.015794756,-0.0032021024,-0.0039281407,0.021192096,0.0024777765,0.012965946,-0.0048699356,0.022466088,-0.00043879077,-0.0016798195,-0.010787832,-0.03101416,-0.0104864575,0.002097634,0.036603283,-0.019561935,0.015753658,0.016068732,0.0009888846,-0.012513884,-0.02397296,0.008911092,-0.017603002,0.002267157,-0.0063014636,-0.009582334,-0.025753807,-0.012041275,-0.013897467,0.0013133757,0.0066542085,-0.018246846,0.002924701,0.0067227026,-0.02139758,0.024260635,-0.009685076,0.02619217,0.016055033,0.025877098,0.002885317,0.0016515657,0.008178204,-0.012020727,-0.005897348,0.010376867,0.011356333,-0.01268512,0.015753658,-0.033808723,0.00857547,-0.00074615836,-0.013445405,-0.00775354,0.009794666,0.013267321,-0.00952069,-0.007506961,-0.025877098,-0.011527569,0.0007478707,-0.008739856,-0.01504132,0.010137137,-0.007691895,0.0014777617,0.009363153,0.015767358,0.0281922,0.0063391356,0.00058990606,0.021000313,-0.001657559,0.009561786,0.019877007,0.00161475,0.008541223,0.024712697,0.008424783,-0.00464048,-0.002251746,0.008671362,-0.0025462708,-0.0012594366,0.028959336,-0.01104126,0.00036794212,0.00078554254,0.010863176,0.0019897555,-0.0057295375,-0.0141234975,0.0029760716,-0.0078014857,0.008637114,0.009322057,0.0075480575,-0.030438809,-0.008212451,0.0022123617,-0.0045069163,0.0055754255,-0.0022038,0.005191858,-0.03230185,-0.014986524,-0.0018287944,0.0145892585,0.026520943,-0.0136645865,0.007506961,0.024151044,0.0032003901,-0.017876979,-0.007965872,0.021150999,-0.0072192857,-0.02186334,0.022055123,-0.007178189,-0.027466161,0.029123722,-0.00097347336,-0.029507289,-0.02374008,0.0041404725,-0.019575633,-0.00068751024,-0.040438958,-0.01515091,0.0048493873,0.012678271,0.010349469,0.009342604,-0.0012551557,0.015205706,-0.00050600065,0.0043733525,0.0074658645,-0.008712458,-0.013705683,0.013938564,-0.0026044908,-0.0375896,-0.012322101,0.0019948927,0.0014700561,0.010979615,-0.013520749,-0.01432898,0.005873375,-0.009719322,0.033397757,0.007842583,-0.016493397,-0.019274259,-0.0063185873,0.005143912,0.02678122,-0.028959336,-0.008822049,-0.0023390758,-0.0053528193,-0.03323337,-0.041863635,-0.019712621,0.03701425,0.01950714,-0.010027546,0.0006613968,-0.016246816,-0.020123588,-0.012171414,0.010582349,-0.007068598,-0.0076781963,0.0046678777,-0.0066096876,0.018301642,0.002561682,-0.018342739,0.0022808558,0.0104864575,-0.012589228,-0.022972945,0.016630385,0.03701425,-0.022246907,-0.0145070655,0.004438422,-0.013294718,0.022288002,0.0012714231,-0.0028733304,-0.015452284,0.014616656,0.019630428,0.026246965,0.023753777,0.018424932,-0.013856371,0.0036815617,0.014602957,-0.017301627,-0.026288062,-0.014342679,0.009726172,-0.0077672387,0.0040548546,-0.011787847,-0.01749341,-0.00856862,-0.0015702288,0.021712651,-0.0012876904,-0.00043087112,0.027164787,0.0031575812,-0.021712651,-0.0018048214,0.026589436,-0.024986673,-0.018835897,0.023753777,-0.039863605,0.005161036,-0.0023373635,-0.019479742,-0.020192081,-0.0022055123,-0.004253488,-0.006256942,-0.005195283,0.009630281,0.007541208,-0.017260531,0.020301672,-0.0044007506,-0.014068702,-0.016301611,0.0028116857,0.02689081,0.004489793,-0.01327417,-0.0015453997,-0.018698908,-0.020013995,0.02668533,0.025589421,0.0147399455,0.032658022,0.24635983,-0.01749341,-0.013185128,0.011219345,0.015233103,0.005979541,1.8728875e-05,0.032027874,-0.021055108,-0.012965946,0.016712578,0.006298039,0.0046576033,0.0020222904,0.0013964248,-0.009993299,-0.021041408,-0.008561771,0.0015924894,0.013000193,0.013561846,0.0029469617,0.00045933903,-0.020274274,0.045343142,0.011150851,0.0027226433,0.019274259,-0.014287883,-0.010746735,0.006650784,0.0026216144,0.008020667,0.020466058,-0.016520794,-0.008075463,-0.006006939,-0.016726276,0.025836,0.01468515,0.020986613,-0.009650828,-0.011520719,-0.010828928,0.00927411,0.0031918283,-0.011349484,-0.0125755295,0.00998645,0.007130243,-0.023205824,-0.016137226,0.017164638,0.028959336,-0.0015453997,-0.0107193375,0.0017962595,-0.004061704,0.034603253,0.014109799,-0.035616968,0.010890573,-0.029233312,0.01845233,-0.005178159,-0.0007337438,-0.0029332628,-0.010376867,0.026534641,-0.026164772,-0.01445227,0.007890528,-0.0020633868,-0.0011224482,-0.02572641,-0.005688441,0.03345255,0.019630428,0.020041393,0.023233222,-0.015945442,7.7162964e-05,-0.0020753734,-0.0106439935,-0.01608243,-0.009808365,0.023945563,-0.016041335,0.008130258,0.0066747568,5.7203335e-05,0.0005449567,-0.013089236,-0.007671347,0.0013347801,0.0044007506,0.0048665106,0.025151059,-0.0101782335,0.00061088236,-0.03101416,0.056110423,0.010287824,0.0030497028,0.015370091,0.016150925,0.024397623,0.015109814,0.008479578,-0.015890647,-0.0028048363,-0.050603494,-4.2996144e-05,-0.0073699728,-0.007424768,0.0058220043,0.0015916333,-0.0035137509,0.033671733,-0.010657692,-0.0060446104,-0.01491803,-0.0023664737,0.009760419,0.0118015455,-0.021356482,-0.020315371,-0.001547112,-0.015424887,0.007185038,-0.0012089221,0.01750711,0.002208937,0.02772644,-0.0099453535,-0.01984961,-0.017945472,-0.04098691,0.0035017645,0.009246713,-0.0006926473,0.017287929,0.016589288,-0.016287914,0.0019075626,-0.011554967,0.01210292,0.009691925,-0.015753658,-0.015356393,-0.0051199393,-0.0038664958,-0.015808454,-0.025109963,0.020534553,-0.01244539,-0.012630325,-0.017000252,0.010342619,-0.008068613,-0.011589213,0.0045069163,0.008191903,-0.031315535,-0.013137181,-0.0074521657,-0.17655057,-0.0064795483,0.022781162,-0.043562293,0.018233148,0.021726351,0.012561831,0.0038836193,-0.033699133,0.015178308,0.008315193,-0.0138906175,-0.020972915,0.0049624024,0.004335681,-0.0029555233,-0.03008264,0.016123528,0.0042808857,0.026699027,0.026945606,-0.01950714,0.005191858,-0.0008185053,-0.016424902,-0.0045445883,-0.0031678553,0.011733051,0.011938534,-0.021986628,0.01856192,-0.011828943,0.010575499,0.0074110692,-0.0049521285,-0.010130288,0.0017466013,-0.020781131,-0.005260352,0.012739915,0.025904495,0.010678241,-0.018041365,0.02926071,-0.0011977918,0.0187948,0.021123601,0.002619902,0.00998645,-0.02338391,0.0063151624,-0.011828943,-0.00054324436,-0.001856192,0.017753689,0.02080853,0.016767373,-0.00975357,-0.013678285,-0.029342903,-0.019644128,-0.00657544,0.020013995,-0.0032106643,-0.003373338,-0.004393901,-0.0030736758,0.027123692,-0.053178873,0.0069829808,-0.02032907,0.0031764172,0.005626796,-0.0031079229,-0.0052672015,0.021657856,-0.016548192,0.0052021323,0.018876994,-0.012534433,-0.009527539,0.046713024,-0.0042432137,0.016794771,-0.014863235,0.017192036,0.0041267737,0.03619232,-0.013808425,-0.01010289,0.010239879,-0.038329337,-0.0013793013,-0.012424842,0.02595929,0.02489078,0.010938519,-0.01397966,0.01116455,0.0006699586,-0.002672985,-0.0030291546,-0.028712755,0.017452314,0.02091812,0.0033031313,0.003979511,0.021781147,0.027904525,0.0017962595,-0.036575887,-0.010541253,-0.009589184,-0.012890602,-0.0023459252,0.029589482,0.005921321,0.00017979719,-0.03137033,0.006085707,0.06756265,-0.017657798,0.0029726468,0.0009923093,-0.002455516,-0.030712785,-0.12296073,-0.025109963,0.004301434,-0.0024863384,0.0094795935,0.0035890944,-0.00916452,-0.009849462,-0.025329145,0.017876979,-0.050356913,-0.028164802,-0.0008981298,-0.009315207,-0.015096115,-0.0026781221,0.0056473445,-0.004321982,-0.020589348,0.019712621,-0.03397311,-0.03076758,-0.015561875,0.0023801725,0.018233148,0.005465835,-0.018863294,-0.0024743518,-0.004500067,-0.0013304992,0.027452463,-0.022027725,-0.019192066,-0.0030616894,-0.01397966,-0.011287839,0.005972692,-0.00952069,0.024246937,-0.036849864,0.014356378,-0.020863324,-0.011678256,-0.02009619,-0.011602912,0.0035788203,-0.028931938,0.029918253,0.0074316175,-0.008733006,-0.02043866,0.0040069087,-0.02865796,0.008054914,0.0088152,0.007116544,0.0036096429,0.014835837,-0.008767254,0.016794771,-0.015397489,0.01715094,0.009993299,-0.0048219897,0.032740213,-0.01786328,-0.020959215,-0.019520838,0.0062843403,-0.032822408,-0.0075617563,-0.0012971084,-0.009602883,0.02008249,-0.022507183,-0.01022618,0.00205825,0.004078828,-0.0071918876,-0.016644083,-0.0062843403,-0.007554907,0.018178353,-0.020781131,0.0034521061,0.0072329845,-0.009726172,-0.0176167,-0.017205736,-0.013164579,-0.017301627,0.047041796,0.018808499,-0.029918253,0.0032688843,0.0066199615,0.0005685016,0.0029623727,0.00065925636,0.009582334,-0.03301419,-0.009534389,-0.03980881,0.018863294,-0.016068732,-0.018534523,-0.010685091,-0.019726321,0.0052432287,-0.005835703,0.0048459624,-0.011486473,-0.012972795,0.012328951,-0.030986762,0.0033870367,-0.021520868,8.085523e-05,0.010493306,-0.015000223,0.01693176,-0.009486442,-0.00775354,-0.016342709,-0.0011472773,-0.013075537,-0.010856326,-0.004503492,-0.007657648,0.02442502,-0.022753764,-0.016164623,0.004263762,-0.023246922,0.002774014,0.036603283,0.013130332,-0.009157671,0.007835733,0.017671496,0.037315622,-0.02302774,8.904242e-05,-0.04123349,-0.00927411,-0.013178279,0.017726291,0.0042226654,-0.0038904687,-0.008075463,-0.009602883,-0.002025715,0.019520838,0.022822257,-0.010904272,-0.028164802,-0.01657559,-0.01563037,-0.00057706336,-0.0199729,-0.023000343,-0.017123543,0.035315596,-0.0075617563,0.02220581,-0.011130302,0.014287883,0.0068220193,-0.0027363421,0.01609613,-0.0025753807,-0.026137374,-0.0027979868,0.0014272473,-0.0037637546,-0.0016909498,-0.00012896168,0.01619202,-0.020534553,0.006298039,-0.0011190235,0.041178696,-0.0022140741,-0.011753599,-0.028329188,0.011938534,0.024452418,-0.0019332479,-0.014397474,0.0035959438,0.0043973257,-0.015835851,0.001938385,0.008589169,0.010342619,0.00034503939,0.0005081411,-0.003431558,0.006510371,-0.010500156,0.0005385354,0.015781056,0.0063870815,0.007972721,-0.009582334,-0.02149347,-0.041480068,0.017342724,-0.024479816,-0.050219927,0.013233074,0.006089132,0.018698908,-0.01843863,0.020287974,0.008897393,-0.0061679,0.024027755,-0.016068732,-0.03487723,-0.03665808,0.02279486,0.0040445807,-0.023109933,-0.013048139,0.008383687,0.02478119,0.028383983,0.017411217,-0.024986673,0.023246922,0.015753658,0.001551393,0.0022072247,-0.00158564,-0.018808499,-0.019329054,-0.017603002,0.009137122,0.015397489,-0.0064795483,0.06975446,0.013828973,0.006719278,-0.010527554,-0.0026010661,0.028383983,0.022863355,-4.385232e-05,-0.020630443,-0.025877098,-0.0066199615,0.008171354,-0.029288108,-0.015465983,-0.00974672,0.00029366874,-0.011876889,0.0011130302,-0.02326062,-0.00434938,0.024137346,-0.0005081411,0.010870025,0.0083973855,0.0036986852,0.0034623803,0.0027243556,-0.002654149,0.020781131,-0.015890647,-0.0024092824,0.014068702,-0.028356586,-0.02713739,0.0056062476,0.013952263,-0.0060480353,-0.016150925,-0.0050171977,0.0011798121,-0.0016986554,0.01561667,-0.01668518,-0.011246743,-0.02737027,0.016438602,0.016219418,-0.02279486,-0.0029178516]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.001292003,0.011829233,0.010904539,-0.0060481834,-0.017315751,0.022699524,0.0051166397,0.00060276344,-0.02061725,-0.034467112,0.023233792,-0.0057844743,-0.011116876,0.0069420543,-0.023466678,-0.012411448,0.028439477,0.0072057634,0.008041413,-0.021658387,-0.0073496047,0.016603393,0.0020257647,-0.03978239,-0.017178759,0.021576192,0.028521672,-0.015425265,0.014658111,0.0057296776,0.00048289573,0.013384089,-0.0230968,-0.032713618,-0.007698933,0.021493997,0.010973035,-0.014480023,0.0024401646,-1.7511928e-05,0.03252183,0.004654293,-0.007801677,-0.020672048,0.009856553,0.0073633036,0.011897729,-0.021192616,-0.010103137,-0.004558399,0.020932332,0.028275086,-0.023343384,-0.009534623,-0.01187033,0.009466127,-0.0058974926,0.009534623,0.012466244,-0.0021422077,0.018165099,0.009788057,-0.013329292,0.010746999,-0.029343622,-0.013521081,0.0042844154,0.009651065,-0.023288589,0.020288471,0.049399205,0.029179232,-0.0011430244,-0.015069087,0.00988395,-0.012000472,-0.011897729,-0.015754046,0.005164587,0.0090757,0.0014152954,-0.02245294,-0.02753533,0.039481007,0.009445578,-0.033754755,0.010459316,0.026617486,-0.018452782,0.009815455,-0.010986734,0.017411646,0.020521356,-0.004239893,0.0052536316,0.001974393,0.013062159,0.023891352,0.009705862,0.002325434,-0.011431957,0.009699012,-0.048385467,-0.008767469,-0.015630752,0.0002930338,0.01683628,0.0006323023,0.011966225,-0.02738464,-0.048878636,0.04402913,0.007520844,-0.03087793,0.011253868,-0.0048563555,-0.0017928788,-0.04342637,-0.00775373,-0.0061954493,0.006668071,0.030549148,0.028932646,-0.0055070664,0.019850098,-0.0059625637,-0.033946544,-0.025946228,-0.024110539,-0.009171594,0.027946306,0.014110145,-0.022302248,0.033371177,-0.023055702,0.004914577,-0.005770775,0.033042397,-0.04013857,-0.0152471755,0.0247407,0.0013459434,0.0063598393,0.02079534,-0.0035241114,0.020685745,0.000406266,0.030220369,-0.0052570566,-0.010637405,-0.0014709483,-0.01798701,0.020904932,0.0039898832,0.017343149,0.01932953,0.008466087,-0.001897335,-0.014945794,-0.015767744,-0.0008138163,0.005003622,0.0025257843,0.014260836,0.015891036,0.018260993,0.016082825,-0.001422145,-0.0061098295,0.0117127905,-0.010952486,0.029535409,-0.018795261,0.028823053,0.003565209,0.013253947,0.022000866,-0.027686022,-0.004883754,-0.0006768246,-0.010507263,0.020589853,-0.001633626,0.012281305,-0.009144195,-0.01419234,0.001093365,-0.029151833,-0.00037715526,-0.018507577,-0.011020982,0.015452663,0.008068811,0.012726529,-0.66062874,-0.028850451,0.0008694692,-0.014480023,0.01368547,0.019206235,0.006171476,-0.019809,-0.024466718,0.020329569,-0.01994599,0.0031439594,0.016699288,-0.032604024,-0.016247215,-0.04208385,0.019932292,-0.020028187,-0.013795064,0.015260875,-0.018740464,0.010904539,-0.0149731925,0.020850137,-0.0036508287,0.013267646,-0.0078085265,-0.00841814,0.03350817,0.021672087,-0.0027826438,0.028576467,-0.015849939,0.010479865,0.04011117,-0.016233517,-0.019425422,0.0055036414,-0.0123772,0.043344174,-0.048549857,-0.013753966,0.014096445,0.0041611227,-0.0038117939,0.006301618,0.008931858,-0.010431917,0.018685667,0.013253947,0.001715821,0.02605582,0.0023357084,0.007411251,0.018945951,-0.010883991,0.014493722,-0.00809621,0.016973272,0.0007894146,0.009260639,0.003695351,-0.011836083,-0.0024812622,0.008726371,0.03493288,0.014233437,0.02687777,-0.0053495257,-0.021041924,0.004527576,0.0088633625,-0.003678227,-0.010370271,-0.0008566262,-0.003102862,0.0055344645,0.00758934,0.01680888,0.010130536,-0.00445223,-0.02275432,0.0051097902,0.011404559,-0.006897532,0.006647522,-0.020055585,-0.009014053,0.003241566,-0.012473094,0.019863795,0.03254923,-0.0069694524,-0.030960124,-0.012226509,0.025713341,0.0009991832,0.015480062,0.0019555565,-0.014069047,-0.012548439,0.01304161,-0.0053837737,0.0077811284,0.018754164,-0.00046919656,-0.031617682,0.02838468,0.038686454,0.003133685,-0.0020120656,0.0181514,-0.032056056,0.018987048,-0.0043494864,-0.031727277,0.006668071,-0.0031097115,-0.0057536513,-0.0136101255,0.027480535,-0.0027723694,0.019110342,-0.014658111,0.009157895,0.02542566,0.004058379,-0.01600063,0.006829036,0.017219856,0.024617407,0.02408314,0.013932056,-0.008151006,0.022178955,0.012575838,-0.0035241114,0.009082549,0.007541393,-0.010431917,-0.010596308,0.01271283,4.8401947e-05,0.010123686,-0.016302012,0.005065268,-0.00709617,0.010596308,-0.0029076487,-0.010246979,0.00808251,-0.018206196,-0.010644255,-0.0013390938,-0.015370469,0.0028648388,0.013075857,-0.029754596,-0.006668071,-0.034576703,0.012555289,0.042604417,-0.024494115,0.0059488644,-0.007883872,-0.003099437,-0.012959414,0.024946189,-0.0017389384,-0.019562414,0.014781404,-0.029754596,-0.003907688,0.029645003,-0.010103137,0.006897532,-0.0004520726,-0.01928843,-0.0064112116,-0.015904736,-0.008705823,-0.019206235,0.015808841,0.008240051,0.015617053,0.011247018,0.027275046,0.008479786,-0.032768413,0.041152306,-0.0058255717,0.007322206,-0.010055191,0.0102880765,0.011719639,-0.007637287,0.009692162,-0.0036063064,0.006911231,0.0034932883,0.0053871986,0.009294887,0.026302407,-0.025946228,-0.0062947683,-0.009788057,0.008055111,-0.021096721,0.021822777,0.012336102,0.01831579,0.0004045536,-0.00808936,-0.015055387,0.009185294,-0.0029624454,0.00027590984,0.007123568,-0.009356533,0.032878008,-0.010610007,-0.013897807,0.052906193,-0.00379467,0.013562178,0.024973586,-0.0091304965,0.012260756,0.021973468,-0.029234027,-0.0016961284,0.0032912255,0.0063735386,0.027096957,0.013466284,0.0031747825,-0.022863913,-0.00495225,0.012795025,-0.012438846,0.013945755,0.015658151,-0.0045412746,-0.0117127905,0.03808369,0.004880329,0.03268622,0.01963091,0.0014615302,-0.010500413,-0.011904579,0.0013022773,-0.017315751,-0.0049933475,0.008020864,-0.0029641578,0.012610085,-0.0032449907,0.0181514,0.021836476,0.017315751,0.022726923,0.018808959,-0.03419313,0.03235744,0.0058974926,-0.00956202,-0.026096918,-0.021493997,-0.02901484,-0.022644727,0.0045070266,0.016521199,-0.042275637,0.03712475,0.0053050034,0.019589813,0.012349801,0.03778231,0.014110145,-0.021836476,-0.018041806,0.00363028,0.014480023,0.004846081,0.0021439202,-0.010911388,0.004918002,-0.008603078,-0.0014281385,0.0036885014,0.019535016,-0.0038357675,-0.0028665513,-0.007644137,0.014219739,0.0138841085,-0.0052365074,-0.011678542,-0.012726529,-0.012877219,0.006959178,-0.019096643,-0.030823132,0.037617918,0.007308507,0.015712949,-0.016562296,-0.008883911,-0.02671338,0.0064625833,-0.018904854,-0.0025377711,-0.021713184,0.016219817,0.004024131,-0.028686062,0.016945872,0.02838468,-0.003029229,-0.0030532025,0.0011139137,-0.0020754242,0.0065071057,0.03345337,0.027165454,0.0033682834,0.010164784,-0.040385153,0.0033768453,0.00354466,-0.0059968117,0.002645652,0.018206196,-0.0004525007,0.011075779,-0.002714148,-0.0043118135,0.00070336676,0.014384128,0.026316104,-0.023329686,-0.008644176,-0.014986891,0.0032604025,-0.011130575,0.019247333,0.025316065,0.0132059995,0.0021850176,0.008438689,0.0070687714,0.00210111,-0.017685628,0.004551549,0.014644412,0.018384285,0.019822698,0.007767429,0.0214666,-0.014932095,-0.012822423,0.013808763,0.0074181003,0.011986773,-0.002311735,0.011623746,-0.0070687714,-0.0071852147,-0.013562178,0.018863756,-0.010007244,0.009452427,-0.0004240321,-0.004592647,-0.011733339,-0.04104271,-0.0086578755,0.0053495257,0.011651143,-0.00906885,-0.00029110737,0.0090757,-0.021096721,-0.02557635,-0.008514034,0.012603236,-0.0116442945,0.014219739,-0.0019761052,-0.0034641775,-0.003060052,-0.00024316026,-0.0010205881,0.0023357084,-0.04868685,-0.038713854,-0.011521001,0.021247413,0.030302564,0.008603078,0.0015223202,-0.02708326,0.0013733418,-0.021315908,-0.009507224,-0.0033117742,-0.014466323,0.0076578357,0.014740307,-0.0025634572,-0.0034093808,-0.0029710075,0.013651223,-0.01072645,0.03364516,0.0077194823,-0.021507697,-0.00060447585,0.009192143,0.00016406896,0.021165216,0.0054419953,-0.022329647,0.02754903,-0.023603668,-0.01417864,-0.0070413733,-0.012548439,-0.006945479,0.010788096,0.0075002955,0.004421407,-0.00841814,0.011397709,-0.014617014,0.008788018,-0.017795222,0.000509866,0.0008172411,0.0214666,0.016260915,-0.007945518,0.025836634,0.016849978,-0.041453686,0.016699288,0.010089438,-0.015877338,0.008705823,-0.021000827,0.011329213,-0.02442562,0.016315712,-1.0863014e-05,0.025000984,-0.0076235877,-0.005626934,-0.02789151,-0.0053871986,-0.027617525,-0.014740307,-0.010575759,-0.011034681,0.011931977,-0.0035206866,-0.017507538,-0.00709617,0.008048262,-0.022658426,-0.010109987,0.014438924,-0.007274259,0.040165965,-0.0011464492,-0.0027364092,-0.014863599,-0.02771342,-0.0022483761,-0.028932646,-0.002532634,0.002183305,0.021165216,0.015206078,0.031535488,0.01765823,0.031617682,-0.005654332,-0.0197816,-0.0065721767,0.012438846,-0.004435106,-0.009418179,0.016466402,0.00010236919,-0.029727198,0.007740031,0.0048906035,0.005791324,0.011281266,-0.026179112,-0.01748014,-0.017411646,-0.022165256,0.0006447172,0.022809118,-0.021220013,-0.006287919,-0.03052175,0.015808841,-0.003167933,-0.0039556352,0.021178916,0.0025137977,0.012925167,-0.004965949,0.02243924,-0.0004593503,-0.0017064029,-0.010794946,-0.030987522,-0.010486715,0.002104535,0.03660418,-0.019576114,0.015781444,0.016082825,0.0010163072,-0.012548439,-0.02393245,0.00891816,-0.01767193,0.0022500886,-0.006287919,-0.009623666,-0.025713341,-0.012034721,-0.013829311,0.0012765913,0.0066954694,-0.018233595,0.0029281976,0.00668177,-0.021384403,0.024274928,-0.009705862,0.026179112,0.016028028,0.02589143,0.0028631266,0.00166873,0.008164705,-0.012007322,-0.0058974926,0.010329174,0.011370311,-0.0125963865,0.015781444,-0.033754755,0.008616778,-0.00073675846,-0.0134799825,-0.0077605797,0.009726411,0.0132744955,-0.00956887,-0.007555092,-0.025864033,-0.0115484,0.0007299089,-0.008767469,-0.01501429,0.010123686,-0.007644137,0.0014683797,0.009329135,0.015726646,0.02819289,0.006366689,0.0006340147,0.02095973,-0.0017226706,0.009589419,0.019904893,0.0016361945,0.0085208835,0.0247681,0.008397591,-0.0046645673,-0.002260363,0.008616778,-0.0026285283,-0.0012654607,0.028932646,-0.01104838,0.00042446022,0.0007834213,0.010774397,0.0020069284,-0.0056988546,-0.014055348,0.0029436091,-0.0077605797,0.008651026,0.009329135,0.0075961896,-0.030439556,-0.008192103,0.002226115,-0.0045310003,0.005555013,-0.0022672126,0.0052091093,-0.032247845,-0.0149731925,-0.0018391135,0.014603315,0.026466796,-0.013644373,0.0075002955,0.024110539,0.0032141677,-0.017863717,-0.0079797665,0.021096721,-0.0071509667,-0.021877574,0.021987168,-0.007192064,-0.027466835,0.029124435,-0.00091527577,-0.029508011,-0.02375436,0.0040926267,-0.019617211,-0.00069137994,-0.040467348,-0.015151282,0.0048323823,0.012678581,0.010246979,0.009377082,-0.0012646046,0.015219778,-0.0005252775,0.0043768845,0.007507145,-0.008781168,-0.013740268,0.013890958,-0.0026370902,-0.037563123,-0.012390899,0.0020000788,0.0015582805,0.010931937,-0.013555328,-0.01435673,0.0058563952,-0.009712711,0.033425976,0.007835925,-0.016493801,-0.019247333,-0.0062742196,0.00519541,0.026781878,-0.028932646,-0.008849664,-0.002407629,-0.0053700744,-0.033206787,-0.041864663,-0.019754203,0.037015155,0.019493919,-0.0100140935,0.0006211717,-0.016274614,-0.020082982,-0.012192261,0.010644255,-0.0071030194,-0.0075619416,0.0046405937,-0.006613274,0.01828839,0.0025548951,-0.01828839,0.0022672126,0.0105552105,-0.012575838,-0.02294611,0.01664449,0.036905564,-0.022247452,-0.01452112,0.0044316812,-0.013301894,0.02226115,0.0012526178,-0.002804905,-0.015452663,0.014617014,0.019576114,0.02623391,0.023809157,0.018356888,-0.013795064,0.0036919261,0.014617014,-0.017274654,-0.026357202,-0.014260836,0.009788057,-0.0077605797,0.004109751,-0.0117127905,-0.01746644,-0.008603078,-0.0016199268,0.021699484,-0.0012945716,-0.00043751724,0.027151754,0.0031353976,-0.021589892,-0.0018408259,0.026631186,-0.024959886,-0.018822659,0.023726963,-0.03975499,0.005137189,-0.0023853679,-0.01948022,-0.020178877,-0.0022021416,-0.004178247,-0.006270795,-0.0052056843,0.00956202,0.0076167383,-0.017288351,0.020219974,-0.00445908,-0.014096445,-0.016397906,0.0027860687,0.026918868,0.004520726,-0.013267646,-0.0015865351,-0.01865827,-0.020000787,0.026672283,0.025631147,0.01468551,0.03265882,0.24636586,-0.017439043,-0.013171752,0.01122647,0.0152471755,0.0060173604,3.5425197e-05,0.03200126,-0.020987129,-0.013007361,0.016781483,0.0063324412,0.0046097706,0.0020240524,0.0014067335,-0.009972995,-0.021014526,-0.008596229,0.0016224954,0.013007361,0.013582727,0.0029264851,0.0004338784,-0.020261072,0.045344252,0.011192221,0.0027518207,0.01932953,-0.014247136,-0.010740149,0.0066303983,0.0026507892,0.008007165,0.020466559,-0.016493801,-0.008014014,-0.0060105105,-0.01665819,0.025822936,0.014726607,0.021055624,-0.009623666,-0.011562099,-0.010808645,0.009301736,0.003210743,-0.011370311,-0.012568988,0.0100140935,0.007123568,-0.023137897,-0.01616502,0.017137662,0.028932646,-0.0016070838,-0.010740149,0.0018254144,-0.0040001576,0.034576703,0.014151243,-0.03561784,0.01089084,-0.029124435,0.01848018,-0.0052707554,-0.0007594477,-0.002986419,-0.010315475,0.026521593,-0.026206512,-0.014452624,0.007897572,-0.0020754242,-0.0010736724,-0.025658544,-0.005692005,0.03348077,0.01963091,0.020069284,0.023220092,-0.015945833,5.1264862e-05,-0.002056588,-0.0106237065,-0.016096525,-0.009849703,0.02391875,-0.016055427,0.0081852535,0.0066886195,4.6609286e-05,0.00056680315,-0.0131375035,-0.0076646856,0.0012877219,0.004407708,0.004870055,0.025151676,-0.010171633,0.00056380645,-0.031042319,0.056166597,0.010336024,0.0030634769,0.015411566,0.01615132,0.024329726,0.015069087,0.008466087,-0.015945833,-0.0027603826,-0.05065953,-4.3445366e-06,-0.007342755,-0.007438649,0.0058324216,0.0015976657,-0.00354466,0.033699956,-0.0106237065,-0.006065307,-0.0149046965,-0.0022586505,0.009726411,0.011808684,-0.021357005,-0.020329569,-0.0015231764,-0.015356769,0.0071098693,-0.0011601484,0.01748014,0.002243239,0.027699722,-0.009979845,-0.019850098,-0.018014409,-0.040933117,0.003483014,0.009164744,-0.000622456,0.017233556,0.01664449,-0.016260915,0.0019093218,-0.011500453,0.012075818,0.009767508,-0.015781444,-0.015356769,-0.0050892415,-0.0038494666,-0.01583624,-0.02508318,0.020521356,-0.012390899,-0.012685431,-0.016959572,0.010342873,-0.008055111,-0.0115484,0.00453785,0.0082469005,-0.0313437,-0.013192301,-0.0075002955,-0.1765549,-0.006513955,0.022809118,-0.043618158,0.018219896,0.021726884,0.012514192,0.0038083692,-0.03364516,0.015260875,0.008322245,-0.013890958,-0.021028226,0.004965949,0.004370035,-0.0029470338,-0.030083377,0.016110223,0.0043186634,0.02672708,0.02689147,-0.01946652,0.005198835,-0.0008356494,-0.016397906,-0.0045310003,-0.0031610834,0.011705941,0.011945676,-0.021959769,0.018576074,-0.0117812855,0.010507263,0.0073633036,-0.0049454,-0.010116837,0.0017380822,-0.020754242,-0.005226233,0.012719679,0.025864033,0.010678503,-0.018028107,0.029261427,-0.001196965,0.018781561,0.021110421,0.0026268158,0.009966146,-0.023357084,0.0062468215,-0.0117812855,-0.000553104,-0.0018921978,0.017891116,0.02078164,0.016781483,-0.009760658,-0.013699169,-0.029316222,-0.019589813,-0.0065036807,0.020069284,-0.0032467032,-0.0034042436,-0.0043837344,-0.0030908752,0.027138054,-0.053180177,0.0069797267,-0.020411763,0.003159371,0.0055721374,-0.0031097115,-0.005260481,0.021685785,-0.016439004,0.0051885606,0.018850058,-0.0125963865,-0.009548321,0.04668677,-0.004236468,0.016781483,-0.0148362005,0.01716506,0.0040960517,0.036138408,-0.013829311,-0.010034642,0.010274378,-0.038330276,-0.001369917,-0.012438846,0.02605582,0.024877692,0.011000433,-0.013959453,0.011096328,0.00060875685,-0.0026644885,-0.0030018305,-0.028740859,0.017397946,0.020877535,0.0033083495,0.0040035825,0.021754282,0.027918907,0.0017740425,-0.036494587,-0.010541511,-0.00956202,-0.012815573,-0.0024059166,0.029590206,0.0059248907,0.00016000202,-0.0313437,0.0060755815,0.0676191,-0.01765823,0.0029881315,0.0010017517,-0.0024470142,-0.030631343,-0.12307334,-0.025151676,0.0042604418,-0.0024949613,0.009486675,0.003578908,-0.009137346,-0.009849703,-0.025357163,0.01783632,-0.050385546,-0.028247688,-0.00083393697,-0.009342833,-0.015082786,-0.0027038737,0.0056372085,-0.0043631857,-0.020535056,0.019685706,-0.03400134,-0.030795733,-0.015589655,0.002433315,0.018192498,0.005479668,-0.018891156,-0.002498386,-0.00453785,-0.001270598,0.027439436,-0.022000866,-0.01913774,-0.0030138174,-0.013986852,-0.011336063,0.0059317406,-0.009466127,0.024233831,-0.036850765,0.014329332,-0.020863835,-0.011651143,-0.020178877,-0.011603197,0.0036234304,-0.028987443,0.029891588,0.0073633036,-0.008753769,-0.020493958,0.0040892023,-0.028631264,0.008048262,0.008788018,0.0070824707,0.0035857577,0.014795103,-0.008788018,0.016795183,-0.015315671,0.017137662,0.010007244,-0.0047775856,0.032741014,-0.01780892,-0.020932332,-0.019507617,0.006250246,-0.032878008,-0.0075482423,-0.0012988525,-0.00957572,0.020096682,-0.022494037,-0.0101510845,0.0020343268,0.004102901,-0.0071852147,-0.016630791,-0.006257096,-0.007555092,0.018178798,-0.02078164,0.0034744518,0.0072331615,-0.009746959,-0.017521238,-0.017192459,-0.013212849,-0.017384246,0.047042947,0.018795261,-0.029946385,0.003224442,0.006633823,0.00056637503,0.002994981,0.0006729717,0.00957572,-0.032987602,-0.009520923,-0.03978239,0.018822659,-0.016110223,-0.018521277,-0.0107196,-0.019713106,0.0052159587,-0.0058495454,0.004880329,-0.011445656,-0.012993663,0.012308704,-0.03101492,0.0033631462,-0.021507697,7.604109e-05,0.010452466,-0.0149731925,0.016877377,-0.009507224,-0.0077468804,-0.016384207,-0.0010865154,-0.013069008,-0.010842892,-0.0044145575,-0.007705783,0.024384523,-0.022809118,-0.01615132,0.0042501674,-0.023233792,0.0027689447,0.036686376,0.013158052,-0.0091304965,0.007883872,0.01767193,0.037343938,-0.0231105,0.000104563194,-0.0412619,-0.009308586,-0.013151203,0.017795222,0.0042159194,-0.003924812,-0.00807566,-0.009623666,-0.002056588,0.019452821,0.022809118,-0.010918238,-0.028110696,-0.016562296,-0.015658151,-0.00062288414,-0.020014487,-0.023028305,-0.017206157,0.03534386,-0.007555092,0.022178955,-0.011151124,0.014384128,0.006815337,-0.002739834,0.01615132,-0.0025822935,-0.026096918,-0.0028751132,0.0014324194,-0.0037330238,-0.0017123962,-0.00015411565,0.016233517,-0.020521356,0.0062810695,-0.0010830906,0.041179705,-0.002178168,-0.011808684,-0.02838468,0.011931977,0.024453018,-0.0019281581,-0.014466323,0.0036508287,0.0044111325,-0.015877338,0.0019418573,0.008603078,0.010370271,0.00034033874,0.00047090897,-0.0034025314,0.006500256,-0.010493564,0.0005308428,0.015767744,0.0063290163,0.007966067,-0.00956887,-0.021480298,-0.041481085,0.017343149,-0.024507815,-0.050221156,0.013260797,0.006055033,0.018740464,-0.018425383,0.020274771,0.008870212,-0.006130378,0.023877652,-0.016069125,-0.034905486,-0.036686376,0.022781719,0.0040892023,-0.023137897,-0.013048459,0.00841814,0.024781797,0.028412078,0.017397946,-0.025000984,0.023220092,0.015740346,0.0015993781,0.0022363896,-0.001595097,-0.018781561,-0.019343227,-0.017562335,0.009192143,0.015425265,-0.0063975123,0.06986576,0.013829311,0.006709168,-0.010514113,-0.0025994175,0.02835728,0.022836516,-9.134564e-05,-0.020658348,-0.02589143,-0.0065550525,0.008151006,-0.029234027,-0.015493761,-0.009753808,0.00035553626,-0.011925127,0.0011592922,-0.02327489,-0.004335787,0.024206433,-0.00045892218,0.010856592,0.008377043,0.0037056254,0.0035069874,0.002705586,-0.0026559266,0.02080904,-0.015863638,-0.002433315,0.014027949,-0.02838468,-0.027206551,0.0056029605,0.013932056,-0.0060516084,-0.01619242,-0.005010471,0.0011413121,-0.00171154,0.015617053,-0.016630791,-0.011247018,-0.02738464,0.016439004,0.016219817,-0.022781719,-0.0029966934]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0012767455,0.0118717635,0.010885305,-0.006055764,-0.01729044,0.022674862,0.005076155,0.0006353757,-0.020537535,-0.034471273,0.023209196,-0.005771472,-0.011104518,0.0069086403,-0.023469511,-0.0124609,0.028415509,0.007220334,0.007980729,-0.0216336,-0.0073710433,0.016632799,0.002044848,-0.039704986,-0.017084926,0.021565096,0.028525114,-0.015454529,0.014646181,0.0057988735,0.000465828,0.0133172,-0.023072187,-0.032717567,-0.007686162,0.021482892,0.01098806,-0.014413266,0.0024164827,-1.1031571e-05,0.032498352,0.0046993825,-0.0077752173,-0.02063344,0.009885144,0.007329941,0.011940268,-0.021181474,-0.010111208,-0.0046000513,0.02096226,0.0282785,-0.023318801,-0.009528923,-0.011885464,0.009487821,-0.005884504,0.009515222,0.0124746,-0.0021972696,0.018194694,0.009768687,-0.013330901,0.010755147,-0.029347165,-0.01348161,0.0042678067,0.00965223,-0.023305101,0.020249818,0.049350366,0.029182754,-0.0011662826,-0.015070906,0.009871444,-0.012008772,-0.011885464,-0.015797049,0.0051549347,0.009097347,0.0014146101,-0.022428248,-0.027566057,0.03945837,0.009446718,-0.03378623,0.010419477,0.026661802,-0.018413907,0.009830341,-0.010953808,0.017441148,0.020482732,-0.00424383,0.0052508404,0.0019763438,0.013043184,0.023894237,0.009727585,0.0023222896,-0.011344282,0.009679632,-0.04844611,-0.008713724,-0.01563264,0.0002616001,0.01681091,0.00065549876,0.011960819,-0.027374245,-0.048829734,0.044034448,0.0075080516,-0.030909058,0.0112346755,-0.004860367,-0.0017639811,-0.04340421,-0.0077135637,-0.006254426,0.0066997027,0.030552836,0.028908739,-0.00549403,0.019811392,-0.0059632836,-0.03392324,-0.02593566,-0.024072347,-0.009172701,0.027881175,0.014125549,-0.02229124,0.033375207,-0.023072187,0.0049288715,-0.0057440703,0.033018984,-0.04008861,-0.015235316,0.024729988,0.0013409681,0.00632293,0.020825252,-0.003485147,0.020688243,0.00042558185,0.030196615,-0.0052782423,-0.010597588,-0.0015088032,-0.017975481,0.020948559,0.0039629634,0.017372644,0.019372964,0.00847396,-0.0019215405,-0.0149612995,-0.01581075,-0.0008211931,0.005011076,0.0025158138,0.014276259,0.015934058,0.018249497,0.016084768,-0.0013949152,-0.0061482447,0.011679952,-0.010926407,0.029511575,-0.01879753,0.028799132,0.0035553637,0.013241846,0.021989822,-0.027661962,-0.004904895,-0.0006867538,-0.01048798,0.02063344,-0.0016637938,0.012255386,-0.00915215,-0.01413925,0.001093497,-0.029127952,-0.00037869933,-0.018482411,-0.011015463,0.015481931,0.008042384,0.012762317,-0.66070855,-0.028826533,0.0008254746,-0.014454369,0.013666572,0.019235956,0.006185922,-0.019825092,-0.024524475,0.02029092,-0.019948399,0.0031494768,0.016701303,-0.03255316,-0.01627658,-0.042034127,0.0199621,-0.020016903,-0.0137761785,0.015276418,-0.018756427,0.010912706,-0.014933898,0.020825252,-0.0036307182,0.013282948,-0.007795769,-0.008398605,0.033539616,0.021702105,-0.002760716,0.02860732,-0.015892955,0.01048798,0.040116012,-0.016249176,-0.019414067,0.00549403,-0.0123375915,0.0432946,-0.048528317,-0.013769328,0.0140296435,0.004123948,-0.0037677265,0.0063092294,0.008926087,-0.010398925,0.018701624,0.013214445,0.0016920518,0.026004164,0.0023685298,0.007350492,0.018975642,-0.010885305,0.0144954715,-0.008124588,0.01697532,0.000766818,0.009275458,0.003678671,-0.011858063,-0.0024644358,0.008713724,0.034882296,0.014221455,0.026908418,-0.0053433212,-0.021085568,0.00448702,0.008898685,-0.00374375,-0.010330421,-0.000837891,-0.003092961,0.0055008805,0.007535453,0.016769808,0.01015231,-0.0044493424,-0.022798171,0.005089856,0.011344282,-0.006922341,0.006638049,-0.020044304,-0.009042543,0.0032299692,-0.012440348,0.019811392,0.032498352,-0.006966869,-0.03093646,-0.012221134,0.02562054,0.00097104587,0.01546823,0.0019557925,-0.014084447,-0.012529403,0.013043184,-0.0053467466,0.007830021,0.018770128,-0.00045683683,-0.031594098,0.0282785,0.03858152,0.003110087,-0.0020123085,0.01812619,-0.032059927,0.018975642,-0.0043534366,-0.031703707,0.0066928524,-0.0031460517,-0.005792023,-0.013591217,0.027511254,-0.002769279,0.019112648,-0.014632479,0.00915215,0.025442429,0.004062294,-0.01597516,0.0068401364,0.017235637,0.024606679,0.024099749,0.01396799,-0.008165691,0.022195334,0.0125499545,-0.003510836,0.009076796,0.0075286026,-0.010426327,-0.010611288,0.012721214,5.2261148e-05,0.01013176,-0.01630398,0.0050795805,-0.0070833256,0.010604437,-0.0028960116,-0.010248216,0.0080629345,-0.018167293,-0.01065239,-0.0012878774,-0.015413427,0.0028514839,0.0130979875,-0.02978559,-0.0066723013,-0.034526076,0.012515702,0.04260956,-0.024538176,0.0059804097,-0.007864273,-0.0031135122,-0.01296783,0.0249218,-0.0017674062,-0.019537374,0.014755787,-0.02978559,-0.0039150105,0.029703386,-0.010042704,0.0068504116,-0.0004195877,-0.019277059,-0.0064017097,-0.015906656,-0.008700023,-0.019208554,0.015769647,0.008247896,0.015673742,0.011289478,0.027346844,0.008453408,-0.032690164,0.041129872,-0.00582285,0.007329941,-0.010056404,0.010289319,0.011762157,-0.0076587605,0.009741286,-0.0036718207,0.0068949396,0.0035074109,0.005418676,0.009357663,0.026387786,-0.025894556,-0.006251001,-0.009782388,0.008028682,-0.021030765,0.02181171,0.012330742,0.018400205,0.00039132978,-0.008110887,-0.015098307,0.009220654,-0.0029097125,0.0002746587,0.007103877,-0.009343962,0.032881975,-0.010604437,-0.013920037,0.05288518,-0.0037882777,0.013591217,0.024976602,-0.009124748,0.012262237,0.022072027,-0.029237557,-0.0016877702,0.0033087488,0.0063263555,0.02711393,0.013454209,0.0031426265,-0.022825573,-0.004942572,0.01279657,-0.01248145,0.013933738,0.015673742,-0.004538398,-0.011686803,0.038033485,0.0048637926,0.032690164,0.019674383,0.0014608504,-0.010446878,-0.011899166,0.0013623757,-0.017358944,-0.00499395,0.007994431,-0.0029782166,0.012618459,-0.0032248313,0.018167293,0.021825412,0.01731784,0.022770768,0.018838633,-0.034142453,0.03227914,0.0058468264,-0.009604277,-0.026058966,-0.02144179,-0.028963542,-0.022674862,0.004534973,0.01646839,-0.04225334,0.037184037,0.005336471,0.019564776,0.012358143,0.037814274,0.014152951,-0.021825412,-0.018043986,0.0035964663,0.014440668,0.004860367,0.0021493167,-0.010933258,0.0049322965,-0.008597267,-0.0014240294,0.0036957972,0.019537374,-0.0038636322,-0.0029062873,-0.007672461,0.014221455,0.013899486,-0.0052953684,-0.011734756,-0.012707514,-0.012913026,0.0069805696,-0.019016743,-0.030826854,0.037649862,0.0072751376,0.015701143,-0.016509492,-0.008857583,-0.026648102,0.0064393873,-0.018934539,-0.002510676,-0.02177061,0.016194373,0.0040280423,-0.028634721,0.016906817,0.028415509,-0.002998768,-0.0030124686,0.0011174735,-0.0021424664,0.006504466,0.033512216,0.027155032,0.0034337689,0.010118058,-0.04039003,0.0033738278,0.0035724898,-0.0059769843,0.0026853615,0.018263198,-0.0004649717,0.011042864,-0.0026853615,-0.004274657,0.0006918916,0.014372164,0.02629188,-0.023346204,-0.008693173,-0.014988701,0.0032470953,-0.0111524705,0.019235956,0.025319122,0.013180193,0.0021989823,0.008432857,0.007124428,0.002104789,-0.017701464,0.0045589493,0.014632479,0.018331703,0.019838793,0.007802619,0.021496592,-0.014933898,-0.012830822,0.0138172805,0.0073778937,0.012015622,-0.0023222896,0.011631999,-0.0070764753,-0.007220334,-0.013536414,0.018907137,-0.010029003,0.009433017,-0.00039882242,-0.0045795003,-0.011775858,-0.04107507,-0.00865892,0.005374148,0.01163885,-0.009097347,-0.00041873142,0.009063095,-0.02112667,-0.025552036,-0.008563015,0.012666412,-0.011652551,0.014180353,-0.0019249658,-0.0034354816,-0.0030552836,-0.00029349735,-0.0010660953,0.002397644,-0.048692726,-0.038691126,-0.011529244,0.021208875,0.03025142,0.008590416,0.0015182225,-0.027072828,0.0013538126,-0.021386987,-0.009522072,-0.003320737,-0.014454369,0.007672461,0.014796889,-0.002575755,-0.0034748714,-0.0029679409,0.013618619,-0.010748296,0.033649225,0.0077272644,-0.021482892,-0.00064436684,0.009200103,9.670855e-05,0.021181474,0.005418676,-0.022318643,0.027552357,-0.023592819,-0.014194054,-0.007035373,-0.012563655,-0.00698742,0.010748296,0.0074806497,0.0044013895,-0.008439708,0.011399086,-0.014605078,0.008789078,-0.01779737,0.00047139396,0.0007681024,0.021482892,0.016208075,-0.007932777,0.025880856,0.016838312,-0.041376486,0.016728705,0.010063255,-0.015879255,0.008706873,-0.021017063,0.011316881,-0.024442269,0.016372485,-4.8755664e-05,0.025058806,-0.007638209,-0.00565159,-0.027922278,-0.005319345,-0.02760716,-0.014700984,-0.010583886,-0.011070265,0.011940268,-0.003524537,-0.017537054,-0.0070833256,0.008083486,-0.02264746,-0.01015231,0.014413266,-0.0072751376,0.040170815,-0.0011799835,-0.0027333144,-0.014837992,-0.027757868,-0.002226384,-0.028908739,-0.0025295145,0.0021715804,0.02112667,0.01529012,0.031484492,0.017605558,0.0316215,-0.0056002117,-0.019783989,-0.0065284423,0.012433497,-0.004425366,-0.009439868,0.01645469,0.0001272678,-0.029758189,0.0077135637,0.0048946193,0.0058331257,0.011255227,-0.026195975,-0.017427448,-0.017386345,-0.022099428,0.00064222614,0.02278447,-0.021208875,-0.0062818276,-0.030552836,0.015783349,-0.0031580399,-0.0039355615,0.021181474,0.0025569163,0.012919877,-0.004939147,0.022428248,-0.00046711246,-0.0016612249,-0.010761997,-0.031018665,-0.010529083,0.0021082142,0.0365812,-0.019578477,0.01581075,0.01611217,0.0009984475,-0.012556805,-0.023935338,0.008898685,-0.01761926,0.0022828998,-0.006305804,-0.009624829,-0.025716446,-0.012049874,-0.0138583835,0.0012887337,0.0066928524,-0.018249497,0.002911425,0.0066997027,-0.021345884,0.024332663,-0.009686482,0.026195975,0.016043665,0.025894556,0.0028977243,0.0016209787,0.00815884,-0.012001921,-0.0059290314,0.010344122,0.011378534,-0.012659561,0.015755948,-0.03378623,0.008563015,-0.00076424907,-0.013433658,-0.0077752173,0.0097549865,0.013221295,-0.009528923,-0.0075423033,-0.025826052,-0.011556645,0.0007038798,-0.008754826,-0.014988701,0.010118058,-0.00764506,0.0014891083,0.009330261,0.015687443,0.028168894,0.0063160798,0.00057200936,0.021003362,-0.0016637938,0.009617978,0.019934699,0.0016629375,0.008521913,0.024729988,0.008405455,-0.0046617053,-0.002264061,0.008638369,-0.002587743,-0.0012844523,0.028990943,-0.011063416,0.00042108624,0.00082419015,0.010789399,0.001988332,-0.005709818,-0.014098148,0.002928551,-0.0077820676,0.00864522,0.00931656,0.007583406,-0.03041583,-0.008179392,0.002234947,-0.0045144213,0.0055659595,-0.0022161081,0.005178911,-0.03227914,-0.014988701,-0.001820497,0.014591377,0.026483692,-0.013687123,0.007466949,0.02411345,0.0032111306,-0.017838473,-0.00797388,0.02114037,-0.007199783,-0.021893917,0.022003522,-0.0071929325,-0.027483853,0.029127952,-0.00095220725,-0.029511575,-0.023757229,0.004123948,-0.019551076,-0.0007107302,-0.040444832,-0.015180512,0.0048466665,0.012680112,0.010296169,0.009330261,-0.0012450623,0.015276418,-0.00050008006,0.0043363106,0.007466949,-0.008761677,-0.013721375,0.013913186,-0.0025997313,-0.03759506,-0.0123786945,0.0019729186,0.001585014,0.010953808,-0.013515863,-0.014358463,0.005836551,-0.009693333,0.033402607,0.007836871,-0.016509492,-0.019235956,-0.0063092294,0.0051480844,0.02677141,-0.028963542,-0.008871283,-0.0023753804,-0.005353597,-0.033210795,-0.04186972,-0.019783989,0.037019625,0.019496271,-0.010015302,0.00061696523,-0.016235476,-0.020099109,-0.012214284,0.010604437,-0.0070901765,-0.0076587605,0.0046685557,-0.0066140727,0.018331703,0.002544928,-0.018345403,0.002269199,0.010522232,-0.012584207,-0.022935178,0.016632799,0.036964823,-0.022236437,-0.014509172,0.004439067,-0.0133172,0.02227754,0.0012450623,-0.0028566218,-0.01546823,0.014618779,0.01963328,0.02627818,0.02378463,0.018386506,-0.013872084,0.0036581198,0.014563976,-0.017276738,-0.02627818,-0.014276259,0.009748136,-0.0077820676,0.0040383176,-0.011769008,-0.01746855,-0.0085287625,-0.0016261165,0.021702105,-0.0012561943,-0.00042258477,0.027155032,0.0031717406,-0.021661002,-0.0018410481,0.0265933,-0.024976602,-0.018838633,0.023729827,-0.039787192,0.00515151,-0.0023445534,-0.01945517,-0.020208715,-0.0022109705,-0.0042027277,-0.006251001,-0.0051926123,0.009611128,0.007569705,-0.017263038,0.02029092,-0.00440824,-0.014070746,-0.016331382,0.0028446335,0.026908418,0.004476744,-0.013282948,-0.0015670317,-0.018674223,-0.0199621,0.026648102,0.02563424,0.014742087,0.03260796,0.2461764,-0.01748225,-0.013207594,0.011262077,0.015235316,0.006004386,1.2757554e-05,0.032032527,-0.02096226,-0.012960979,0.016715005,0.0063263555,0.0046617053,0.0020225842,0.0014557125,-0.009960499,-0.020989662,-0.008604118,0.0015721695,0.013029483,0.013577516,0.0029319762,0.00047524733,-0.02029092,0.045322325,0.0111524705,0.0027076253,0.01929076,-0.014262557,-0.010700343,0.006600372,0.0026511094,0.008021832,0.02046903,-0.016509492,-0.008049234,-0.006052339,-0.016701303,0.025826052,0.014728385,0.021003362,-0.009631679,-0.011529244,-0.010837352,0.009275458,0.0032025676,-0.011392235,-0.012584207,0.009994751,0.007124428,-0.023168093,-0.01615327,0.01712603,0.028963542,-0.0015439115,-0.010768848,0.0017948078,-0.0040006405,0.034608282,0.014084447,-0.03559474,0.010871603,-0.029182754,0.01846871,-0.00524399,-0.0007368474,-0.0029319762,-0.010371524,0.026497394,-0.026182273,-0.014440668,0.0078916745,-0.0020516983,-0.0011003474,-0.025730146,-0.0056824167,0.033484813,0.019605879,0.020030605,0.023222895,-0.015961459,9.842115e-05,-0.0020825253,-0.01065239,-0.016125869,-0.009830341,0.023935338,-0.016029963,0.00815199,0.0066654505,1.5895097e-05,0.0005621619,-0.013084287,-0.007638209,0.0012998657,0.004404815,0.0048774933,0.025168413,-0.010159161,0.0005621619,-0.031073468,0.056118574,0.01030302,0.0030998113,0.0154271275,0.01611217,0.024346363,0.015098307,0.008439708,-0.015934058,-0.002760716,-0.050638244,-3.8720882e-05,-0.0073778937,-0.0073984447,0.005819425,0.0015755948,-0.003510836,0.033649225,-0.010666091,-0.0060591893,-0.014920197,-0.0022760492,0.009713884,0.011803259,-0.021373285,-0.02026352,-0.0014899645,-0.015386025,0.00715183,-0.0011568633,0.01746855,0.0022520728,0.027716767,-0.0099262465,-0.019893596,-0.017989181,-0.041020267,0.0034731587,0.009200103,-0.00069917017,0.017276738,0.016632799,-0.01629028,0.0019301035,-0.011570346,0.012097827,0.009713884,-0.015742246,-0.015317521,-0.005103557,-0.003873908,-0.01581075,-0.02512731,0.020523833,-0.012399245,-0.012659561,-0.017030124,0.010337272,-0.008090337,-0.011590897,0.004538398,0.008206793,-0.031320084,-0.013159641,-0.007439547,-0.17657621,-0.006501041,0.02278447,-0.04359602,0.018153591,0.02177061,0.012543104,0.0038465064,-0.033649225,0.015221615,0.008378054,-0.013865233,-0.020989662,0.0049494226,0.004373988,-0.0029542402,-0.030059608,0.01611217,0.004312334,0.026702905,0.026922118,-0.019482572,0.00524399,-0.0007950759,-0.016440988,-0.004524697,-0.0031631778,0.011762157,0.011960819,-0.021989822,0.018537214,-0.011816961,0.010577036,0.0073778937,-0.0049494226,-0.010104357,0.0017691188,-0.020784149,-0.0052508404,0.012700664,0.025894556,0.010672942,-0.018016582,0.029292362,-0.0012090977,0.01878383,0.02109927,0.0025963061,0.0099879,-0.023401007,0.0062955283,-0.011837511,-0.00050093635,-0.0018564616,0.017838473,0.02081155,0.01679721,-0.009761837,-0.013680273,-0.029374566,-0.019674383,-0.0065626944,0.020030605,-0.0032470953,-0.0033841035,-0.0043842634,-0.0030604214,0.027141333,-0.053131793,0.006973719,-0.020345723,0.0031306383,0.0055796606,-0.003096386,-0.0052474155,0.021688404,-0.016495792,0.005206313,0.018838633,-0.012536254,-0.009528923,0.04669241,-0.0042335545,0.016769808,-0.014824291,0.01715343,0.004096546,0.036170173,-0.0138172805,-0.010070105,0.010234515,-0.038362306,-0.001334974,-0.012454049,0.026004164,0.024880696,0.010953808,-0.013995391,0.011159321,0.0006537862,-0.0026733733,-0.003002193,-0.028744329,0.017441148,0.020893756,0.003300186,0.0039629634,0.02179801,0.027908579,0.0017571306,-0.036553796,-0.010590737,-0.009542624,-0.0128445225,-0.0023873686,0.029566377,0.005877653,0.00018731595,-0.031374887,0.006120843,0.067627266,-0.017687764,0.0029747915,0.001019855,-0.0024798492,-0.030689845,-0.12319781,-0.025154712,0.0042780824,-0.002505538,0.009494671,0.0035690647,-0.009159001,-0.009823491,-0.025387626,0.017879575,-0.050419033,-0.028196296,-0.0008837031,-0.009350812,-0.015180512,-0.0026973498,0.005641314,-0.0043157595,-0.020564936,0.019715486,-0.034005444,-0.03077205,-0.015564135,0.002437034,0.018263198,0.0054700538,-0.018893436,-0.0024986877,-0.004524697,-0.0013135665,0.027483853,-0.022030925,-0.019153751,-0.0030724097,-0.013981691,-0.011330581,0.005959858,-0.00948097,0.02427786,-0.036855217,0.014358463,-0.020838954,-0.0116457,-0.020112809,-0.011604598,0.0035793402,-0.028963542,0.029895198,0.007405295,-0.008741125,-0.02045533,0.0040485933,-0.028662123,0.008056085,0.00880963,0.0071107275,0.0035964663,0.014837992,-0.008727425,0.01678351,-0.015386025,0.017194534,0.010001602,-0.0047850125,0.032690164,-0.01782477,-0.020948559,-0.019496271,0.0062989537,-0.032827172,-0.0075286026,-0.0013221295,-0.009570025,0.020071706,-0.022510454,-0.0102208145,0.0020003202,0.0041170977,-0.007199783,-0.0166465,-0.0062612765,-0.007569705,0.018222095,-0.020784149,0.003476584,0.0072614364,-0.009707034,-0.017591858,-0.01715343,-0.013200744,-0.017304141,0.047021225,0.01878383,-0.029922599,0.0032316819,0.0065969466,0.0005728657,0.0029833543,0.0006255282,0.009576876,-0.033018984,-0.009535774,-0.03975979,0.018852333,-0.016098468,-0.018523514,-0.010707194,-0.019715486,0.0052097384,-0.0058502518,0.004870643,-0.011460739,-0.01296783,0.012303339,-0.031018665,0.0033618396,-0.021537695,4.064756e-05,0.010453728,-0.014975,0.016879415,-0.009508371,-0.0077272644,-0.016345082,-0.0011114794,-0.013077436,-0.010871603,-0.0044561927,-0.007672461,0.024373766,-0.022770768,-0.016166972,0.00423698,-0.023236597,0.0028001058,0.036636002,0.013104837,-0.009159001,0.007871123,0.017660363,0.037321042,-0.023058487,0.00010173932,-0.041239478,-0.009254906,-0.013159641,0.017715165,0.0041650506,-0.003928711,-0.008076635,-0.009604277,-0.0020191588,0.01946887,0.022798171,-0.010905855,-0.028168894,-0.016564297,-0.01563264,-0.0005882791,-0.0199621,-0.023017384,-0.017180832,0.035293322,-0.0075423033,0.022209035,-0.011186723,0.014289959,0.006874388,-0.0027504403,0.01613957,-0.0025826052,-0.02610007,-0.0028668973,0.0014351613,-0.0037197736,-0.0017203097,-0.00014310938,0.016194373,-0.020482732,0.0062955283,-0.0011166171,0.041157275,-0.0021887065,-0.011755306,-0.028360706,0.011933417,0.02445597,-0.0019455169,-0.014413266,0.0036307182,0.0044013895,-0.015865553,0.0019729186,0.008604118,0.010337272,0.000338025,0.0005052179,-0.003459458,0.0065421434,-0.0105153825,0.00055830856,0.015755948,0.006350332,0.007946477,-0.009563175,-0.021523993,-0.041513495,0.017331542,-0.024469672,-0.050172415,0.013255547,0.006107142,0.018742727,-0.018400205,0.02026352,0.008871283,-0.006165371,0.023976441,-0.016057365,-0.0349097,-0.036690805,0.02278447,0.0040348927,-0.02311329,-0.013029483,0.008419156,0.02478479,0.028415509,0.017413747,-0.024976602,0.023236597,0.015742246,0.0015653191,0.0021938444,-0.0015910082,-0.01879753,-0.019359265,-0.017605558,0.009193253,0.015399726,-0.006453088,0.0698742,0.013810431,0.0067476556,-0.010508532,-0.0025826052,0.028388107,0.022866676,-4.8381033e-05,-0.02063344,-0.025894556,-0.006586671,0.008206793,-0.029319763,-0.015481931,-0.009720734,0.00029777884,-0.011851213,0.0011577196,-0.023305101,-0.0043328856,0.024195654,-0.0005094994,0.010844202,0.008405455,0.003726624,0.0034868596,0.0027024874,-0.002644259,0.020825252,-0.015879255,-0.0024524475,0.014043344,-0.028360706,-0.027182434,0.0055830856,0.013954289,-0.0060626143,-0.016208075,-0.0050145015,0.0011602885,-0.0017588432,0.015605238,-0.0166465,-0.011214124,-0.02742905,0.016399886,0.016235476,-0.02278447,-0.0029645157]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
0.7352237923352475
0.7929468663232165
0.6953656435171842
0.7593032723187475
0.7677162634582637
0.7605080117806414
0.7468003367059699
0.739093607430268
0.7231749361482606
0.7274201414249856
0.7200963320021405
0.7529354807800486
0.763224238598779
0.7733796742161203
0.6921474030140716
0.734285155446562
0.7115060827741667
0.747339636001138
0.7242373283175555
0.7474816379064805
0.7794997783779418
0.7488052439145635
0.7406136745972025
0.7508596166564624
0.7127298598772511
0.7512779821047576
0.6909546597104109
0.7518085452262342
0.7512096952856163
0.7382764609167003
0.778697108133166
0.6620374506988733
0.7376681779742961
0.7350158009645085
0.7207083018054288
0.748559220217019
0.7182104492869809
0.6640384111392028
0.7480150255508645
0.7551263417209996
0.7713507728025755
0.7318771708789712
0.6954232144520828
0.7349829274371745
0.6833493764944625
0.7724336456549008
0.6986418199053714
0.6840834394117934
0.7549987934933318
0.7661879328205735
0.7578689462868657
0.7793298559863288
0.7652452923545622
0.7387706026054693
0.7219644101210344
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0013378564,0.011881398,0.010887856,-0.0061119995,-0.017308196,0.022680176,0.005149291,0.0006445179,-0.020528644,-0.034561574,0.023242043,-0.0057454165,-0.011086564,0.0068862773,-0.023488715,-0.012491227,0.028422168,0.007222026,0.00801686,-0.02170719,-0.007400179,0.016581882,0.002040188,-0.0397417,-0.017102635,0.021556446,0.028504392,-0.015430743,0.014663317,0.005786529,0.00044024212,0.013375138,-0.023118706,-0.032752644,-0.0077359276,0.02143311,0.010956376,-0.014444052,0.002389641,-1.14289505e-05,0.03250597,0.0047004838,-0.007790744,-0.020597164,0.009921721,0.007386475,0.01188825,-0.021213846,-0.010127282,-0.0045600175,0.020980878,0.02825772,-0.023337971,-0.009517452,-0.01185399,0.009517452,-0.005858475,0.009565416,0.012395299,-0.0022012105,0.018157845,0.009798385,-0.013409398,0.0107439635,-0.02940886,-0.013498474,0.004282511,0.009675048,-0.023337971,0.020295676,0.049361933,0.029217001,-0.0011597039,-0.015074438,0.009853201,-0.011984178,-0.01188825,-0.015800752,0.005115031,0.009051515,0.0014098026,-0.02251573,-0.02754511,0.039522436,0.00944208,-0.033766743,0.01046303,0.026681755,-0.018459335,0.009846349,-0.010942671,0.017417828,0.020460123,-0.0042482507,0.005207533,0.002028197,0.013066797,0.023927245,0.00975042,0.0023451028,-0.011326385,0.009709309,-0.04837524,-0.00872947,-0.015622599,0.00029228136,0.016869666,0.0006325268,0.011991031,-0.027435478,-0.04884118,0.04401736,0.0075714793,-0.030916302,0.011216752,-0.0048991926,-0.0017489775,-0.04344179,-0.0077633355,-0.0062558916,0.006721829,0.030559998,0.028860698,-0.005515874,0.01980233,-0.005978385,-0.033986006,-0.02598285,-0.024064286,-0.009195407,0.027887711,0.014156268,-0.022296464,0.03335562,-0.023118706,0.0048991926,-0.0057145823,0.033026725,-0.040125415,-0.015238887,0.024680967,0.0013858204,0.006324412,0.020843837,-0.0034619817,0.020734204,0.00044880714,0.030258508,-0.0052589234,-0.010565811,-0.0014903138,-0.017952286,0.02092606,0.00392278,0.017376715,0.0193638,0.008482797,-0.0019099999,-0.014964806,-0.015814455,-0.0009275919,0.0050191027,0.0025472373,0.014293308,0.015937792,0.018267479,0.016074833,-0.0012916053,-0.0061496855,0.011696394,-0.010949523,0.0295459,-0.018774528,0.028778473,0.003573327,0.013183282,0.02200868,-0.02761363,-0.0049197483,-0.00070190354,-0.010545255,0.020624572,-0.0016556187,0.012230851,-0.009133739,-0.014115156,0.0011057443,-0.02910737,-0.00037579032,-0.018500447,-0.010983784,0.015471855,0.008105936,0.012772161,-0.6604248,-0.028860698,0.00086292595,-0.014457757,0.013710886,0.019254168,0.0061633894,-0.01987085,-0.024516517,0.020268267,-0.019953074,0.003146789,0.016732626,-0.032588195,-0.016307801,-0.042098794,0.02000789,-0.020035299,-0.013786259,0.015279999,-0.018829344,0.010956376,-0.014923694,0.020802725,-0.003600735,0.013286062,-0.0077633355,-0.008414277,0.033547476,0.021666078,-0.002771641,0.028586617,-0.015924089,0.010497291,0.040070597,-0.016225576,-0.01950084,0.0054850397,-0.012278815,0.043359566,-0.04859451,-0.013847927,0.013964411,0.0041112103,-0.0037583315,0.006303856,0.008982995,-0.010408214,0.018692303,0.013176429,0.0016813137,0.02605137,0.002370798,0.0073590665,0.018980088,-0.010846743,0.014430349,-0.008092232,0.017006706,0.00079826004,0.009263927,0.0036863852,-0.011840286,-0.0024393182,0.00872947,0.03491788,0.014169971,0.026873613,-0.0052966094,-0.021172734,0.0044435333,0.008900771,-0.0037651835,-0.010387658,-0.00081025105,-0.0030885467,0.005481614,0.007564627,0.016732626,0.010120429,-0.004426403,-0.022776106,0.005139013,0.011353793,-0.0069171116,0.0066601606,-0.020021595,-0.009024107,0.0032547081,-0.012450116,0.019774921,0.032588195,-0.0069547975,-0.030998526,-0.012189738,0.025695065,0.00092502235,0.0155129675,0.00197852,-0.0140466355,-0.012484375,0.013039389,-0.0053205914,0.0077838916,0.018774528,-0.00039013673,-0.031574097,0.02839476,0.03859056,0.0031450759,-0.0019322688,0.018157845,-0.03206744,0.018938975,-0.004323623,-0.031738546,0.0066807168,-0.00315878,-0.0057351384,-0.013560142,0.027531406,-0.002766502,0.01908972,-0.014690725,0.009174851,0.025489504,0.004046116,-0.016006313,0.006831461,0.017308196,0.024653558,0.024023173,0.013957559,-0.008167605,0.022173127,0.0125666,-0.0035185108,0.009078923,0.007598887,-0.01036025,-0.010593219,0.01270364,7.344506e-05,0.010140985,-0.016321504,0.0050567887,-0.00709869,0.010613775,-0.0029617844,-0.010264322,0.008003157,-0.018226366,-0.010572663,-0.0012188025,-0.015403335,0.002840161,0.013066797,-0.029765163,-0.006690995,-0.034561574,0.012559747,0.042592138,-0.02448911,0.005950977,-0.007893524,-0.003100538,-0.012916053,0.024982454,-0.0017678204,-0.019555658,0.01477295,-0.029874796,-0.003912502,0.029710347,-0.0100107975,0.006821183,-0.0004419551,-0.019213056,-0.0064203404,-0.015882976,-0.008756878,-0.019254168,0.015773343,0.008249829,0.015663711,0.011182493,0.02731214,0.008455389,-0.03267042,0.04116692,-0.0058379187,0.0073179547,-0.010099874,0.010271174,0.011812878,-0.007626295,0.009736717,-0.0036521251,0.006879425,0.003528789,0.005419946,0.009325596,0.02639397,-0.025969146,-0.006320986,-0.009757273,0.008037416,-0.021035694,0.021830527,0.012306223,0.01837711,0.00041133518,-0.008051121,-0.015156662,0.0092296675,-0.0028641433,0.00025138338,0.0071329502,-0.009394116,0.032889683,-0.010606923,-0.01399182,0.052870166,-0.0038062956,0.013553291,0.025009863,-0.009120035,0.012299371,0.022063496,-0.02924441,-0.0017309908,0.0033283674,0.006273022,0.027120285,0.013429954,0.003117668,-0.022803513,-0.0049677123,0.0127995685,-0.012484375,0.013937003,0.015677415,-0.0045668697,-0.011744358,0.038069807,0.0049197483,0.032752644,0.019651586,0.0014603361,-0.010469883,-0.01192251,0.0013618384,-0.017363012,-0.0050362325,0.007989452,-0.0030097486,0.012573452,-0.0031998921,0.018116733,0.02184423,0.0173219,0.022748698,0.018911568,-0.034177862,0.03223189,0.0058139367,-0.009592825,-0.026078777,-0.021474222,-0.029025145,-0.022666473,0.0045291833,0.016458545,-0.042235836,0.037137933,0.0053000352,0.019514546,0.012354187,0.037823137,0.01412886,-0.021803118,-0.01803451,0.0035904571,0.01440294,0.0048580803,0.0021344034,-0.010922115,0.0049540084,-0.008599281,-0.0014406366,0.0037137934,0.01959677,-0.0038199998,-0.0029549324,-0.0076879635,0.014183676,0.0139232995,-0.0053000352,-0.011751209,-0.012731048,-0.012964017,0.0069445195,-0.019034903,-0.030779261,0.037658688,0.0072288783,0.015732232,-0.01647225,-0.008859659,-0.026668051,0.0064477483,-0.018870456,-0.0025609415,-0.021803118,0.01619817,0.004056394,-0.028641433,0.016924482,0.028449576,-0.0030063225,-0.0030046096,0.0011014618,-0.0021686635,0.0065025645,0.03335562,0.027133988,0.0034362867,0.010161541,-0.040426902,0.0033643404,0.003545919,-0.005968107,0.0026551567,0.018294886,-0.00040619614,0.010983784,-0.002761363,-0.0042413985,0.00071646407,0.014348124,0.026298042,-0.023351675,-0.008715766,-0.015005918,0.0032992463,-0.011134529,0.019199353,0.025325056,0.013231246,0.0021532464,0.008414277,0.0070849857,0.0021206993,-0.017691908,0.0045257574,0.014663317,0.018335998,0.019816034,0.007790744,0.02150163,-0.014909989,-0.0128475325,0.013847927,0.0073727705,0.012032143,-0.0023194079,0.011696394,-0.007112394,-0.00720147,-0.01348477,0.018870456,-0.010038205,0.0094009675,-0.00044238337,-0.0045839995,-0.011799173,-0.04105729,-0.0086678015,0.0053891116,0.011710098,-0.009072071,-0.0004258957,0.009085775,-0.021186437,-0.025544321,-0.008523909,0.01263512,-0.01164843,0.014211084,-0.0018980087,-0.0034277216,-0.003146789,-0.00031497868,-0.0010483586,0.002365659,-0.048731547,-0.038700193,-0.011573058,0.021241253,0.0302311,0.008565022,0.0015648295,-0.027092876,0.0013515605,-0.021309774,-0.0095106,-0.0033249415,-0.014444052,0.0077222236,0.014814061,-0.0025215424,-0.0034842507,-0.0029634975,0.013635514,-0.010709703,0.033657108,0.0077290754,-0.021515334,-0.0006586502,0.009181703,0.00013993104,0.021172734,0.005454206,-0.02235128,0.027558813,-0.023584643,-0.014211084,-0.0070164655,-0.012621416,-0.006985632,0.010771371,0.007578331,0.004412699,-0.00842113,0.011401757,-0.014581093,0.008852806,-0.017815245,0.0004787847,0.0008171031,0.021474222,0.016252985,-0.007968896,0.025845809,0.016855963,-0.041413594,0.016705219,0.010045057,-0.015910383,0.008743174,-0.021076806,0.011305829,-0.024434295,0.016362617,-4.7241447e-05,0.025078384,-0.0076468512,-0.005618654,-0.027928822,-0.0053171655,-0.02768215,-0.014718133,-0.010572663,-0.011031748,0.01195677,-0.003535641,-0.017500052,-0.007119246,0.00801686,-0.022680176,-0.010079318,0.014444052,-0.0072905463,0.040125415,-0.00119739,-0.002744233,-0.01484147,-0.027723262,-0.0021977846,-0.028888104,-0.0025695064,0.0021635245,0.021172734,0.01532111,0.03151928,0.017609684,0.03165632,-0.0056152283,-0.01980233,-0.0065608067,0.01249808,-0.0044435333,-0.009414672,0.01640373,9.464349e-05,-0.029737756,0.0077222236,0.0048717842,0.005858475,0.011230457,-0.026284339,-0.017472643,-0.017417828,-0.022090904,0.00064366136,0.022776106,-0.021268662,-0.006297004,-0.030477773,0.015787048,-0.0031930401,-0.003915928,0.021213846,0.0024701522,0.012957165,-0.0048580803,0.022460913,-0.00039013673,-0.0016564751,-0.010846743,-0.030998526,-0.0104767345,0.0021241254,0.03658977,-0.01952825,0.015814455,0.01603372,0.000987547,-0.012552896,-0.023954652,0.008914474,-0.017637093,0.0022543138,-0.006297004,-0.00957912,-0.025736177,-0.0120664025,-0.013868483,0.0013138743,0.006643031,-0.018281182,0.0029412284,0.0066807168,-0.021378294,0.024310958,-0.0096819,0.02618841,0.016061129,0.025859512,0.0029326633,0.0016907352,0.008201865,-0.011997882,-0.005889309,0.01036025,0.011360644,-0.012676232,0.015773343,-0.03379415,0.008571873,-0.0007447286,-0.013402546,-0.0077838916,0.009777829,0.013265505,-0.009558564,-0.007496107,-0.025845809,-0.011525093,0.00077342143,-0.008708914,-0.015074438,0.010120429,-0.0076879635,0.0014945962,0.009387264,0.01575964,0.028202903,0.006297004,0.0005785672,0.020980878,-0.0016547622,0.009496896,0.019925667,0.0016162195,0.008565022,0.024708373,0.008400573,-0.0046422416,-0.0022834348,0.008640394,-0.0025695064,-0.0012984573,0.02897033,-0.011024896,0.00039913002,0.00079611875,0.010874151,0.0019716679,-0.0057488424,-0.014101451,0.0029823405,-0.0077838916,0.00862669,0.009311891,0.0075714793,-0.030422958,-0.008222421,0.0022149147,-0.0045257574,0.0055672643,-0.0022132015,0.005190403,-0.03234152,-0.015019622,-0.0017986546,0.014594797,0.026476195,-0.013635514,0.007496107,0.024132805,0.003208457,-0.017870061,-0.007934636,0.021145325,-0.00723573,-0.021885343,0.022022383,-0.007208322,-0.027531406,0.02910737,-0.0009378699,-0.029491082,-0.023762796,0.0041557485,-0.019555658,-0.0006946233,-0.040426902,-0.015088142,0.0048306724,0.012648824,0.010339694,0.009325596,-0.0012873227,0.015197774,-0.0005121883,0.004340753,0.0074549946,-0.008722618,-0.013683478,0.013909595,-0.0025986275,-0.03760387,-0.012381596,0.001980233,0.0015168653,0.010970079,-0.013477918,-0.014348124,0.0058756047,-0.009736717,0.033410437,0.007866116,-0.016499657,-0.019254168,-0.006344968,0.005162995,0.026791388,-0.028915513,-0.008852806,-0.002348529,-0.0053411475,-0.03324599,-0.041961756,-0.019733809,0.0370283,0.019514546,-0.010031354,0.00063980714,-0.016266689,-0.020117523,-0.012189738,0.010558959,-0.007071282,-0.0076674074,0.0047004838,-0.0065984926,0.018322295,0.0025369595,-0.018335998,0.0022337576,0.01046303,-0.012559747,-0.022954257,0.016622994,0.037000895,-0.022255352,-0.014526277,0.0044640894,-0.01327921,0.02228276,0.0012753317,-0.0028487262,-0.015485559,0.014594797,0.01963788,0.026270634,0.023790205,0.01840452,-0.013882187,0.0037069414,0.014622205,-0.017349308,-0.026339155,-0.014307012,0.009709309,-0.0077496315,0.0040838025,-0.011799173,-0.017527461,-0.008551317,-0.001593094,0.02170719,-0.0013010268,-0.00042139908,0.0271751,0.003162206,-0.02170719,-0.0017952286,0.026640642,-0.02496875,-0.018829344,0.023721684,-0.039851334,0.005173273,-0.002336538,-0.01945973,-0.020268267,-0.0021446815,-0.0042516766,-0.0062456136,-0.005214385,0.009633936,0.007537219,-0.017239675,0.020323083,-0.004409273,-0.01406034,-0.01633521,0.0028298832,0.02690102,0.004481219,-0.0133134695,-0.0015870985,-0.01871971,-0.019980483,0.026681755,0.025653953,0.014718133,0.03264301,0.24645336,-0.017486349,-0.013162726,0.011251013,0.015238887,0.0059715332,-2.4507337e-06,0.032012627,-0.021021988,-0.013011981,0.016705219,0.006324412,0.0046525197,0.0020830133,0.001379825,-0.00998339,-0.021049397,-0.008565022,0.0016376321,0.013046241,0.013525882,0.0029600714,0.0004839237,-0.020268267,0.045387764,0.011161936,0.0026774257,0.019308984,-0.014320716,-0.0107439635,0.006653309,0.0026191836,0.0080305645,0.020501235,-0.016513363,-0.00808538,-0.006036627,-0.016732626,0.025873218,0.014677021,0.020967172,-0.009688753,-0.011497685,-0.010894707,0.00927078,0.003203318,-0.011346941,-0.0125803035,0.010017649,0.007160358,-0.023187226,-0.01619817,0.017102635,0.028997738,-0.0015545514,-0.010737111,0.0017695335,-0.004046116,0.034616392,0.014142564,-0.035575673,0.010874151,-0.029217001,0.018431926,-0.0051869773,-0.0007344506,-0.0029806276,-0.010346546,0.02655842,-0.026202114,-0.01440294,0.007852412,-0.0020932914,-0.0011382913,-0.025722474,-0.0056837485,0.03352007,0.019583065,0.020049002,0.023173522,-0.01589668,0.000116912546,-0.0020898653,-0.010634331,-0.016129648,-0.009832645,0.024023173,-0.016020017,0.008119641,0.006690995,6.1025778e-05,0.0005147578,-0.013094205,-0.007660555,0.0013215828,0.0044401074,0.004837524,0.025146903,-0.010195802,0.00061967934,-0.03108075,0.056131724,0.010312286,0.0030902599,0.015403335,0.016157057,0.02442059,0.015142959,0.008482797,-0.015910383,-0.00281104,-0.050650112,-2.3941911e-05,-0.0073179547,-0.007400179,0.0058379187,0.0015571209,-0.003528789,0.033657108,-0.010661739,-0.006026349,-0.014909989,-0.002312556,0.009770976,0.011806026,-0.021337181,-0.020254564,-0.0015271434,-0.015417039,0.007146654,-0.0011862555,0.017472643,0.0022114886,0.027723262,-0.009935425,-0.019857146,-0.017952286,-0.040975064,0.0034619817,0.009250224,-0.000690769,0.017280787,0.016581882,-0.016280392,0.0019048608,-0.011566205,0.012148627,0.0096819,-0.015745936,-0.015348519,-0.005108179,-0.0038782419,-0.015787048,-0.025105791,0.020542348,-0.012463819,-0.012621416,-0.017006706,0.010305434,-0.008051121,-0.0116004655,0.0044743675,0.008208716,-0.03135483,-0.013121613,-0.0074549946,-0.1766176,-0.0065094163,0.02278981,-0.043633647,0.018198958,0.021734599,0.012594008,0.0038850938,-0.03368452,0.015211479,0.008304645,-0.013861631,-0.020994581,0.0049471566,0.004368161,-0.0029600714,-0.030121468,0.016129648,0.0043099187,0.02669546,0.026942132,-0.01952825,0.0052109594,-0.0008115358,-0.01640373,-0.0045223315,-0.003186188,0.011751209,0.011915658,-0.021994976,0.01858267,-0.011840286,0.010565811,0.007468699,-0.0049300264,-0.010127282,0.0017446949,-0.020775316,-0.005255497,0.012710492,0.025900625,0.010654887,-0.01803451,0.029217001,-0.0011674125,0.018801935,0.021145325,0.0026363137,0.009976537,-0.023420196,0.00630043,-0.011833434,-0.0005759977,-0.0018997218,0.017746724,0.02078902,0.016732626,-0.009770976,-0.013649219,-0.029354041,-0.01963788,-0.0065984926,0.019994186,-0.003172484,-0.0033523494,-0.0044298293,-0.0030491478,0.027133988,-0.053199064,0.0070233177,-0.020350492,0.003146789,0.0056392103,-0.003100538,-0.0053000352,0.021624967,-0.01654077,0.005221237,0.018897863,-0.012511783,-0.009490044,0.046730757,-0.0042139906,0.016801147,-0.014868878,0.017212268,0.0041317665,0.036233466,-0.013799963,-0.010093021,0.010209505,-0.03831648,-0.0014243631,-0.01242956,0.026010258,0.024913935,0.010894707,-0.013978115,0.011168788,0.0006869147,-0.0026962687,-0.0030285916,-0.028778473,0.01745894,0.020871244,0.0032889682,0.003998152,0.021775711,0.027915118,0.0018123586,-0.03658977,-0.010517847,-0.00957912,-0.012916053,-0.0023382509,0.029573306,0.005892735,0.00017247812,-0.031437054,0.0060880175,0.06764311,-0.017637093,0.0029926186,0.000980695,-0.0024290401,-0.030697038,-0.123117045,-0.025105791,0.004268807,-0.0025026994,0.009490044,0.003576753,-0.009174851,-0.009825793,-0.02533876,0.017870061,-0.05040344,-0.028148087,-0.0008659237,-0.009353003,-0.015129254,-0.0027116858,0.0056597665,-0.004337327,-0.020624572,0.019720105,-0.0339586,-0.030724445,-0.015567783,0.002382789,0.018185254,0.005526152,-0.01888416,-0.0024530222,-0.004518905,-0.0013018833,0.027408069,-0.022063496,-0.019240465,-0.0030166006,-0.013957559,-0.01131268,0.005968107,-0.009496896,0.024242437,-0.036891263,0.014375532,-0.02085754,-0.011641578,-0.020090114,-0.011593613,0.003604161,-0.02894292,0.029902203,0.007434439,-0.008743174,-0.02044642,0.00400843,-0.02866884,0.007989452,0.008811695,0.0070849857,0.0036418473,0.014882581,-0.008756878,0.016773738,-0.015389631,0.017171156,0.010017649,-0.004786134,0.032752644,-0.017870061,-0.020980878,-0.01952825,0.006324412,-0.032834865,-0.007502959,-0.0012941748,-0.0096202325,0.02007641,-0.02251573,-0.010250618,0.0020384751,0.004066672,-0.007194618,-0.016636698,-0.0062901517,-0.0075851833,0.018185254,-0.02078902,0.0034431387,0.007222026,-0.009729865,-0.017609684,-0.017171156,-0.013183282,-0.017294493,0.04703225,0.018829344,-0.029902203,0.0032906814,0.006619049,0.0005383116,0.0029172464,0.00064751564,0.00954486,-0.032999314,-0.009531156,-0.039796516,0.01885675,-0.016074833,-0.01851415,-0.010709703,-0.019678993,0.0052246633,-0.0058139367,0.00484095,-0.011436017,-0.012984573,0.012340483,-0.031025935,0.0033592016,-0.02157015,7.472981e-05,0.010510994,-0.014978509,0.016910778,-0.009490044,-0.0077564837,-0.01633521,-0.0011340089,-0.013039389,-0.010860448,-0.0044914973,-0.0076674074,0.02442059,-0.022762401,-0.01619817,0.0042653806,-0.023242043,0.002775067,0.036617182,0.013183282,-0.009161147,0.007872968,0.017705612,0.037302382,-0.023077594,9.53394e-05,-0.04127655,-0.009263927,-0.013203837,0.017719317,0.004234547,-0.0039193537,-0.008071677,-0.009640789,-0.0020196321,0.01950084,0.022844626,-0.010887856,-0.028175496,-0.016581882,-0.015650008,-0.0005340291,-0.019980483,-0.023022778,-0.017171156,0.035329003,-0.007523515,0.02221424,-0.011127676,0.014279604,0.0068143313,-0.0026962687,0.016143354,-0.0026311746,-0.026133593,-0.002792197,0.0014509147,-0.0037960175,-0.0016975873,-0.00013725446,0.01619817,-0.020487532,0.006324412,-0.0011340089,0.041112103,-0.0022166276,-0.011730653,-0.02839476,0.011949918,0.024475405,-0.0019271299,-0.014416644,0.0036247172,0.0044435333,-0.01582816,0.0019082868,0.008565022,0.010346546,0.0003192612,0.0005160426,-0.0034345738,0.0065539544,-0.010538403,0.0005734282,0.015787048,0.006358672,0.00794834,-0.00957912,-0.021542743,-0.041523226,0.017280787,-0.02448911,-0.050293807,0.013251801,0.0060674613,0.018706007,-0.018445631,0.020323083,0.008893918,-0.0061668158,0.023995765,-0.016102241,-0.03480825,-0.036671996,0.022762401,0.004046116,-0.02313241,-0.013039389,0.008393722,0.024790598,0.028367352,0.017404124,-0.024982454,0.023214635,0.015745936,0.001586242,0.0022012105,-0.0015853855,-0.018829344,-0.01929528,-0.01759598,0.009188555,0.015403335,-0.0064854342,0.069780946,0.013806815,0.006721829,-0.010504142,-0.0026106185,0.028367352,0.02285833,-3.094114e-05,-0.020624572,-0.025900625,-0.0066259005,0.008174457,-0.029299226,-0.015458151,-0.009736717,0.00028478698,-0.011901954,0.0011254438,-0.023283156,-0.004323623,0.024119101,-0.00048092596,0.010887856,0.008393722,0.0037549054,0.0034619817,0.002703121,-0.0026671477,0.020775316,-0.015882976,-0.0024050581,0.014101451,-0.02839476,-0.027133988,0.005642636,0.013930151,-0.0060811653,-0.016157057,-0.005029381,0.0011597039,-0.0017172869,0.015608896,-0.016636698,-0.0112099005,-0.027394366,0.01647225,0.016225576,-0.022776106,-0.0028761344]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0013010816,0.011936718,0.010915724,-0.006129388,-0.017240403,0.022681134,0.005012462,0.00065996277,-0.020515805,-0.03459044,0.023243023,-0.005800477,-0.011114441,0.0069722217,-0.02353082,-0.012546573,0.028395958,0.0072086263,0.007989789,-0.021653289,-0.0073799337,0.016651105,0.0020231435,-0.039770786,-0.017034834,0.021612175,0.028560413,-0.015445098,0.014691344,0.0057970514,0.00048779856,0.013334588,-0.023064863,-0.032808844,-0.007633469,0.02142031,0.011059622,-0.014376138,0.0023794633,3.535897e-05,0.03247993,0.004652716,-0.00778422,-0.020598033,0.0098947305,0.0073045585,0.011902456,-0.021255855,-0.010141414,-0.0046013235,0.020940648,0.02831373,-0.023256728,-0.009497297,-0.011881899,0.009490444,-0.005831313,0.009517853,0.0124163795,-0.002191025,0.01821343,0.009730275,-0.013341441,0.010744416,-0.02935528,-0.013471634,0.00424843,0.009641195,-0.023366366,0.020323941,0.049391422,0.029218234,-0.0011845925,-0.015088779,0.009860469,-0.011936718,-0.0118956035,-0.015760304,0.0050741327,0.009140977,0.0013584697,-0.02243445,-0.027532566,0.039441876,0.009524706,-0.03390521,0.010484029,0.026614359,-0.018405294,0.009819355,-0.010970542,0.017432267,0.020433577,-0.004272413,0.0052454406,0.0019974473,0.013046791,0.023900844,0.009757685,0.0023143664,-0.011292601,0.0096549,-0.0484321,-0.008716133,-0.015636964,0.00024625476,0.016884083,0.000625273,0.011984684,-0.027436635,-0.049007695,0.044019215,0.0075306846,-0.030999834,0.0112583395,-0.0048685637,-0.001721642,-0.043416213,-0.0077088447,-0.0062938435,0.0067426693,0.030479059,0.028889323,-0.0055263853,0.019775756,-0.005971785,-0.03396003,-0.025956536,-0.024106413,-0.009182091,0.027875183,0.014225388,-0.022242587,0.03330221,-0.023119682,0.0049096774,-0.005769642,0.033082936,-0.040099695,-0.015239529,0.024695711,0.001343052,0.0063178265,0.020872125,-0.0033936047,0.020721374,0.00046809818,0.030259784,-0.0052625714,-0.010593666,-0.0015075074,-0.01803527,0.020981763,0.0038989624,0.017363744,0.019419435,0.008462599,-0.0019546205,-0.014979142,-0.015787713,-0.0008702429,0.0050295927,0.0025096573,0.014321321,0.01595217,0.018254545,0.016048102,-0.0013559001,-0.0062081898,0.0116900345,-0.01087461,0.029574554,-0.018734206,0.028807096,0.0035529209,0.013204394,0.021982199,-0.0276285,-0.004902825,-0.0007370512,-0.010511438,0.020611737,-0.0016591147,0.012224515,-0.009106715,-0.014074638,0.0010783817,-0.029081188,-0.00047280913,-0.018473817,-0.010956838,0.015472508,0.008030903,0.012779552,-0.6604527,-0.028834505,0.00082784425,-0.014458367,0.013704613,0.019227572,0.0062047634,-0.019885393,-0.024544962,0.020228008,-0.019981325,0.0031880355,0.016705923,-0.032534752,-0.016322194,-0.042045753,0.020008735,-0.020049848,-0.013821102,0.015308052,-0.018761614,0.010881462,-0.014938028,0.02085842,-0.00362487,0.013334588,-0.007743106,-0.00840778,0.033576302,0.021680698,-0.0027923149,0.028587822,-0.015965873,0.010470324,0.040154517,-0.016185148,-0.019474255,0.0054647145,-0.012347856,0.043279167,-0.04851433,-0.013793693,0.013958148,0.0041182362,-0.0037413593,0.0062938435,0.008955965,-0.010388097,0.018665683,0.013197542,0.001723355,0.026011355,0.002441134,0.007359377,0.019090526,-0.010922576,0.01449948,-0.008181654,0.017034834,0.00073576637,0.009257466,0.0036968193,-0.011888752,-0.0025130834,0.008695576,0.03491935,0.014252797,0.026861042,-0.0053756344,-0.021146217,0.004409459,0.008894294,-0.0038407177,-0.010333278,-0.0007952958,-0.0030047363,0.0054818452,0.007496423,0.016801855,0.01018938,-0.0043889023,-0.022804476,0.00513923,0.01132001,-0.0068899943,0.006639885,-0.020049848,-0.009065601,0.0032582716,-0.012423231,0.01981687,0.03250734,-0.007023614,-0.030945016,-0.012183401,0.02566874,0.0009259179,0.015472508,0.0019768905,-0.014033523,-0.012491754,0.013039939,-0.0053310944,0.0078733,0.0187205,-0.00040064577,-0.03154802,0.028286321,0.0386196,0.003110947,-0.0018929497,0.018117499,-0.032068793,0.018967183,-0.00433751,-0.031712472,0.0067769308,-0.0031709047,-0.005862148,-0.013581271,0.027477749,-0.0027803234,0.01907682,-0.014663936,0.0091683855,0.025476875,0.004029156,-0.015993282,0.006866011,0.017199289,0.024654599,0.024079004,0.014019819,-0.0080994265,0.022174064,0.012491754,-0.0034552754,0.009113568,0.007578651,-0.01042921,-0.010579961,0.012772699,6.9660655e-06,0.0101688225,-0.016335899,0.0050672805,-0.007092137,0.010538847,-0.002908804,-0.010292164,0.008030903,-0.018172316,-0.010655336,-0.0012608244,-0.015445098,0.0028505595,0.013142724,-0.02973901,-0.0066775726,-0.034563035,0.01253972,0.042621344,-0.02457237,0.0060060467,-0.007852743,-0.0031212256,-0.012916598,0.0249561,-0.0017627558,-0.019529073,0.014718754,-0.029876055,-0.00389211,0.029684192,-0.010004368,0.0067700786,-0.0004379052,-0.019337209,-0.0064240373,-0.015856236,-0.008681872,-0.01925498,0.015760304,0.008209063,0.015678076,0.0112583395,0.027381817,0.008421484,-0.032644387,0.04111384,-0.005755937,0.0073114107,-0.010079742,0.010257903,0.01185449,-0.0075992076,0.009798798,-0.0037756208,0.006845454,0.0034741194,0.005440731,0.009353398,0.026504721,-0.025956536,-0.0062424513,-0.0098262075,0.008010346,-0.020995466,0.021913676,0.01229989,0.018419,0.00040471434,-0.0080994265,-0.015171006,0.009264318,-0.0028385678,0.0002719509,0.007051023,-0.009401364,0.03286366,-0.01060737,-0.013971853,0.052927215,-0.0037996038,0.01360868,0.024983509,-0.009182091,0.012293038,0.022091836,-0.029190825,-0.0016788151,0.0033062377,0.006365793,0.027176248,0.013423668,0.0030903902,-0.022886703,-0.0049747746,0.012800109,-0.012512311,0.014006115,0.01571919,-0.0045841928,-0.011642069,0.038071413,0.0049302345,0.032808844,0.019734642,0.0014201405,-0.01042921,-0.011881899,0.0014252798,-0.017404858,-0.0049782004,0.008017198,-0.0029464918,0.012615096,-0.0031777571,0.018227136,0.021858858,0.01729522,0.022777066,0.018939774,-0.034151893,0.03223325,0.005831313,-0.009641195,-0.026079878,-0.021502538,-0.028944142,-0.02266743,0.0045533576,0.016472945,-0.042265024,0.0371395,0.0053550773,0.019529073,0.012375265,0.03782473,0.014156865,-0.021845153,-0.01803527,0.0035700516,0.014403548,0.004895973,0.002146485,-0.010936281,0.004943939,-0.008579087,-0.0014081489,0.0037619162,0.019570187,-0.0038852578,-0.0029327872,-0.007797925,0.014239092,0.013944443,-0.0053550773,-0.011738,-0.012663062,-0.012937155,0.0069893524,-0.019035706,-0.030890197,0.037605457,0.007290854,0.015705487,-0.016500354,-0.008812066,-0.026655471,0.006389776,-0.018926071,-0.002501092,-0.021858858,0.016239965,0.00402573,-0.028642641,0.016911492,0.028505594,-0.0029550572,-0.0029567701,0.0011494744,-0.0021344933,0.006509691,0.033357028,0.027107723,0.003515233,0.010141414,-0.040373787,0.0033370731,0.0035426423,-0.0059546544,0.0026467033,0.018336771,-0.0004310529,0.010984247,-0.0026929565,-0.004227873,0.00067495217,0.014362434,0.026312856,-0.023366366,-0.008681872,-0.014992846,0.0033028116,-0.011169259,0.019268686,0.025380943,0.013183838,0.002215008,0.008448894,0.007188069,0.0021087972,-0.017706359,0.004608176,0.014650231,0.018323068,0.01981687,0.0077568106,0.021488832,-0.014965437,-0.01283437,0.013807397,0.0073045585,0.012066912,-0.0023126535,0.011628364,-0.007064728,-0.0073114107,-0.013505896,0.01889866,-0.010038629,0.009408217,-0.00046981126,-0.0045773406,-0.011779115,-0.04111384,-0.008681872,0.005324242,0.011607807,-0.009065601,-0.00046595684,0.009072454,-0.021173626,-0.025545398,-0.008565383,0.012676767,-0.011642069,0.014184274,-0.0018843842,-0.003400457,-0.0030749724,-0.00036081675,-0.0010843775,0.0024736826,-0.04876101,-0.038701825,-0.0115324315,0.021255855,0.030259784,0.008565383,0.0015588996,-0.027080314,0.0013644655,-0.0213929,-0.0094630355,-0.003311377,-0.014444661,0.00769514,0.014842096,-0.0026073025,-0.0034963894,-0.002997884,0.013581271,-0.010730712,0.033685938,0.007715697,-0.021475129,-0.00066809985,0.009195795,9.031126e-05,0.021228446,0.005368782,-0.022379633,0.027587386,-0.023599343,-0.0142116835,-0.007006483,-0.012608244,-0.006999631,0.010717007,0.0075512417,0.0043751975,-0.008435189,0.011443351,-0.014581708,0.0088737365,-0.017774882,0.0004608176,0.0008055743,0.021488832,0.016171442,-0.007928118,0.025805786,0.016884083,-0.04136052,0.016719628,0.010059185,-0.015842533,0.00867502,-0.0210914,0.01132001,-0.02444903,0.016390717,-0.00013865213,0.025038328,-0.0076745832,-0.0055846297,-0.02795741,-0.005296833,-0.027669612,-0.014732459,-0.010552552,-0.011045918,0.01194357,-0.0035837563,-0.017541904,-0.0070784325,0.008072017,-0.02264002,-0.010107152,0.014430957,-0.0072154785,0.040127106,-0.0011880186,-0.0027323572,-0.014828391,-0.027792955,-0.002170468,-0.028834505,-0.0025798935,0.002211582,0.021132512,0.01539028,0.0314932,0.017583018,0.031630248,-0.0055777775,-0.019803165,-0.0064754295,0.012464345,-0.0044197375,-0.009380807,0.016404422,0.000106050145,-0.0297116,0.007722549,0.004895973,0.0059375237,0.011176112,-0.02623063,-0.017487086,-0.017418563,-0.02207813,0.00063940586,0.022708543,-0.021255855,-0.0063109742,-0.030506467,0.015787713,-0.0031674786,-0.0039503546,0.021146217,0.0025199356,0.012909745,-0.004889121,0.022448156,-0.0004745222,-0.0016925196,-0.010847201,-0.031082062,-0.010484029,0.0021087972,0.036700953,-0.019556483,0.015801419,0.016116625,0.0010132848,-0.012587687,-0.023983072,0.008914851,-0.017651541,0.0022458434,-0.0063109742,-0.009558967,-0.025682444,-0.012046355,-0.01387592,0.0012805248,0.0066330326,-0.01824084,0.002884821,0.0067255385,-0.021379195,0.024407916,-0.009682309,0.026244333,0.016048102,0.025888013,0.0029190825,0.0016299924,0.008202211,-0.011950422,-0.005930671,0.010415506,0.011333715,-0.012697323,0.015760304,-0.033822984,0.008544826,-0.00075717986,-0.013423668,-0.0077773677,0.009791946,0.013224951,-0.0094630355,-0.007448457,-0.02579208,-0.011600954,0.00070535927,-0.008757248,-0.015020256,0.010175675,-0.0077088447,0.0014484063,0.009401364,0.015691781,0.028176684,0.006263008,0.00053533644,0.02103658,-0.0016522624,0.0096000815,0.019926507,0.0016599712,0.008524269,0.024709417,0.008414633,-0.0046835514,-0.0021944512,0.00867502,-0.0025713278,-0.0012942294,0.028971551,-0.011080179,0.00039229455,0.0008252746,0.010881462,0.0019494812,-0.005742233,-0.014088342,0.002975614,-0.007839038,0.008613349,0.009325989,0.007564946,-0.03045165,-0.008154244,0.002237278,-0.004498539,0.005612039,-0.0022475566,0.0052248836,-0.032342885,-0.015006551,-0.0017730342,0.014581708,0.026436199,-0.013704613,0.0074553094,0.024147527,0.0032291494,-0.01785711,-0.007989789,0.021173626,-0.007181217,-0.02189997,0.022091836,-0.007188069,-0.027518863,0.029136006,-0.00093448325,-0.029574554,-0.023777504,0.004142219,-0.019583892,-0.00067538046,-0.040483426,-0.015157302,0.004762353,0.012642506,0.010353835,0.009257466,-0.0012325586,0.015335462,-0.00050450105,0.0043203793,0.007469014,-0.008812066,-0.013752579,0.0139855575,-0.0025370663,-0.037632868,-0.012327299,0.001992308,0.0015708912,0.011025361,-0.013512748,-0.014307615,0.0058518695,-0.009702866,0.033494074,0.007811629,-0.016500354,-0.019323504,-0.006372645,0.0051323776,0.026806222,-0.028916733,-0.008818918,-0.0022886703,-0.005283128,-0.033219982,-0.041881297,-0.019803165,0.037057273,0.019529073,-0.010059185,0.0005790199,-0.016212557,-0.020077258,-0.012203958,0.0105319945,-0.0070852847,-0.0076608784,0.00469383,-0.0066056233,0.018336771,0.002554197,-0.018350476,0.0022424173,0.010470324,-0.012580834,-0.022968931,0.016623694,0.037002455,-0.022269996,-0.014540594,0.004409459,-0.013348293,0.02231111,0.0012385544,-0.0029259347,-0.015499917,0.014581708,0.01969353,0.026299153,0.023791207,0.018432705,-0.013882773,0.0036214439,0.014636527,-0.01732263,-0.026312856,-0.014321321,0.009750832,-0.007722549,0.004046287,-0.011840785,-0.017487086,-0.008565383,-0.0016522624,0.021666992,-0.001196584,-0.0003715235,0.027135134,0.0031931747,-0.021708107,-0.0017935912,0.02655954,-0.02492869,-0.018816434,0.023750095,-0.039825603,0.0051563606,-0.0023212188,-0.019474255,-0.020269122,-0.002211582,-0.0042826915,-0.0062732864,-0.0051974743,0.009641195,0.0075717987,-0.017281517,0.02035135,-0.00438205,-0.014060932,-0.016322194,0.0028300025,0.02691586,0.004491687,-0.013320884,-0.0016137181,-0.018789023,-0.019967621,0.026682882,0.025627626,0.014773573,0.032644387,0.2460252,-0.017459676,-0.013170132,0.011244635,0.015253234,0.0058929836,-8.585458e-06,0.032068793,-0.020968057,-0.012937155,0.016664809,0.0063144,0.0046869777,0.002057405,0.0014612543,-0.0099632535,-0.020968057,-0.008572236,0.0015186424,0.013060496,0.013588124,0.0029636226,0.0005271993,-0.020310236,0.045417085,0.011134998,0.0027100872,0.0193098,-0.014252797,-0.01069645,0.0065953447,0.002662121,0.008058312,0.020460987,-0.01651406,-0.008133688,-0.006084848,-0.016747037,0.0258469,0.014732459,0.020968057,-0.009661752,-0.011505023,-0.010833496,0.00929858,0.0031554871,-0.011388533,-0.0126219485,0.0100317765,0.0070852847,-0.023215614,-0.016157739,0.017158175,0.028971551,-0.0014758154,-0.01069645,0.0018004435,-0.0040188776,0.034563035,0.014115751,-0.035577174,0.010860906,-0.029218234,0.018473817,-0.005207753,-0.0007901566,-0.0029190825,-0.0104634715,0.026545836,-0.026216924,-0.0144172525,0.007866448,-0.0020625442,-0.0011246348,-0.025750967,-0.0056908405,0.033494074,0.01963871,0.020036144,0.023284137,-0.015938465,0.00018051545,-0.0021327804,-0.010593666,-0.016157739,-0.009867321,0.02403789,-0.016061805,0.008147392,0.0066501633,-3.407751e-06,0.00051520776,-0.013094758,-0.007633469,0.0013010816,0.004392328,0.004837728,0.025120554,-0.010134561,0.00061713584,-0.031054653,0.056134094,0.010264755,0.0030818249,0.01539028,0.016089216,0.02439421,0.0151435975,0.008428337,-0.015869942,-0.002794028,-0.05062484,-3.9106326e-05,-0.0073799337,-0.007352525,0.005862148,0.0016274228,-0.0034998155,0.03365853,-0.010717007,-0.0060094725,-0.014938028,-0.0023075142,0.009743979,0.011792819,-0.021324378,-0.020241713,-0.001498942,-0.015445098,0.0071675126,-0.0011794532,0.017445972,0.0022287127,0.02777925,-0.009956401,-0.019926507,-0.017953042,-0.04103161,0.003559773,0.009223204,-0.000682661,0.01729522,0.016486648,-0.01628108,0.0019340635,-0.01152558,0.012149139,0.009702866,-0.0157466,-0.015308052,-0.005039871,-0.0038407177,-0.015815124,-0.025106851,0.0205021,-0.012471197,-0.012711029,-0.017007424,0.010319574,-0.008037755,-0.011600954,0.0045259483,0.008161097,-0.031356152,-0.0131221665,-0.0073730815,-0.17662504,-0.006502839,0.02281818,-0.043635488,0.018172316,0.02174922,0.01256713,0.0038544224,-0.033685938,0.0152121205,0.00838037,-0.0139170345,-0.020968057,0.004943939,0.0042689866,-0.0029464918,-0.030122738,0.01610292,0.004310101,0.02671029,0.026943268,-0.019570187,0.0052385884,-0.00083212694,-0.016486648,-0.0045396527,-0.0031846093,0.011738,0.0119641265,-0.022037018,0.018542342,-0.011875047,0.010689598,0.007407343,-0.004971348,-0.010161971,0.0017798865,-0.020762488,-0.0052934065,0.012697323,0.025942832,0.010717007,-0.018076384,0.029327871,-0.0012034363,0.018830137,0.021118809,0.0025816064,0.010011219,-0.023421183,0.0063452357,-0.011868195,-0.00048351588,-0.0018381312,0.017761178,0.02085842,0.01676074,-0.009785093,-0.013684056,-0.029382689,-0.01963871,-0.006571362,0.020036144,-0.0032514194,-0.0033644824,-0.004409459,-0.0030355717,0.02709402,-0.053173896,0.0069962046,-0.02037876,0.0030921032,0.005567499,-0.0030578417,-0.005283128,0.021639584,-0.016582582,0.005296833,0.018912366,-0.01256713,-0.009497297,0.04673273,-0.0042450037,0.016829265,-0.0148558,0.017212994,0.004077122,0.036180176,-0.013773136,-0.010072891,0.010257903,-0.038345505,-0.0013815963,-0.012354708,0.025929127,0.024901282,0.010888315,-0.014033523,0.011237782,0.0007019331,-0.0027220787,-0.002996171,-0.028724868,0.017459676,0.02085842,0.0032839677,0.0039503546,0.021735515,0.027916295,0.0017627558,-0.036563907,-0.010586813,-0.009606933,-0.012964563,-0.0023657589,0.029547146,0.005899836,0.00019786034,-0.03143838,0.006170502,0.06759115,-0.017706359,0.0030732595,0.0010158544,-0.0024479865,-0.03075315,-0.12323188,-0.025230192,0.004347788,-0.002504518,0.009524706,0.0035426423,-0.009140977,-0.00980565,-0.025422057,0.01791193,-0.050460383,-0.028176684,-0.0008668167,-0.009373955,-0.0151435975,-0.002636425,0.0056531527,-0.0043135267,-0.020625442,0.019775756,-0.034042258,-0.03078056,-0.015527327,0.0023606196,0.018309362,0.005385913,-0.018871251,-0.002528501,-0.004556784,-0.0013756005,0.02745034,-0.022023313,-0.019186458,-0.003066407,-0.013978705,-0.011354271,0.006016325,-0.00947674,0.024229756,-0.036838,0.0143487295,-0.020872125,-0.011635216,-0.020077258,-0.011600954,0.0035426423,-0.028944142,0.029930875,0.0074553094,-0.008777805,-0.020433577,0.0040394347,-0.02861523,0.008065165,0.008846328,0.007119546,0.0036180178,0.014883209,-0.008722986,0.01681556,-0.015335462,0.017212994,0.009970106,-0.00478291,0.032671798,-0.017843407,-0.020968057,-0.01943314,0.006328105,-0.032808844,-0.007578651,-0.0013062209,-0.00956582,0.020132076,-0.022544088,-0.010285311,0.0020471264,0.004029156,-0.007181217,-0.016596286,-0.00626986,-0.0076197647,0.018199725,-0.020803602,0.0034963894,0.0072223307,-0.009723423,-0.017651541,-0.017185584,-0.013238656,-0.017240403,0.047006823,0.018843843,-0.029930875,0.0032360016,0.0066775726,0.0005580347,0.0028985257,0.0005841591,0.00953841,-0.03294589,-0.0095315585,-0.039770786,0.018884957,-0.01610292,-0.018542342,-0.01069645,-0.019734642,0.005207753,-0.005786773,0.00473837,-0.011450204,-0.012957712,0.012347856,-0.030999834,0.0034073093,-0.021584764,2.3608336e-05,0.010442914,-0.015047665,0.016966311,-0.0095315585,-0.0076403217,-0.016322194,-0.0011357698,-0.013074201,-0.010936281,-0.004563636,-0.0076197647,0.024380505,-0.022681134,-0.016185148,0.0041936114,-0.023284137,0.0027803234,0.036591318,0.013108462,-0.009175238,0.007866448,0.017720064,0.037331365,-0.02305116,7.5696575e-05,-0.041223474,-0.009195795,-0.013156428,0.017720064,0.0041696285,-0.0039058146,-0.008085721,-0.009586376,-0.0020488396,0.019529073,0.022831885,-0.01087461,-0.028176684,-0.016596286,-0.015636964,-0.0005109251,-0.019926507,-0.023023749,-0.01717188,0.035303082,-0.007585503,0.022215176,-0.011128145,0.0142116835,0.0068317493,-0.002727218,0.01613033,-0.0026073025,-0.02617581,-0.0028197241,0.0014552586,-0.003734507,-0.0017130766,-0.00012987261,0.01607551,-0.0205021,0.0063144,-0.0011460482,0.041196067,-0.0022167212,-0.011731149,-0.028368548,0.011923013,0.024435325,-0.0020077256,-0.014403548,0.0036180178,0.004399181,-0.015856236,0.0019751773,0.0085996445,0.010312721,0.0003610309,0.0005387626,-0.0035357901,0.006554231,-0.0105319945,0.0005636022,0.01577401,0.006376071,0.007976085,-0.009552115,-0.021543652,-0.041579794,0.017254107,-0.024544962,-0.05018629,0.013204394,0.006108831,0.018734206,-0.018405294,0.02035135,0.008907998,-0.0062287464,0.024133824,-0.01610292,-0.034891944,-0.036700953,0.022777066,0.0040325825,-0.023119682,-0.013012529,0.008394076,0.02477794,0.028395958,0.017418563,-0.024942394,0.023284137,0.015760304,0.0015786,0.0021790334,-0.0015828827,-0.018830137,-0.019323504,-0.017637836,0.009099863,0.015376575,-0.006461725,0.06978389,0.013766283,0.006691277,-0.010477177,-0.0025250749,0.028368548,0.022900408,5.0830193e-05,-0.020666556,-0.02587431,-0.006602197,0.008250177,-0.029327871,-0.015458803,-0.009743979,0.00018811722,-0.011792819,0.0011760271,-0.023270432,-0.0042998223,0.024202347,-0.00053362333,0.0108266445,0.008421484,0.0037208023,0.0034946762,0.0026655472,-0.0026278596,0.020817306,-0.015938465,-0.0024102987,0.014074638,-0.02831373,-0.027176248,0.0055846297,0.013992409,-0.006084848,-0.016226262,-0.0049987575,0.0011905882,-0.0017396293,0.015609554,-0.016719628,-0.011203521,-0.027409226,0.016445536,0.016239965,-0.022831885,-0.0028711164]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
0.7580018896488978
0.7637750753570236
0.6864517179406447
0.7341996410891527
0.748854815957866
0.76797169363042
0.6872967536817165
0.7510665207642598
0.7760292480243737
0.6919704182452218
0.7649560472482897
0.7042936595760976
0.7069644162104946
0.7558126583439693
0.7747237212170256
0.7015772831257484
0.6965170769183073
0.7640973056155397
0.6955968817219526
0.6278032570404478
0.7711384763841935
0.7388399693558833
0.673759985418271
0.7116273329010435
0.7460175820411711
0.7203565070574138
0.678857027163599
0.7575549381220922
0.7484691855289094
0.7134614972820943
0.743919725280269
0.7538903985235317
0.743087467840811
0.72586365960797
0.7183630464299746
0.7363476019578671
0.7553986314255527
0.7078449637422646
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0013075032,0.011830036,0.010912129,-0.006055444,-0.017303225,0.022701064,0.005106712,0.00066531106,-0.02060495,-0.03444205,0.023194268,-0.0057677417,-0.011165581,0.006935675,-0.02349567,-0.01242599,0.028441407,0.007199402,0.007987157,-0.021632457,-0.0073980535,0.01660452,0.0019848018,-0.039785087,-0.017138824,0.021536555,0.028523607,-0.0154811125,0.014645406,0.0057711666,0.00050347863,0.013419247,-0.023098368,-0.03271584,-0.0076789055,0.021536555,0.01099433,-0.014439905,0.0024488927,-2.6691112e-05,0.032496635,0.004695709,-0.007815907,-0.020646049,0.0098572215,0.007343253,0.011932787,-0.021194054,-0.010103824,-0.004558708,0.020961152,0.028222205,-0.02335867,-0.009542119,-0.011891686,0.009507868,-0.0059218677,0.009507868,0.01246709,-0.0021372156,0.018138932,0.009781871,-0.013350747,0.010768278,-0.029318212,-0.013521998,0.004308681,0.00963117,-0.02324907,0.020235047,0.049402557,0.029208612,-0.0011782085,-0.015083809,0.009918872,-0.011994437,-0.011905386,-0.015768815,0.005140962,0.009096866,0.0014153915,-0.022440763,-0.027592,0.039483685,0.009446219,-0.033757046,0.010425775,0.026605593,-0.018440334,0.0098572215,-0.010953229,0.017440226,0.020536449,-0.004253881,0.005260838,0.0019865143,0.013090445,0.023851873,0.00968597,0.0023341544,-0.0113779325,0.00969282,-0.04838875,-0.008802313,-0.015645513,0.00028449114,0.016823722,0.00062849204,0.012001287,-0.027359098,-0.048827153,0.04403212,0.0075213546,-0.030880025,0.011275182,-0.0048532602,-0.0017844379,-0.043401916,-0.007726856,-0.0062643704,0.0067096236,0.030523822,0.02890721,-0.00548004,0.019837745,-0.0059937933,-0.033948846,-0.025975388,-0.024071075,-0.009165366,0.027907101,0.014124802,-0.02227636,0.033346042,-0.023125768,0.0049080607,-0.0057437667,0.03307204,-0.04016869,-0.01523451,0.02474238,0.0013794288,0.0063294456,0.02083785,-0.0035449008,0.02070085,0.00039430597,0.03024982,-0.005250563,-0.010610727,-0.0014710481,-0.01801563,0.020878952,0.003990154,0.017385425,0.019399341,0.008494061,-0.0019077389,-0.014974209,-0.015727714,-0.0008459811,0.0050005363,0.002503693,0.014261804,0.015919516,0.018262232,0.016097616,-0.0013777162,-0.006082844,0.011665635,-0.01096693,0.029510014,-0.018837636,0.02882501,0.0036031262,0.013268546,0.02198866,-0.0276742,-0.0049080607,-0.00069998944,-0.010535376,0.02061865,-0.0016748371,0.012234189,-0.009158516,-0.014152203,0.0010917267,-0.02909901,-0.0003465697,-0.018522535,-0.01104228,0.015453712,0.008069359,0.012727392,-0.66067356,-0.028852409,0.0008369904,-0.014481005,0.01370695,0.019207539,0.0061547696,-0.019837745,-0.024495777,0.020330947,-0.019933645,0.0030927975,0.01670042,-0.032578837,-0.016289419,-0.042086706,0.019933645,-0.020002145,-0.01377545,0.015261911,-0.018796537,0.010912129,-0.014933108,0.02078305,-0.0036408014,0.013295947,-0.0077885063,-0.008418711,0.033510443,0.021659857,-0.0027913952,0.028605808,-0.015892114,0.010501126,0.040113892,-0.016234618,-0.01942674,0.00552799,-0.012323239,0.043374516,-0.048580553,-0.0137823,0.014056302,0.00414428,-0.0038257528,0.006336296,0.008932465,-0.010439476,0.018673236,0.013206895,0.0017313501,0.026016489,0.0023153168,0.0074117538,0.019015737,-0.0108710285,0.014453605,-0.008089908,0.016947024,0.0008018839,0.009261267,0.0036887517,-0.0118368855,-0.0024677303,0.008685863,0.034935255,0.014234403,0.026879596,-0.0052950885,-0.021084452,0.0045107575,0.008863964,-0.0036956018,-0.010357275,-0.0008862252,-0.003104785,0.005531415,0.007596705,0.016796323,0.010117523,-0.0044422573,-0.022742165,0.005140962,0.011412183,-0.006898,0.006623998,-0.020043245,-0.009042066,0.0032109607,-0.01242599,0.019824043,0.032524034,-0.0069630756,-0.030962225,-0.012199938,0.025632886,0.001006101,0.015426312,0.0019574016,-0.014097402,-0.012556141,0.013035645,-0.005329339,0.0077953567,0.018769136,-0.00045338765,-0.03159243,0.028359206,0.03860688,0.00311506,-0.0020276147,0.01812523,-0.032030832,0.018988337,-0.0043326565,-0.03170203,0.0066719484,-0.0031236226,-0.005760892,-0.013611048,0.027523499,-0.002817083,0.019111639,-0.0146728065,0.009158516,0.025454784,0.0040518045,-0.016001716,0.0068294993,0.017234724,0.024619078,0.024057373,0.013933001,-0.00817896,0.02218046,0.012576691,-0.0035106505,0.009083166,0.0075145043,-0.010439476,-0.010576476,0.012727392,4.4605596e-05,0.010090123,-0.016316818,0.0050827367,-0.0070761014,0.010597027,-0.0029095586,-0.010192874,0.008055658,-0.018207433,-0.010658678,-0.0012963719,-0.015385211,0.0028958584,0.0130493445,-0.029811416,-0.0066787982,-0.03457905,0.012556141,0.04263471,-0.024536878,0.0059424182,-0.007857007,-0.0030739598,-0.012960294,0.024961581,-0.0017424814,-0.019536342,0.014809808,-0.029784016,-0.0039456286,0.029701816,-0.010055873,0.006894575,-0.00041721083,-0.01928974,-0.0064356215,-0.015905816,-0.008679013,-0.019207539,0.015782515,0.008240609,0.015631814,0.011247781,0.027317997,0.008500911,-0.032770637,0.0411551,-0.005808842,0.0073501035,-0.010035323,0.010309325,0.011734135,-0.0076378053,0.00972707,-0.0036271012,0.006915125,0.0034883877,0.0054081143,0.009357167,0.026304191,-0.025947988,-0.0062643704,-0.009788721,0.008028259,-0.021111853,0.021783158,0.01233694,0.018344432,0.0003846731,-0.008117309,-0.01507011,0.009206466,-0.0029232586,0.00028020985,0.0071172016,-0.009398269,0.03288024,-0.010597027,-0.013946701,0.05285498,-0.0037675274,0.013576798,0.02500268,-0.009131116,0.012275289,0.02200236,-0.029263413,-0.0016868247,0.0032931613,0.006349996,0.027126197,0.013432947,0.0031338977,-0.022796964,-0.004969711,0.012809593,-0.01243284,0.013974101,0.015686614,-0.0045895334,-0.011686184,0.038058877,0.0048087346,0.032688435,0.019687044,0.0015112922,-0.010501126,-0.011946486,0.0013177783,-0.017330626,-0.0050347866,0.008000858,-0.0029763465,0.012583541,-0.0031989731,0.018097831,0.021837959,0.017303225,0.022769565,0.018823937,-0.034168046,0.032304835,0.0058807675,-0.00958322,-0.02608499,-0.021468056,-0.02901681,-0.022646263,0.004538158,0.016481219,-0.042305905,0.037127268,0.0053156386,0.019618543,0.01236434,0.037812274,0.014097402,-0.021837959,-0.018070431,0.003606551,0.014467305,0.00483271,0.0021252278,-0.010912129,0.0049286108,-0.008576262,-0.001447073,0.003733277,0.019577442,-0.0038223276,-0.002823933,-0.0076789055,0.014193303,0.013891901,-0.0053087883,-0.011679335,-0.012720542,-0.0128986435,0.00695965,-0.019070538,-0.030797822,0.037647873,0.007302153,0.015672913,-0.01653602,-0.008911914,-0.026660394,0.0064390465,-0.018933536,-0.0025191058,-0.021700958,0.016179817,0.004044954,-0.028660608,0.016905922,0.028386606,-0.0030140218,-0.0030448472,0.001106283,-0.0021252278,0.006507547,0.033346042,0.027153596,0.0033702245,0.010165473,-0.04038789,0.0034078998,0.003575726,-0.0060006436,0.0026561068,0.018262232,-0.00047008466,0.01104913,-0.0027143322,-0.004298406,0.0007111208,0.014398804,0.02627679,-0.02333127,-0.0086927125,-0.014974209,0.003245211,-0.011117631,0.01926234,0.025317783,0.013200046,0.0021457782,0.0084392615,0.0070966515,0.0020875526,-0.017673127,0.004558708,0.014686506,0.018358134,0.019796643,0.0077679562,0.021481756,-0.014946808,-0.012830143,0.01383025,0.0074391537,0.012001287,-0.002342717,0.0116313845,-0.007062401,-0.007178852,-0.013542548,0.018837636,-0.009980522,0.009398269,-0.00042106397,-0.0045929584,-0.011754685,-0.041072898,-0.008637913,0.005353314,0.011645084,-0.009090016,-0.0003429306,0.009090016,-0.021166652,-0.025591785,-0.008548862,0.012610941,-0.011651934,0.014261804,-0.001995077,-0.0034438625,-0.0030602596,-0.00023525639,-0.0010497702,0.0023786798,-0.048717555,-0.03871648,-0.011556034,0.021166652,0.03030462,0.008576262,0.0015249923,-0.027085096,0.0013888476,-0.021331055,-0.009494169,-0.0032794613,-0.014481005,0.007685756,0.014768707,-0.0025345183,-0.0034729752,-0.0029814842,0.0136589985,-0.0107203275,0.033647444,0.0077816565,-0.021481756,-0.0006409078,0.0091996165,0.00016022695,0.021152953,0.0054423646,-0.022344861,0.0275646,-0.023646371,-0.014193303,-0.007035001,-0.012562991,-0.00695965,0.010788828,0.007473404,0.0044456823,-0.008432411,0.011398482,-0.014604306,0.008788614,-0.017796429,0.0005390133,0.00081173086,0.021468056,0.016220918,-0.007959758,0.025824687,0.016851122,-0.0414291,0.016673021,0.010076423,-0.015878415,0.008733814,-0.021043353,0.011309432,-0.024468377,0.016344218,-1.9493207e-05,0.025057482,-0.0076583554,-0.005678691,-0.027893402,-0.0053430386,-0.027619401,-0.014713907,-0.010590177,-0.011069681,0.011967037,-0.0035209255,-0.017508727,-0.007062401,0.0080830585,-0.022659965,-0.010103824,0.014426204,-0.007281603,0.04008649,-0.0011165581,-0.0027057696,-0.014850908,-0.027729,-0.0022485289,-0.02893461,-0.0025310933,0.0021680407,0.021139253,0.01524821,0.03153763,0.017618328,0.03159243,-0.005630741,-0.019796643,-0.0065246723,0.0124396905,-0.0044217072,-0.009446219,0.01646752,8.1665436e-05,-0.029729215,0.007726856,0.0048772353,0.005805417,0.011247781,-0.02618089,-0.017453926,-0.017412826,-0.02211196,0.0006413359,0.022783265,-0.021235153,-0.006295196,-0.03049642,0.015796214,-0.003178423,-0.003938779,0.021221453,0.002567056,0.012960294,-0.0049560107,0.022481862,-0.0004542439,-0.0016739808,-0.010754578,-0.030989625,-0.010528526,0.0021132403,0.036579266,-0.019536342,0.015782515,0.016097616,0.0009949697,-0.01250134,-0.023934074,0.008905064,-0.017632028,0.0022331162,-0.0062849205,-0.00959692,-0.025701387,-0.0120355375,-0.013857651,0.0012586967,0.0066822236,-0.018234832,0.0029198336,0.0066822236,-0.021413255,0.024262875,-0.0097065205,0.02618089,0.016042816,0.025865788,0.0028684584,0.0016500057,0.008199509,-0.011973887,-0.0059184427,0.010309325,0.011398482,-0.012638342,0.015782515,-0.033784445,0.008603662,-0.0007423741,-0.013480898,-0.0077679562,0.00967912,0.013295947,-0.00958322,-0.0075076544,-0.025865788,-0.011542333,0.0007111208,-0.008754363,-0.014987908,0.010158624,-0.0076515055,0.001483892,0.0093503175,0.015700314,0.028194804,0.0063260207,0.00062849204,0.020974852,-0.001697956,0.009555819,0.019892544,0.001664562,0.008514612,0.02475608,0.008432411,-0.004644334,-0.0022451037,0.008672163,-0.0025961688,-0.0012895218,0.02896201,-0.011069681,0.00041999368,0.0007877557,0.010816229,0.002015627,-0.005699241,-0.014083702,0.0029369588,-0.007747406,0.008637913,0.009316067,0.007535055,-0.03041422,-0.008172109,0.0022348287,-0.0045313076,0.005538265,-0.0022142786,0.0051889126,-0.032277435,-0.014974209,-0.0018632135,0.014604306,0.026523393,-0.013638449,0.0074391537,0.024112174,0.0031989731,-0.01786493,-0.007980308,0.021139253,-0.007151452,-0.021837959,0.02202976,-0.0072268024,-0.0274824,0.029126411,-0.00092390046,-0.029510014,-0.023714872,0.0040792045,-0.019604841,-0.000711977,-0.040442694,-0.01515231,0.00484641,0.0126451915,0.010247674,0.009357167,-0.0012689717,0.01519341,-0.00052317255,0.0043532066,0.0075008045,-0.008774914,-0.0137617495,0.01387135,-0.002633844,-0.037593074,-0.01241229,0.0019556892,0.0015832178,0.010980629,-0.013501448,-0.014330304,0.005843092,-0.00972707,0.03340084,0.007884407,-0.016481219,-0.01924864,-0.0063054706,0.0051752124,0.026769994,-0.02896201,-0.008863964,-0.0024009424,-0.005377289,-0.03326384,-0.041867502,-0.019728143,0.03704507,0.019508941,-0.010021622,0.00059852307,-0.016248317,-0.020056946,-0.012199938,0.010597027,-0.0070761014,-0.007617255,0.0046340586,-0.006620573,0.018330732,0.0025430808,-0.018289633,0.002282779,0.010555927,-0.012562991,-0.022933966,0.01661822,0.036908068,-0.02226266,-0.014522105,0.0044936324,-0.0133027965,0.02226266,0.0012749655,-0.0028222206,-0.0154811125,0.014659106,0.019604841,0.02623569,0.023797072,0.018371833,-0.0138234,0.003723002,0.014631706,-0.017221024,-0.026290491,-0.014248103,0.009781871,-0.0077885063,0.004106605,-0.0117820855,-0.017481327,-0.008596812,-0.0016140429,0.021700958,-0.0013357596,-0.0004281281,0.027153596,0.0031201977,-0.021632457,-0.0018221132,0.026646692,-0.024975281,-0.018878737,0.023742272,-0.03983989,0.0051889126,-0.0023547045,-0.019508941,-0.020221347,-0.0021611906,-0.00417168,-0.0063020457,-0.0051957625,0.00959692,0.0075693047,-0.017303225,0.020248746,-0.0044628074,-0.014028901,-0.01642642,0.0028633208,0.026948094,0.0044662324,-0.013227446,-0.001590924,-0.018659536,-0.020002145,0.026632993,0.025632886,0.014700207,0.032606237,0.24616338,-0.017508727,-0.013193196,0.011268332,0.01523451,0.006038319,2.726641e-05,0.032003433,-0.020947453,-0.012973994,0.016796323,0.0063260207,0.0046272087,0.002022477,0.0013819975,-0.009973672,-0.021002252,-0.008617362,0.0016448682,0.013042495,0.013535698,0.0029198336,0.00043433596,-0.020276146,0.04534733,0.011199831,0.002697207,0.01931714,-0.014261804,-0.0107203275,0.006610298,0.002609869,0.007987157,0.020467948,-0.01646752,-0.008014558,-0.0060040685,-0.01670042,0.025824687,0.014727606,0.021029653,-0.009617469,-0.011549184,-0.010850479,0.009281817,0.0032006856,-0.0113779325,-0.012549291,0.010042173,0.0070898016,-0.023166867,-0.016166117,0.017125124,0.02896201,-0.0016303118,-0.010740878,0.001798138,-0.004000429,0.03457905,0.014070002,-0.035620257,0.010877878,-0.029208612,0.018467734,-0.005264263,-0.00075907115,-0.0029763465,-0.010309325,0.026523393,-0.02613979,-0.014481005,0.007918658,-0.00207214,-0.0011045705,-0.025660286,-0.0056821164,0.033537842,0.019604841,0.020084346,0.023262769,-0.015919516,8.530453e-05,-0.0021098154,-0.010692927,-0.016070217,-0.009884622,0.023988875,-0.016070217,0.008206359,0.0066822236,6.78583e-05,0.00055956346,-0.0131520955,-0.007644655,0.0012963719,0.004438832,0.0049080607,0.025125982,-0.010165473,0.00057626044,-0.031099224,0.056115605,0.010302475,0.0030962224,0.015453712,0.016152417,0.024331376,0.01511121,0.008452961,-0.015960615,-0.0027862578,-0.05066297,1.7111744e-05,-0.0073364032,-0.0074391537,0.0058944677,0.0016020554,-0.0035551758,0.033674844,-0.010651827,-0.006041744,-0.014905708,-0.002226266,0.009747621,0.011775236,-0.021385854,-0.020289848,-0.0015078671,-0.015357811,0.0071240515,-0.0011910524,0.017481327,0.0022639413,0.027701601,-0.009946272,-0.019892544,-0.01801563,-0.040935896,0.0034918129,0.009158516,-0.0006678798,0.017262125,0.016673021,-0.016234618,0.0019128764,-0.011542333,0.012083488,0.009768171,-0.015727714,-0.015357811,-0.0051306873,-0.003873703,-0.015796214,-0.025098583,0.020550149,-0.01237804,-0.012624642,-0.016974423,0.010370975,-0.0080830585,-0.011535483,0.0045073326,0.008240609,-0.031318426,-0.013145246,-0.0075076544,-0.17656688,-0.006531522,0.022824366,-0.043593716,0.018180031,0.021783158,0.012556141,0.0038154777,-0.033674844,0.015275611,0.00839131,-0.0138782,-0.021043353,0.004952586,0.0044011567,-0.0029489463,-0.030058017,0.016152417,0.004384032,0.026660394,0.026893295,-0.01945414,0.0051820627,-0.0007843307,-0.016399018,-0.0045244577,-0.0031869856,0.011761535,0.011939636,-0.02193386,0.018563634,-0.011809486,0.0105148265,0.0073843533,-0.004952586,-0.010165473,0.0017827254,-0.02076935,-0.005247138,0.012720542,0.025865788,0.010665528,-0.01801563,0.029290812,-0.0011670772,0.018782835,0.021125553,0.0026184316,0.009980522,-0.02339977,0.006254095,-0.011795785,-0.0005056193,-0.0018923262,0.017892329,0.02078305,0.016755221,-0.009781871,-0.0137001,-0.029318212,-0.019604841,-0.006528097,0.020029545,-0.003221236,-0.0033976247,-0.0043977317,-0.0030808097,0.027098797,-0.053156383,0.007004176,-0.020413147,0.003168148,0.0055896407,-0.003091085,-0.005260838,0.021700958,-0.01645382,0.005206038,0.018837636,-0.012535591,-0.009514719,0.04666254,-0.0042710057,0.016823722,-0.014809808,0.017125124,0.0041203047,0.036168262,-0.01384395,-0.010055873,0.010268224,-0.03833288,-0.0013691536,-0.01243284,0.026057588,0.024879381,0.010987479,-0.013974101,0.011110781,0.00062892016,-0.002686932,-0.0029986093,-0.028770208,0.017440226,0.020892652,0.0033034363,0.004024404,0.021783158,0.027866002,0.0017827254,-0.036579266,-0.010535376,-0.009542119,-0.012816443,-0.0023923798,0.029592214,0.005904743,0.00015369798,-0.03137323,0.006099969,0.06767849,-0.017673127,0.0029968966,0.0009872634,-0.00244033,-0.030660823,-0.12308169,-0.025153382,0.0042710057,-0.0024951305,0.009473619,0.003606551,-0.009144817,-0.009843522,-0.025345184,0.01787863,-0.050334163,-0.028222205,-0.00082928414,-0.009322917,-0.015138609,-0.0027194696,0.0056410157,-0.0043566315,-0.02057755,0.019687044,-0.034003645,-0.030743023,-0.015577013,0.0024506052,0.018193731,0.0054903147,-0.018892437,-0.0024985557,-0.0045107575,-0.0012955157,0.027427599,-0.02202976,-0.01918014,-0.0030431345,-0.013974101,-0.011336832,0.005925293,-0.009535269,0.024208076,-0.03685327,0.014344004,-0.020933751,-0.011658785,-0.020180246,-0.011610834,0.003579151,-0.02893461,0.029921018,0.0073775034,-0.008747513,-0.020481648,0.004113455,-0.028578406,0.008035108,0.008802313,0.007069251,0.003586001,0.014809808,-0.008781764,0.01678262,-0.015344111,0.017166225,0.010007923,-0.0047847596,0.03271584,-0.017823828,-0.020961152,-0.019495241,0.0062780706,-0.03285284,-0.007493954,-0.0013109283,-0.00954897,0.020098045,-0.022495562,-0.010186024,0.0020190522,0.0040860544,-0.007178852,-0.016645622,-0.0062643704,-0.007603555,0.018207433,-0.020796752,0.0034815378,0.0072747525,-0.009747621,-0.017495027,-0.017152524,-0.013213745,-0.017303225,0.04704614,0.018782835,-0.029948417,0.0032092482,0.006596598,0.0005745479,0.002967784,0.000685005,0.009542119,-0.032989837,-0.009514719,-0.039785087,0.018837636,-0.016097616,-0.018536234,-0.0107203275,-0.019687044,0.0052094627,-0.0058533675,0.0048772353,-0.011425883,-0.012994545,0.012343789,-0.031044425,0.0033633744,-0.021522855,5.1589435e-05,0.0104668755,-0.015001609,0.016905922,-0.009514719,-0.007733706,-0.016344218,-0.0010514826,-0.013035645,-0.010829928,-0.004414857,-0.007747406,0.024372477,-0.022810666,-0.016166117,0.0042710057,-0.023221668,0.0027828326,0.036634065,0.013158945,-0.009124266,0.007877558,0.017645728,0.03731907,-0.023112068,8.942526e-05,-0.0412373,-0.009309217,-0.013179496,0.017796429,0.0042059305,-0.003959329,-0.008103609,-0.009610619,-0.0020430272,0.019413041,0.022796964,-0.01096693,-0.028167404,-0.01653602,-0.015590713,-0.0005869636,-0.020015845,-0.023029868,-0.017207325,0.035318855,-0.0075693047,0.02218046,-0.011151881,0.014344004,0.0068431995,-0.0027246072,0.016166117,-0.002603019,-0.02613979,-0.002897571,0.0014462167,-0.0037641022,-0.001751044,-0.00015787224,0.016262017,-0.020536449,0.0062986207,-0.0010908704,0.0412099,-0.0021646158,-0.011788935,-0.028414005,0.011953336,0.024509478,-0.0019111638,-0.014453605,0.0036408014,0.004449107,-0.015864715,0.0019128764,0.0085899625,0.010370975,0.00033137115,0.00051461,-0.0034181748,0.006480147,-0.010487426,0.00055827905,0.015796214,0.0063054706,0.007946057,-0.009555819,-0.021509156,-0.0415113,0.017330626,-0.024482077,-0.050197165,0.013261696,0.006058869,0.018741736,-0.018481433,0.020262446,0.008898214,-0.0061410693,0.023920374,-0.016097616,-0.034853052,-0.036688864,0.022755865,0.0040757796,-0.023112068,-0.013035645,0.00839131,0.024797179,0.028386606,0.017385425,-0.025030082,0.023235368,0.015727714,0.0015994866,0.002205716,-0.0015952053,-0.018782835,-0.01938564,-0.017563527,0.009240717,0.015412612,-0.006442472,0.0698157,0.01378915,0.0067301737,-0.0105148265,-0.0026252815,0.028386606,0.022824366,-0.00010039604,-0.02067345,-0.025865788,-0.0065452224,0.008172109,-0.029263413,-0.015467412,-0.009740771,0.00036369482,-0.011925937,0.0011722147,-0.023276469,-0.0043395064,0.024180675,-0.000497913,0.0109189795,0.008384461,0.0036990268,0.0034729752,0.0027348823,-0.0026167189,0.020824151,-0.015864715,-0.0024369052,0.014056302,-0.028386606,-0.027208397,0.0056204656,0.0139604015,-0.006065719,-0.016193517,-0.0050347866,0.0011379645,-0.0017116561,0.015590713,-0.016673021,-0.011240931,-0.027386498,0.016385319,0.016248317,-0.022714764,-0.002957509]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
0.7399025189780007
0.752664701728835
0.7513148094467128
0.6946793224124459
0.7344757168588051
0.7495211756586452
0.7512467095705162
0.7442860259251604
0.7396457238220179
0.751088290530449
0.731866235540115
0.7302425686418033
0.7550456924244073
0.7347252070820062
0.7552342787442654
0.7641061975402713
0.7363219554987669
0.7539538158837003
0.7574526489910581
0.7382717479095466
0.7281010682059589
0.7121689975036908
0.7644322420844354
0.7508103327514478
0.7481936347667445
0.6965169953373841
0.7430492983512699
0.7681786188322952
0.7667806536221429
0.7334532216328561
0.7353701016448456
0.741282659443597
0.7774977893288385
0.7498736204353261
0.7560497440416042
0.7343333459950077
0.7712837290034241
0.7472113336481674
0.7490770470679027
0.7557987393605268
0.7556006400159075
0.754652843252005
0.7494535531947226
0.7347133376764294
0.7647090353379653
0.7230645853434428
0.7728621861980115
0.7715159407839107
0.7640129267048118
0.7424317029275235
0.6981840127936004
[{"sentences":["The model takes this text as input and generates the answer or ranks different options."],"sections":[{"title":"Main results","number":"3"}],"section_type":"main"},{"sentences":["Architecture.","Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) .","In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center.","We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center.","For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W.","We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh."],"sections":[{"title":"Related work","number":"7"}],"section_type":"main"},{"sentences":["Our models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95.","We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate.","We use a weight decay of 0.1 and gradient clipping of 1.0.","We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details)."],"sections":[{"title":"Optimizer","number":"2.3"}],"section_type":"main"}]
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0013490428,0.011881854,0.010949944,-0.0061327913,-0.017308861,0.022681048,0.005108375,0.00060899643,-0.020570546,-0.034508087,0.023229232,-0.005738785,-0.01108699,0.006876264,-0.023489619,-0.012471151,0.028478079,0.007249713,0.008010316,-0.021625798,-0.007373054,0.016596224,0.0020179967,-0.039770637,-0.017103292,0.02159839,0.028478079,-0.015431336,0.014677585,0.005783325,0.0004685247,0.013375652,-0.02307848,-0.032753903,-0.0077293725,0.021475047,0.0109636495,-0.0144171985,0.0024394118,1.8428887e-05,0.03250722,0.0047006644,-0.0078116,-0.020625364,0.009887841,0.0073593496,0.011881854,-0.02126948,-0.010127671,-0.0045533404,0.020981684,0.028286215,-0.023325164,-0.009510966,-0.01186815,0.009510966,-0.0058518476,0.009579488,0.012423185,-0.0021584684,0.018131135,0.009805613,-0.013375652,0.010744376,-0.029382579,-0.013464731,0.0043066586,0.009648011,-0.023297755,0.020282751,0.049336422,0.029190715,-0.0011263436,-0.015047608,0.009874136,-0.011977786,-0.011922969,-0.01577395,0.005125506,0.009099829,0.0013952956,-0.022475481,-0.027559873,0.039523955,0.009462999,-0.03376804,0.010449728,0.026682781,-0.018487453,0.009812466,-0.010970501,0.017432202,0.020474615,-0.0042621186,0.0052659777,0.0020077182,0.013005629,0.023900755,0.0097302385,0.002345193,-0.011313115,0.009695977,-0.04848674,-0.008770919,-0.01565061,0.00026723894,0.016829202,0.00064026,0.0120189,-0.027436532,-0.04881565,0.04404646,0.0075580655,-0.03091749,0.011230888,-0.0048548407,-0.0017062179,-0.04344346,-0.0077362247,-0.006290394,0.0067289397,0.030533763,0.028889215,-0.0055092336,0.019816795,-0.005995746,-0.033987314,-0.025997553,-0.024051506,-0.009175204,0.027861373,0.014156812,-0.022283617,0.033384312,-0.023147004,0.0048651192,-0.0057010977,0.033055402,-0.040126957,-0.015253177,0.024723029,0.0013558951,0.0063417857,0.020830933,-0.0035083678,0.020707592,0.00039978776,0.03025967,-0.0052419947,-0.010559364,-0.0014826623,-0.017980384,0.02088575,0.0039366353,0.017322566,0.01940566,0.008476271,-0.0019117863,-0.014979086,-0.015828768,-0.00091649254,0.0049884603,0.0025027955,0.014293858,0.0159247,0.01829559,0.01610286,-0.0012993637,-0.006119087,0.011662582,-0.0109636495,0.029547034,-0.018775249,0.02877958,0.0036042996,0.013211197,0.022009525,-0.027600987,-0.0049165115,-0.00071435026,-0.01054566,0.02063907,-0.0016299862,0.012238174,-0.009113533,-0.014115699,0.0010955083,-0.029108489,-0.0004064259,-0.018473748,-0.01102532,0.015472449,0.008071987,0.012772651,-0.6604502,-0.028834397,0.0008629591,-0.014472017,0.013718266,0.019254908,0.0061327913,-0.019844204,-0.02451746,0.020296454,-0.019940136,0.0031314923,0.01673327,-0.032562036,-0.016335838,-0.04210041,0.020022364,-0.020063478,-0.013793641,0.0153079955,-0.018802658,0.010943092,-0.014951676,0.020858342,-0.0036282826,0.013320833,-0.0077362247,-0.008421453,0.033548765,0.021694321,-0.0027546168,0.028560305,-0.01589729,0.010511398,0.040154364,-0.016212497,-0.019487886,0.005498955,-0.012299844,0.043388642,-0.048568964,-0.013800493,0.013964948,0.004077107,-0.0037756066,0.006307524,0.008990192,-0.010381205,0.018651908,0.01319064,0.0016848046,0.026066076,0.0024342728,0.007352497,0.018994521,-0.010840308,0.014444607,-0.008099396,0.016952543,0.00078629924,0.009264284,0.003662544,-0.011820184,-0.0024548296,0.008750362,0.03491922,0.014197925,0.026902054,-0.0053345007,-0.021173548,0.0044779656,0.008880556,-0.0037584759,-0.010360648,-0.0008141366,-0.0030698217,0.0055297907,0.0075032474,0.016801793,0.010107114,-0.004416295,-0.022776982,0.005152915,0.011361081,-0.0069002467,0.0066775475,-0.020063478,-0.00904501,0.0032548334,-0.012464299,0.019803092,0.032562036,-0.0069482126,-0.03091749,-0.012203912,0.025682349,0.00095846277,0.015499859,0.0019666045,-0.0140745845,-0.012505412,0.013026185,-0.0053139436,0.0077978955,0.018775249,-0.0004057835,-0.031602718,0.028368441,0.038592044,0.0031948758,-0.0019648916,0.01817225,-0.032041263,0.018939704,-0.004347772,-0.031712353,0.006711809,-0.00316918,-0.005735359,-0.01360863,0.02754617,-0.0027717475,0.019131567,-0.0146912895,0.009154647,0.025490483,0.0040359935,-0.016006928,0.0068557067,0.017308861,0.0246408,0.024051506,0.0139718,-0.008140509,0.02217398,0.012567082,-0.0034860978,0.009113533,0.0076197363,-0.010394909,-0.010614183,0.012745242,3.8008744e-05,0.0101413755,-0.016322132,0.005053557,-0.0070715537,0.010579921,-0.0029601853,-0.010271569,0.008010316,-0.018227067,-0.010600478,-0.0012479717,-0.015376518,0.0028985147,0.013087856,-0.029793717,-0.006663843,-0.03459031,0.012539674,0.042593777,-0.024490051,0.005906666,-0.007845862,-0.0031383445,-0.012916549,0.024942301,-0.0017456185,-0.019542705,0.0147598125,-0.029875943,-0.003926357,0.02968408,-0.009990625,0.00683515,-0.00043105127,-0.0192275,-0.0064308653,-0.015883587,-0.008750362,-0.0192275,0.015801359,0.008236442,0.01565061,0.011196626,0.027313191,0.008489976,-0.032671675,0.041168503,-0.0058484217,0.007297679,-0.010066001,0.010292126,0.011779071,-0.007599179,0.009771353,-0.003683101,0.0068728374,0.0035066546,0.005450989,0.009346511,0.026394986,-0.025983848,-0.0063040983,-0.0097645,0.008024021,-0.021022797,0.021858776,0.012299844,0.018391522,0.00041070857,-0.008058282,-0.015129835,0.00922317,-0.00290708,0.0002702368,0.0071195196,-0.009401329,0.032918356,-0.010593626,-0.014012914,0.052899607,-0.0037653283,0.013553811,0.02499712,-0.0091340905,0.0123204,0.022064343,-0.029245533,-0.0017062179,0.00331993,0.0063178027,0.027135031,0.013444175,0.0031777453,-0.022845503,-0.004950773,0.012813765,-0.012471151,0.013985504,0.015678018,-0.0045430623,-0.011710548,0.03807127,0.0048993807,0.032726493,0.01967975,0.0014552531,-0.0104839895,-0.011922969,0.001354182,-0.017391087,-0.004998739,0.007996611,-0.0029601853,0.0125876395,-0.003222285,0.018144839,0.021858776,0.017308861,0.022763276,0.01889859,-0.034151766,0.032233126,0.005817586,-0.009606898,-0.02607978,-0.021516161,-0.028971443,-0.02265364,0.0045259316,0.016459178,-0.04218264,0.03716677,0.005296813,0.019542705,0.012430037,0.03779718,0.014156812,-0.02184507,-0.018007794,0.0036180043,0.014403494,0.0048548407,0.002101937,-0.010943092,0.004954199,-0.008620169,-0.0014081437,0.003713936,0.019570114,-0.003806442,-0.0029396284,-0.0077293725,0.014197925,0.013930687,-0.0052591255,-0.0117174,-0.012717833,-0.012943958,0.0069208033,-0.019063044,-0.030835263,0.037605315,0.0072291563,0.015664313,-0.016500292,-0.008846294,-0.026682781,0.006393178,-0.018884886,-0.0025678922,-0.021803956,0.016198792,0.0040634023,-0.028669942,0.016925134,0.02839585,-0.003004725,-0.003004725,0.0010775211,-0.0021464769,0.006519945,0.033329494,0.027135031,0.0034535495,0.0101413755,-0.040428456,0.0033524784,0.0035323508,-0.0059683365,0.0027015116,0.01829559,-0.00040556936,0.01099791,-0.0027460514,-0.0042347093,0.00067837577,0.01436238,0.026299054,-0.023379982,-0.008661283,-0.015006495,0.003294234,-0.01114866,0.0192275,0.025339734,0.013259163,0.0021670337,0.008455714,0.007105815,0.0021036502,-0.017747408,0.0045362096,0.014677585,0.018377816,0.019775681,0.007784191,0.021502458,-0.014910563,-0.012834322,0.013827902,0.0074004633,0.012066866,-0.0022749573,0.011710548,-0.007105815,-0.0071880426,-0.01351955,0.01887118,-0.010052295,0.009401329,-0.00047195083,-0.004584176,-0.011813332,-0.041086275,-0.008647578,0.0053687617,0.011669434,-0.009120385,-0.0004128499,0.009086125,-0.021173548,-0.025572712,-0.008558499,0.012669867,-0.011676286,0.014197925,-0.0018980817,-0.0034244272,-0.0031366316,-0.00030064382,-0.0010775211,0.0024051506,-0.048678603,-0.038646862,-0.011573502,0.021228366,0.030232262,0.00859276,0.0015194933,-0.027093917,0.0013901565,-0.021310592,-0.009517818,-0.0033010861,-0.0144171985,0.007708816,0.014787221,-0.00256104,-0.0035015154,-0.002982455,0.013615482,-0.0106895575,0.033658404,0.0077567818,-0.021529866,-0.0006710952,0.009175204,0.00015171377,0.021159843,0.005450989,-0.022338435,0.027600987,-0.023599254,-0.014197925,-0.0069893263,-0.012573935,-0.0069859,0.010716967,0.0075306566,0.0044265734,-0.00844201,0.011443309,-0.014595358,0.00883259,-0.017761111,0.00051177974,0.00082270196,0.021475047,0.0162262,-0.00796235,0.025846804,0.016842905,-0.041415185,0.016664747,0.010038591,-0.015910996,0.008716101,-0.021077616,0.011319968,-0.024476347,0.016335838,-2.49332e-05,0.025093053,-0.00766085,-0.005687393,-0.027916191,-0.00527283,-0.027628396,-0.014718699,-0.010573069,-0.011073286,0.011943526,-0.0035529076,-0.017473316,-0.0070921103,0.008044577,-0.022667345,-0.01009341,0.01438979,-0.007249713,0.040154364,-0.0011828749,-0.0027289207,-0.01484204,-0.027724328,-0.0022321304,-0.028916625,-0.002590162,0.00214819,0.021187251,0.015349109,0.031465672,0.017610362,0.031684946,-0.005622296,-0.0198305,-0.006523371,0.012457446,-0.0044334256,-0.009394477,0.01640436,9.630666e-05,-0.029738897,0.0077293725,0.004889102,0.0058244388,0.011244592,-0.026244234,-0.01745961,-0.017418498,-0.022105457,0.000670667,0.02280439,-0.021242071,-0.0063178027,-0.030478945,0.015787655,-0.0031708928,-0.003946914,0.021173548,0.0024788126,0.012937106,-0.0048925285,0.022448072,-0.00042227178,-0.0016565388,-0.010819751,-0.031027127,-0.010477137,0.002098511,0.036618587,-0.019583818,0.015746541,0.016089154,0.0009875849,-0.012525969,-0.023955572,0.008928522,-0.017624065,0.0022406958,-0.006307524,-0.0095931925,-0.025723461,-0.012053162,-0.013848459,0.0012916549,0.006687826,-0.018227067,0.0029139323,0.006687826,-0.02139282,0.024284482,-0.00970283,0.026175711,0.016089154,0.025887916,0.0029173584,0.0016479735,0.00820218,-0.012046309,-0.0059135184,0.010333239,0.011381638,-0.012690424,0.01577395,-0.033822857,0.0085859075,-0.0007293396,-0.013416765,-0.0077910433,0.009785057,0.013313982,-0.00952467,-0.007489543,-0.025860507,-0.01156665,0.00073190924,-0.008757215,-0.015006495,0.010161933,-0.007688259,0.0014706707,0.009380772,0.015760245,0.028203987,0.0062801153,0.00061799004,0.021022797,-0.0016282732,0.009538375,0.019926433,0.0016308428,0.008544794,0.024736734,0.008435157,-0.004591028,-0.0022766702,0.008716101,-0.0025559007,-0.0012642458,0.028971443,-0.011045877,0.00036873834,0.00079957553,0.010840308,0.0019871613,-0.0057730465,-0.014129403,0.0029961597,-0.007818452,0.008606465,0.009291693,0.0075649177,-0.030424125,-0.008215885,0.002221852,-0.004546488,0.0055537736,-0.0021944428,0.0051837503,-0.032315355,-0.014979086,-0.0018672465,0.014595358,0.026518326,-0.0136703,0.007496395,0.024202256,0.0031931628,-0.017884452,-0.007941794,0.021159843,-0.0072154514,-0.021858776,0.02205064,-0.007201747,-0.027477646,0.029108489,-0.0009618889,-0.029519625,-0.023722596,0.004135351,-0.019583818,-0.00067837577,-0.040483274,-0.015116131,0.004813727,0.01264931,0.010333239,0.009346511,-0.0012753807,0.015212063,-0.0005280539,0.004347772,0.007468986,-0.008702396,-0.013718266,0.013992357,-0.0026107188,-0.037605315,-0.012354662,0.0019580391,0.0015220628,0.011018467,-0.013457879,-0.0143486755,0.005862126,-0.0097302385,0.033384312,0.007914384,-0.016513996,-0.019241204,-0.006348638,0.005194029,0.026765008,-0.028944034,-0.00883259,-0.0023726022,-0.00531737,-0.033247266,-0.04185373,-0.019693455,0.037057135,0.019501591,-0.010024887,0.00064668397,-0.016322132,-0.020118296,-0.01219706,0.010538808,-0.0070647015,-0.007667702,0.004638994,-0.0065816157,0.018350407,0.002564466,-0.018350407,0.0022252782,0.010436024,-0.012580788,-0.02295514,0.016609928,0.037002314,-0.022283617,-0.014526835,0.0044882437,-0.013272868,0.022269912,0.0012616762,-0.0028419835,-0.015486155,0.014595358,0.019624932,0.026285348,0.023777414,0.018405225,-0.013862164,0.0037036578,0.014609062,-0.017349975,-0.026299054,-0.014293858,0.0097302385,-0.007784191,0.004097664,-0.011827037,-0.017487021,-0.00856535,-0.0015708853,0.021680616,-0.0012907984,-0.0004501092,0.02716244,0.0031434838,-0.021694321,-0.0017952975,0.026614258,-0.02499712,-0.018816363,0.0237363,-0.039880272,0.005132358,-0.0023143578,-0.019474182,-0.020227933,-0.0021601815,-0.0042175786,-0.006245854,-0.005218012,0.009634307,0.0075512133,-0.017226635,0.020296454,-0.0044128685,-0.014047176,-0.016349541,0.0028522618,0.026915759,0.0044745393,-0.013272868,-0.0016060033,-0.018693022,-0.020022364,0.026669076,0.025654938,0.0147598125,0.032644264,0.24624355,-0.017473316,-0.013170083,0.0112377405,0.015212063,0.0060197287,-1.3122385e-05,0.032041263,-0.021036502,-0.012991924,0.016692156,0.0063040983,0.0046698293,0.0020693887,0.0013841607,-0.009970068,-0.021036502,-0.008599612,0.0015914422,0.0129987765,0.013588073,0.0029139323,0.0004950773,-0.020241637,0.045362096,0.011155513,0.0026997987,0.019323431,-0.014239039,-0.010730672,0.0066706953,0.0026329888,0.007996611,0.020474615,-0.016513996,-0.008065134,-0.005995746,-0.01673327,0.025860507,0.0146912895,0.020981684,-0.009695977,-0.011532389,-0.010881422,0.009332806,0.0031863104,-0.011381638,-0.012594492,0.010018034,0.0070989626,-0.023229232,-0.016157677,0.017103292,0.028971443,-0.0015640331,-0.010744376,0.0018398374,-0.00405655,0.03459031,0.014143107,-0.03557704,0.010881422,-0.029218124,0.018473748,-0.0051871766,-0.0007190612,-0.0029584721,-0.010367501,0.026573144,-0.026148302,-0.014430903,0.007845862,-0.0020368404,-0.0011357656,-0.025723461,-0.00570795,0.033521358,0.019597523,0.020063478,0.02325664,-0.015938405,9.8769204e-05,-0.0020899456,-0.010614183,-0.016130269,-0.009874136,0.023996687,-0.016061746,0.008119953,0.006667269,1.0285113e-05,0.0005456128,-0.013108413,-0.0076814066,0.0013207771,0.004453982,0.00488225,0.025161576,-0.010175637,0.0006222727,-0.031054536,0.056188703,0.010298978,0.0030629695,0.015417632,0.016130269,0.024380414,0.015116131,0.008455714,-0.015883587,-0.0028042959,-0.050652057,-4.539636e-05,-0.0073593496,-0.0074347244,0.0058724047,0.0015426197,-0.0035494813,0.033603586,-0.010682706,-0.0060437117,-0.014937972,-0.002345193,0.009771353,0.011792775,-0.021365412,-0.020255342,-0.0015417632,-0.015431336,0.0071743377,-0.0011631746,0.017473316,0.002196156,0.027738033,-0.009942659,-0.019871615,-0.017980384,-0.04097664,0.0034946632,0.009202613,-0.0006856563,0.017281452,0.016596224,-0.016267315,0.0018997948,-0.011573502,0.012162798,0.009668568,-0.015760245,-0.015349109,-0.0050878185,-0.003881817,-0.015842473,-0.025120461,0.020515729,-0.012457446,-0.012615048,-0.01700736,0.010298978,-0.008099396,-0.011587206,0.004522505,0.008188476,-0.031328626,-0.01312897,-0.007441577,-0.17662439,-0.0065267975,0.022776982,-0.043635324,0.01824077,0.021735433,0.012567082,0.0039058,-0.03368581,0.015225768,0.0083118165,-0.013875868,-0.020995388,0.0049096593,0.0043820334,-0.00292935,-0.030150035,0.016185086,0.0043272153,0.026682781,0.026970576,-0.019501591,0.005194029,-0.00078544265,-0.016418064,-0.004546488,-0.0032137197,0.011744809,0.011964082,-0.02199582,0.018555976,-0.011820184,0.01054566,0.0074552814,-0.004937068,-0.01015508,0.0017696015,-0.020789819,-0.0052831084,0.012710981,0.025901621,0.0106895575,-0.018048907,0.029245533,-0.0011828749,0.018802658,0.021118728,0.0026278496,0.009970068,-0.023421096,0.006297246,-0.0118338885,-0.00057601987,-0.0019049341,0.017747408,0.02081723,0.01673327,-0.009778204,-0.013649743,-0.029409988,-0.019597523,-0.006564485,0.020022364,-0.0031983021,-0.0033576174,-0.0044128685,-0.0030663956,0.027121328,-0.053201105,0.007009883,-0.020378683,0.0031297791,0.005615444,-0.003074961,-0.0052625514,0.021666912,-0.016513996,0.0052145855,0.018857477,-0.012532821,-0.009531522,0.046705145,-0.0042415615,0.016801793,-0.014855744,0.017171815,0.004104516,0.03618004,-0.013827902,-0.01009341,0.010278421,-0.038345363,-0.0014124264,-0.01240948,0.025970144,0.024901187,0.010915683,-0.01399921,0.0111692175,0.00064668397,-0.0026912333,-0.0029995858,-0.02875217,0.017432202,0.020926865,0.0032822425,0.0039914534,0.021776548,0.027929896,0.0017918714,-0.036618587,-0.0105525125,-0.00961375,-0.012868583,-0.0023366278,0.029601853,0.0058758305,0.00016188512,-0.031383447,0.006050564,0.0675909,-0.017692588,0.0029756029,0.0009884415,-0.002465108,-0.030698217,-0.12323142,-0.025188984,0.004299806,-0.002511361,0.009469852,0.0035803167,-0.009188908,-0.009867284,-0.025339734,0.017911863,-0.050350558,-0.028176578,-0.00090278796,-0.009346511,-0.015129835,-0.0026895201,0.005629149,-0.0043169367,-0.020584252,0.019720864,-0.033959903,-0.030753035,-0.0155135635,0.0023982981,0.01824077,0.0054852506,-0.01887118,-0.0024839519,-0.0045122267,-0.0013156378,0.027422827,-0.022036934,-0.019172681,-0.0030544042,-0.013978653,-0.01132682,0.0059923194,-0.009545227,0.024298187,-0.03686527,0.01436238,-0.02088575,-0.011621468,-0.020077182,-0.011573502,0.0035803167,-0.028944034,0.029903352,0.007441577,-0.008750362,-0.02046091,0.004032567,-0.028615125,0.008024021,0.008866851,0.007105815,0.0036454133,0.014814631,-0.008770919,0.016788088,-0.015335404,0.01718552,0.009997478,-0.0048240055,0.032726493,-0.01784334,-0.020981684,-0.019501591,0.006314377,-0.032836128,-0.007523804,-0.0013019333,-0.009606898,0.020077182,-0.022530299,-0.01021675,0.0020454058,0.0040908116,-0.0072085992,-0.016609928,-0.006314377,-0.0075854748,0.018213362,-0.020830933,0.0034638278,0.0072360085,-0.009716534,-0.017596656,-0.017199224,-0.013218049,-0.017267747,0.047061462,0.018788954,-0.029930761,0.003247981,0.0066227294,0.0005456128,0.0029670375,0.0006668126,0.00952467,-0.033000585,-0.009545227,-0.039798047,0.018843772,-0.01607545,-0.018542271,-0.010662149,-0.019734569,0.005255699,-0.0058484217,0.0048000226,-0.011443309,-0.012985072,0.0123204,-0.030999718,0.0033507652,-0.02154357,6.54714e-05,0.010470285,-0.014979086,0.016925134,-0.009483556,-0.007715668,-0.016363246,-0.0011186348,-0.01303989,-0.010874569,-0.0044985223,-0.007612884,0.024407825,-0.022749571,-0.016212497,0.004275823,-0.023242936,0.0027820258,0.036618587,0.013149527,-0.009175204,0.007859566,0.01766518,0.037331223,-0.02307848,7.944363e-05,-0.04122332,-0.009264284,-0.013218049,0.017747408,0.0041901697,-0.0038920955,-0.00805143,-0.0095931925,-0.0020351273,0.019501591,0.0228318,-0.010908831,-0.028203987,-0.016582519,-0.015636904,-0.00056574144,-0.019967547,-0.023037368,-0.017158112,0.03530295,-0.0075649177,0.022215094,-0.011114399,0.014252744,0.0067940364,-0.0027169292,0.016116563,-0.002634702,-0.026162008,-0.0027820258,0.0014543965,-0.0037653283,-0.0017344835,-0.00014122122,0.016185086,-0.020543138,0.0062938198,-0.001134909,0.041168503,-0.002223565,-0.011744809,-0.028368441,0.011943526,0.024462642,-0.0019186386,-0.01438979,0.0036556916,0.0044574086,-0.015856177,0.0019220647,0.008551646,0.010340092,0.00038586906,0.0004723791,-0.0034107226,0.0065370756,-0.010518251,0.0005773046,0.015705427,0.0063657686,0.007976055,-0.009579488,-0.021529866,-0.04152482,0.017267747,-0.024490051,-0.050240923,0.013231754,0.0061088083,0.018706726,-0.018432636,0.02031016,0.008901113,-0.0061636264,0.0240378,-0.01607545,-0.034809586,-0.036673408,0.022790685,0.004032567,-0.0231333,-0.01303989,0.008359782,0.024791552,0.028368441,0.017445907,-0.02496971,0.023229232,0.01577395,0.0015974379,0.0021927299,-0.0016094294,-0.018830067,-0.019296022,-0.017582953,0.009188908,0.015349109,-0.0064993883,0.06983844,0.013779936,0.0067220875,-0.010538808,-0.0026021537,0.028341033,0.022845503,-4.5985227e-05,-0.020666478,-0.025887916,-0.0065679112,0.008154214,-0.029272944,-0.015458745,-0.009737091,0.00026081494,-0.011875003,0.0011451874,-0.02328405,-0.0043340675,0.024133733,-0.0005049274,0.010854012,0.008414601,0.0037310668,0.0034775324,0.002713503,-0.0026552589,0.020776115,-0.015869882,-0.0023777415,0.014088289,-0.02839585,-0.02716244,0.0055777566,0.013958096,-0.0060882512,-0.016198792,-0.0050364262,0.001158892,-0.0016959395,0.01565061,-0.016692156,-0.011203479,-0.027395418,0.016418064,0.0162262,-0.02280439,-0.002908793]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
{"doc":null,"source":"async def answer(\n    context: str, question: str, answer_model: str = \"chatgpt\", **kwargs\n) -> str:\n    \n    prompt = F(\nf\"\"\"Background text: \"{context}\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"{question}\"\nAnswer: \"\"\"\n    ).strip()\n\n    prompt = prompt\n    answer = await recipe.agent(answer_model).complete(prompt=prompt, stop='\"')\n    return answer\n"}
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"The model takes this text as input and generates the answer or ranks different options.","formatted":"The model takes this text as input and generates the answer or ranks different options."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh.","formatted":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Our models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95. We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details).","formatted":"Our models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95. We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details)."}]},"question":"How does the model get applied?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
0.7192402446432246
0.7612798366637998
0.7617781690644838
0.7445077977469086
0.7229732906902953
0.730229093681278
0.7608208176211514
0.7666525010670274
{"doc":"Generate an answer to a question given some context.","source":"    async def complete(\n        self,\n        *,\n        prompt: str,\n        stop: Stop = None,\n        verbose: bool = False,\n        default: str = \"\",\n        max_tokens: int = 256,\n    ) -> str:\n        \"\"\"Generate an answer to a question given some context.\"\"\"\n        if verbose:\n            self._print_markdown(prompt)\n        response = await self._complete(prompt, stop=stop, max_tokens=max_tokens)\n        completion = self._extract_completion(response)\n        if verbose:\n            self._print_markdown(completion)\n        return completion\n"}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"The model takes this text as input and generates the answer or ranks different options.","formatted":"The model takes this text as input and generates the answer or ranks different options."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh.","formatted":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Our models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95. We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details).","formatted":"Our models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95. We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details)."}]},"formatted":"The model takes this text as input and generates the answer or ranks different options.\n\nArchitecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh.\n\nOur models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95. We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details)."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
[{"sentences":["During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position.","Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch.","As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training.","However, this evaluation procedure is extremely expensive.","We will show that our proposed architecture is able to substantially improve the evaluation speed."],"sections":[{"title":"Vanilla Transformer Language Models","number":"3.1"}],"section_type":"main"},{"sentences":["In order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation.","Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network.","However, this is usually infeasible with the limited resource in practice."],"sections":[{"title":"Vanilla Transformer Language Models","number":"3.1"}],"section_type":"main"},{"sentences":["To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input.","Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."],"sections":[{"title":"Related Work","number":"2"}],"section_type":"main"}]
{"doc":"Send a completion request to the OpenAI API with the given prompt and parameters.","source":"    async def _complete(self, prompt, **kwargs) -> dict:\n        \"\"\"Send a completion request to the OpenAI API with the given prompt and parameters.\"\"\"\n        kwargs.update(\n            {\n                \"model\": self.model,\n                \"temperature\": self.temperature,\n                \"top_p\": self.top_p,\n                \"n\": 1,\n            }\n        )\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        response = await openai_chatcomplete(messages, **kwargs)\n        if \"choices\" not in response:\n            raise ValueError(f\"No choices in response: {response}\")\n        return response\n"}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"The model takes this text as input and generates the answer or ranks different options.","formatted":"The model takes this text as input and generates the answer or ranks different options."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh.","formatted":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Our models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95. We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details).","formatted":"Our models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95. We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details)."}]},"formatted":"The model takes this text as input and generates the answer or ranks different options.\n\nArchitecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh.\n\nOur models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95. We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details)."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"doc":"Send a completion request to the OpenAI API and return the JSON response.","source":"@trace\nasync def openai_chatcomplete(\n    messages: list[dict[str, str]],\n    stop: Optional[str] = \"\\n\",\n    top_p: float = 1,\n    temperature: float = 0,\n    model: str = \"gpt-3.5-turbo\",\n    max_tokens: int = 256,\n    logit_bias: Optional[Mapping[str, Union[int, float]]] = None,\n    n: int = 1,\n    cache_id: int = 0,  # for repeated non-deterministic sampling using caching\n) -> dict:\n    \"\"\"Send a completion request to the OpenAI API and return the JSON response.\"\"\"\n    params = {\n        \"messages\": messages,\n        \"stop\": stop,\n        \"top_p\": top_p,\n        \"temperature\": temperature,\n        \"model\": model,\n        \"max_tokens\": max_tokens,\n        \"n\": n,\n    }\n    if logit_bias:\n        params[\"logit_bias\"] = logit_bias  # type: ignore[assignment]\n    response = await _post(\"chat/completions\", json=params, cache_id=cache_id)\n    if isinstance(response, TooLongRequestError):\n        raise response\n    add_fields(total_tokens=extract_total_tokens(response))\n    return response\n"}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"The model takes this text as input and generates the answer or ranks different options.","formatted":"The model takes this text as input and generates the answer or ranks different options."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh.","formatted":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Our models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95. We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details).","formatted":"Our models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95. We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details)."}]},"formatted":"The model takes this text as input and generates the answer or ranks different options.\n\nArchitecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh.\n\nOur models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017) , with the following hyper-parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.95. We use a cosine learning rate schedule, such that the final learning rate is equal to 10% of the maximal learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2, 000 warmup 0 200 400 600 800 1000 1200 1400 Billion of tokens steps, and vary the learning rate and batch size with the size of the model (see Table 2 for details)."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position. Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch. As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. We will show that our proposed architecture is able to substantially improve the evaluation speed.","formatted":"During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position. Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch. As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. We will show that our proposed architecture is able to substantially improve the evaluation speed."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"In order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation. Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network. However, this is usually infeasible with the limited resource in practice.","formatted":"In order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation. Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network. However, this is usually infeasible with the limited resource in practice."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) .","formatted":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."}]},"question":"How does the model get applied?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
0.7530937767009644
0.7251469175584522
0.7440979534092244
0.7504732497172623
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position. Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch. As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. We will show that our proposed architecture is able to substantially improve the evaluation speed.","formatted":"During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position. Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch. As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. We will show that our proposed architecture is able to substantially improve the evaluation speed."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"In order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation. Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network. However, this is usually infeasible with the limited resource in practice.","formatted":"In order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation. Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network. However, this is usually infeasible with the limited resource in practice."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) .","formatted":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."}]},"formatted":"During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position. Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch. As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. We will show that our proposed architecture is able to substantially improve the evaluation speed.\n\nIn order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation. Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network. However, this is usually infeasible with the limited resource in practice.\n\nTo capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
0.7504381724011325
0.7601487466261175
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position. Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch. As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. We will show that our proposed architecture is able to substantially improve the evaluation speed.","formatted":"During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position. Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch. As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. We will show that our proposed architecture is able to substantially improve the evaluation speed."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"In order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation. Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network. However, this is usually infeasible with the limited resource in practice.","formatted":"In order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation. Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network. However, this is usually infeasible with the limited resource in practice."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) .","formatted":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."}]},"formatted":"During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position. Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch. As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. We will show that our proposed architecture is able to substantially improve the evaluation speed.\n\nIn order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation. Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network. However, this is usually infeasible with the limited resource in practice.\n\nTo capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
0.7265216181015767
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position. Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch. As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. We will show that our proposed architecture is able to substantially improve the evaluation speed.","formatted":"During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position. Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch. As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. We will show that our proposed architecture is able to substantially improve the evaluation speed."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"In order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation. Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network. However, this is usually infeasible with the limited resource in practice.","formatted":"In order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation. Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network. However, this is usually infeasible with the limited resource in practice."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) .","formatted":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."}]},"formatted":"During evaluation, at each step, the vanilla model also consumes a segment of the same length as in training, but only makes one prediction at the last position. Then, at the next step, the segment is shifted to the right by only one position, and the new segment has to be processed all from scratch. As shown in Fig. 1b , this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. We will show that our proposed architecture is able to substantially improve the evaluation speed.\n\nIn order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation. Given infinite memory and computation, a simple solution would be to process the entire context sequence using an unconditional Transformer decoder, similar to a feed-forward neural network. However, this is usually infeasible with the limited resource in practice.\n\nTo capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
0.756582806918882
0.7563944742041374
0.7295170232476694
0.754609882103819
0.7324791621188751
0.7501134184499315
0.7486830492687339
0.7272750955125306
0.7517324978944924
0.728502929059306
0.7174597454827298
0.7384960227888759
0.7785615877828728
0.7511839696729984
0.7176739003777746
0.7684568608163325
0.7556922179868037
0.7666695177364921
0.7438511693595189
0.752094606722814
0.7261944597956532
0.7601173974493981
0.7461866061452839
0.7534171217500388
0.7572747513759205
0.7705857575001709
0.733314065101977
0.7364689574484987
0.7244192444648315
0.7361157846806177
0.7484576099507347
0.7325955827636493
0.766619617885506
0.746840590295034
0.7041064005943581
0.7354806787259257
0.7268325765456833
0.7608664600163121
0.7383431168380807
0.7629503497520954
0.7605172860968361
0.7345957843164493
0.7430506404649918
0.7373995109093953
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.001338233,0.011877139,0.010863405,-0.0060858354,-0.017274594,0.022672048,0.0050994987,0.00062759104,-0.02060348,-0.034549188,0.023261111,-0.005763906,-0.011103139,0.006952305,-0.023480296,-0.012459352,0.028439378,0.007246836,0.007979739,-0.021630915,-0.0073427297,0.016589638,0.0019863728,-0.039754853,-0.017082807,0.02156242,0.02857637,-0.015356717,0.014671761,0.0057399324,0.00046534208,0.013384043,-0.023069322,-0.0327683,-0.0076304115,0.021480225,0.011027793,-0.014452575,0.0024298818,4.109737e-05,0.032466922,0.004667976,-0.0078016506,-0.020644577,0.009890767,0.007329031,0.01187029,-0.021206241,-0.010103103,-0.0045720823,0.020959659,0.028329786,-0.023315907,-0.0095003415,-0.01187029,0.009459244,-0.005897472,0.00952774,0.012390857,-0.0021422002,0.01813764,0.009740076,-0.013329246,0.0107401125,-0.029370919,-0.013500486,0.004263852,0.009657881,-0.023315907,0.020274702,0.049399037,0.029179132,-0.0011310339,-0.015069035,0.009849669,-0.011925086,-0.011925086,-0.015740292,0.005075525,0.00906197,0.0013896048,-0.022425463,-0.027548935,0.039398678,0.009479793,-0.033809435,0.010438732,0.026658492,-0.018452719,0.009788023,-0.010979847,0.017425284,0.020493887,-0.004274126,0.0052364897,0.0019538375,0.013075813,0.02389127,0.009733227,0.002311727,-0.011336024,0.00969213,-0.0484127,-0.0087400405,-0.015603301,0.00027847747,0.016891018,0.0006382935,0.011966184,-0.027411945,-0.048905868,0.043974183,0.007541367,-0.030932618,0.011288078,-0.004873463,-0.0017303705,-0.04345362,-0.007712606,-0.006263924,0.0067125703,0.030521646,0.02887775,-0.0055138967,0.019808931,-0.0059899413,-0.033973824,-0.025973536,-0.024096757,-0.009171562,0.027905112,0.014164893,-0.022261074,0.03339846,-0.023083022,0.0049385335,-0.005777605,0.03306968,-0.040056236,-0.015247123,0.024726916,0.0013322397,0.0063461186,0.020836366,-0.0034556037,0.020685675,0.0004417967,0.030220265,-0.0052878615,-0.010582573,-0.0014726557,-0.018028045,0.020918561,0.0039453474,0.017329391,0.019425357,0.0084592085,-0.0019589746,-0.01500054,-0.015808787,-0.0008647571,0.0050310027,0.0025446122,0.014260787,0.015918382,0.018247232,0.016055372,-0.0013853238,-0.006150906,0.011719599,-0.010918201,0.029590106,-0.018767798,0.028795555,0.0035857453,0.013205954,0.022000792,-0.02764483,-0.004907711,-0.0006905214,-0.010500378,0.020576082,-0.0016276271,0.012226467,-0.00906882,-0.014151194,0.0010608258,-0.029096937,-0.00045121484,-0.018521214,-0.010972997,0.015466309,0.008082482,0.012781282,-0.6606265,-0.028850352,0.00086432905,-0.014466274,0.013726521,0.01920617,0.006154331,-0.019877426,-0.02452143,0.020261003,-0.01998702,0.003149086,0.016726628,-0.032576513,-0.016329354,-0.042083707,0.019959621,-0.020028118,-0.013801866,0.015288221,-0.018754099,0.010897652,-0.014918345,0.020795269,-0.0036919136,0.0132813,-0.007760553,-0.008397562,0.03356285,0.02171311,-0.0027963335,0.028521573,-0.015918382,0.010459281,0.040165827,-0.016233461,-0.019452754,0.0055173216,-0.012342909,0.04328923,-0.04854969,-0.013801866,0.0139868045,0.0041474095,-0.0037227366,0.0062844725,0.008986625,-0.010370236,0.018658206,0.013205954,0.0017483506,0.026014633,0.0023870722,0.0073769777,0.01904178,-0.010925051,0.014479972,-0.008171527,0.016959514,0.0007607294,0.009233208,0.0037227366,-0.011849741,-0.0024538555,0.008685244,0.034850568,0.01420599,0.026877679,-0.0053769057,-0.021110348,0.0044316663,0.008911279,-0.0037878074,-0.010383935,-0.0008313655,-0.0030549043,0.005527596,0.0075482167,0.016808823,0.010137351,-0.0043494715,-0.022754243,0.0051097726,0.011342874,-0.0068769595,0.006616676,-0.020028118,-0.00905512,0.0032415548,-0.012425104,0.019808931,0.032549117,-0.0070208004,-0.030932618,-0.012199068,0.025631059,0.0009460957,0.015493708,0.0019555497,-0.014041601,-0.0124936,0.013041565,-0.0053323833,0.007822199,0.0187267,-0.00041953565,-0.03159018,0.028329786,0.03860413,0.003154223,-0.0019538375,0.018082842,-0.03202855,0.018945886,-0.004342622,-0.03169977,0.0067399684,-0.0031405238,-0.0057844548,-0.013616928,0.027521538,-0.0028374307,0.019069178,-0.014658062,0.009157863,0.025494067,0.0040309667,-0.016000574,0.006835862,0.017233497,0.024617324,0.02404196,0.013966256,-0.008157828,0.022178879,0.0124936,-0.0034898515,0.0090825185,0.0075961635,-0.010438732,-0.010589422,0.012753883,1.5933258e-05,0.0101579,-0.016343053,0.0051131975,-0.0070481985,0.010568873,-0.0029453114,-0.010226395,0.008020836,-0.018192435,-0.010623669,-0.0013005604,-0.015411513,0.002834006,0.01311691,-0.029781893,-0.0066748974,-0.034549188,0.0125415465,0.04260427,-0.02452143,0.005979667,-0.007829049,-0.003106276,-0.012918273,0.024946103,-0.0017226647,-0.01953495,0.014753955,-0.02980929,-0.003952197,0.029644901,-0.010027758,0.00679134,-0.00042724138,-0.019274665,-0.006448862,-0.015863584,-0.008692093,-0.01921987,0.01578139,0.008219474,0.015644398,0.01123328,0.02730235,0.008472907,-0.032686107,0.041152164,-0.0057844548,0.007274234,-0.010075705,0.010288041,0.011767547,-0.0076441104,0.0097743245,-0.0036953383,0.0068838093,0.003491564,0.005390605,0.009301704,0.026357112,-0.025973536,-0.0062844725,-0.009835971,0.008007137,-0.021041853,0.0218638,0.012274414,0.018356824,0.0004146125,-0.008109881,-0.015123831,0.009260607,-0.0028545547,0.00027398244,0.007096146,-0.009356501,0.032877896,-0.01061682,-0.013973105,0.05290601,-0.0038117808,0.013562132,0.025028298,-0.009123616,0.012240166,0.022055587,-0.029179132,-0.0016926979,0.0033237496,0.0063666673,0.027137961,0.013452538,0.0031268247,-0.022863835,-0.004983056,0.012781282,-0.012452503,0.013979955,0.015685495,-0.004585781,-0.011657953,0.03805616,0.0048905867,0.0327957,0.019658241,0.0014675185,-0.0104661295,-0.011931936,0.0013279587,-0.017370488,-0.0049556578,0.008013987,-0.0030206565,0.012582644,-0.0032038824,0.018151337,0.0218638,0.017329391,0.022754243,0.01887739,-0.034165613,0.032275133,0.0058563747,-0.009616784,-0.026124228,-0.021507623,-0.028932547,-0.022672048,0.0045481087,0.016466346,-0.042275492,0.037124623,0.005294711,0.01952125,0.012377158,0.03780958,0.014110097,-0.021822702,-0.018041745,0.003606294,0.014452575,0.0048837373,0.0021285012,-0.010904502,0.0049385335,-0.008603049,-0.0014426889,0.0037432853,0.01952125,-0.0038357545,-0.0029110636,-0.0077194558,0.014219689,0.013918309,-0.0052844365,-0.011726449,-0.012637441,-0.012918273,0.006962579,-0.019069178,-0.030823026,0.03761779,0.007260535,0.015712894,-0.016521143,-0.008849633,-0.026658492,0.006418039,-0.01889109,-0.0025274882,-0.021822702,0.016192364,0.0040343916,-0.028658565,0.016932115,0.028439378,-0.0029949707,-0.0029966831,0.0011772683,-0.0021576118,0.0065105082,0.03323407,0.027137961,0.0034367675,0.010109953,-0.04041241,0.0033460108,0.003544648,-0.006013915,0.0026439307,0.01827463,-0.0004193216,0.011007245,-0.0026884528,-0.0042398786,0.00075173937,0.014384079,0.026288617,-0.023343306,-0.008692093,-0.014959442,0.0032895019,-0.011171634,0.019247267,0.025343377,0.013212804,0.0021867224,0.008370164,0.0071303933,0.0020822666,-0.017699266,0.0045789317,0.014644362,0.018343125,0.019808931,0.007760553,0.021493923,-0.014918345,-0.012849777,0.013842964,0.007383827,0.012068927,-0.0023014527,0.011664803,-0.007068747,-0.007233137,-0.013507335,0.018849993,-0.010027758,0.009404448,-0.00048289407,-0.004544684,-0.011774396,-0.04109737,-0.008678394,0.0053495076,0.011630556,-0.009075669,-0.00038742833,0.0090825185,-0.021151446,-0.025548864,-0.008575651,0.012671689,-0.011651104,0.014192292,-0.0019332886,-0.0034419047,-0.003066891,-0.00030202285,-0.0010633944,0.002404196,-0.048686683,-0.03871372,-0.01156206,0.021165146,0.030275062,0.008555102,0.0015480008,-0.027083166,0.0013998791,-0.021343233,-0.009493492,-0.0032706656,-0.014479972,0.007712606,0.014767654,-0.0026131077,-0.0034761524,-0.0029846963,0.013610078,-0.010712714,0.03369984,0.0076783583,-0.021439128,-0.00063058775,0.009198961,0.00013677718,0.02121994,0.00538718,-0.022302171,0.027590033,-0.023589889,-0.01420599,-0.0070481985,-0.012589494,-0.0069934023,0.01076751,0.007555066,0.0044248165,-0.0084592085,0.011418219,-0.014575867,0.008842784,-0.01778146,0.00048375028,0.0007988301,0.021493923,0.016233461,-0.007959191,0.025850244,0.01686362,-0.041343953,0.01669923,0.010055156,-0.015849885,0.008719492,-0.021028154,0.0112949265,-0.024411837,0.016370451,-8.7974055e-05,0.025083093,-0.0076441104,-0.005620065,-0.027891414,-0.005328959,-0.027590033,-0.014726557,-0.0105346255,-0.011007245,0.011966184,-0.0035343736,-0.017548576,-0.00702765,0.008000287,-0.02265835,-0.010082554,0.014438875,-0.007294783,0.04011103,-0.0012080914,-0.0027620855,-0.014849849,-0.027727025,-0.002210696,-0.02887775,-0.0025857093,0.002238094,0.021165146,0.015343018,0.031480584,0.01764447,0.031617574,-0.0056337644,-0.019822631,-0.0064865346,0.012500449,-0.0044111176,-0.009411298,0.016411548,0.00010295747,-0.029727096,0.007746854,0.0048494893,0.005866649,0.01124013,-0.026261218,-0.017507479,-0.017356789,-0.022110384,0.00067810656,0.022767942,-0.02123364,-0.006260499,-0.030466849,0.015822487,-0.003162785,-0.0039761704,0.021165146,0.002513789,0.012863476,-0.004907711,0.022452863,-0.0004597768,-0.0017038283,-0.010801759,-0.031014813,-0.010493528,0.0020959657,0.036631454,-0.019562347,0.01579509,0.016096469,0.0009769187,-0.012568945,-0.023987165,0.00889758,-0.017671868,0.0022620677,-0.006322145,-0.009555138,-0.025726952,-0.012096325,-0.0138498135,0.0012825803,0.006668048,-0.018233532,0.0029179133,0.006637225,-0.021411728,0.024343342,-0.00967843,0.026179023,0.016041672,0.025891341,0.0029093511,0.0016704368,0.008212624,-0.012000431,-0.005900897,0.010404483,0.011301776,-0.01265114,0.01576769,-0.033809435,0.008548252,-0.00075387984,-0.013493636,-0.0077879513,0.009753776,0.013233352,-0.00951404,-0.00750027,-0.025809146,-0.01156206,0.0006990834,-0.008746889,-0.0150279375,0.0101168025,-0.007671509,0.0014854986,0.009411298,0.015726592,0.028165396,0.006339269,0.0005882061,0.021000756,-0.0016730054,0.009596235,0.019918524,0.0016652996,0.008534553,0.024699518,0.00842496,-0.0046851,-0.0022124082,0.008650996,-0.0025805722,-0.0012611755,0.028959945,-0.0110894395,0.00041439847,0.0007637261,0.010829156,0.0019572622,-0.0056885607,-0.014068999,0.0029949707,-0.007781102,0.008650996,0.0092948545,0.0075482167,-0.030412052,-0.008233173,0.0022192579,-0.0045652324,0.0055652685,-0.0022278198,0.0051714187,-0.032247733,-0.014973141,-0.0017825983,0.014562167,0.026453005,-0.013658025,0.0074523226,0.024110457,0.0032090195,-0.017836258,-0.007993438,0.021151446,-0.00717834,-0.0218638,0.022082986,-0.0072194375,-0.02749414,0.029124334,-0.0009109917,-0.02950791,-0.023767978,0.0041165864,-0.019589746,-0.00070079573,-0.04046721,-0.015123831,0.004808392,0.01264429,0.010322289,0.009322253,-0.0012303524,0.015247123,-0.00050173036,0.0043700202,0.00750027,-0.0088085355,-0.013753919,0.01391146,-0.0025651606,-0.037590392,-0.012308662,0.0019863728,0.0015779677,0.010993546,-0.013521034,-0.014329283,0.005842676,-0.009671581,0.033480655,0.007849597,-0.016493743,-0.019288365,-0.0063118706,0.00515087,0.026781784,-0.028932547,-0.008815385,-0.0023442623,-0.005304985,-0.033206675,-0.041864518,-0.019795232,0.037042428,0.019493852,-0.010014059,0.0005916309,-0.016233461,-0.020055516,-0.0121922195,0.010568873,-0.0070550484,-0.0076235617,0.0046645515,-0.006616676,0.018343125,0.002575435,-0.018315727,0.0022483685,0.010472979,-0.0125415465,-0.022932332,0.016644435,0.036960233,-0.022233676,-0.01453477,0.0044419407,-0.013294999,0.022261074,0.0012526135,-0.002864829,-0.015507407,0.014616964,0.019603444,0.02623382,0.023767978,0.018452719,-0.013788167,0.0036679402,0.014616964,-0.017301992,-0.026302315,-0.014288185,0.009760625,-0.007760553,0.0040994626,-0.011760697,-0.017438984,-0.008603049,-0.001623346,0.02169941,-0.0012474763,-0.00039235145,0.027151661,0.003162785,-0.021644615,-0.001811709,0.026603697,-0.024905005,-0.018822595,0.023767978,-0.039837047,0.0051611443,-0.0023459748,-0.019480152,-0.020206206,-0.0022295322,-0.0042296043,-0.006277623,-0.0052056666,0.0096373325,0.007603013,-0.017288294,0.0203021,-0.0043974183,-0.014068999,-0.016356753,0.0027963335,0.026905077,0.004476188,-0.013288149,-0.0016293394,-0.018713001,-0.01998702,0.026658492,0.025631059,0.014740256,0.032603912,0.24636503,-0.017452683,-0.013151158,0.011281228,0.015260823,0.005935145,1.3070355e-05,0.03200115,-0.020959659,-0.01295937,0.01669923,0.0063152956,0.0046337284,0.0020445941,0.0014067286,-0.010000359,-0.021000756,-0.008616748,0.001557419,0.0130210165,0.01358268,0.0029025017,0.0004593487,-0.020247303,0.045371495,0.011178484,0.0027518112,0.019329462,-0.014274486,-0.010726413,0.0066132513,0.0026165324,0.008027686,0.02046649,-0.016480045,-0.008041385,-0.006013915,-0.016726628,0.025795449,0.014753955,0.021014454,-0.009644182,-0.0115004135,-0.010856555,0.009281156,0.0031850461,-0.01139767,-0.012596344,0.010007209,0.007096146,-0.023206314,-0.016096469,0.0171787,0.028959945,-0.0015428637,-0.010733263,0.0017894479,-0.0040378165,0.034576587,0.014137494,-0.035535526,0.010890802,-0.029179132,0.018466417,-0.0052227904,-0.0007954053,-0.0029572982,-0.010418183,0.026494103,-0.026179023,-0.014425176,0.007849597,-0.0020548685,-0.0011387395,-0.025672156,-0.0057193837,0.033508055,0.019644542,0.020028118,0.023261111,-0.01593208,0.00014630235,-0.0020908285,-0.01060997,-0.016137566,-0.009863368,0.024014562,-0.016027974,0.008157828,0.006616676,5.3672735e-05,0.00050472707,-0.013103211,-0.0076304115,0.0012817242,0.004414542,0.0048494893,0.02515159,-0.0101579,0.00057450694,-0.03106961,0.05605681,0.01030859,0.003078878,0.015411513,0.016137566,0.02435704,0.015110132,0.0084660575,-0.01593208,-0.0028288688,-0.05060456,-7.592043e-06,-0.007322181,-0.007418075,0.0058597997,0.0016396138,-0.003561772,0.033672445,-0.010678466,-0.006013915,-0.014904645,-0.0022466562,0.009753776,0.011815493,-0.02139803,-0.0202884,-0.0015291646,-0.015397814,0.007137243,-0.0011687065,0.017452683,0.002207271,0.027699627,-0.009918164,-0.019877426,-0.01797325,-0.040960375,0.0035240992,0.009130465,-0.0006395778,0.017274594,0.01656224,-0.016260859,0.0019332886,-0.011534661,0.012068927,0.0097058285,-0.015726592,-0.015343018,-0.0050686756,-0.0038597279,-0.015808787,-0.025110492,0.020480188,-0.012438804,-0.01265799,-0.016986912,0.010335988,-0.008061933,-0.011527812,0.00453441,0.008185226,-0.03137099,-0.01311006,-0.00749342,-0.17655429,-0.0065105082,0.022836437,-0.043535814,0.018219832,0.02172681,0.012582644,0.0038494535,-0.03372724,0.015219726,0.008329066,-0.013918309,-0.021000756,0.0049385335,0.0043186485,-0.0029572982,-0.030110672,0.016123867,0.0043460466,0.026672192,0.026959874,-0.019507552,0.0051988172,-0.0008172383,-0.01639785,-0.0045207106,-0.0031713468,0.011733298,0.0119867325,-0.021987092,0.018548612,-0.011808644,0.010596272,0.007431774,-0.004948808,-0.0101168025,0.001772324,-0.020726772,-0.005277587,0.012692237,0.025891341,0.010705864,-0.018041745,0.029288724,-0.001219222,0.018781498,0.021110348,0.0026285192,0.009952413,-0.023384403,0.00632557,-0.011842892,-0.00050258654,-0.0018767798,0.017836258,0.020863764,0.016754027,-0.009767475,-0.013692273,-0.029398317,-0.019617144,-0.0065721544,0.020055516,-0.0032586788,-0.00339567,-0.004359746,-0.0030686036,0.027096866,-0.053152595,0.0069968267,-0.020370595,0.0030874398,0.0056269146,-0.0031114132,-0.0052570384,0.021644615,-0.016521143,0.005215941,0.01887739,-0.012596344,-0.009534589,0.046741407,-0.00421933,0.01684992,-0.0148224505,0.017219797,0.0040891883,0.036138285,-0.013836114,-0.010034608,0.010281191,-0.03827535,-0.0014349831,-0.012390857,0.026014633,0.024905005,0.010959298,-0.014007353,0.011151086,0.0006896652,-0.0026918775,-0.0029470238,-0.02871336,0.017480081,0.020863764,0.0032929266,0.00398302,0.02171311,0.027864015,0.0017791736,-0.036494464,-0.0105346255,-0.009596235,-0.012904573,-0.002364811,0.029562706,0.0058940477,0.00016278411,-0.03137099,0.0061166584,0.06756407,-0.017699266,0.0029966831,0.0009948988,-0.0024367315,-0.030631239,-0.1232921,-0.025165288,0.004280976,-0.002508652,0.009445545,0.0035720463,-0.009151014,-0.009856518,-0.025370775,0.01794585,-0.05041277,-0.028192794,-0.00082365976,-0.009349652,-0.015137531,-0.0026696166,0.005650888,-0.0043700202,-0.020576082,0.019754134,-0.034001224,-0.030740831,-0.015562204,0.0023716607,0.01826093,0.0054419767,-0.018918488,-0.0025035148,-0.004558383,-0.0013228216,0.027425643,-0.02201449,-0.01920617,-0.003075453,-0.013952556,-0.011342874,0.0060344636,-0.00952089,0.02422005,-0.03687804,0.014329283,-0.020891162,-0.011610007,-0.020110313,-0.011623706,0.0036165684,-0.028959945,0.029891485,0.0074523226,-0.008760589,-0.02046649,0.004075489,-0.028658565,0.008027686,0.008849633,0.0070824465,0.0036131437,0.0148224505,-0.008746889,0.016822523,-0.015356717,0.017206099,0.00999351,-0.0047741444,0.032686107,-0.017836258,-0.020932259,-0.019493852,0.006291322,-0.0327957,-0.00749342,-0.0012928547,-0.009616784,0.020110313,-0.022507658,-0.010212696,0.0020428817,0.004078914,-0.0072057387,-0.016658133,-0.0062810476,-0.007575615,0.018206134,-0.020795269,0.0035069755,0.0072057387,-0.009719527,-0.017589673,-0.0171924,-0.013240202,-0.017274594,0.047042787,0.018808896,-0.029946283,0.0032415548,0.006650924,0.00054496824,0.0029230504,0.000640434,0.009534589,-0.03293269,-0.00952089,-0.039754853,0.018863693,-0.016096469,-0.018534914,-0.010651068,-0.019726736,0.005137171,-0.005822127,0.0047844187,-0.011425069,-0.012918273,0.012315512,-0.031042213,0.003390533,-0.02153502,6.7585905e-05,0.010383935,-0.01498684,0.016918417,-0.009479793,-0.0077400045,-0.016356753,-0.0010993546,-0.013062114,-0.010904502,-0.00453441,-0.007664659,0.024343342,-0.022754243,-0.016164964,0.004215905,-0.02327481,0.0028134573,0.036604054,0.013144309,-0.009157863,0.007876996,0.017685568,0.03731641,-0.023096722,0.00010841571,-0.04126176,-0.009260607,-0.01311691,0.017740363,0.0041748076,-0.003907675,-0.0081167305,-0.009603085,-0.002036032,0.019452754,0.022877535,-0.01093875,-0.028137999,-0.016603338,-0.015617,-0.00057236647,-0.019959621,-0.023041924,-0.0171787,0.035316337,-0.007527668,0.022219976,-0.011123688,0.014274486,0.0068255877,-0.002702152,0.016137566,-0.002606258,-0.026151625,-0.0027826342,0.0014675185,-0.0037364357,-0.0016995474,-0.00016299816,0.016151266,-0.020507587,0.0063015963,-0.0011044918,0.041179564,-0.0022055588,-0.011733298,-0.028357184,0.011904538,0.024439234,-0.0019795233,-0.014438875,0.0036268428,0.004421392,-0.015890982,0.0019367135,0.008603049,0.010342837,0.00035681934,0.0004970213,-0.0034761524,0.0065481807,-0.010520927,0.00057579123,0.015726592,0.0063700923,0.00797289,-0.009548289,-0.021507623,-0.04153574,0.017247196,-0.024507731,-0.050220985,0.013260751,0.006099534,0.0187267,-0.01842532,0.020329498,0.008911279,-0.006157756,0.024028262,-0.016069071,-0.034877967,-0.036658853,0.02278164,0.004072064,-0.023096722,-0.013034715,0.008418111,0.024781713,0.02841198,0.017384186,-0.0249598,0.02327481,0.01576769,0.0015480008,0.0021987092,-0.0015865297,-0.018822595,-0.019329462,-0.01763077,0.009089368,0.015425212,-0.006438588,0.069701135,0.013788167,0.0066920216,-0.010514077,-0.0025240635,0.028329786,0.022891235,-2.2033648e-05,-0.02060348,-0.025877643,-0.006575579,0.008198925,-0.029261326,-0.015411513,-0.009726377,0.0002470123,-0.01187029,0.0011841179,-0.023288509,-0.004294675,0.02419265,-0.00047604452,0.010815457,0.008377014,0.003719312,0.0034949887,0.002679891,-0.0026182448,0.020850064,-0.015849885,-0.0024007712,0.014068999,-0.028302388,-0.027179059,0.005637189,0.013973105,-0.0060824105,-0.016164964,-0.0049693566,0.0011644254,-0.0017440695,0.015617,-0.016658133,-0.011205883,-0.027384546,0.016452646,0.016247159,-0.02278164,-0.002935037]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
0.7349031174934385
0.7388871904132768
0.751603176105624
0.7450520915126
0.7567741391799059
0.7230989146950948
0.7326788520485581
0.7532204700787032
[{"sentences":["This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place?","We take it as a given that it should be fluent and socially engaging.","Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions.","But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user.","In other words, the model must offer utility to the user.","It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models."],"sections":[{"title":"Introduction","number":"1"}],"section_type":"main"},{"sentences":["We evaluate fine-tuned models in two different setups: few-shot and full.","Our evaluation focuses primarily on few-shot finetuning, for the following reasons.","First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few.","Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models.","Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics."],"sections":[{"title":"Experimental Setup","number":"5.1"}],"section_type":"main"},{"sentences":["Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research.","While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility).","For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics."," Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities.","BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2 ","The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions.","We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly.","A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix."," Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness.","Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv).","By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets.","Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness).","In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation.","Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."],"sections":[{"title":"Related Work","number":"2"}],"section_type":"main"}]
0.7123619468619147
0.7224752929405657
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models.","formatted":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We evaluate fine-tuned models in two different setups: few-shot and full. Our evaluation focuses primarily on few-shot finetuning, for the following reasons. First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few. Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models. Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics.","formatted":"We evaluate fine-tuned models in two different setups: few-shot and full. Our evaluation focuses primarily on few-shot finetuning, for the following reasons. First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few. Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models. Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.","formatted":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."}]},"question":"How does the model get applied?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models.","formatted":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We evaluate fine-tuned models in two different setups: few-shot and full. Our evaluation focuses primarily on few-shot finetuning, for the following reasons. First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few. Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models. Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics.","formatted":"We evaluate fine-tuned models in two different setups: few-shot and full. Our evaluation focuses primarily on few-shot finetuning, for the following reasons. First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few. Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models. Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.","formatted":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."}]},"formatted":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models.\n\nWe evaluate fine-tuned models in two different setups: few-shot and full. Our evaluation focuses primarily on few-shot finetuning, for the following reasons. First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few. Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models. Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics.\n\nLarge pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
0.7445883987195201
0.7086296725428348
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models.","formatted":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We evaluate fine-tuned models in two different setups: few-shot and full. Our evaluation focuses primarily on few-shot finetuning, for the following reasons. First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few. Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models. Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics.","formatted":"We evaluate fine-tuned models in two different setups: few-shot and full. Our evaluation focuses primarily on few-shot finetuning, for the following reasons. First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few. Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models. Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.","formatted":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."}]},"formatted":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models.\n\nWe evaluate fine-tuned models in two different setups: few-shot and full. Our evaluation focuses primarily on few-shot finetuning, for the following reasons. First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few. Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models. Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics.\n\nLarge pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
0.7543408630885522
0.7743541136227482
0.698627594437797
0.7650392535911134
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models.","formatted":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We evaluate fine-tuned models in two different setups: few-shot and full. Our evaluation focuses primarily on few-shot finetuning, for the following reasons. First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few. Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models. Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics.","formatted":"We evaluate fine-tuned models in two different setups: few-shot and full. Our evaluation focuses primarily on few-shot finetuning, for the following reasons. First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few. Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models. Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.","formatted":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."}]},"formatted":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models.\n\nWe evaluate fine-tuned models in two different setups: few-shot and full. Our evaluation focuses primarily on few-shot finetuning, for the following reasons. First, datasets of goal-directed dialogs (e.g., MultiWOZ) are more expensive to construct and tend to be much smaller than chitchat datasets, hence we want to assess models' ability to perform well even if fine-tuning examples are relatively few. Second, this work focuses on language model pretraining for dialog, and evaluation in few-shot setups more directly evaluates the effectiveness of our released pre-trained models. Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics.\n\nLarge pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
0.7425317771975629
0.7466622503172373
0.710091815392428
0.7367718646173499
0.7443868060837919
0.7511434045089745
0.7372569152601371
0.7437546656218249
0.7199561030688166
0.6851173326197463
0.6913727788431089
0.7048793903979896
0.7562403583458622
0.7321350408632663
0.7295947161976982
0.7007559843977775
0.697130625561991
0.6977477969632985
0.6956985260598049
0.7486221426866443
0.7617465820008791
0.7355579804568697
0.7281234921140568
0.7150024387833727
0.714648482989321
0.6933006369852676
0.6876498969917801
0.6915859551278986
0.691273381542697
0.6734175271723821
0.7152568374067583
0.7335437141286031
0.721321330554897
0.6900893009092237
0.6757733535955718
0.7050240121312122
0.7188607746040019
0.6882575232977289
0.711442747078321
0.7434706714843445
0.7458935303648739
0.6931306164955763
0.7339318539213417
0.6812253224917325
0.6879782689860241
0.7977251438963441
0.7163736714782295
0.702266370920831
0.698487091335141
0.7413100539358151
0.7210245216306879
0.7396791256199073
0.7796962710450875
0.7505450823711393
0.7552800942726762
0.700855415614647
0.693201615179383
0.7002787466255027
0.7568688786997985
0.7116145446006477
0.6909559509123686
0.7492237161121756
0.7367795118149811
0.7159668364216449
0.7043091248232126
0.7493542875167306
0.7413554433859838
0.7236588600215818
0.6922582129528266
0.720378728459408
0.7110335677153768
0.7441578886246899
0.7198745112868681
0.7382048163507794
0.7171035495986516
0.710615538016014
0.6957098901210763
0.6865586299811899
0.717768615231157
0.7543339266278245
0.7322308209878583
0.7577613272891247
0.7231750768342512
0.7517071563264568
0.7541561108227736
0.7421176615464111
0.6765121702032829
0.756842890651709
0.7363966415717124
0.7218403539039958
0.7469483298281772
0.7394430824200403
0.6915245170779022
0.7356213239635131
0.7279802646925343
0.7108856034303241
0.7877037145842699
0.7327797162180589
0.6912443885852839
0.7521594966698055
0.7195766724221699
0.7564987555662906
0.7403129178817796
0.7270111388503425
0.6935987446069716
0.7471368354084958
0.7329538036968138
0.7383411812563891
0.7130863341503288
0.7517357084173095
0.7568730954766265
0.7156137334775343
0.7745584596216406
0.6820282545305406
0.7463676626032877
0.7464013963741827
0.7992804639313063
0.7224207918075082
0.7354637055824391
0.7459374846497387
0.7431192179553961
0.7452287280325253
0.7458413269685722
0.7252455208056026
0.7016415867573272
0.7320942644857246
0.75817796158339
0.7347023346545758
0.7599148690404138
0.7431575308536399
0.761589352774263
0.7318338817427029
0.700315294884139
0.7077434790753292
0.7483099960447687
0.7415068795293853
0.7486557975963527
0.6911018793694931
0.6969389292224335
0.7558286848691436
0.7429698851585508
0.7468889086511787
0.7384409127822377
0.7284676541305974
0.7679298399244292
0.7213729005430971
0.741991300713224
0.7130460761822999
0.7761382201682562
0.7450793063458283
0.743078435102011
0.7194001868451565
0.7307717803791443
0.7102942507976596
0.6784135397352139
0.733656414510198
0.6745920738900901
0.6950573697195724
0.7328165720955397
0.7235524358466665
0.7298815203458564
0.7969678860287366
0.6714938360847719
0.7129508920433266
0.7035590720259589
0.6890453724669258
0.6967615444842712
0.7156393204905421
0.7299397271493108
0.7149904175670956
0.7538784451000915
0.7371408894399349
0.7093954599575676
0.7402188031722408
0.7501561739364598
0.7295914743659059
0.7400530662868159
0.7021600083348517
0.7327181481949862
0.7275891470194454
0.7701991300582771
0.7503424224392231
0.727729396008438
0.7599328395571
0.738995136242566
0.7256409960449558
0.7257839550137781
0.7271032178185212
0.7660408495090567
0.6966939850547837
0.7398754439715695
0.765957758981389
0.7101939390570322
0.737336863651442
0.7217308503692771
0.7441890889453481
0.7216290430434916
0.7493693314173241
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.001255972,0.011869662,0.010897076,-0.006054692,-0.017314775,0.022698246,0.0051095025,0.00062327716,-0.020629788,-0.03446517,0.023205087,-0.005763601,-0.011136798,0.0069313897,-0.023465356,-0.012458693,0.028437875,0.0072122067,0.008006714,-0.021629771,-0.007362889,0.016629856,0.00201024,-0.03978015,-0.017095601,0.021533882,0.028520066,-0.015465491,0.014684684,0.0057807243,0.00048672123,0.01334909,-0.023081802,-0.032739174,-0.0076779523,0.021506486,0.010992965,-0.01445181,0.0024588625,-6.491355e-06,0.032547396,0.004698551,-0.007801238,-0.020657185,0.009890243,0.007349191,0.01189021,-0.021246215,-0.010075172,-0.0045718406,0.020931153,0.02830089,-0.023369469,-0.009527236,-0.011910757,0.009534085,-0.005934831,0.009547784,0.012444995,-0.0021557854,0.018150378,0.00975326,-0.0133764865,0.010760092,-0.029369367,-0.01351347,0.0042567775,0.009643673,-0.02325988,0.020218836,0.049314234,0.029204985,-0.0011352547,-0.01505454,0.00983545,-0.012013496,-0.011855964,-0.015766857,0.0051095025,0.009075189,0.001381826,-0.022479072,-0.02753378,0.039451387,0.009486141,-0.033807646,0.010424482,0.026657084,-0.018438045,0.00983545,-0.010938171,0.017438062,0.020492803,-0.0042122575,0.005208816,0.0019708571,0.013054574,0.023848912,0.009705315,0.0023098926,-0.011349123,0.009725863,-0.048382744,-0.008760126,-0.01564357,0.0002666907,0.016794236,0.00063098245,0.011992948,-0.027355703,-0.048848487,0.044026654,0.007520421,-0.030848794,0.011225837,-0.0048629316,-0.0017422651,-0.043396525,-0.0076985,-0.0062601683,0.006746461,0.030574825,0.02890362,-0.0054896334,0.01983528,-0.005996474,-0.033944633,-0.02591737,-0.024095483,-0.009157379,0.027876241,0.014123049,-0.022314692,0.03342409,-0.023068104,0.004886904,-0.005705383,0.03304054,-0.040163703,-0.015205222,0.024739308,0.0013578538,0.0063355095,0.020821566,-0.0034982285,0.020698281,0.00041780114,0.030218666,-0.0052910065,-0.010623108,-0.0015282276,-0.017972298,0.020890057,0.0039485632,0.01736957,0.019369535,0.008486158,-0.0019194881,-0.014999746,-0.015766857,-0.00085144106,0.0049759434,0.002506807,0.014273731,0.015931237,0.018259965,0.016123015,-0.0014032297,-0.006123184,0.0116778845,-0.010965568,0.02950635,-0.018794203,0.028821431,0.0035889803,0.013225804,0.02198593,-0.02762967,-0.0048903283,-0.00066437235,-0.01052722,0.020629788,-0.0016652115,0.012253217,-0.009171078,-0.014177842,0.0010727558,-0.029095398,-0.0003392494,-0.018506536,-0.01102721,0.015438095,0.008061508,0.012725812,-0.66059154,-0.028848827,0.0008257566,-0.014438112,0.0136573035,0.01924625,0.0061368826,-0.019780487,-0.024520133,0.020301027,-0.019944869,0.0031249472,0.016643554,-0.032602187,-0.0162463,-0.042136274,0.019972265,-0.020040756,-0.013787438,0.01531481,-0.018821599,0.0109244725,-0.014944953,0.020807868,-0.0036335003,0.013307994,-0.0077532935,-0.008417666,0.033561077,0.02164347,-0.002775638,0.028602256,-0.015876444,0.010486124,0.04010891,-0.0162463,-0.019424329,0.0055067562,-0.012301162,0.04336913,-0.048547123,-0.0137531925,0.0140408585,0.0041197934,-0.003791032,0.006318386,0.008910808,-0.010397084,0.018698314,0.013212105,0.0016866153,0.026013259,0.00233044,0.007362889,0.018972281,-0.010903926,0.014492906,-0.008088904,0.016972316,0.00080135633,0.009287514,0.0036677462,-0.011821718,-0.0024622872,0.008739579,0.034930915,0.014164144,0.026876258,-0.005356074,-0.02112293,0.0045615667,0.008903959,-0.003701992,-0.010362838,-0.0008617149,-0.0031198103,0.0055375774,0.0075478177,0.01675314,0.010109418,-0.0044622533,-0.02276674,0.0051095025,0.01137652,-0.0069382386,0.0066368743,-0.020040756,-0.009054641,0.0032396712,-0.0124039,0.01983528,0.032547396,-0.006955362,-0.03095838,-0.012218972,0.025643403,0.0009897093,0.01547919,0.0019794186,-0.014123049,-0.012513487,0.013075122,-0.005314979,0.007801238,0.01873941,-0.00045589983,-0.031615905,0.028355684,0.038629483,0.0031317964,-0.001993117,0.018109282,-0.032054253,0.018985981,-0.004404035,-0.031698093,0.0066471477,-0.0031420703,-0.005763601,-0.013554566,0.027478987,-0.0027824873,0.019122964,-0.014670985,0.009102586,0.02549272,0.004095821,-0.015958635,0.0068731713,0.017273681,0.024616022,0.024081785,0.013951818,-0.008191642,0.022177707,0.01257513,-0.0034588457,0.009054641,0.007595762,-0.01043818,-0.010595711,0.012718963,6.6405126e-05,0.010116267,-0.016314793,0.005064983,-0.007088921,0.010616259,-0.0029776893,-0.010212156,0.008006714,-0.018191474,-0.010677902,-0.001285081,-0.015410698,0.0029417311,0.013102518,-0.029807715,-0.006722489,-0.034547362,0.0125271855,0.042629417,-0.024479039,0.0059382557,-0.007828635,-0.0030924135,-0.013013478,0.024944784,-0.0017688057,-0.019547615,0.0147942705,-0.029780319,-0.003900619,0.029670732,-0.010047776,0.0068149534,-0.00045547175,-0.01923255,-0.0064074257,-0.015890142,-0.008698483,-0.01923255,0.015780555,0.008232738,0.015670968,0.011239536,0.027328305,0.00846561,-0.03268438,0.041177385,-0.005808121,0.007362889,-0.010075172,0.0103491405,0.011760076,-0.007636857,0.009732712,-0.0036129525,0.0068731713,0.0035136393,0.005362923,0.009362855,0.02635572,-0.025931068,-0.0062841405,-0.0097875055,0.00804096,-0.021081835,0.021766756,0.012342257,0.018369552,0.00041630288,-0.00812315,-0.01505454,0.009191626,-0.0029091975,0.0002718276,0.007123167,-0.009376554,0.032876156,-0.010602561,-0.013979216,0.052875817,-0.0038081547,0.013540867,0.024944784,-0.009088888,0.01232171,0.022040723,-0.029259779,-0.0016934645,0.0032807665,0.0063012633,0.027150227,0.013410732,0.003118098,-0.022848928,-0.004969094,0.012766907,-0.01248609,0.013938121,0.015684666,-0.004575265,-0.011705281,0.03805415,0.0048526577,0.032656983,0.0196709,0.0014503179,-0.010486124,-0.011958702,0.0013201832,-0.017328475,-0.005023888,0.007999864,-0.0030222093,0.012609376,-0.003210562,0.018109282,0.021807851,0.01736957,0.022780437,0.018848997,-0.03413641,0.032273427,0.0059074345,-0.009575181,-0.026068052,-0.021437993,-0.029040605,-0.022643453,0.0045204717,0.016451776,-0.042273257,0.037150055,0.0053081294,0.01958871,0.012342257,0.03780758,0.014136747,-0.021807851,-0.018068187,0.0035958297,0.01445181,0.004849233,0.0021095534,-0.010910775,0.0049314233,-0.008575197,-0.0014477494,0.0037054168,0.019547615,-0.0038560992,-0.0028698144,-0.0076711033,0.014191541,0.013876477,-0.0052499115,-0.01171898,-0.012725812,-0.012931288,0.006975909,-0.019040775,-0.030821396,0.037670597,0.0072670006,0.015698364,-0.016492872,-0.008862864,-0.026629686,0.006441672,-0.018931186,-0.0025290668,-0.021739358,0.016205205,0.0040786983,-0.028629653,0.01693122,0.028383082,-0.0029845387,-0.0030067984,0.0010890227,-0.0021437993,0.0065409853,0.033396695,0.027163925,0.0033972028,0.010123117,-0.040437672,0.0033886414,0.003558159,-0.0059690773,0.0027139953,0.018205171,-0.00043920492,0.011040909,-0.0027088583,-0.0043252693,0.00070204295,0.014383319,0.026273528,-0.023355769,-0.008698483,-0.015027143,0.0032482326,-0.011136798,0.019218853,0.02531464,0.013225804,0.0021386624,0.0084587615,0.007088921,0.002083869,-0.01769833,0.0045581423,0.014657286,0.018355854,0.019807884,0.007801238,0.021479089,-0.014917556,-0.012862796,0.013814835,0.0074313814,0.011992948,-0.0022927695,0.01162994,-0.007116318,-0.007205358,-0.013499772,0.018876392,-0.010034077,0.009451895,-0.00040731332,-0.004595813,-0.011787472,-0.041095197,-0.008657387,0.0053321016,0.011664187,-0.009082038,-0.00040410276,0.009047792,-0.021095533,-0.025629703,-0.008547801,0.012636772,-0.011664187,0.01420524,-0.0019280496,-0.0034126134,-0.003039332,-0.0002872383,-0.0010230992,0.0024023566,-0.048711505,-0.03868428,-0.011575147,0.021177724,0.030246064,0.008595745,0.0015573367,-0.027095431,0.001370696,-0.021301009,-0.009527236,-0.0032807665,-0.014438112,0.007705349,0.014753175,-0.0024999578,-0.0034845301,-0.0029845387,0.0136641525,-0.010794338,0.033643268,0.007808087,-0.02154758,-0.0006356913,0.0092190225,7.432451e-05,0.02112293,0.005438264,-0.022314692,0.027588574,-0.02360234,-0.014164144,-0.0070204292,-0.0125271855,-0.006979334,0.010760092,0.0074793254,0.004438281,-0.008410817,0.011397067,-0.014643588,0.008773824,-0.017725728,0.00050127576,0.00082490046,0.021492787,0.016218904,-0.007931373,0.025862576,0.016890125,-0.041423958,0.016698347,0.0100683225,-0.015931237,0.008719031,-0.021027042,0.011321726,-0.024451641,0.016355887,-5.1154955e-05,0.025054371,-0.007664254,-0.005677986,-0.027944732,-0.0053081294,-0.027602272,-0.01471208,-0.010629958,-0.011095703,0.011910757,-0.0035478852,-0.017492855,-0.0070957704,0.008075206,-0.02267085,-0.010123117,0.01436962,-0.0073149446,0.040136307,-0.0011763499,-0.0027379673,-0.014862763,-0.027739257,-0.0022311267,-0.028931018,-0.0025718743,0.0021592102,0.021150328,0.015287412,0.031506315,0.017602442,0.031615905,-0.0056334664,-0.019821582,-0.006558108,0.012451844,-0.0043937615,-0.009424498,0.01642438,0.000100597616,-0.029698128,0.0077121984,0.004900602,0.0057944227,0.011273782,-0.02625983,-0.01745176,-0.01736957,-0.022122914,0.00064981775,0.022821533,-0.021205122,-0.0062601683,-0.030520031,0.01582165,-0.003169467,-0.0039485632,0.021191422,0.002553039,0.012958685,-0.0049348483,0.022424279,-0.00040881158,-0.0016926083,-0.010787489,-0.031013174,-0.010506672,0.002135238,0.03660212,-0.019533915,0.015794253,0.016123015,0.0010094007,-0.012520337,-0.023931103,0.008931356,-0.01761614,0.0022739342,-0.006297839,-0.009636823,-0.025766687,-0.012027194,-0.013828534,0.0012859371,0.0067361873,-0.018273663,0.0029160467,0.0066882432,-0.021369502,0.024273561,-0.009677919,0.02617764,0.016027126,0.025889974,0.0029211836,0.0016686362,0.00821219,-0.012013496,-0.0059040096,0.010308045,0.01137652,-0.012616225,0.015794253,-0.033725455,0.008629991,-0.0007337205,-0.013403883,-0.007801238,0.009794355,0.013287446,-0.009575181,-0.0075341193,-0.025889974,-0.011520353,0.0007033271,-0.008766975,-0.015013445,0.010123117,-0.007657405,0.0015111046,0.009335458,0.01573946,0.028191304,0.0063320845,0.000639544,0.020985946,-0.0016720608,0.009561482,0.019944869,0.0016438079,0.00855465,0.024753006,0.008445063,-0.004602662,-0.0022636603,0.008677935,-0.002570162,-0.0013090532,0.028985811,-0.011061457,0.0004008922,0.0008124863,0.010787489,0.002061609,-0.0057190815,-0.014068255,0.002958854,-0.0077327457,0.008629991,0.009308062,0.0075546666,-0.030383049,-0.00821219,0.0022259897,-0.004530745,0.005551276,-0.0022259897,0.005201967,-0.032273427,-0.014999746,-0.0018372977,0.014588795,0.026492702,-0.013629907,0.007486175,0.024122879,0.0032191237,-0.017903807,-0.00795192,0.021150328,-0.007219056,-0.021794152,0.022040723,-0.007246453,-0.02753378,0.029040605,-0.0009212173,-0.029533748,-0.023753023,0.0040889718,-0.019602409,-0.0007247309,-0.040465068,-0.015123032,0.0048629316,0.01265732,0.010301196,0.009369705,-0.0012662457,0.015260016,-0.00051197765,0.004311571,0.007486175,-0.00872588,-0.013732645,0.013897025,-0.0026506402,-0.03756101,-0.012383352,0.001958871,0.0016301094,0.010986116,-0.013479224,-0.014355921,0.0058218194,-0.009712164,0.033396695,0.007890278,-0.01650657,-0.019205155,-0.0062841405,0.0052053914,0.026739273,-0.028958414,-0.008849165,-0.0024143427,-0.005356074,-0.033232316,-0.0419171,-0.019711995,0.037013073,0.019520218,-0.01000668,0.00059716456,-0.016287396,-0.020081852,-0.012225821,0.01060941,-0.00710262,-0.007630008,0.0046643047,-0.0066231755,0.018342156,0.0025444776,-0.018355854,0.002267085,0.010499823,-0.012568281,-0.022944817,0.016657252,0.03693088,-0.022273596,-0.014492906,0.0045136223,-0.01326005,0.022273596,0.001273951,-0.002838993,-0.015465491,0.014602493,0.019616107,0.026232433,0.023794118,0.018383252,-0.013869628,0.0037191152,0.014629889,-0.017218888,-0.026273528,-0.014260033,0.009746411,-0.0077875396,0.0040992456,-0.011746377,-0.017465457,-0.008575197,-0.0016181234,0.02172566,-0.0013244639,-0.00043920492,0.027177623,0.0031557686,-0.021657169,-0.0018167502,0.026657084,-0.024931084,-0.018848997,0.023739325,-0.039807547,0.005147173,-0.0023475632,-0.019465424,-0.020218836,-0.0021660593,-0.0042122575,-0.0062704417,-0.0051642964,0.00958203,0.0075478177,-0.01728738,0.020301027,-0.004428007,-0.014068255,-0.016383285,0.0028235824,0.026903655,0.004482801,-0.013301145,-0.0015753158,-0.018670917,-0.019999662,0.026657084,0.025670798,0.01471208,0.03257479,0.246352,-0.017465457,-0.013246351,0.011273782,0.015260016,0.0060170214,2.9189361e-05,0.031999458,-0.021013344,-0.012965534,0.016739443,0.0063252356,0.0046334835,0.0020581845,0.0013861067,-0.009992981,-0.021013344,-0.008575197,0.001621548,0.013027177,0.013554566,0.0029502925,0.00046959822,-0.020314725,0.045369096,0.0111094015,0.0026883108,0.019287346,-0.014260033,-0.010725846,0.0066402988,0.002631805,0.007999864,0.020492803,-0.016465476,-0.008013563,-0.0059896247,-0.016698347,0.025876274,0.014725778,0.02104074,-0.009650522,-0.01154775,-0.01086283,0.009246419,0.003227685,-0.011355972,-0.012540883,0.01000668,0.0071300166,-0.023163991,-0.016150411,0.017122999,0.028958414,-0.0015701789,-0.01078064,0.0017927779,-0.003999932,0.03462955,0.014081954,-0.03564323,0.010883378,-0.02917759,0.018520234,-0.0052567604,-0.00074056967,-0.002929745,-0.010308045,0.026533797,-0.026191337,-0.014438112,0.007890278,-0.0020718828,-0.0010950158,-0.025698196,-0.0056951093,0.03353368,0.01958871,0.020095551,0.023205087,-0.015890142,9.503264e-05,-0.002119827,-0.010650504,-0.016136713,-0.009883394,0.023999594,-0.016027126,0.008143698,0.006660846,3.34166e-05,0.00058988726,-0.013102518,-0.0076848017,0.001255972,0.0044622533,0.0049553956,0.025163958,-0.01017791,0.00058731885,-0.031095365,0.056081243,0.010301196,0.0031026872,0.015438095,0.016109318,0.024328357,0.015109333,0.008431364,-0.015958635,-0.0027961857,-0.05062928,-2.9617437e-05,-0.007287548,-0.0074108336,0.0058629145,0.0015804528,-0.0035650083,0.033670664,-0.0106916,-0.006013597,-0.014876461,-0.0022687973,0.009725863,0.01180117,-0.021410597,-0.020287327,-0.0015385014,-0.015424397,0.0071300166,-0.0011523778,0.017410664,0.0022533867,0.02771186,-0.009931339,-0.019862678,-0.017944902,-0.04095821,0.0034571334,0.009205324,-0.0006784988,0.017259981,0.016670952,-0.016232602,0.0019160635,-0.011561449,0.012102535,0.009760109,-0.015766857,-0.015410698,-0.0051129274,-0.0038595237,-0.015807953,-0.025136562,0.020561296,-0.0124381455,-0.012623074,-0.01702711,0.010335442,-0.008102602,-0.011568298,0.0045067733,0.008219039,-0.031341936,-0.013164161,-0.007499873,-0.17654496,-0.0065204375,0.022794135,-0.043588303,0.018191474,0.021753056,0.012561431,0.003791032,-0.033643268,0.015205222,0.0083697215,-0.013883327,-0.020972248,0.004941697,0.00436294,-0.002929745,-0.030054286,0.016123015,0.0043286937,0.02668448,0.026931051,-0.019451726,0.00521909,-0.00077010685,-0.01641068,-0.004541019,-0.0031883023,0.011794321,0.011945004,-0.021944834,0.018588727,-0.011787472,0.010513521,0.007403984,-0.004917725,-0.010129966,0.001787641,-0.020766772,-0.005304705,0.012705265,0.025889974,0.010677902,-0.017985998,0.029287176,-0.0011789184,0.018794203,0.021136628,0.0026249557,0.009999831,-0.023410562,0.006297839,-0.011849115,-0.0005556413,-0.0019057897,0.017890109,0.020848963,0.016780538,-0.009773808,-0.013698398,-0.029369367,-0.019629804,-0.0065546837,0.019999662,-0.0032054253,-0.0033903536,-0.004404035,-0.0030598799,0.027150227,-0.05320458,0.006979334,-0.020383216,0.0031335086,0.0055820975,-0.0030581674,-0.005225939,0.021657169,-0.016465476,0.005191693,0.018821599,-0.012513487,-0.009554633,0.046684142,-0.0042533525,0.016807934,-0.0147942705,0.017164093,0.00410267,0.036163773,-0.013814835,-0.010054625,0.010205307,-0.03832812,-0.0013458676,-0.01248609,0.025999561,0.024835197,0.010986116,-0.013965517,0.011095703,0.00062584557,-0.0026814614,-0.002998237,-0.02873924,0.017410664,0.020848963,0.0033201494,0.00397596,0.021807851,0.027876241,0.0017927779,-0.03651993,-0.0105409175,-0.009568332,-0.012855947,-0.002364686,0.029588541,0.005893736,0.00016373867,-0.031396728,0.006123184,0.06767009,-0.017670933,0.0029794017,0.000976867,-0.0024468764,-0.030684413,-0.123176,-0.025136562,0.004239654,-0.0024828347,0.009479292,0.003602679,-0.00915053,-0.009842299,-0.025369434,0.017862711,-0.05038271,-0.028163908,-0.0008582903,-0.009356006,-0.015150429,-0.0027157075,0.005595796,-0.0043389676,-0.020547599,0.019711995,-0.03397203,-0.030766603,-0.01556138,0.0024092058,0.018246267,0.0055410024,-0.018890092,-0.002518793,-0.0044964994,-0.0012688142,0.027424194,-0.022027025,-0.019191457,-0.003054743,-0.013979216,-0.011308028,0.0058868867,-0.009486141,0.024246166,-0.03687609,0.01436962,-0.02087636,-0.01162994,-0.020136645,-0.011616242,0.0035615836,-0.028985811,0.029889906,0.0074313814,-0.008732729,-0.020479105,0.0040478767,-0.028602256,0.008027261,0.008780673,0.007109469,0.0035821311,0.014780572,-0.008760126,0.016794236,-0.015383301,0.017218888,0.009999831,-0.004780741,0.032739174,-0.017835315,-0.020972248,-0.019547615,0.0063012633,-0.032876156,-0.0075067226,-0.0012893617,-0.009547784,0.020027058,-0.022561261,-0.010219005,0.0019948294,0.0041300673,-0.007150564,-0.016657252,-0.0062738666,-0.007636857,0.018191474,-0.020766772,0.003472544,0.0072670006,-0.009719014,-0.017575046,-0.017150395,-0.013212105,-0.017259981,0.047012903,0.018794203,-0.0299447,0.003237959,0.0065752314,0.0005744766,0.002940019,0.0006956218,0.009588879,-0.03301314,-0.009527236,-0.039807547,0.018848997,-0.016068222,-0.018547632,-0.010698449,-0.019684598,0.005191693,-0.0058457917,0.0048937527,-0.011410766,-0.012979233,0.012301162,-0.031013174,0.0033252863,-0.021533882,5.7897138e-05,0.01052037,-0.014958651,0.016890125,-0.009506688,-0.0077738413,-0.01634219,-0.0010864543,-0.013040875,-0.010897076,-0.0044348566,-0.007705349,0.02436945,-0.022780437,-0.016205205,0.0042875987,-0.023218786,0.0028013226,0.036684312,0.013150463,-0.009143681,0.007924523,0.017643537,0.037314437,-0.023163991,9.4390525e-05,-0.041259576,-0.009314911,-0.013164161,0.017766822,0.0042054085,-0.0039485632,-0.008075206,-0.009643673,-0.0020239383,0.019492822,0.022794135,-0.010951869,-0.028191304,-0.01652027,-0.015629873,-0.0006074384,-0.019972265,-0.023027008,-0.01719149,0.035287075,-0.0074930238,0.022177707,-0.01111625,0.014314827,0.006825227,-0.0027448167,0.016177809,-0.002616394,-0.02609545,-0.0028800883,0.0013784013,-0.0037430874,-0.0017448335,-0.00015913686,0.016205205,-0.020479105,0.006321811,-0.0011155633,0.041122593,-0.002152361,-0.011746377,-0.028437875,0.0119724,0.024437943,-0.0019314742,-0.014355921,0.0036369248,0.004428007,-0.015862746,0.0019297618,0.008602594,0.010397084,0.00031613334,0.0004978512,-0.003398915,0.0065546837,-0.010534069,0.0005659151,0.015780555,0.0063423584,0.007917674,-0.009561482,-0.021533882,-0.041533545,0.01735587,-0.024506435,-0.05021833,0.013266899,0.006058117,0.018712012,-0.018438045,0.020287327,0.008883411,-0.006133458,0.023931103,-0.015999729,-0.034848727,-0.036684312,0.02276674,0.004054726,-0.023150293,-0.013061423,0.008438214,0.024794102,0.02841048,0.017410664,-0.02498588,0.02325988,0.015753157,0.0015359329,0.002210579,-0.0015744597,-0.018807901,-0.01934214,-0.017575046,0.009171078,0.015369603,-0.0064964653,0.069752246,0.013842232,0.0066985167,-0.01052037,-0.0025889974,0.028383082,0.022862626,-5.155628e-05,-0.020643486,-0.025889974,-0.006568382,0.008184793,-0.029287176,-0.015492889,-0.009760109,0.00036750236,-0.01189021,0.0011677885,-0.023246182,-0.004335543,0.024177674,-0.0004785878,0.010869679,0.008397118,0.0037156907,0.0034280242,0.0027105706,-0.0026335171,0.020821566,-0.015876444,-0.0024246166,0.014081954,-0.028383082,-0.027150227,0.005630042,0.013951818,-0.0060923626,-0.016191507,-0.005013614,0.0011635077,-0.0017379844,0.015602476,-0.016629856,-0.011218988,-0.027383098,0.01641068,0.016287396,-0.022698246,-0.0029622787]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
0.7181424226288884
0.7119056931293253
0.7136412624136902
0.7693553813244225
0.7401521426514628
0.73293966259122
0.7262922622732199
0.7116323681953612
0.7085166062150668
0.7571673883320333
0.7208291043381729
0.7550485797683031
0.7713723670516838
0.7530705349455838
0.7587502979446313
0.7130771369036162
0.6634122771438296
0.7681942707476443
0.693227467955923
0.6981968905805718
0.759124985443876
0.6734382060446154
0.7667213157333387
0.7494245704484409
0.7117559570653642
0.6887482874184976
0.7561794215892622
0.7574130485432834
0.7142521694116418
0.6871062587537008
0.7505991130713847
0.7237673173620902
0.732262357946912
0.7006852631008296
0.7507636724540797
0.6869073043309879
0.7462699797352154
0.7028002753559506
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0013202792,0.011863677,0.010904719,-0.00611678,-0.017302336,0.022672499,0.0050927503,0.0006430154,-0.020535395,-0.034522478,0.023247873,-0.0057434714,-0.01111021,0.0068976455,-0.023467064,-0.012493849,0.028412547,0.0072332807,0.008041545,-0.021658745,-0.007370275,0.016589968,0.002005249,-0.039728247,-0.017110545,0.021590248,0.028467344,-0.0153981205,0.014685752,0.0058119684,0.00046021407,0.01338431,-0.023069782,-0.032714155,-0.007747008,0.021453254,0.0109458165,-0.014411764,0.0024299303,-8.488541e-06,0.032522365,0.004712592,-0.007767557,-0.02063129,0.009897813,0.0073771244,0.011911624,-0.021261461,-0.010103304,-0.004572173,0.020987473,0.028275553,-0.02334377,-0.00950738,-0.011897925,0.009466282,-0.0058496417,0.009569027,0.012439051,-0.0021645045,0.018137999,0.009781368,-0.013336361,0.010726627,-0.029344104,-0.013473355,0.004253662,0.009630675,-0.02335747,0.020234007,0.04937262,0.029179713,-0.0011284878,-0.015041936,0.009884113,-0.012000671,-0.011891075,-0.015768005,0.0051338486,0.009110098,0.0014238809,-0.022494407,-0.027563184,0.03945426,0.009432034,-0.03383751,0.01042524,0.026659023,-0.018453086,0.0098156165,-0.010952666,0.01745303,0.020507995,-0.0042673615,0.005236594,0.0019983994,0.013000727,0.023878045,0.0097539695,0.0023665705,-0.011336249,0.009685473,-0.048413664,-0.008726515,-0.01564471,0.0003013867,0.016891355,0.00062760356,0.011980121,-0.027426189,-0.048824646,0.044029858,0.0075346674,-0.030933235,0.011233504,-0.0048667104,-0.0017466729,-0.043399684,-0.007767557,-0.006270898,0.006685305,0.030522253,0.028905725,-0.0055105817,0.019823026,-0.005959237,-0.033947103,-0.025974054,-0.024069838,-0.009185445,0.02787827,0.014151475,-0.022275217,0.033371728,-0.02312458,0.0048769847,-0.0057468964,0.03304294,-0.040139228,-0.015247427,0.02471371,0.0013725082,0.0063359705,0.02083678,-0.0034471103,0.020686086,0.00041611915,0.030220866,-0.005233169,-0.010575933,-0.0014615542,-0.017918808,0.020932676,0.0039351513,0.017343435,0.019384645,0.008486776,-0.0019144905,-0.014918641,-0.015809102,-0.0009161471,0.0050002793,0.0025395255,0.014302169,0.015918698,0.018247595,0.016069392,-0.0013630899,-0.0061613033,0.011685585,-0.010911568,0.029535897,-0.018754473,0.028768731,0.003558418,0.013185668,0.022014929,-0.027672779,-0.004900959,-0.0006871103,-0.010514286,0.02063129,-0.0016507772,0.01224726,-0.0091237975,-0.014137777,0.001093383,-0.029124916,-0.0004176175,-0.018494183,-0.011041713,0.015480317,0.008048395,0.012767836,-0.66063964,-0.028850926,0.00083009776,-0.014439163,0.013685696,0.019233951,0.006185277,-0.019836724,-0.02450822,0.020275105,-0.01996002,0.0031662728,0.016740661,-0.03257716,-0.01630228,-0.04208454,0.019987417,-0.020055914,-0.013795291,0.015302225,-0.018754473,0.0109458165,-0.014932341,0.020781983,-0.003626915,0.013281564,-0.007753858,-0.008397729,0.03350872,0.021686142,-0.0027621407,0.028576938,-0.015904998,0.010500587,0.040084433,-0.01628858,-0.019439442,0.005486608,-0.0123226065,0.04334489,-0.048578057,-0.013802141,0.013959684,0.004099544,-0.0037536344,0.006291447,0.008986804,-0.010370443,0.018685976,0.013240466,0.0016953002,0.026028851,0.0023956818,0.007370275,0.01901476,-0.010863621,0.014439163,-0.008116892,0.016987251,0.00077230344,0.00929504,0.0037022617,-0.011863677,-0.0024950025,0.008767613,0.03493346,0.014233672,0.026905613,-0.0052948166,-0.021124467,0.0044317544,0.00882926,-0.003757059,-0.010370443,-0.0008437971,-0.0030960634,0.005490033,0.007514118,0.016809158,0.010082755,-0.0044523035,-0.022782095,0.0051578223,0.011343099,-0.0069455933,0.0066647558,-0.020028517,-0.009021052,0.00322792,-0.012439051,0.019768227,0.032522365,-0.0069216196,-0.030960634,-0.01224041,0.025672667,0.00090672873,0.015466617,0.0019230526,-0.014069279,-0.012493849,0.013041824,-0.0053804377,0.007794956,0.01878187,-0.00042874826,-0.031590804,0.028385147,0.038550097,0.0031782598,-0.0019555888,0.018151699,-0.032001786,0.018946264,-0.004305035,-0.031700402,0.0066955797,-0.0031491485,-0.005736622,-0.01358295,0.027522085,-0.0027552908,0.019096958,-0.014685752,0.009144346,0.025480876,0.004010498,-0.015987195,0.0068222987,0.017288636,0.02467261,0.024097236,0.013959684,-0.008137441,0.022138223,0.012562346,-0.0034847837,0.009103248,0.007589465,-0.0103841415,-0.010589633,0.012740438,3.034202e-05,0.010144402,-0.016274882,0.0050379527,-0.007089437,0.010589633,-0.0029967427,-0.010240298,0.008041545,-0.018220196,-0.010617032,-0.0012826059,-0.01541182,0.0028357748,0.013076073,-0.029782485,-0.0066750306,-0.034549877,0.012534947,0.04260512,-0.02450822,0.0059455377,-0.007877152,-0.003094351,-0.012939079,0.024960298,-0.0017723592,-0.019562736,0.014754249,-0.029809885,-0.003924877,0.029645491,-0.010034807,0.0068531227,-0.00046192648,-0.01926135,-0.0064250166,-0.015918698,-0.008699116,-0.019247651,0.015809102,0.008212788,0.015658408,0.011233504,0.027316594,0.008459377,-0.03265936,0.041152984,-0.0058359425,0.007294928,-0.0100690555,0.0102539975,0.01178833,-0.007610014,0.009733421,-0.003674863,0.006846273,0.003474509,0.005397562,0.009322438,0.026412435,-0.026001453,-0.0063291206,-0.00974712,0.008041545,-0.02104227,0.021823136,0.012302057,0.018398289,0.00037780363,-0.008103193,-0.015137832,0.009260791,-0.0028991345,0.0003082364,0.007109986,-0.0093772365,0.032878548,-0.010562234,-0.013959684,0.052907065,-0.003784458,0.01358295,0.024987698,-0.009110098,0.012295207,0.022083426,-0.029152313,-0.0016901629,0.0033221033,0.0063188463,0.027152201,0.013466505,0.0031440114,-0.022795795,-0.0049352073,0.012795235,-0.012507548,0.013973383,0.015685808,-0.004555049,-0.011719833,0.03805692,0.0048667104,0.032714155,0.019658633,0.0014392927,-0.010452638,-0.011870526,0.0013493905,-0.017370833,-0.005031103,0.008007296,-0.0029162588,0.012589744,-0.0032125083,0.018137999,0.021850536,0.017316036,0.022768395,0.01883667,-0.03416629,0.032275777,0.0058530667,-0.009644374,-0.026028851,-0.021508051,-0.02901532,-0.022645101,0.0045173755,0.01653517,-0.042221535,0.03718016,0.00532564,0.019521639,0.012377404,0.037810333,0.014110377,-0.021782039,-0.017987305,0.0036406144,0.014398064,0.0048769847,0.00215423,-0.010925268,0.0049386322,-0.008548423,-0.0014187436,0.0037091114,0.019576436,-0.0038152817,-0.0029145463,-0.007657962,0.014165175,0.013891187,-0.005281117,-0.0117609305,-0.012726738,-0.01292538,0.006928469,-0.019096958,-0.03082364,0.03761854,0.00724698,0.015685808,-0.01650777,-0.00884981,-0.026659023,0.006394193,-0.018864067,-0.0025429502,-0.021823136,0.016178986,0.0040378966,-0.028659135,0.016905054,0.028412547,-0.0029881806,-0.0030241415,0.0011233505,-0.0021473803,0.0065140626,0.03350872,0.027138503,0.003429986,0.0101307025,-0.040440615,0.0033426525,0.0035447185,-0.0059695113,0.0026559704,0.018261295,-0.00040327595,0.010986915,-0.002727892,-0.004246813,0.0006824011,0.014315868,0.026302839,-0.023384867,-0.008685417,-0.015014538,0.003304979,-0.011158157,0.019247651,0.025343882,0.013185668,0.0022210146,0.008404579,0.0070825876,0.0021131318,-0.01768592,0.004513951,0.014644654,0.018398289,0.019795626,0.007767557,0.021453254,-0.014932341,-0.012822635,0.01382269,0.007363425,0.0120075205,-0.0023186228,0.011651336,-0.007089437,-0.007205882,-0.013528153,0.018850368,-0.010048507,0.009418335,-0.00041890182,-0.0046064216,-0.011815729,-0.041098185,-0.008651168,0.0053598885,0.011665035,-0.009103248,-0.00038786413,0.009082699,-0.021138167,-0.025521973,-0.008521024,0.012665091,-0.011644486,0.0142062735,-0.0019264775,-0.0034231364,-0.0030857888,-0.0003090926,-0.0010462913,0.0023528712,-0.04874245,-0.03871449,-0.011521191,0.021247763,0.030220866,0.008582671,0.0015437506,-0.027083704,0.0013750768,-0.02131626,-0.009466282,-0.0032741555,-0.014384366,0.007685361,0.014809047,-0.0025549373,-0.0034847837,-0.0029556446,0.0136445975,-0.010706077,0.033673115,0.0076990603,-0.021535449,-0.00061390415,0.009158046,0.00014373663,0.021179266,0.005455784,-0.022302616,0.027549485,-0.02357666,-0.014233672,-0.00702779,-0.012582894,-0.0069832667,0.010747176,0.007514118,0.0044557285,-0.008431978,0.011404747,-0.014589856,0.00882926,-0.017754417,0.00045764542,0.00082795724,0.021480652,0.016220083,-0.007973048,0.025891857,0.016809158,-0.04142697,0.016658464,0.010014258,-0.015891299,0.008719665,-0.02105597,0.0113294,-0.024426023,0.01632968,-3.0930667e-05,0.025083592,-0.007616864,-0.005637301,-0.027919369,-0.00531879,-0.02764538,-0.01472685,-0.010610182,-0.011048563,0.011952722,-0.0035515684,-0.017494127,-0.007109986,0.008041545,-0.0226588,-0.010123854,0.014439163,-0.00725383,0.040139228,-0.0011473243,-0.0027159052,-0.014863844,-0.027727576,-0.0022278642,-0.028905725,-0.0025429502,0.0021764915,0.021110767,0.015288525,0.03148121,0.017590024,0.031618204,-0.005637301,-0.019795626,-0.006548311,0.012480149,-0.00442148,-0.009384085,0.016398177,0.000117194046,-0.029755088,0.007726459,0.004900959,0.0058290926,0.011233504,-0.026234342,-0.01748043,-0.01742563,-0.022110824,0.0006661331,0.022795795,-0.021234063,-0.006301722,-0.030494854,0.015795402,-0.0031816845,-0.0039522755,0.021151867,0.0024950025,0.012959628,-0.004897534,0.02243961,-0.00043153096,-0.0016644766,-0.010781424,-0.030960634,-0.010500587,0.0020891577,0.036577385,-0.019549036,0.015754305,0.01608309,0.0009615263,-0.012534947,-0.023973942,0.008897757,-0.017603723,0.0022449885,-0.0063085714,-0.009555329,-0.025741164,-0.0120075205,-0.013870638,0.0013048674,0.0066544814,-0.018247595,0.002900847,0.0067229783,-0.021398455,0.024275329,-0.009692322,0.026179545,0.01609679,0.025878157,0.0029350955,0.0016550582,0.008199088,-0.012021219,-0.00588389,0.010370443,0.011349949,-0.012651391,0.015781704,-0.03378271,0.008534723,-0.0007367706,-0.013445957,-0.007747008,0.009767669,0.013254165,-0.009527929,-0.007500419,-0.025878157,-0.011514341,0.0007427641,-0.008747064,-0.015041936,0.010144402,-0.0076511125,0.0014735413,0.009390935,0.015795402,0.028193356,0.006294872,0.0006284598,0.020960076,-0.0016970126,0.009534779,0.019891523,0.0015951233,0.008507324,0.02471371,0.008418279,-0.004671494,-0.0022295767,0.008651168,-0.0025789111,-0.0012338018,0.028960522,-0.011062262,0.0003647464,0.0008048395,0.010863621,0.0019744253,-0.005729772,-0.014124077,0.003013867,-0.007849754,0.008651168,0.009322438,0.0076031643,-0.030440057,-0.008212788,0.0021901908,-0.0045208004,0.0056133275,-0.0022090275,0.0051783714,-0.032303173,-0.014987139,-0.0018288693,0.014589856,0.026467232,-0.013651447,0.007527818,0.024152035,0.0031988088,-0.017836614,-0.00793195,0.021138167,-0.0072127315,-0.021850536,0.022028629,-0.0072127315,-0.027494688,0.029124916,-0.0009829316,-0.029508498,-0.023727354,0.004096119,-0.019562736,-0.0006811168,-0.040468015,-0.015151531,0.004849586,0.012651391,0.010322494,0.009322438,-0.001262913,0.015220028,-0.0005047371,0.0043564076,0.0074867196,-0.008678567,-0.013665147,0.013945985,-0.002609735,-0.03756374,-0.012343155,0.0019864123,0.0015223454,0.010980066,-0.013466505,-0.014329568,0.005887315,-0.009712871,0.033426523,0.007849754,-0.016494073,-0.01926135,-0.0063325455,0.005168097,0.02676862,-0.028933123,-0.008801862,-0.002356296,-0.005329065,-0.033234734,-0.041865353,-0.01969973,0.037015766,0.019507939,-0.009993709,0.000645584,-0.016261183,-0.020124411,-0.012185613,0.010534835,-0.00702779,-0.0076374128,0.0046269707,-0.0065859845,0.018316092,0.0025429502,-0.018329792,0.002231289,0.010480038,-0.012541796,-0.022932788,0.016644765,0.037043165,-0.02223412,-0.014535058,0.004438604,-0.013295263,0.022302616,0.0012483575,-0.0028494743,-0.015480317,0.014617255,0.019644933,0.026302839,0.02379585,0.018384589,-0.013863788,0.0036954118,0.014589856,-0.017316036,-0.026289139,-0.014288469,0.00974027,-0.0077607078,0.0040926943,-0.01177463,-0.017494127,-0.008541573,-0.001593411,0.021672444,-0.001303155,-0.00045807354,0.027138503,0.003142299,-0.021699842,-0.0018203072,0.026617926,-0.024973998,-0.01883667,0.023713654,-0.03986524,0.0051749465,-0.0023220475,-0.01948054,-0.020192908,-0.002174779,-0.004243388,-0.0062400745,-0.00521947,0.009637524,0.0075483667,-0.017288636,0.020288805,-0.0044454536,-0.014028181,-0.01630228,0.0028186506,0.026905613,0.004489977,-0.013274714,-0.0015608749,-0.018658577,-0.019987417,0.026631625,0.02563157,0.01471315,0.03263196,0.24636993,-0.017494127,-0.013185668,0.011240354,0.015233728,0.0059455377,1.5318171e-06,0.032056585,-0.021014873,-0.012993877,0.016699564,0.006305147,0.0046577943,0.0020240857,0.0013622337,-0.010007408,-0.021014873,-0.0085621225,0.0015985483,0.012959628,0.013569252,0.0029282458,0.00043923687,-0.020234007,0.0453176,0.011158157,0.0027056306,0.019275049,-0.01427477,-0.010747176,0.006637357,0.0026131596,0.008007296,0.020466898,-0.016494073,-0.008062094,-0.006048283,-0.016658464,0.02583706,0.014699452,0.020973774,-0.009637524,-0.0115074925,-0.0108841695,0.00928819,0.0032142207,-0.011356799,-0.0125760455,0.010000559,0.0071442346,-0.023206776,-0.016124189,0.017137943,0.028960522,-0.0015668684,-0.010726627,0.001799758,-0.0040378966,0.034577273,0.014137777,-0.03559103,0.010870471,-0.02923451,0.018439386,-0.0052228947,-0.00072649604,-0.0029470825,-0.010397841,0.026576826,-0.026179545,-0.014439163,0.007863453,-0.0020583342,-0.0011481806,-0.025700066,-0.0056955237,0.033453923,0.019590136,0.020028517,0.023247873,-0.015932396,0.000100604935,-0.0020840205,-0.010623882,-0.016151587,-0.009863565,0.024015041,-0.016055692,0.00817169,0.00668873,3.986738e-05,0.00053641695,-0.013103472,-0.007657962,0.0013048674,0.004442029,0.0048769847,0.025206888,-0.010171801,0.0006032015,-0.031042831,0.05616752,0.010288246,0.00305839,0.015384421,0.016124189,0.024384923,0.015137832,0.008425129,-0.0158639,-0.0028100885,-0.05057817,-2.4094346e-05,-0.0073771244,-0.007431922,0.0058153933,0.0015480317,-0.0035173197,0.033590917,-0.010678679,-0.006048283,-0.014932341,-0.002335747,0.0097539695,0.011802029,-0.021357358,-0.020302504,-0.0015146394,-0.0153981205,0.0071716337,-0.0011892788,0.01748043,0.0022295767,0.027754975,-0.00998686,-0.019850424,-0.017959908,-0.040933795,0.0034625223,0.009233393,-0.0006721266,0.017316036,0.01654887,-0.01628858,0.0019144905,-0.01155544,0.012130815,0.009664924,-0.015809102,-0.015343323,-0.005079051,-0.0038563798,-0.015809102,-0.025110992,0.020521695,-0.0124527505,-0.012651391,-0.016973551,0.010336194,-0.008082643,-0.011589688,0.004483127,0.0081853885,-0.031371616,-0.0131377205,-0.007438772,-0.17655781,-0.0064729643,0.022782095,-0.043536678,0.018206496,0.021713542,0.012548646,0.0038803539,-0.033673115,0.015233728,0.008274435,-0.013870638,-0.020987473,0.0049386322,0.0043701073,-0.0029385204,-0.030056473,0.016124189,0.0042913356,0.026700122,0.026905613,-0.019507939,0.0052228947,-0.0008125454,-0.016452974,-0.0045379247,-0.0032262076,0.011754082,0.011966422,-0.02197383,0.01859008,-0.011815729,0.010582783,0.007425072,-0.004983155,-0.010151252,0.001738967,-0.020754583,-0.005226319,0.012733588,0.025891857,0.01065813,-0.018014705,0.02926191,-0.0011610237,0.01880927,0.021124467,0.0026371337,0.009945761,-0.02337117,0.006301722,-0.01178148,-0.0005758027,-0.0018528432,0.017795514,0.020809382,0.016781759,-0.0097539695,-0.013671997,-0.029344104,-0.019603835,-0.0065791346,0.020001117,-0.0032039462,-0.003352927,-0.0043598325,-0.0030532528,0.027111104,-0.053153653,0.0069969664,-0.020357301,0.0031611356,0.005623602,-0.0030892137,-0.0052674175,0.021631345,-0.01653517,0.005216045,0.018850368,-0.012534947,-0.009493681,0.04668754,-0.004233113,0.01676806,-0.014891243,0.017165342,0.0041200933,0.036193803,-0.013808991,-0.010117004,0.010233449,-0.03830351,-0.0013562401,-0.012425352,0.026028851,0.024850704,0.010959516,-0.013987083,0.011178707,0.000653718,-0.00266282,-0.0029761936,-0.028768731,0.01748043,0.020905277,0.0032912798,0.0039762496,0.021768339,0.027905669,0.0017723592,-0.036604784,-0.010534835,-0.009623826,-0.01291168,-0.002371708,0.029563295,0.00589759,0.00015904142,-0.031371616,0.0060928063,0.06762022,-0.01768592,0.002989893,0.000984644,-0.0024213681,-0.030741444,-0.123075366,-0.025110992,0.0042707864,-0.0024624662,0.00950738,0.0035447185,-0.009144346,-0.0098156165,-0.025357582,0.017877711,-0.050386377,-0.028165957,-0.0009024477,-0.0093155885,-0.015124133,-0.0027176177,0.0056749745,-0.004325584,-0.020562792,0.01972713,-0.034001898,-0.030768842,-0.0155214155,0.0024282178,0.018206496,0.0054729083,-0.018864067,-0.0024744533,-0.004486552,-0.0013288413,0.027467288,-0.02198753,-0.019220252,-0.0030207166,-0.0139528345,-0.011288302,0.0059489626,-0.00951423,0.02423423,-0.036878772,0.014370666,-0.02087788,-0.011665035,-0.020083314,-0.01156229,0.003602941,-0.028933123,0.029919479,0.0073908237,-0.008740215,-0.020439498,0.0040207724,-0.028631736,0.008020996,0.00882241,0.0070757377,0.0036406144,0.014863844,-0.008801862,0.016795458,-0.015357022,0.017192742,0.010041657,-0.0048393114,0.032741554,-0.017864011,-0.020946376,-0.01948054,0.006301722,-0.032851152,-0.007527818,-0.0013245603,-0.009623826,0.020097014,-0.022508107,-0.010247148,0.0020206608,0.004085845,-0.0072195814,-0.016603667,-0.0062640486,-0.007527818,0.018192798,-0.020781983,0.0034385482,0.0072127315,-0.009699172,-0.017603723,-0.017165342,-0.013192518,-0.017302336,0.04707112,0.01879557,-0.029919479,0.0032416196,0.0066270824,0.00057194976,0.0029299583,0.00063530944,0.00950738,-0.032988146,-0.009541629,-0.039755646,0.018850368,-0.01611049,-0.018535282,-0.010747176,-0.01972713,0.0052023456,-0.005846217,0.0048153377,-0.011493793,-0.013028125,0.012350005,-0.030988032,0.0033786134,-0.021535449,6.929968e-05,0.01042524,-0.014987139,0.016918754,-0.00951423,-0.007767557,-0.016357077,-0.0011550303,-0.013048674,-0.010843071,-0.004513951,-0.007657962,0.024412323,-0.022740997,-0.016192686,0.0042981855,-0.023234176,0.0027689904,0.036604784,0.0131445695,-0.009151196,0.007822355,0.01768592,0.037344553,-0.023069782,7.3206145e-05,-0.04123518,-0.009260791,-0.013178819,0.017740717,0.004233113,-0.003921452,-0.008048395,-0.009623826,-0.002008674,0.019507939,0.022823192,-0.01087732,-0.028165957,-0.016589968,-0.015672108,-0.00057751517,-0.01993262,-0.023028683,-0.017124245,0.03531704,-0.0075620664,0.02223412,-0.011137608,0.01427477,0.006781201,-0.0027090556,0.016124189,-0.0025908982,-0.026152145,-0.002816938,0.0014358679,-0.0037707586,-0.001710712,-0.00012939508,0.016192686,-0.020549092,0.006298297,-0.0011276315,0.041180383,-0.002207315,-0.011747232,-0.02833035,0.011904774,0.02446712,-0.001957301,-0.014425463,0.0035960914,0.0044283294,-0.015850201,0.0019110657,0.008589521,0.010356743,0.0003292136,0.0005394137,-0.0034025873,0.0065551605,-0.010493737,0.0005458353,0.015726905,0.006363369,0.007986748,-0.009589577,-0.021494351,-0.04148177,0.017288636,-0.02450822,-0.050194584,0.013261015,0.0060893814,0.018713374,-0.018425686,0.020288805,0.008904607,-0.0061613033,0.024001341,-0.016069392,-0.03485126,-0.036659583,0.022809494,0.0040515964,-0.02312458,-0.013048674,0.008390879,0.024782207,0.028385147,0.017411932,-0.024960298,0.023193076,0.015740605,0.0015779991,0.0021679294,-0.0015865612,-0.01883667,-0.019343546,-0.017617423,0.009178595,0.015370722,-0.0064695394,0.06981212,0.013836389,0.0067264033,-0.010500587,-0.0025771987,0.02833035,0.022823192,-6.6302935e-05,-0.020658689,-0.025891857,-0.006613383,0.00815799,-0.02926191,-0.015452918,-0.009760819,0.00029325267,-0.011870526,0.0011653048,-0.023261573,-0.0043564076,0.024124635,-0.000504309,0.01087732,0.008370331,0.0036954118,0.0034882086,0.0027501537,-0.0026422709,0.020809382,-0.0158639,-0.0024333552,0.01404188,-0.028357748,-0.027152201,0.0055893534,0.0139528345,-0.0060585574,-0.016151587,-0.00498658,0.0012046905,-0.0017030061,0.015603611,-0.016685864,-0.011212955,-0.027371392,0.016411876,0.016233783,-0.022782095,-0.00288886]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
0.7506765898004643
0.7494506511910853
0.7252789330479716
0.7124931252981694
0.7393873004202789
0.7260670024398506
0.7036748526024537
0.755217379057451
0.71736109676927
0.7802427647563539
0.7504910885964399
0.7061293688808249
0.7523485586845169
0.7138573235193132
0.77328136972255
0.7529608752545464
0.6993236334407644
0.726476976743222
0.7343669157500594
0.7162843709834659
0.732846206404735
0.7263548792143251
0.6717344076594609
0.7067219280410934
0.7102366739398648
0.7107461849165523
0.753425816886759
0.7709762714505036
0.7233188046678736
0.7008607832678534
0.7250702055521165
0.7339184905092423
0.7197710530720272
0.757876538578989
0.7682518494841272
0.7536664288291967
0.7371495920192859
0.7333886926150934
0.7232030285859807
0.7124570762520988
0.7218446586054833
0.7541701195937495
0.7533037484050785
0.7419660483491719
0.7500329016858975
0.7222518184772566
0.7585811655071877
0.6916842568761924
0.7372299429314256
0.7308118485279833
0.6754081570062902
0.752535626878578
0.7252481505602656
0.692049154938136
0.7243773886995392
0.7280398405447343
0.6947357626259129
0.7270083532987712
0.7154147987062588
0.7260777888671489
0.7046927601522587
0.7051429389356216
0.7209897546123899
0.6814750732800591
0.6801720370784086
0.6939285247946071
0.7129593693556725
0.7025049891254456
0.7380146723756407
0.6966855974134286
0.7113812365609384
0.7500357181405135
0.6847926251103482
0.6925080129202329
0.7287180376561165
0.7238285605196565
0.6883312285825616
0.7314185895669516
0.7176002702784805
0.7380884014078264
0.6898991671471617
0.7601190224174993
0.765673665025032
0.7490968939722213
0.6900245376630537
0.7032834727341948
0.7474114064223537
0.7287395205314713
0.7415261741293809
0.7058160652025146
0.6900160638170413
0.706134113160529
0.695584312451905
0.7162554141140866
0.6875073666451883
0.7397316741258643
0.7140969330770813
0.7279595376794081
0.7665913764612041
0.7195192611189323
0.7203628388041246
0.7000875742225761
0.7271579613903139
0.6765041636759397
0.7528626348318462
0.7021306260721051
0.7149973673388563
0.736333836074352
0.7302392797398681
0.6929994832400882
0.6976324151959996
0.7462861968902683
0.7374513924871154
0.7409962099941945
0.7292854336658098
0.7262589853958658
0.7449367666729241
0.7607098696938555
0.7393685934716503
0.6930296579999663
0.7235737901124184
0.7494449477743054
0.7126112192238253
0.6937308861335387
0.7239298965688704
0.7032388710832235
0.7353326796949413
0.7194380716526864
[{"sentences":["Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications.","BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding.","The solid lines present the existing knowledge facts.","The red dotted lines present the facts extracted from the sentence in red.","The green dotdash lines present the facts extracted from the sentence in green."],"sections":[{"title":"Introduction","number":"1"}],"section_type":"main"},{"sentences":["The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations.","As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010).","Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings."],"sections":[{"title":"Related Work","number":"2"}],"section_type":"main"},{"sentences":["(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives.","Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments.","Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model."],"sections":[{"title":"Introduction","number":"1"}],"section_type":"main"}]
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.","formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.","formatted":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives. Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments. Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model.","formatted":"(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives. Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments. Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model."}]},"question":"How does the model get applied?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.","formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.","formatted":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives. Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments. Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model.","formatted":"(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives. Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments. Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model."}]},"formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.\n\nThe early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.\n\n(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives. Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments. Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.","formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.","formatted":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives. Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments. Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model.","formatted":"(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives. Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments. Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model."}]},"formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.\n\nThe early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.\n\n(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives. Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments. Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.","formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.","formatted":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives. Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments. Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model.","formatted":"(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives. Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments. Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model."}]},"formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.\n\nThe early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.\n\n(2) Similar to BERT, we adopt the masked language model and the next sentence prediction as the pre-training objectives. Besides, for the better fusion of textual and knowledge features, we design a new pre-training objective by randomly masking some of the named entity alignments in the input text and asking the model to select appropriate entities from KGs to complete the alignments. Unlike the existing pre-trained language representation models only utilizing local context to predict tokens, our objectives require models to aggregate both context and knowledge facts for predicting both tokens and entities, and lead to a knowledgeable language representation model."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"id":"chatcmpl-7lfvcWf9E3bNOQafT2kCZGe1bIVhz","object":"chat.completion","created":1691596944,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model gets applied in dialog systems and Conversational AI applications."},"finish_reason":"stop"}],"usage":{"prompt_tokens":972,"completion_tokens":13,"total_tokens":985}}
"The model gets applied in dialog systems and Conversational AI applications."
0.7235463882779799
["2022_Peng.pdf","The model gets applied in dialog systems and Conversational AI applications."]
[{"sentences":["We inference the five trained models and use the predicted confidence score to select the best model per target."],"sections":[{"title":"Inference regimen","number":null}],"section_type":"main"},{"sentences":["We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details).","We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d ."],"sections":[{"title":"Training regimen","number":null}],"section_type":"main"},{"sentences":["To train, we use structures from the PDB with a maximum release date of 30 April 2018.","Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering.","We then randomly crop them to 256 residues and assemble into batches of size 128.","We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores.","The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration).","The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days."],"sections":[{"title":"Training regimen","number":null}],"section_type":"main"}]
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"We inference the five trained models and use the predicted confidence score to select the best model per target.","formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .","formatted":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"To train, we use structures from the PDB with a maximum release date of 30 April 2018. Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering. We then randomly crop them to 256 residues and assemble into batches of size 128. We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores. The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration). The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days.","formatted":"To train, we use structures from the PDB with a maximum release date of 30 April 2018. Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering. We then randomly crop them to 256 residues and assemble into batches of size 128. We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores. The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration). The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days."}]},"question":"How does the model get applied?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"We inference the five trained models and use the predicted confidence score to select the best model per target.","formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .","formatted":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"To train, we use structures from the PDB with a maximum release date of 30 April 2018. Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering. We then randomly crop them to 256 residues and assemble into batches of size 128. We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores. The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration). The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days.","formatted":"To train, we use structures from the PDB with a maximum release date of 30 April 2018. Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering. We then randomly crop them to 256 residues and assemble into batches of size 128. We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores. The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration). The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days."}]},"formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target.\n\nWe train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .\n\nTo train, we use structures from the PDB with a maximum release date of 30 April 2018. Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering. We then randomly crop them to 256 residues and assemble into batches of size 128. We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores. The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration). The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"We inference the five trained models and use the predicted confidence score to select the best model per target.","formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .","formatted":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"To train, we use structures from the PDB with a maximum release date of 30 April 2018. Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering. We then randomly crop them to 256 residues and assemble into batches of size 128. We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores. The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration). The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days.","formatted":"To train, we use structures from the PDB with a maximum release date of 30 April 2018. Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering. We then randomly crop them to 256 residues and assemble into batches of size 128. We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores. The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration). The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days."}]},"formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target.\n\nWe train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .\n\nTo train, we use structures from the PDB with a maximum release date of 30 April 2018. Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering. We then randomly crop them to 256 residues and assemble into batches of size 128. We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores. The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration). The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"We inference the five trained models and use the predicted confidence score to select the best model per target.","formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .","formatted":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"To train, we use structures from the PDB with a maximum release date of 30 April 2018. Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering. We then randomly crop them to 256 residues and assemble into batches of size 128. We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores. The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration). The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days.","formatted":"To train, we use structures from the PDB with a maximum release date of 30 April 2018. Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering. We then randomly crop them to 256 residues and assemble into batches of size 128. We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores. The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration). The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days."}]},"formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target.\n\nWe train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .\n\nTo train, we use structures from the PDB with a maximum release date of 30 April 2018. Chains are sampled in inverse proportion to cluster size of a 40% sequence identity clustering. We then randomly crop them to 256 residues and assemble into batches of size 128. We train the model on Tensor Processing Unit (TPU) v3 with a batch size of 1 per TPU core, hence the model uses 128 TPU v3 cores. The model is trained until convergence (around 10 million samples) and further fine-tuned using longer crops of 384 residues, larger MSA stack and reduced learning rate (see Supplementary Methods 1.11 for the exact configuration). The initial training stage takes approximately 1 week, and the fine-tuning stage takes approximately 4 additional days."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"id":"chatcmpl-7lfvdOUFdPdzjr20prlAeEmIZF7HR","object":"chat.completion","created":1691596945,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model takes text as input and generates an answer or ranks different options."},"finish_reason":"stop"}],"usage":{"prompt_tokens":384,"completion_tokens":15,"total_tokens":399}}
"The model takes text as input and generates an answer or ranks different options."
["2023_Touvron.pdf","The model takes text as input and generates an answer or ranks different options."]
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[0.0012899983,0.011889228,0.010916161,-0.006088518,-0.017295914,0.022654632,0.0050914674,0.00065570633,-0.020571448,-0.034537006,0.023243954,-0.0057870043,-0.011114886,0.00689027,-0.023463236,-0.012485402,0.028424505,0.0071952096,0.007983256,-0.021626744,-0.0073802294,0.01659695,0.0020026667,-0.03971756,-0.017062927,0.02155822,0.028561557,-0.015445717,0.014705638,0.0057767257,0.00045740977,0.013321417,-0.023079492,-0.032755338,-0.0076817432,0.021503398,0.011005245,-0.014445241,0.0024052558,4.523774e-06,0.032536052,0.00467346,-0.007798237,-0.020639973,0.009888274,0.007352819,0.01192349,-0.021243,-0.010121262,-0.004587803,0.020927781,0.028314864,-0.023298774,-0.009531939,-0.011909786,0.009490824,-0.005876088,0.009545645,0.012464845,-0.0021911126,0.018131929,0.009764927,-0.013376238,0.010751699,-0.029383866,-0.013485879,0.004272584,0.009641581,-0.02331248,0.020242523,0.049365994,0.029164584,-0.0011478072,-0.015007152,0.009867717,-0.011998869,-0.011889228,-0.015802052,0.0051462883,0.009093375,0.0013850778,-0.022476465,-0.02758849,0.039416045,0.009490824,-0.03382434,0.010470743,0.026615424,-0.018419737,0.009840306,-0.010964129,0.01744667,0.020420691,-0.0042211898,0.005228519,0.0020249377,0.013061019,0.023901802,0.009703254,0.0023161722,-0.011347874,0.009668992,-0.04843404,-0.008737041,-0.015623884,0.00026789308,0.016884759,0.0006364334,0.011992016,-0.027369207,-0.048845194,0.044048388,0.007503576,-0.030891433,0.011245085,-0.0048550535,-0.001769679,-0.04350018,-0.007695448,-0.0062701115,0.006712103,0.0305351,0.02891789,-0.0055163275,0.019803958,-0.0059994343,-0.03396139,-0.025930166,-0.02407997,-0.009168753,0.027821478,0.014143727,-0.022298297,0.033385772,-0.023093197,0.0048927427,-0.0057287575,0.03300203,-0.0401013,-0.015226434,0.024765227,0.0013285441,0.0063180793,0.020804435,-0.003467406,0.020681089,0.00040515885,0.030260997,-0.005273061,-0.010607795,-0.0015135638,-0.018022288,0.020941487,0.003974497,0.017350735,0.019406509,0.008476642,-0.0018964517,-0.014952331,-0.015788347,-0.0008552877,0.0050126626,0.002501192,0.014308189,0.015939103,0.018227864,0.016076155,-0.0013730859,-0.006150191,0.011676798,-0.010916161,0.029575739,-0.018789776,0.02880825,0.0035256527,0.013225481,0.02198308,-0.027657015,-0.0048790374,-0.0006784055,-0.010539269,0.020639973,-0.0016686034,0.012259267,-0.009161901,-0.014116316,0.0010921301,-0.029082352,-0.00036746965,-0.018488264,-0.01101895,0.015459422,0.008031225,0.012807474,-0.6604791,-0.02883566,0.0008253077,-0.014445241,0.013677752,0.019242046,0.00616047,-0.019845074,-0.02453224,0.020338459,-0.01994101,0.003114498,0.016720297,-0.032590874,-0.016295437,-0.042102255,0.019982126,-0.019995831,-0.013801098,0.015349781,-0.018776072,0.010895603,-0.014924921,0.020845551,-0.003621589,0.013328269,-0.0077434164,-0.008394412,0.033522826,0.021695271,-0.0027770083,0.028561557,-0.015925398,0.010470743,0.040073894,-0.016226912,-0.019475035,0.0055163275,-0.0123620555,0.04330831,-0.048516273,-0.0137668345,0.014034085,0.004080712,-0.0037929034,0.006300948,0.008970028,-0.010395365,0.018652724,0.013232334,0.0017191411,0.026026102,0.002406969,0.0073733767,0.018967943,-0.010895603,0.014458945,-0.008099751,0.016980695,0.0008064631,0.009264689,0.0036729833,-0.011820702,-0.0024840606,0.00870963,0.03486593,0.014212253,0.026889527,-0.005300471,-0.021105949,0.0045124246,0.00889465,-0.003775772,-0.010367955,-0.00084201084,-0.0030459722,0.0055368855,0.0075241337,0.016775118,0.010155525,-0.004443899,-0.022805389,0.0050914674,0.011341021,-0.0068936963,0.0066230195,-0.020064356,-0.009045406,0.0032703942,-0.012457992,0.019831369,0.032536052,-0.006962222,-0.030918844,-0.012225004,0.025669767,0.0009653573,0.015514242,0.0019546987,-0.014075201,-0.01253337,0.013019904,-0.0053587183,0.007811942,0.018748662,-0.00047325637,-0.031576693,0.028314864,0.038621146,0.0031350558,-0.0019906748,0.018131929,-0.032070078,0.018981649,-0.004337684,-0.031713743,0.00667784,-0.0031470477,-0.0057527414,-0.0135955205,0.027506258,-0.002787287,0.019077584,-0.014678228,0.009120785,0.025477896,0.0040533016,-0.015966512,0.0068525807,0.017282208,0.024628175,0.02407997,0.013972412,-0.008134013,0.022161245,0.012567633,-0.003481111,0.009107079,0.0075926594,-0.010436481,-0.010580385,0.012711537,5.1902945e-05,0.010114409,-0.016295437,0.0050674835,-0.007112979,0.010580385,-0.0029534623,-0.010251461,0.0080175195,-0.018200455,-0.010648911,-0.0012651577,-0.015404602,0.0028541,0.013095282,-0.02976761,-0.006667561,-0.034591828,0.012512812,0.042568233,-0.02450483,0.0059685977,-0.007866763,-0.003114498,-0.012937672,0.024943395,-0.0017868105,-0.01957097,0.014760459,-0.02979502,-0.0039093974,0.02965797,-0.010039031,0.0068354495,-0.0004651189,-0.019283162,-0.0064105894,-0.015897987,-0.008737041,-0.019242046,0.015760936,0.008264212,0.01569241,0.011245085,0.027355503,0.0084423795,-0.032700516,0.041142896,-0.0058246935,0.0073459665,-0.010059589,0.010313134,0.011806997,-0.007613217,0.009744369,-0.0036592782,0.0068834173,0.0035050951,0.005416965,0.009333215,0.026409846,-0.025930166,-0.0062872428,-0.009764927,0.00804493,-0.021023719,0.021804912,0.012334646,0.018392326,0.00040815683,-0.008092898,-0.015144204,0.009237279,-0.0028952153,0.00025204648,0.007092421,-0.009388036,0.032919798,-0.0106146475,-0.013910739,0.052874513,-0.003786051,0.013581815,0.024970803,-0.009127637,0.012279824,0.02206531,-0.029246815,-0.001687448,0.0033235017,0.0063180793,0.027122514,0.013437911,0.0031436214,-0.02288762,-0.004968121,0.01277321,-0.01250596,0.013986117,0.015706114,-0.004515851,-0.01168365,0.03804553,0.00488589,0.032700516,0.019680612,0.001451034,-0.010477596,-0.011930343,0.0013011338,-0.01736444,-0.0050126626,0.008024372,-0.002950036,0.012636159,-0.003234418,0.01815934,0.021846028,0.017350735,0.022736862,0.018899418,-0.034125853,0.03223454,0.0058623827,-0.009579908,-0.026067218,-0.021475988,-0.028972711,-0.022668337,0.0045364085,0.016473604,-0.04226672,0.037140988,0.0053381603,0.01954356,0.012368908,0.037826248,0.014171137,-0.021832323,-0.018022288,0.0035804734,0.014445241,0.004861906,0.0021243,-0.010950424,0.004974974,-0.008599989,-0.0013765121,0.0037380827,0.019529855,-0.0038511504,-0.0029123467,-0.0077091535,0.014184842,0.013958707,-0.005276487,-0.011759029,-0.012684127,-0.012910262,0.0069896323,-0.019077584,-0.030836614,0.037661783,0.0072979983,0.015706114,-0.01651472,-0.008826124,-0.026642835,0.006431147,-0.018940533,-0.0025303154,-0.021791207,0.016226912,0.0040670065,-0.028671198,0.016898464,0.028451916,-0.003008283,-0.002998004,0.001080138,-0.002112308,0.0065065254,0.033413183,0.02713622,0.0034759715,0.010121262,-0.040402815,0.0033217885,0.0035564895,-0.00594804,0.002667367,0.01826898,-0.00043021358,0.01101895,-0.0027101957,-0.0042520263,0.00067669235,0.014376715,0.0262865,-0.02333989,-0.00868222,-0.015020857,0.0033235017,-0.011176559,0.019255752,0.025340844,0.013218628,0.0021791207,0.008428674,0.007092421,0.002102029,-0.017693363,0.0045364085,0.014623407,0.018337507,0.019790253,0.007757121,0.021530809,-0.014924921,-0.012793768,0.013801098,0.0073802294,0.012046837,-0.0022699174,0.011635683,-0.0071061263,-0.0072294725,-0.013526995,0.018899418,-0.010032178,0.009394888,-0.00040473056,-0.0045809504,-0.011779586,-0.041088074,-0.008668515,0.0053758495,0.011649387,-0.009065964,-0.00039530825,0.009072817,-0.021188179,-0.025560126,-0.008565726,0.012656717,-0.01168365,0.014157432,-0.0019375673,-0.0034245772,-0.003032267,-0.00028502452,-0.0010004768,0.00242924,-0.048762966,-0.038703375,-0.011519188,0.021229295,0.030260997,0.008593136,0.0015538227,-0.027122514,0.0013850778,-0.021366347,-0.009518235,-0.0032978044,-0.014486356,0.007716006,0.014774164,-0.0025919888,-0.0034879637,-0.0029842989,0.013636636,-0.010751699,0.033605058,0.007757121,-0.02155822,-0.0006398597,0.009237279,0.00010857057,0.021147065,0.005416965,-0.022325708,0.027574785,-0.023586582,-0.014157432,-0.0070513054,-0.012567633,-0.0070033376,0.010717437,0.0075241337,0.0044062096,-0.008394412,0.011368431,-0.014623407,0.0088055665,-0.01776189,0.00047968066,0.0008343017,0.021475988,0.016226912,-0.007901026,0.02586164,0.016884759,-0.041417,0.016706591,0.010080147,-0.015870577,0.008716483,-0.021051127,0.011279348,-0.024408892,0.016363963,-5.2679214e-05,0.025053035,-0.0076543326,-0.00561569,-0.027931118,-0.005286766,-0.027602196,-0.0147467535,-0.010580385,-0.011073771,0.01189608,-0.003563342,-0.017515196,-0.0070992736,0.008079193,-0.022668337,-0.010134967,0.014404125,-0.007270588,0.040183533,-0.001174361,-0.0027187613,-0.01484269,-0.027752953,-0.0022202362,-0.028890481,-0.0025662915,0.0021808338,0.021119654,0.015294961,0.03143964,0.017611133,0.031631514,-0.005619116,-0.019790253,-0.0065339357,0.012437434,-0.0044541773,-0.009415446,0.016418783,9.30452e-05,-0.029740201,0.007729711,0.0048893164,0.0058452515,0.01125879,-0.02620427,-0.017432965,-0.01741926,-0.02209272,0.00061159284,0.022791684,-0.021201884,-0.006300948,-0.03050769,0.01574723,-0.003184737,-0.0039539393,0.021188179,0.0025303154,0.012917114,-0.004896169,0.022421645,-0.00041265384,-0.0016703166,-0.010765404,-0.031028485,-0.010511859,0.002146571,0.036647603,-0.019557266,0.015788347,0.016130975,0.00103217,-0.012581338,-0.023970328,0.008935765,-0.017638544,0.002266491,-0.006324932,-0.009621023,-0.025724588,-0.012005721,-0.013842213,0.0012634445,0.0067086765,-0.018227864,0.002890076,0.0067189555,-0.021352641,0.024367778,-0.009675844,0.026176859,0.016021334,0.025875345,0.00291406,0.001645476,0.008188834,-0.012005721,-0.005910351,0.010326839,0.0114232525,-0.012636159,0.015760936,-0.03379693,0.008586284,-0.00075078587,-0.0133830905,-0.007818795,0.009751222,0.013225481,-0.009538792,-0.0075309863,-0.025834229,-0.011580861,0.0007456464,-0.008785008,-0.014993447,0.010114409,-0.007661185,0.0014793009,0.009367478,0.015706114,0.028150402,0.0063215056,0.0005876088,0.021023719,-0.0016103565,0.009579908,0.019913599,0.0016437628,0.008545168,0.024710406,0.008435527,-0.004625492,-0.0022801962,0.008627399,-0.0025782834,-0.0012677275,0.029000122,-0.011087475,0.00037796266,0.0008128874,0.010813372,0.001995814,-0.005721905,-0.014130021,0.0029517491,-0.007784532,0.008634252,0.009285247,0.007544691,-0.030398048,-0.008195686,0.0022596384,-0.0045364085,0.0055403113,-0.002252786,0.0052113878,-0.03228936,-0.014966036,-0.0018347785,0.014527471,0.026437256,-0.013643488,0.0075104283,0.0241622,0.003234418,-0.01787153,-0.007955846,0.021119654,-0.0071883574,-0.021859733,0.0220379,-0.0072226203,-0.027519964,0.029109763,-0.00096964015,-0.029520918,-0.023778455,0.004118401,-0.019557266,-0.00070110464,-0.040485047,-0.015199024,0.004803659,0.012677275,0.010306281,0.00934692,-0.0012583052,0.015253845,-0.0004963838,0.004296568,0.007455608,-0.008785008,-0.013725719,0.013917591,-0.0026056939,-0.037606962,-0.0123826135,0.0019769697,0.0015666713,0.010964129,-0.013499584,-0.014335599,0.0058246935,-0.009710107,0.033468004,0.007873615,-0.01648731,-0.019283162,-0.0062975218,0.0051634195,0.026779886,-0.0289453,-0.008846682,-0.0023692797,-0.005334734,-0.033221312,-0.041882973,-0.019762842,0.037058756,0.01951615,-0.010004768,0.00063343544,-0.016268026,-0.020132883,-0.012177036,0.0105940895,-0.0070718634,-0.007661185,0.0046803127,-0.006595609,0.018282685,0.0025628651,-0.018323801,0.002266491,0.010511859,-0.012588191,-0.02294244,0.016624361,0.036976527,-0.022257183,-0.014486356,0.0044404725,-0.013307712,0.022270888,0.0012377474,-0.0028643787,-0.015473127,0.014568587,0.01962579,0.026272794,0.02379216,0.018378621,-0.013849066,0.0036558518,0.014595997,-0.017268503,-0.026341321,-0.014253368,0.009737518,-0.0077776792,0.004094417,-0.011806997,-0.017487787,-0.008538316,-0.0016266314,0.021681566,-0.0012899983,-0.00042550243,0.027177336,0.0031162112,-0.02166786,-0.0018090813,0.026642835,-0.024970803,-0.018844597,0.023709929,-0.03979979,0.005159993,-0.0023435827,-0.01943392,-0.020228818,-0.002172268,-0.004231469,-0.0062495535,-0.0052011088,0.009586761,0.007572102,-0.017254798,0.02031105,-0.0044199144,-0.014075201,-0.016336553,0.0028146976,0.026944347,0.0044781617,-0.013294007,-0.0015940816,-0.01872125,-0.019995831,0.026683949,0.025628652,0.0147467535,0.032700516,0.24625434,-0.017487787,-0.013177513,0.011245085,0.01521273,0.005996008,4.272825e-06,0.032015257,-0.020982603,-0.013019904,0.016706591,0.0063283583,0.004639197,0.002042069,0.0014167711,-0.009956799,-0.020996308,-0.008599989,0.0015889421,0.013061019,0.0135544045,0.0029191994,0.00046426235,-0.020269934,0.045336675,0.011162854,0.0026947774,0.019310573,-0.014267073,-0.010710584,0.006605888,0.0026382436,0.008031225,0.020461807,-0.01648731,-0.008051783,-0.006030271,-0.016692886,0.02580682,0.014719344,0.021010013,-0.009648434,-0.011546599,-0.010875045,0.009285247,0.0032035816,-0.011375284,-0.01256078,0.010004768,0.0071198316,-0.023189133,-0.01614468,0.017145157,0.028972711,-0.0015478267,-0.010744846,0.0017988024,-0.0039950544,0.03461924,0.014143727,-0.035606008,0.010881898,-0.029191993,0.018460853,-0.0052525033,-0.0007336544,-0.0029534623,-0.0103816595,0.026588013,-0.026190564,-0.014445241,0.007921583,-0.002054061,-0.001104122,-0.025683472,-0.0057047736,0.033495415,0.01962579,0.020064356,0.023271365,-0.015952809,0.00015621743,-0.002088324,-0.010628353,-0.016158385,-0.009826601,0.024011442,-0.016035039,0.008168276,0.0067360867,2.4117871e-05,0.0005396407,-0.013074724,-0.0076748906,0.0013088429,0.0044404725,0.0048653325,0.025148971,-0.0101897875,0.00060217053,-0.031083306,0.05619116,0.010326839,0.0030836614,0.015390896,0.016158385,0.024367778,0.015116793,0.008435527,-0.015911693,-0.002795853,-0.050654277,-4.2721556e-05,-0.0073733767,-0.007421345,0.005886367,0.0015649581,-0.003563342,0.033659875,-0.010717437,-0.0060234186,-0.014911216,-0.0022939015,0.009730665,0.011779586,-0.021393757,-0.02028364,-0.0014793009,-0.015404602,0.0071677994,-0.0011966319,0.017460376,0.0022356545,0.027739247,-0.00992939,-0.019872485,-0.017994877,-0.041005842,0.0034896769,0.009182458,-0.00065527804,0.017254798,0.016610656,-0.016268026,0.0019152963,-0.011580861,0.012142773,0.00971696,-0.015733525,-0.015377191,-0.0050846147,-0.0038648555,-0.015788347,-0.025135266,0.020557743,-0.012437434,-0.012636159,-0.017008105,0.010347397,-0.008106603,-0.011580861,0.0045535397,0.008202539,-0.03133,-0.013122692,-0.007448755,-0.17674176,-0.006547641,0.022805389,-0.043637235,0.018200455,0.021763796,0.012588191,0.0038682818,-0.033632465,0.01521273,0.00833959,-0.013903886,-0.021023719,0.0049030217,0.0043685203,-0.0029346177,-0.030123945,0.01608986,0.0042999946,0.02671136,0.026944347,-0.01946133,0.005204535,-0.0008064631,-0.016432488,-0.004543261,-0.00318645,0.011738471,0.01192349,-0.021955669,0.018556789,-0.011813849,0.010580385,0.0074007874,-0.004968121,-0.01014182,0.0017611133,-0.020777024,-0.0052593555,0.012697832,0.025902756,0.010696879,-0.018049698,0.029274225,-0.0011649387,0.018762367,0.02116077,0.0025680047,0.00998421,-0.023394711,0.006300948,-0.01184126,-0.0005494913,-0.0018776071,0.01784412,0.020859256,0.016775118,-0.009778633,-0.013684603,-0.029356455,-0.01962579,-0.006564772,0.020036947,-0.0032481232,-0.0033886011,-0.004426767,-0.0030408327,0.02716363,-0.053176027,0.0069999113,-0.02039328,0.0031487609,0.005591706,-0.0030973665,-0.005266208,0.021654155,-0.01648731,0.005228519,0.018885713,-0.012526518,-0.009518235,0.04670719,-0.0042280424,0.016788824,-0.014815279,0.017227389,0.004084138,0.036209036,-0.013828508,-0.010066441,0.010244608,-0.038319632,-0.0013593807,-0.012444287,0.025984986,0.024888573,0.010957276,-0.014013528,0.011135444,0.0006505669,-0.0026982038,-0.0030065698,-0.02875343,0.017405555,0.020872962,0.003326928,0.003950513,0.021804912,0.027931118,0.001793663,-0.03656537,-0.010552974,-0.009586761,-0.012862294,-0.0023538615,0.029575739,0.005900072,0.00017645395,-0.03143964,0.006102223,0.06759386,-0.017720774,0.0030254144,0.0010030465,-0.0024155348,-0.030726973,-0.12312717,-0.025176382,0.0042794365,-0.002490913,0.009511382,0.0035496368,-0.009168753,-0.009833453,-0.025409369,0.017898941,-0.050434995,-0.028177813,-0.0009191024,-0.009381183,-0.015130498,-0.0026844984,0.005625969,-0.004306847,-0.020571448,0.019721728,-0.0339888,-0.030754382,-0.015610179,0.0023932639,0.01824157,0.005488917,-0.018872008,-0.002501192,-0.0045089982,-0.0012977074,0.027396617,-0.022024194,-0.019159816,-0.0030511115,-0.014006675,-0.011354727,0.0059857294,-0.009490824,0.02429925,-0.036894295,0.014376715,-0.020845551,-0.01165624,-0.020091766,-0.0115945665,0.003573621,-0.028972711,0.029904662,0.0074144923,-0.008757598,-0.020489216,0.004070433,-0.028643787,0.0080380775,0.0088055665,0.0070992736,0.0036044575,0.014856395,-0.008757598,0.016802529,-0.0153634865,0.017158862,0.010025325,-0.004755691,0.032727927,-0.017857825,-0.020955192,-0.019488739,0.006324932,-0.032810155,-0.007544691,-0.0013156955,-0.009586761,0.020064356,-0.022503875,-0.0102309035,0.00203179,0.0041252538,-0.0071952096,-0.016624361,-0.0063043744,-0.007572102,0.018255275,-0.02073591,0.0034399955,0.007256883,-0.009744369,-0.017570017,-0.017145157,-0.013218628,-0.017254798,0.047036115,0.018776072,-0.029904662,0.0032515496,0.006616167,0.0005811845,0.0029997171,0.000625298,0.00955935,-0.03300203,-0.009566203,-0.039827198,0.018844597,-0.01606245,-0.018529378,-0.010683173,-0.019708022,0.0052353716,-0.0058452515,0.0048550535,-0.011430104,-0.013033609,0.012334646,-0.031028485,0.003350912,-0.021571925,4.6950885e-05,0.010505007,-0.014979742,0.016884759,-0.009525088,-0.0077228583,-0.016350258,-0.0011101181,-0.013067871,-0.010902456,-0.0044576037,-0.0076748906,0.024395188,-0.022764273,-0.016185796,0.0042451737,-0.023243954,0.0027941398,0.03659278,0.013108987,-0.009141343,0.007887321,0.017720774,0.03730545,-0.023065787,8.860173e-05,-0.041225124,-0.009257836,-0.013191218,0.017775595,0.004200632,-0.0039368076,-0.008065487,-0.009607318,-0.0020249377,0.019529855,0.022805389,-0.010936718,-0.028150402,-0.016555835,-0.015623884,-0.0005529176,-0.019954715,-0.023052081,-0.017186273,0.035304494,-0.007572102,0.022216067,-0.011149148,0.014308189,0.0067703496,-0.0027290403,0.01611727,-0.0025508732,-0.026163153,-0.0028626656,0.0014321894,-0.0037449354,-0.0017559738,-0.00013951426,0.01617209,-0.020516627,0.0063043744,-0.0011460942,0.041142896,-0.0021739812,-0.011779586,-0.028369684,0.011950901,0.024463713,-0.0018844598,-0.014390419,0.0036181626,0.0043959306,-0.015856871,0.0019290015,0.008606842,0.010374807,0.00037089593,0.00052079617,-0.0034160116,0.0065236567,-0.010498154,0.0006064534,0.01574723,0.0063831788,0.007948994,-0.009566203,-0.021530809,-0.041526638,0.017295914,-0.024545943,-0.05024312,0.013259743,0.0061056493,0.01872125,-0.018433442,0.02031105,0.008887798,-0.006167323,0.023984032,-0.016021334,-0.034920752,-0.036675014,0.022791684,0.0040533016,-0.023148017,-0.013033609,0.008414969,0.024778932,0.028369684,0.017405555,-0.024943395,0.023243954,0.01574723,0.0015538227,0.002172268,-0.001575237,-0.018817186,-0.019351687,-0.017611133,0.009161901,0.0153634865,-0.0064893938,0.069841504,0.013807951,0.0066915452,-0.010498154,-0.0025680047,0.028369684,0.022873914,-4.574633e-05,-0.020667383,-0.02586164,-0.006564772,0.008216244,-0.029329045,-0.015459422,-0.009744369,0.00030515398,-0.011875522,0.0012026279,-0.023285069,-0.0043136994,0.02418961,-0.0005062344,0.010840783,0.008373854,0.0037072462,0.0035016688,0.0027153352,-0.00264167,0.02081814,-0.015870577,-0.002418961,0.01404779,-0.028369684,-0.027177336,0.0055540167,0.013951855,-0.0061090756,-0.016226912,-0.0050332206,0.0011649387,-0.0017782447,0.015623884,-0.016665477,-0.011197117,-0.027437733,0.016391372,0.016226912,-0.022777978,-0.0029551755]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":7,"total_tokens":7}}
0.6818780164176538
0.7312801826652431
{"id":"chatcmpl-7lfvcrZ0dxPjDK8sB2IwIgMNfwyuc","object":"chat.completion","created":1691596944,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model gets applied by consuming a segment of the same length as in training during evaluation. It makes one prediction at the last position of the segment. The segment is then shifted to the right by one position, and the new segment is processed from scratch. This ensures that each prediction utilizes the longest possible context exposed during training and relieves context fragmentation issue encountered in training."},"finish_reason":"stop"}],"usage":{"prompt_tokens":338,"completion_tokens":74,"total_tokens":412}}
0.6983411227988753
"The model gets applied by consuming a segment of the same length as in training during evaluation. It makes one prediction at the last position of the segment. The segment is then shifted to the right by one position, and the new segment is processed from scratch. This ensures that each prediction utilizes the longest possible context exposed during training and relieves context fragmentation issue encountered in training."
["2019_Dai.pdf","The model gets applied by consuming a segment of the same length as in training during evaluation. It makes one prediction at the last position of the segment. The segment is then shifted to the right by one position, and the new segment is processed from scratch. This ensures that each prediction utilizes the longest possible context exposed during training and relieves context fragmentation issue encountered in training."]
[{"sentences":["Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket."],"sections":[{"title":"I Example Model Outputs","number":null}],"section_type":"main"},{"sentences":["Model don't lie to your boss."],"sections":[{"title":"Gold","number":null}],"section_type":"main"},{"sentences":["In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary.","To do this with the same template, for each example we randomly selected 4 out of the 5 summaries.","This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."],"sections":[{"title":"F Human Evaluation Details","number":null}],"section_type":"main"}]
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket.","formatted":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Model don't lie to your boss.","formatted":"Model don't lie to your boss."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task.","formatted":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."}]},"question":"How does the model get applied?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket.","formatted":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Model don't lie to your boss.","formatted":"Model don't lie to your boss."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task.","formatted":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."}]},"formatted":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket.\n\nModel don't lie to your boss.\n\nIn experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket.","formatted":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Model don't lie to your boss.","formatted":"Model don't lie to your boss."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task.","formatted":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."}]},"formatted":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket.\n\nModel don't lie to your boss.\n\nIn experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket.","formatted":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Model don't lie to your boss.","formatted":"Model don't lie to your boss."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task.","formatted":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."}]},"formatted":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket.\n\nModel don't lie to your boss.\n\nIn experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model get applied?","formatted":"How does the model get applied?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"id":"chatcmpl-7lfvdUFWhv1VKPowW86VAQ41WcOsm","object":"chat.completion","created":1691596945,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model gets applied through pre-training and fine-tuning. In the pre-training phase, the model uses masked language modeling and next sentence prediction as objectives. Additionally, a new pre-training objective is designed where named entity alignments in the input text are masked and the model is asked to select appropriate entities from knowledge graphs to complete the alignments. In the fine-tuning phase, the model is further trained on specific NLP tasks by using the pre-trained language representation to improve performance on those tasks."},"finish_reason":"stop"}],"usage":{"prompt_tokens":517,"completion_tokens":98,"total_tokens":615}}
"The model gets applied through pre-training and fine-tuning. In the pre-training phase, the model uses masked language modeling and next sentence prediction as objectives. Additionally, a new pre-training objective is designed where named entity alignments in the input text are masked and the model is asked to select appropriate entities from knowledge graphs to complete the alignments. In the fine-tuning phase, the model is further trained on specific NLP tasks by using the pre-trained language representation to improve performance on those tasks."
["2019_Zhang.pdf","The model gets applied through pre-training and fine-tuning. In the pre-training phase, the model uses masked language modeling and next sentence prediction as objectives. Additionally, a new pre-training objective is designed where named entity alignments in the input text are masked and the model is asked to select appropriate entities from knowledge graphs to complete the alignments. In the fine-tuning phase, the model is further trained on specific NLP tasks by using the pre-trained language representation to improve performance on those tasks."]
{"id":"chatcmpl-7lfvfvL3oYhuTNPyuvSs6TcImOCIE","object":"chat.completion","created":1691596947,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model gets applied by inferring the five trained models and using the predicted confidence score to select the best model per target."},"finish_reason":"stop"}],"usage":{"prompt_tokens":302,"completion_tokens":25,"total_tokens":327}}
"The model gets applied by inferring the five trained models and using the predicted confidence score to select the best model per target."
["2021_Jumper.pdf","The model gets applied by inferring the five trained models and using the predicted confidence score to select the best model per target."]
{"id":"chatcmpl-7lfvgR67ofdK6SMSETkrsT1ryTcNZ","object":"chat.completion","created":1691596948,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model gets applied by automatically selecting model outputs and generating LATEX tables using a program. The program follows a specific process, which includes selecting the first 300 examples of triplets from the test split dataset, ranking the examples based on ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics, dividing the examples into buckets based on document lengths, and randomly picking one example from each bucket."},"finish_reason":"stop"}],"usage":{"prompt_tokens":241,"completion_tokens":86,"total_tokens":327}}
"The model gets applied by automatically selecting model outputs and generating LATEX tables using a program. The program follows a specific process, which includes selecting the first 300 examples of triplets from the test split dataset, ranking the examples based on ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics, dividing the examples into buckets based on document lengths, and randomly picking one example from each bucket."
["2020_Zhang.pdf","The model gets applied by automatically selecting model outputs and generating LATEX tables using a program. The program follows a specific process, which includes selecting the first 300 examples of triplets from the test split dataset, ranking the examples based on ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics, dividing the examples into buckets based on document lengths, and randomly picking one example from each bucket."]
[["2023_Touvron.pdf","The model takes text as input and generates an answer or ranks different options."],["2019_Dai.pdf","The model gets applied by consuming a segment of the same length as in training during evaluation. It makes one prediction at the last position of the segment. The segment is then shifted to the right by one position, and the new segment is processed from scratch. This ensures that each prediction utilizes the longest possible context exposed during training and relieves context fragmentation issue encountered in training."],["2022_Peng.pdf","The model gets applied in dialog systems and Conversational AI applications."],["2019_Zhang.pdf","The model gets applied through pre-training and fine-tuning. In the pre-training phase, the model uses masked language modeling and next sentence prediction as objectives. Additionally, a new pre-training objective is designed where named entity alignments in the input text are masked and the model is asked to select appropriate entities from knowledge graphs to complete the alignments. In the fine-tuning phase, the model is further trained on specific NLP tasks by using the pre-trained language representation to improve performance on those tasks."],["2021_Jumper.pdf","The model gets applied by inferring the five trained models and using the predicted confidence score to select the best model per target."],["2020_Zhang.pdf","The model gets applied by automatically selecting model outputs and generating LATEX tables using a program. The program follows a specific process, which includes selecting the first 300 examples of triplets from the test split dataset, ranking the examples based on ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics, dividing the examples into buckets based on document lengths, and randomly picking one example from each bucket."]]
