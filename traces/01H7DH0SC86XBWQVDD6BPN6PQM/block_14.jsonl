{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.","formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"In conclusion, we find that the pre-trained language models can provide more information for training set. It demonstrates extra knowledge helps the model make full use of small training data, which is important for most NLP tasks as large-scale annotated data is unavailable.","formatted":"In conclusion, we find that the pre-trained language models can provide more information for training set. It demonstrates extra knowledge helps the model make full use of small training data, which is important for most NLP tasks as large-scale annotated data is unavailable."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"answering (Rajpurkar et al., 2016;Zellers et al., 2018), natural language inference (Bowman et al., 2015), and text classification .","formatted":"answering (Rajpurkar et al., 2016;Zellers et al., 2018), natural language inference (Bowman et al., 2015), and text classification ."}]},"formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.\n\nIn conclusion, we find that the pre-trained language models can provide more information for training set. It demonstrates extra knowledge helps the model make full use of small training data, which is important for most NLP tasks as large-scale annotated data is unavailable.\n\nanswering (Rajpurkar et al., 2016;Zellers et al., 2018), natural language inference (Bowman et al., 2015), and text classification ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"We inference the five trained models and use the predicted confidence score to select the best model per target.","formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"An initial model trained with the above objectives was used to make structure predictions for a Uniclust dataset of 355,993 sequences with the full MSAs. These predictions were then used to train a final model with identical hyperparameters, except for sampling examples 75% of the time from the Uniclust prediction set, with sub-sampled MSAs, and 25% of the time from the clustered PDB set.","formatted":"An initial model trained with the above objectives was used to make structure predictions for a Uniclust dataset of 355,993 sequences with the full MSAs. These predictions were then used to train a final model with identical hyperparameters, except for sampling examples 75% of the time from the Uniclust prediction set, with sub-sampled MSAs, and 25% of the time from the clustered PDB set."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Not applicable, no experimental work is described in this study. The results are the output of a computational method which will be made available.","formatted":"Not applicable, no experimental work is described in this study. The results are the output of a computational method which will be made available."}]},"formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target.\n\nAn initial model trained with the above objectives was used to make structure predictions for a Uniclust dataset of 355,993 sequences with the full MSAs. These predictions were then used to train a final model with identical hyperparameters, except for sampling examples 75% of the time from the Uniclust prediction set, with sub-sampled MSAs, and 25% of the time from the clustered PDB set.\n\nNot applicable, no experimental work is described in this study. The results are the output of a computational method which will be made available."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"This figure shows an example model summary from the CNN/DailyMail dataset exhibiting high fluency, coherence, although highly abstractive, and only ROUGE2-F of 16. The model understood that the football team \"Chelsea\" could be paraphrased as \"Jose Mourinho's side\" and \"The Blues\" and highlighted the same four matches to be played.","formatted":"This figure shows an example model summary from the CNN/DailyMail dataset exhibiting high fluency, coherence, although highly abstractive, and only ROUGE2-F of 16. The model understood that the football team \"Chelsea\" could be paraphrased as \"Jose Mourinho's side\" and \"The Blues\" and highlighted the same four matches to be played."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Model don't lie to your boss.","formatted":"Model don't lie to your boss."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket.","formatted":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket."}]},"formatted":"This figure shows an example model summary from the CNN/DailyMail dataset exhibiting high fluency, coherence, although highly abstractive, and only ROUGE2-F of 16. The model understood that the football team \"Chelsea\" could be paraphrased as \"Jose Mourinho's side\" and \"The Blues\" and highlighted the same four matches to be played.\n\nModel don't lie to your boss.\n\nModel outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
{"doc":"Send a completion request to the OpenAI API with the given prompt and parameters.","source":"    async def _complete(self, prompt, **kwargs) -> dict:\n        \"\"\"Send a completion request to the OpenAI API with the given prompt and parameters.\"\"\"\n        kwargs.update(\n            {\n                \"model\": self.model,\n                \"temperature\": self.temperature,\n                \"top_p\": self.top_p,\n                \"n\": 1,\n            }\n        )\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        response = await openai_chatcomplete(messages, **kwargs)\n        if \"choices\" not in response:\n            raise ValueError(f\"No choices in response: {response}\")\n        return response\n"}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"The model takes this text as input and generates the answer or ranks different options.","formatted":"The model takes this text as input and generates the answer or ranks different options."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh.","formatted":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Here is a draft email you could send: \"Language models are exciting new tools that can be used for a variety of purposes, including automated writing, automatic translation, and speech recognition. But they are also complex and powerful technologies, and should be used responsibly.","formatted":"Here is a draft email you could send: \"Language models are exciting new tools that can be used for a variety of purposes, including automated writing, automatic translation, and speech recognition. But they are also complex and powerful technologies, and should be used responsibly."}]},"formatted":"The model takes this text as input and generates the answer or ranks different options.\n\nArchitecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh.\n\nHere is a draft email you could send: \"Language models are exciting new tools that can be used for a variety of purposes, including automated writing, automatic translation, and speech recognition. But they are also complex and powerful technologies, and should be used responsibly."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) .","formatted":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency.","formatted":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Language modeling is among the important problems that require modeling long-term dependency, with successful applications such as unsupervised pretraining (Dai and Le, 2015; Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018). However, it has been a challenge to equip neural networks with the capability to model long-term dependency in sequential data. Recurrent neural networks (RNNs), in particular Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), have been a standard solution to language modeling and obtained strong results on multiple benchmarks. Despite the wide adaption, RNNs are difficult to optimize due to gradient vanishing and explosion (Hochreiter et al., 2001), and the introduction of gating in LSTMs and the gradient clipping technique (Graves, 2013) might not be sufficient to fully address this issue. Empirically, previous work has found that LSTM language models use 200 context words on average (Khandelwal et al., 2018) , indicating room for further improvement.","formatted":"Language modeling is among the important problems that require modeling long-term dependency, with successful applications such as unsupervised pretraining (Dai and Le, 2015; Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018). However, it has been a challenge to equip neural networks with the capability to model long-term dependency in sequential data. Recurrent neural networks (RNNs), in particular Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), have been a standard solution to language modeling and obtained strong results on multiple benchmarks. Despite the wide adaption, RNNs are difficult to optimize due to gradient vanishing and explosion (Hochreiter et al., 2001), and the introduction of gating in LSTMs and the gradient clipping technique (Graves, 2013) might not be sufficient to fully address this issue. Empirically, previous work has found that LSTM language models use 200 context words on average (Khandelwal et al., 2018) , indicating room for further improvement."}]},"formatted":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) .\n\nMore broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency.\n\nLanguage modeling is among the important problems that require modeling long-term dependency, with successful applications such as unsupervised pretraining (Dai and Le, 2015; Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018). However, it has been a challenge to equip neural networks with the capability to model long-term dependency in sequential data. Recurrent neural networks (RNNs), in particular Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), have been a standard solution to language modeling and obtained strong results on multiple benchmarks. Despite the wide adaption, RNNs are difficult to optimize due to gradient vanishing and explosion (Hochreiter et al., 2001), and the introduction of gating in LSTMs and the gradient clipping technique (Graves, 2013) might not be sufficient to fully address this issue. Empirically, previous work has found that LSTM language models use 200 context words on average (Khandelwal et al., 2018) , indicating room for further improvement."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models.","formatted":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"GODEL can be used as an initial model to finetune for any open-domain goal-directed dialog tasks with a handful of annotated examples. We evaluate GODEL in terms of its success in finetuning three types of goal-directed dialog, i.e., knowledge-grounded response generation, taskoriented dialog, and conversational QA:","formatted":"GODEL can be used as an initial model to finetune for any open-domain goal-directed dialog tasks with a handful of annotated examples. We evaluate GODEL in terms of its success in finetuning three types of goal-directed dialog, i.e., knowledge-grounded response generation, taskoriented dialog, and conversational QA:"},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.","formatted":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."}]},"formatted":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models.\n\nGODEL can be used as an initial model to finetune for any open-domain goal-directed dialog tasks with a handful of annotated examples. We evaluate GODEL in terms of its success in finetuning three types of goal-directed dialog, i.e., knowledge-grounded response generation, taskoriented dialog, and conversational QA:\n\nLarge pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.","formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"In conclusion, we find that the pre-trained language models can provide more information for training set. It demonstrates extra knowledge helps the model make full use of small training data, which is important for most NLP tasks as large-scale annotated data is unavailable.","formatted":"In conclusion, we find that the pre-trained language models can provide more information for training set. It demonstrates extra knowledge helps the model make full use of small training data, which is important for most NLP tasks as large-scale annotated data is unavailable."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"answering (Rajpurkar et al., 2016;Zellers et al., 2018), natural language inference (Bowman et al., 2015), and text classification .","formatted":"answering (Rajpurkar et al., 2016;Zellers et al., 2018), natural language inference (Bowman et al., 2015), and text classification ."}]},"formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.\n\nIn conclusion, we find that the pre-trained language models can provide more information for training set. It demonstrates extra knowledge helps the model make full use of small training data, which is important for most NLP tasks as large-scale annotated data is unavailable.\n\nanswering (Rajpurkar et al., 2016;Zellers et al., 2018), natural language inference (Bowman et al., 2015), and text classification ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"We inference the five trained models and use the predicted confidence score to select the best model per target.","formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"An initial model trained with the above objectives was used to make structure predictions for a Uniclust dataset of 355,993 sequences with the full MSAs. These predictions were then used to train a final model with identical hyperparameters, except for sampling examples 75% of the time from the Uniclust prediction set, with sub-sampled MSAs, and 25% of the time from the clustered PDB set.","formatted":"An initial model trained with the above objectives was used to make structure predictions for a Uniclust dataset of 355,993 sequences with the full MSAs. These predictions were then used to train a final model with identical hyperparameters, except for sampling examples 75% of the time from the Uniclust prediction set, with sub-sampled MSAs, and 25% of the time from the clustered PDB set."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Not applicable, no experimental work is described in this study. The results are the output of a computational method which will be made available.","formatted":"Not applicable, no experimental work is described in this study. The results are the output of a computational method which will be made available."}]},"formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target.\n\nAn initial model trained with the above objectives was used to make structure predictions for a Uniclust dataset of 355,993 sequences with the full MSAs. These predictions were then used to train a final model with identical hyperparameters, except for sampling examples 75% of the time from the Uniclust prediction set, with sub-sampled MSAs, and 25% of the time from the clustered PDB set.\n\nNot applicable, no experimental work is described in this study. The results are the output of a computational method which will be made available."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"This figure shows an example model summary from the CNN/DailyMail dataset exhibiting high fluency, coherence, although highly abstractive, and only ROUGE2-F of 16. The model understood that the football team \"Chelsea\" could be paraphrased as \"Jose Mourinho's side\" and \"The Blues\" and highlighted the same four matches to be played.","formatted":"This figure shows an example model summary from the CNN/DailyMail dataset exhibiting high fluency, coherence, although highly abstractive, and only ROUGE2-F of 16. The model understood that the football team \"Chelsea\" could be paraphrased as \"Jose Mourinho's side\" and \"The Blues\" and highlighted the same four matches to be played."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Model don't lie to your boss.","formatted":"Model don't lie to your boss."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket.","formatted":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket."}]},"formatted":"This figure shows an example model summary from the CNN/DailyMail dataset exhibiting high fluency, coherence, although highly abstractive, and only ROUGE2-F of 16. The model understood that the football team \"Chelsea\" could be paraphrased as \"Jose Mourinho's side\" and \"The Blues\" and highlighted the same four matches to be played.\n\nModel don't lie to your boss.\n\nModel outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"doc":"Send a completion request to the OpenAI API and return the JSON response.","source":"@trace\nasync def openai_chatcomplete(\n    messages: list[dict[str, str]],\n    stop: Optional[str] = \"\\n\",\n    top_p: float = 1,\n    temperature: float = 0,\n    model: str = \"gpt-3.5-turbo\",\n    max_tokens: int = 256,\n    logit_bias: Optional[Mapping[str, Union[int, float]]] = None,\n    n: int = 1,\n    cache_id: int = 0,  # for repeated non-deterministic sampling using caching\n) -> dict:\n    \"\"\"Send a completion request to the OpenAI API and return the JSON response.\"\"\"\n    params = {\n        \"messages\": messages,\n        \"stop\": stop,\n        \"top_p\": top_p,\n        \"temperature\": temperature,\n        \"model\": model,\n        \"max_tokens\": max_tokens,\n        \"n\": n,\n    }\n    if logit_bias:\n        params[\"logit_bias\"] = logit_bias  # type: ignore[assignment]\n    response = await _post(\"chat/completions\", json=params, cache_id=cache_id)\n    if isinstance(response, TooLongRequestError):\n        raise response\n    add_fields(total_tokens=extract_total_tokens(response))\n    return response\n"}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"The model takes this text as input and generates the answer or ranks different options.","formatted":"The model takes this text as input and generates the answer or ranks different options."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh.","formatted":"Architecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Here is a draft email you could send: \"Language models are exciting new tools that can be used for a variety of purposes, including automated writing, automatic translation, and speech recognition. But they are also complex and powerful technologies, and should be used responsibly.","formatted":"Here is a draft email you could send: \"Language models are exciting new tools that can be used for a variety of purposes, including automated writing, automatic translation, and speech recognition. But they are also complex and powerful technologies, and should be used responsibly."}]},"formatted":"The model takes this text as input and generates the answer or ranks different options.\n\nArchitecture. Traditionally, language models were based on n-gram count statistics (Bahl et al., 1983), and various smoothing techniques were proposed to improve the estimation of rare events (Katz, 1987; Kneser and Ney, 1995) . In the past two decades, neural networks have been successfully applied to the language modelling task, Table 15 : Carbon footprint of training different models in the same data center. We follow Wu et al. (2022) to compute carbon emission of training OPT, BLOOM and our models in the same data center. For the power consumption of a A100-80GB, we take the thermal design power for NVLink systems, that is 400W. We take a PUE of 1.1 and a carbon intensity factor set at the national US average of 0.385 kg CO 2 e per KWh.\n\nHere is a draft email you could send: \"Language models are exciting new tools that can be used for a variety of purposes, including automated writing, automatic translation, and speech recognition. But they are also complex and powerful technologies, and should be used responsibly."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) .","formatted":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency.","formatted":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Language modeling is among the important problems that require modeling long-term dependency, with successful applications such as unsupervised pretraining (Dai and Le, 2015; Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018). However, it has been a challenge to equip neural networks with the capability to model long-term dependency in sequential data. Recurrent neural networks (RNNs), in particular Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), have been a standard solution to language modeling and obtained strong results on multiple benchmarks. Despite the wide adaption, RNNs are difficult to optimize due to gradient vanishing and explosion (Hochreiter et al., 2001), and the introduction of gating in LSTMs and the gradient clipping technique (Graves, 2013) might not be sufficient to fully address this issue. Empirically, previous work has found that LSTM language models use 200 context words on average (Khandelwal et al., 2018) , indicating room for further improvement.","formatted":"Language modeling is among the important problems that require modeling long-term dependency, with successful applications such as unsupervised pretraining (Dai and Le, 2015; Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018). However, it has been a challenge to equip neural networks with the capability to model long-term dependency in sequential data. Recurrent neural networks (RNNs), in particular Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), have been a standard solution to language modeling and obtained strong results on multiple benchmarks. Despite the wide adaption, RNNs are difficult to optimize due to gradient vanishing and explosion (Hochreiter et al., 2001), and the introduction of gating in LSTMs and the gradient clipping technique (Graves, 2013) might not be sufficient to fully address this issue. Empirically, previous work has found that LSTM language models use 200 context words on average (Khandelwal et al., 2018) , indicating room for further improvement."}]},"formatted":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) .\n\nMore broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency.\n\nLanguage modeling is among the important problems that require modeling long-term dependency, with successful applications such as unsupervised pretraining (Dai and Le, 2015; Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018). However, it has been a challenge to equip neural networks with the capability to model long-term dependency in sequential data. Recurrent neural networks (RNNs), in particular Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), have been a standard solution to language modeling and obtained strong results on multiple benchmarks. Despite the wide adaption, RNNs are difficult to optimize due to gradient vanishing and explosion (Hochreiter et al., 2001), and the introduction of gating in LSTMs and the gradient clipping technique (Graves, 2013) might not be sufficient to fully address this issue. Empirically, previous work has found that LSTM language models use 200 context words on average (Khandelwal et al., 2018) , indicating room for further improvement."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models.","formatted":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"GODEL can be used as an initial model to finetune for any open-domain goal-directed dialog tasks with a handful of annotated examples. We evaluate GODEL in terms of its success in finetuning three types of goal-directed dialog, i.e., knowledge-grounded response generation, taskoriented dialog, and conversational QA:","formatted":"GODEL can be used as an initial model to finetune for any open-domain goal-directed dialog tasks with a handful of annotated examples. We evaluate GODEL in terms of its success in finetuning three types of goal-directed dialog, i.e., knowledge-grounded response generation, taskoriented dialog, and conversational QA:"},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.","formatted":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."}]},"formatted":"This poses a fundamental question: what do we want of a good general-purpose dialog model in the first place? We take it as a given that it should be fluent and socially engaging. Indeed, most SOTA PLMs are primarily evaluated on such intrinsic communicative dimensions. But beyond that, we must also acknowledge that machine-human conversation typically serves a purpose and aims to fulfill one or more goals on the part of the user. In other words, the model must offer utility to the user. It is this extrinsic dimension of functional utility, we suggest, that constitutes the proper focus of automated evaluation in general-domain models.\n\nGODEL can be used as an initial model to finetune for any open-domain goal-directed dialog tasks with a handful of annotated examples. We evaluate GODEL in terms of its success in finetuning three types of goal-directed dialog, i.e., knowledge-grounded response generation, taskoriented dialog, and conversational QA:\n\nLarge pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.","formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"In conclusion, we find that the pre-trained language models can provide more information for training set. It demonstrates extra knowledge helps the model make full use of small training data, which is important for most NLP tasks as large-scale annotated data is unavailable.","formatted":"In conclusion, we find that the pre-trained language models can provide more information for training set. It demonstrates extra knowledge helps the model make full use of small training data, which is important for most NLP tasks as large-scale annotated data is unavailable."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"answering (Rajpurkar et al., 2016;Zellers et al., 2018), natural language inference (Bowman et al., 2015), and text classification .","formatted":"answering (Rajpurkar et al., 2016;Zellers et al., 2018), natural language inference (Bowman et al., 2015), and text classification ."}]},"formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.\n\nIn conclusion, we find that the pre-trained language models can provide more information for training set. It demonstrates extra knowledge helps the model make full use of small training data, which is important for most NLP tasks as large-scale annotated data is unavailable.\n\nanswering (Rajpurkar et al., 2016;Zellers et al., 2018), natural language inference (Bowman et al., 2015), and text classification ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"We inference the five trained models and use the predicted confidence score to select the best model per target.","formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"An initial model trained with the above objectives was used to make structure predictions for a Uniclust dataset of 355,993 sequences with the full MSAs. These predictions were then used to train a final model with identical hyperparameters, except for sampling examples 75% of the time from the Uniclust prediction set, with sub-sampled MSAs, and 25% of the time from the clustered PDB set.","formatted":"An initial model trained with the above objectives was used to make structure predictions for a Uniclust dataset of 355,993 sequences with the full MSAs. These predictions were then used to train a final model with identical hyperparameters, except for sampling examples 75% of the time from the Uniclust prediction set, with sub-sampled MSAs, and 25% of the time from the clustered PDB set."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Not applicable, no experimental work is described in this study. The results are the output of a computational method which will be made available.","formatted":"Not applicable, no experimental work is described in this study. The results are the output of a computational method which will be made available."}]},"formatted":"We inference the five trained models and use the predicted confidence score to select the best model per target.\n\nAn initial model trained with the above objectives was used to make structure predictions for a Uniclust dataset of 355,993 sequences with the full MSAs. These predictions were then used to train a final model with identical hyperparameters, except for sampling examples 75% of the time from the Uniclust prediction set, with sub-sampled MSAs, and 25% of the time from the clustered PDB set.\n\nNot applicable, no experimental work is described in this study. The results are the output of a computational method which will be made available."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"This figure shows an example model summary from the CNN/DailyMail dataset exhibiting high fluency, coherence, although highly abstractive, and only ROUGE2-F of 16. The model understood that the football team \"Chelsea\" could be paraphrased as \"Jose Mourinho's side\" and \"The Blues\" and highlighted the same four matches to be played.","formatted":"This figure shows an example model summary from the CNN/DailyMail dataset exhibiting high fluency, coherence, although highly abstractive, and only ROUGE2-F of 16. The model understood that the football team \"Chelsea\" could be paraphrased as \"Jose Mourinho's side\" and \"The Blues\" and highlighted the same four matches to be played."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Model don't lie to your boss.","formatted":"Model don't lie to your boss."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket.","formatted":"Model outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket."}]},"formatted":"This figure shows an example model summary from the CNN/DailyMail dataset exhibiting high fluency, coherence, although highly abstractive, and only ROUGE2-F of 16. The model understood that the football team \"Chelsea\" could be paraphrased as \"Jose Mourinho's side\" and \"The Blues\" and highlighted the same four matches to be played.\n\nModel don't lie to your boss.\n\nModel outputs were selected (and L A T E X tables generated) automatically by a program in the following way: (1) pick first 300 examples of triplets (document, gold summary, model output) from the dataset test split; (2) rank the examples by ROUGE1-F1/ROUGE2-F1/ROUGEL-F1 metrics in descending order; (3) divide the examples into 2-10 buckets depending on the documents lengths; (4) randomly pick one example from each bucket."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"What is the application of the model?","formatted":"What is the application of the model?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"id":"chatcmpl-7lg3ant99472jRyBM2HOFwK19GL7r","object":"chat.completion","created":1691597438,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The application of the model is language modeling."},"finish_reason":"stop"}],"usage":{"prompt_tokens":287,"completion_tokens":9,"total_tokens":296}}
"The application of the model is language modeling."
["2023_Touvron.pdf","The application of the model is language modeling."]
{"id":"chatcmpl-7lg3a5H8w9xtyMSdIGkHu1AqUVJLK","object":"chat.completion","created":1691597438,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The application of the model is language modeling, specifically in capturing long-term dependency in sequential data."},"finish_reason":"stop"}],"usage":{"prompt_tokens":548,"completion_tokens":19,"total_tokens":567}}
"The application of the model is language modeling, specifically in capturing long-term dependency in sequential data."
["2019_Dai.pdf","The application of the model is language modeling, specifically in capturing long-term dependency in sequential data."]
{"id":"chatcmpl-7lg3aL3tC31gHbTdWSyfqZZ01myBA","object":"chat.completion","created":1691597438,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The application of the model is to make structure predictions for a Uniclust dataset of sequences."},"finish_reason":"stop"}],"usage":{"prompt_tokens":167,"completion_tokens":19,"total_tokens":186}}
{"id":"chatcmpl-7lg3awHU4RApdxh2Ie5Ym9wFZd8h8","object":"chat.completion","created":1691597438,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The application of the model is to generate model outputs for summarizing documents from the CNN/DailyMail dataset."},"finish_reason":"stop"}],"usage":{"prompt_tokens":223,"completion_tokens":22,"total_tokens":245}}
"The application of the model is to make structure predictions for a Uniclust dataset of sequences."
"The application of the model is to generate model outputs for summarizing documents from the CNN/DailyMail dataset."
["2021_Jumper.pdf","The application of the model is to make structure predictions for a Uniclust dataset of sequences."]
["2020_Zhang.pdf","The application of the model is to generate model outputs for summarizing documents from the CNN/DailyMail dataset."]
{"id":"chatcmpl-7lg3aFVnPfkn2nsumelGfHT0mgWwN","object":"chat.completion","created":1691597438,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The application of the model is in various NLP tasks, including named entity recognition, question answering, natural language inference, and text classification."},"finish_reason":"stop"}],"usage":{"prompt_tokens":342,"completion_tokens":28,"total_tokens":370}}
{"id":"chatcmpl-7lg3aYBt0pxfTTrzZXN6H2vixpreD","object":"chat.completion","created":1691597438,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The application of the model is in Conversational AI, specifically in dialog tasks such as knowledge-grounded response generation, task-oriented dialog, and conversational QA."},"finish_reason":"stop"}],"usage":{"prompt_tokens":894,"completion_tokens":32,"total_tokens":926}}
"The application of the model is in various NLP tasks, including named entity recognition, question answering, natural language inference, and text classification."
"The application of the model is in Conversational AI, specifically in dialog tasks such as knowledge-grounded response generation, task-oriented dialog, and conversational QA."
["2019_Zhang.pdf","The application of the model is in various NLP tasks, including named entity recognition, question answering, natural language inference, and text classification."]
["2022_Peng.pdf","The application of the model is in Conversational AI, specifically in dialog tasks such as knowledge-grounded response generation, task-oriented dialog, and conversational QA."]
[["2023_Touvron.pdf","The application of the model is language modeling."],["2019_Dai.pdf","The application of the model is language modeling, specifically in capturing long-term dependency in sequential data."],["2022_Peng.pdf","The application of the model is in Conversational AI, specifically in dialog tasks such as knowledge-grounded response generation, task-oriented dialog, and conversational QA."],["2019_Zhang.pdf","The application of the model is in various NLP tasks, including named entity recognition, question answering, natural language inference, and text classification."],["2021_Jumper.pdf","The application of the model is to make structure predictions for a Uniclust dataset of sequences."],["2020_Zhang.pdf","The application of the model is to generate model outputs for summarizing documents from the CNN/DailyMail dataset."]]
