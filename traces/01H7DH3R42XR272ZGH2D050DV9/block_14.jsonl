{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011188642,0.0044754567,-0.0022132338,-0.01471057,-0.0025684012,0.024522282,-0.01535442,0.017621892,-0.011302365,-0.03443197,0.0047798855,0.016012266,-0.016110243,0.013569836,-0.0030057991,-0.025068155,0.027979476,0.0063755135,-0.011512316,-0.014283669,-0.003649649,0.01770587,-0.0070403586,-0.038742967,0.007071851,0.033760127,0.027867502,-0.01539641,0.02281468,0.009104877,-0.0060500894,0.015270439,-0.037679214,-0.024242347,0.0012072185,-0.00014937142,0.010112642,-0.0008966659,0.004108042,0.004433466,0.011113409,0.0065434743,0.001359433,-0.014780554,-0.00802013,-0.008188091,0.0155083835,-0.039862704,-0.008034127,-0.013485855,0.010371582,0.024886196,-0.019119542,-0.012632054,-0.016278204,-0.003032043,-0.004870864,0.009188858,0.013681809,-0.014906525,0.021219052,0.018111777,-0.017747862,-0.001436415,-0.021624958,0.004450962,-0.024718236,-0.012317128,-0.0140597215,0.0076142247,0.03448796,0.010273605,-0.01007765,-0.025684012,0.034711905,-0.0072083194,-0.003504433,-0.02580998,-0.013919754,0.016320195,-0.00090978784,-0.02341654,-0.015172462,0.020505218,0.012464094,-0.016838074,0.0034344492,0.01552238,-0.013485855,0.0037406278,-0.003968075,-0.00082143344,0.020323262,0.015284436,0.0077122017,-0.0058436375,-0.008607993,0.02603393,0.0011241129,0.009797716,-0.0071418346,-0.0036111579,-0.021023098,-0.009839706,-0.01475256,0.0029445635,0.013751794,0.003705636,0.0058646323,-0.01338088,-0.03619556,0.03546773,0.011680276,-0.038071122,-3.0973246e-05,-0.009874698,0.007642218,-0.01784584,0.0037126343,-0.015942283,0.023696475,0.014486622,0.01809778,-0.008600995,0.01209318,-0.0065294774,-0.0061690616,-0.011603295,-0.017229982,-0.013401875,0.0011914722,0.010693506,0.0050843144,0.019189525,-0.015088482,0.01741194,-0.014360651,0.013289901,-0.02543207,-0.030568872,0.0076912064,0.0051752934,-0.019609427,0.017957812,-0.0020225283,0.016026264,0.011015432,0.026257878,0.016992038,0.012967976,0.0021257543,-0.038239084,0.021708937,0.029197192,0.016586132,0.021037094,-0.02950512,-0.009314828,-0.021177063,-0.0081600975,-0.007313295,0.013786785,0.0059556114,0.018209754,0.010756492,0.010021663,0.014612593,-0.0052942657,0.0125130825,0.004293499,-0.011309363,0.031688612,-0.028833278,0.00049994595,-0.0069878707,0.01942747,0.021191059,-0.0057316637,-0.017509917,-0.025502054,0.01728597,-0.0017644636,0.005035326,0.024984173,-0.019371483,-0.023752462,0.01685207,-0.012247144,0.005248776,0.0018668147,0.018755626,0.016110243,-0.0018423204,0.004979339,-0.6704997,-0.021820912,0.0038910927,-0.025292102,0.015466394,0.016992038,-0.0020907626,-0.016250212,-0.032584403,0.01239411,-0.021163065,0.006788417,0.028021466,-0.028833278,-0.0072503095,-0.026131907,-0.0030372918,-0.03328424,0.009671745,0.0029043227,-0.018671647,0.015928285,-0.019273506,-0.009041891,-0.00156501,0.028595332,0.0016831076,-0.016796084,0.018797617,0.010154632,-0.009377813,0.03359217,0.00536075,0.015606361,0.043641824,-0.020939117,-0.006994869,0.015550374,0.00020579576,0.05036026,-0.033032298,-0.0119322175,0.004937349,0.0005244402,-0.011197389,0.0037616228,0.022310797,0.0025526548,0.02019729,0.010616524,0.012058188,0.015760325,0.009601762,0.0084540285,0.020127308,-0.020505218,0.023122609,-0.011379346,0.0114493305,0.008300065,0.012590065,0.005210285,-0.017090015,-0.006421003,-0.0071943225,0.02624388,-0.021191059,0.013884762,-0.004695905,-0.045741335,-0.0068164105,0.017146003,-0.021512983,0.0053922427,-0.011043425,0.02594995,0.0153124295,0.016446166,0.017761858,0.018937584,-0.00040852974,-0.030764826,0.004185024,0.020421239,0.033900097,-0.00073176686,-0.03320026,-0.008866932,-0.0047099018,0.0026646287,0.0077192,0.019357486,-0.016516149,-0.019581433,0.0015265191,0.036447503,-0.009867699,0.01660013,-0.016236214,-0.015074485,-0.0023811948,-0.0107215,0.009755725,-0.0072643063,-0.0103855785,0.005238279,0.00047501424,0.027797518,0.020001337,-0.02040724,0.010266606,0.019189525,-0.011855235,0.014542609,-0.012289135,-0.03370414,0.04087047,-0.01424168,0.0008577375,-0.0073482865,0.003422202,0.012772022,0.0077541918,-0.018363718,0.007572234,0.03297631,-0.014283669,-0.03118473,-0.013891761,0.0083560515,0.0227307,-0.018265741,0.014283669,-0.012261141,0.017719869,-0.00058567594,-0.00052094104,0.0020662681,0.0042270143,-0.022520749,-0.0045069493,0.011295366,0.0015335174,0.017985806,-0.025921956,-0.0040310603,-0.007978139,0.008132104,-0.0055007176,-0.008887928,-0.010784485,-0.021177063,-0.012450097,-0.020351255,0.005301264,0.008461027,0.015382413,-0.031212723,-0.025767991,-0.027671548,0.010658515,0.025614027,-0.015648352,0.017551908,-0.015550374,0.00690389,-0.0016997287,0.034236018,0.007341288,-0.022464762,0.014780554,-0.027797518,0.009594763,0.013149934,-0.0027206156,0.0025229116,0.0050703175,-0.013170929,-0.021261042,-0.014892528,0.00089229195,-0.00080218795,0.011694273,-0.00043039964,0.014486622,0.009118874,0.02462026,0.010924453,-0.016712103,0.03507582,-0.0063090287,0.011953213,-0.018125774,-0.01020362,-0.00053318817,-0.007845171,0.00848902,-0.01664212,0.0024809216,0.015704338,0.01664212,0.019693408,0.0080621205,-0.0072503095,0.0071138414,-0.018377716,-0.0011118657,-0.014115709,0.019091548,0.014143702,0.026229884,-0.040002674,-0.02127504,-0.0068688984,0.011946214,0.009853702,0.00023488273,0.011820244,-0.021498987,0.015536377,-0.035327762,0.0009657748,0.012576068,-0.0002683437,-0.018727634,0.010714502,-0.0034326995,0.019875366,0.014206687,-0.01483654,0.006043091,0.026943717,-0.00058567594,0.031548645,0.021051092,-0.018083783,0.010392576,0.0059591103,0.0021415006,0.0025316598,-0.0049863374,0.0069353827,-0.0151164755,0.005665179,0.03597161,-0.0092238495,0.033732135,0.01921752,-0.02697171,-0.0015790068,-0.011939216,0.009384812,-0.0035516717,-0.00904889,0.009139868,0.0048218756,0.014255676,-0.006165562,-0.0039225854,0.020491222,0.0069808722,0.020057322,0.033340227,-0.012289135,0.0278815,-0.0047029033,-0.012366117,-0.032304466,-0.0227307,0.0031037764,-0.01363982,-0.00038294197,0.005896125,-0.028077453,0.02603393,0.01707602,0.017173996,0.01475256,0.03418003,0.016110243,-0.034040064,-0.026915723,0.018951582,0.0052942657,-0.009013899,0.0049163536,-0.02208685,0.010700505,-0.010273605,0.0074672587,0.021526981,0.017355952,-0.0037966147,-0.004842871,-0.018489689,0.0039085886,0.031352688,-0.011589298,-0.0011827243,-0.0060395915,0.0074252686,0.019609427,-0.0051263045,-0.041710276,0.017104011,-0.031324696,0.031128742,-0.0071733273,-0.01693605,-0.019329492,0.006574967,-0.025278106,0.022324795,-0.018461695,0.014080717,0.0017215986,0.008083115,-0.017229982,0.030036997,0.018167764,0.0057106684,-0.026257878,-0.024214353,0.008873931,0.06371314,0.052739702,-0.0057771527,0.019539444,-0.0023514517,-0.0070823487,-0.0137238,-0.0054867207,0.0067989146,-0.0040590535,-0.010217617,-0.019035561,0.018321728,-0.010903457,0.005112308,0.0077681886,0.018167764,-0.014318661,-0.022618726,-0.039638758,-0.007015864,0.007586231,0.041290373,0.031940553,0.008866932,0.006452495,0.02860933,0.013996736,-0.013373882,-0.018251745,0.01604026,0.015760325,0.009699739,0.006001101,0.0030110478,0.037875168,0.0005261898,0.014297666,0.020533212,0.012023197,0.01539641,0.00874796,0.007432267,-0.0052417777,-0.014808547,-0.007106843,-0.011316361,-0.0010733748,-0.0015273938,-0.013016965,-0.0002687811,-0.016278204,-0.043809786,-0.008076116,0.011057422,0.0010777487,-0.017663881,-0.00840504,-0.004870864,-0.00033963955,-0.026481826,-0.023766458,-0.003593662,0.0035901628,0.018195758,-0.016530145,-0.0066239554,0.004814877,-0.030372918,-0.008642985,-0.012443098,-0.035803653,-0.019721402,-0.005112308,0.03409605,0.018377716,0.024410307,-0.0071383356,-0.013814779,0.0066099586,-0.0050493227,-0.0028115944,-0.011456328,-0.0028325894,0.01741194,-0.0074252686,0.0011669779,-0.0032227486,-0.005567202,0.0137657905,-0.0012168413,0.007978139,-0.0038526016,-0.02075716,-0.021750929,0.010413572,0.021708937,0.03331223,-0.009895693,-0.025376083,0.007341288,-0.030064989,-0.021023098,-0.009013899,-0.0056161904,-0.006312528,0.004338988,-0.0080621205,-0.010140635,0.0032087518,0.03182858,-0.012464094,0.011890228,0.003628654,0.005570701,0.03031693,0.0013891761,0.009489787,-0.018993571,-0.024242347,0.011309363,-0.02457827,0.0060500894,0.0038246082,-0.03353618,0.012562071,0.017649885,0.006095579,-0.03320026,0.015200456,-0.013562838,0.048176765,-0.016180227,-0.0017705872,-0.016250212,-0.0002845274,-0.013149934,-0.0034834377,-0.012408107,-0.003241994,0.0065539717,-0.02002933,-0.010476558,-0.00995168,0.003478189,-0.033564173,-0.012443098,0.024214353,0.004772887,0.0106725115,0.002766105,-0.0074252686,-0.0057316637,-0.0072503095,0.0005384369,-0.019595431,-0.0045349426,0.007852169,0.011484322,0.027041694,0.021191059,-0.0077192,0.016404174,0.0109664425,-0.01471057,0.00015680719,0.0008161847,0.021051092,-0.01338088,0.035579704,-0.0034641922,-0.0076912064,-0.014374648,0.007089347,0.026621792,0.007411272,-0.017663881,-0.018657649,-0.029393146,-0.028595332,0.016628122,0.0129959695,-0.008985905,-0.0037021367,-0.021722935,0.0026821245,0.0029008237,0.004489453,-0.0017093514,-0.010658515,0.0060185967,-0.007565236,0.02337455,-0.0022062357,0.018209754,-0.017761858,-0.030596865,-0.028525349,0.010259608,0.031156735,-0.018559672,0.026369851,0.017929818,-0.008607993,0.0039645755,-0.002822092,0.0023549509,0.00832106,-0.0047553913,-0.01325491,0.016572136,-0.023024632,-0.025712004,-0.007789184,0.0040730503,0.012534077,-0.011673278,0.013079951,0.006879396,-0.021345023,0.020267274,-0.003800114,0.04868065,0.022842674,0.023122609,0.025068155,0.0013664314,0.003765122,0.00165074,0.003894592,0.013464861,0.019329492,0.009832707,-0.010259608,-0.021820912,0.0042865006,0.017593898,-0.02470424,-0.01720199,-0.011169395,0.001985787,0.0025054158,-0.002598144,-0.008328058,0.011869232,-0.0034711906,-0.010917454,0.008426035,0.01809778,-0.011918221,-0.0031755096,0.026663782,0.018195758,0.02727964,-0.010252609,0.0030635358,0.0040940456,0.009412806,0.023556508,0.013520847,-0.02019729,0.029393146,-0.009195856,-0.0059241187,0.024424305,-0.0053957417,0.0155083835,-0.007257308,0.0042480095,0.030512886,-0.01471057,0.012107177,-0.006536476,0.006441998,0.007050856,-0.007341288,-0.0014547858,-0.008740962,-0.009685742,0.023570504,0.012667047,0.008251076,-0.030988775,-0.00313002,-0.0020890129,-0.01231013,-0.0012378363,0.006095579,-0.0011748511,-0.03353618,-0.027265642,-0.008314061,0.01620822,0.03661546,-0.0054657254,-0.023626491,0.012128172,0.017481923,-0.032024533,0.016320195,0.019007567,-0.01265305,-0.019147536,0.011673278,-0.018587666,-0.035887633,0.010749494,-0.017551908,-0.038603,-0.025362086,0.001629745,-0.00450345,0.0022534747,-0.022058856,-0.0058296407,-0.0055986946,0.0034414476,0.0034904361,-0.025530048,0.016754093,0.009622756,0.0028273407,0.015984273,-0.014262674,0.018447699,-0.020141304,-0.01693605,-0.0022149836,-0.04425768,-0.026859738,-0.022394778,-0.008691973,-0.008559004,-0.0022027364,-0.009461794,-0.007089347,-0.014374648,0.0071803257,0.001753966,-0.0063965083,-0.0049443473,0.008985905,0.0036111579,0.012464094,-0.021429004,-0.008146101,-0.0022867168,0.022436768,-0.0274476,-0.01432566,-0.014920521,0.04078649,0.01707602,-0.0151164755,-0.006421003,-0.006344021,-0.031408675,0.0023164598,0.0047973813,0.0005786776,-0.0076352195,0.007488254,0.012072185,0.03627954,-0.003268238,-0.006536476,0.0028973245,0.009986672,-0.020995105,-0.020001337,0.006001101,0.0033207256,-0.021107078,0.0026226384,-0.0020977608,-0.015536377,0.022464762,-0.005472724,-0.016964044,-0.017901827,0.008880929,0.031352688,0.029953016,0.023920422,0.02148499,-0.022744697,-0.013674811,0.020365251,-0.015144468,-0.01475256,-0.02337455,0.010392576,0.0015326426,0.012457095,-0.0024581768,-0.029001238,0.012408107,0.004108042,-0.0053502526,0.0031930055,0.029561108,0.03294832,0.014724567,-0.019371483,-0.0040170634,0.025558041,-0.023262575,-0.0043214923,0.022156833,-0.029925022,0.0060500894,-0.016236214,-0.019833375,-0.018489689,-0.01599827,-0.011778254,-0.0017810847,-0.004594429,0.014115709,0.018979574,-0.023276573,0.025110144,0.009797716,0.0015851303,-0.018223751,-0.0045524384,0.0071943225,-0.019567437,0.0036321532,0.0059276177,-0.01917553,-0.0105815325,0.0066449507,0.017257975,0.017957812,0.010714502,0.231562,-0.018671647,-0.013387878,0.0120092,0.0180138,0.002538658,0.023290569,0.019203523,0.00020776405,0.010602528,0.009111876,0.01998734,0.004695905,-0.007586231,0.0227307,-0.017425938,-0.022534745,-0.00840504,0.0046609133,0.017691875,0.013982739,-0.009146867,-0.0047833845,-0.022576736,0.04296998,-0.011050424,-0.009853702,0.002899074,0.0060150973,0.0069283843,-0.0075232456,-0.0030845308,0.021037094,0.0012369616,-0.0143466545,-0.00041027935,0.021722935,-0.008649983,0.012569069,0.0015247695,0.037063356,-0.024998171,-0.0016962294,-0.012128172,0.012779021,0.022870667,-0.01990336,-0.020365251,0.02817543,0.015550374,-0.016530145,-0.0052767694,0.0027293635,0.029029232,0.00832106,-0.009839706,-0.0116452845,0.0025194124,0.012366117,-0.019833375,-0.024242347,0.008041125,-0.008433034,0.022716703,-0.0013760541,-0.0015597614,-0.0067709214,-0.01007765,0.018125774,-0.015676344,-0.015494388,-0.015368417,-0.0076072263,-0.012835007,-0.029477127,-0.015718335,0.029057225,-0.00044286548,0.02277269,0.029001238,-0.020645186,-0.000831931,-0.0010996186,-0.014374648,-0.009069885,-0.021261042,0.035551712,-0.0061445674,-0.0064874873,-0.0068933927,-0.016138237,0.014038727,-0.011981206,0.009958678,-0.0009001651,0.00024887946,0.010455562,0.012576068,0.0054062395,0.0011897226,-0.02594995,0.07631021,0.0070473566,-0.003061786,0.00035757286,0.0101896245,0.0021345024,0.023024632,0.0055602035,-0.011337357,0.0020137804,-0.018083783,0.0008310562,-0.021387013,-0.012247144,0.0027783522,0.023598498,-0.006253042,0.015690342,0.0016393678,-0.030456899,-0.013065954,-0.008524013,0.011183392,0.0038246082,-0.006599461,0.0070438576,-0.001900057,-0.017299967,-0.007008866,0.0047273976,-0.019735398,0.008838939,0.01552238,-0.010455562,-0.022548743,-0.01736995,-0.008887928,0.01784584,-0.0051403013,0.0020680178,0.016152233,-0.0057491595,-0.011246378,-0.013408873,-0.009916687,-0.012282136,0.009104877,0.006651949,0.00035560457,-0.004870864,0.012779021,-0.009874698,-0.015844306,0.0061445674,-0.012282136,0.015956279,0.0022919655,0.0029533114,-0.0050458233,-0.023598498,0.0046714107,0.009531777,-0.01861566,-0.014199689,-0.018517682,-0.18240547,0.008999902,0.022324795,-0.037679214,0.010910456,0.001059378,0.028721303,-0.012338123,-0.044201694,0.015606361,0.03490786,-0.012946981,-0.03031693,-0.0026488823,-0.0053502526,-0.0128070135,-0.008803947,-0.0028938253,0.003513181,0.013730798,0.04770088,-0.020183293,-0.0025596533,0.007131337,-0.017859835,-0.0029865536,0.0043984745,0.023052625,0.015270439,-0.030848807,-0.00892292,-0.0034641922,0.01784584,-0.0056931726,-0.008482022,-0.0039050893,0.00437398,-0.021946883,-0.021107078,-0.00079825136,0.02028127,0.016824078,0.014976508,-0.0017557156,-0.015536377,0.0025456564,0.023444533,-0.013170929,0.0054482296,-0.028749296,0.0024424305,-0.0070823487,0.0116382865,-0.0065469733,0.002006782,0.00553221,-0.0063615167,-0.019189525,0.0044124713,-0.0046434174,0.002157247,-0.0053712474,0.012023197,0.018559672,0.005206786,0.0062285475,9.3985895e-05,0.014892528,-0.04087047,0.009314828,-0.008754958,-0.0052172835,-0.011204387,-0.0048218756,0.0021467495,0.035859637,-0.018447699,-0.009496786,0.003401207,-0.022156833,-0.008600995,0.018223751,-0.007432267,-0.0017443433,-0.00420252,-0.0045629363,-0.00049251015,0.037903164,-0.007957145,-0.01350685,0.020617193,-0.047448937,-0.0045314436,-0.014556605,-0.0014171696,0.018349722,0.014227683,-0.021415006,0.015200456,-0.0048078788,0.01363982,0.0002902136,-0.0016708605,-0.00028955747,0.030540878,0.0032524916,0.0029165698,0.0151164755,0.03370414,-0.006312528,-0.026705774,-0.021778923,9.2892406e-05,0.0039015904,0.014402642,0.028119443,-0.0075092493,0.00995168,0.009832707,-0.0067569246,0.066008605,0.0018790618,-0.01380778,0.0144446315,-0.009062887,-0.022856671,-0.11656482,-0.046357192,-0.004541941,-0.0030530381,-0.008342055,0.024256345,-0.008076116,0.0016218718,-0.028889263,0.0317446,-0.016908057,-0.030120976,0.023906427,0.0018388212,-0.004314494,-0.032780357,0.003109025,-0.006599461,-0.02774153,0.033256244,-0.012128172,-0.021443,0.006386011,-0.020911124,0.012324126,0.004370481,-0.03362016,-0.008314061,0.003649649,-0.006994869,0.010259608,-0.01063752,0.014570602,5.6697718e-05,-0.0037756197,-0.023444533,-0.004902357,-0.010406573,0.020351255,-0.017887829,0.011211386,-0.0037406278,-0.0007466384,-0.008873931,-0.03949879,-0.02200287,-0.007215318,0.02079915,0.030120976,-0.021359019,-0.036979377,0.0120092,-0.019525448,0.004433466,0.009545774,-0.0028465863,-0.0034466963,0.0048078788,0.0045314436,0.012828009,-0.018839607,0.0070753503,-0.009454795,-0.0015002752,0.010861468,-0.02967308,-0.0034344492,-0.015732331,0.011414339,-0.02054721,-0.005112308,-0.0032140005,-0.00904889,0.01179225,-0.015606361,-0.014010733,-0.011995203,-0.021037094,0.005441231,-0.0044264677,-0.005700171,-0.011729265,-0.0092308475,-0.014283669,0.018265741,-0.0037196327,-0.025446067,-0.017887829,0.01110641,-0.008426035,0.0005734288,0.032052528,0.010357585,-0.027503587,0.019105544,0.014542609,-0.02834339,-6.364141e-05,0.008559004,0.010392576,-0.027391613,-0.0070823487,-0.04708502,0.02800747,-0.003109025,-0.03409605,-0.015676344,-0.0050073327,0.008733964,-0.008132104,-0.012492087,0.020183293,-0.016306197,0.010735497,-0.014318661,-0.003135269,-0.017313963,-0.012233147,0.0188676,-0.011918221,-0.0037126343,-0.005112308,0.015270439,-0.0015623857,0.012233147,0.011442332,-0.012345121,0.0010191373,-0.010497552,0.0127020385,-0.01209318,-0.013079951,-0.0036916393,-0.02208685,0.0034834377,0.023122609,-0.0007943148,0.0012911989,-0.013219917,0.03294832,0.02727964,0.02204486,-0.003457194,-0.032584403,-0.0006591588,-0.018895594,-0.0036566474,-0.010574535,-0.0057491595,-0.007642218,-0.007565236,-0.0017006035,0.024760226,0.0065259784,-0.0072363126,-0.039778724,0.006501484,0.020127308,-0.009790717,-0.017957812,-0.0064874873,0.004734396,0.043893766,-0.012128172,-0.0045349426,-0.0010025162,0.006707936,-0.009083882,-0.0031877568,0.010518547,0.018461695,-0.0038106116,0.007432267,0.008426035,-0.003075783,0.017607894,-0.008992903,-0.02040724,0.009405807,0.001814327,0.0030197958,0.032864336,0.012863001,0.0014005484,-0.009727731,-5.2542437e-05,0.0047238986,0.004748393,-0.010728498,0.008677976,-0.008803947,0.004926851,0.028665315,0.014052724,-0.014402642,0.011855235,-0.015424403,-0.018517682,-0.0045069493,-0.009468792,0.015382413,0.022590732,-0.0072922995,-0.0014084216,-0.006865399,-0.030232951,-0.025572037,0.023080619,-0.0127020385,-0.037847176,-0.0047973813,0.033256244,0.03280835,-0.002054021,0.0014862785,0.009216851,-0.018279737,0.024200357,-0.011561304,-0.023122609,-0.036223553,0.020141304,0.025935952,0.0010392576,-0.0026436336,-0.008579999,0.011659281,0.03289233,0.02470424,-0.009545774,0.006253042,0.029477127,0.0005358126,0.0012981973,-0.0050948123,-0.008286068,-0.01813977,-0.025614027,-0.018349722,0.0077122017,0.015186459,0.068695985,0.015900293,-0.008656981,0.019889362,-0.022226818,0.020463228,0.034319997,-0.0046609133,-0.024158366,-0.012261141,-0.012296133,0.010392576,-0.014094713,0.0058016474,0.0024109378,0.017271973,-0.008419037,0.0035656686,-0.018027797,0.017789852,0.0084540285,-0.0031002772,0.02345853,-0.0027328627,-0.017691875,0.015186459,0.0060500894,0.0068339068,0.002766105,-0.016138237,0.025753995,0.014192691,-0.024844207,-0.022156833,-0.0082580745,0.011862234,-0.0059941025,-0.034963846,-0.0030110478,0.0028448366,-0.006683442,-0.021750929,-0.01745393,0.0033224754,-0.009888695,0.0089369165,-0.010476558,-0.01946946,-0.015746329]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.7787155482774982
0.7597602460841417
0.7825369562659455
0.7945773806018265
0.7319146694329606
0.7943474908716687
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011509225,0.0045162337,-0.0020971976,-0.0147625925,-0.0025817044,0.024501706,-0.015294326,0.017631153,-0.01132032,-0.034450714,0.0047331247,0.015979981,-0.01611991,0.013622165,-0.0030364762,-0.02513139,0.02799995,0.0064017875,-0.011600179,-0.014258845,-0.0036031918,0.017659139,-0.007055959,-0.038732566,0.007136419,0.033751063,0.027888006,-0.015378283,0.022822548,0.009130418,-0.0060729524,0.015294326,-0.037697084,-0.024207853,0.0012392531,-0.0001726165,0.01012392,-0.0008990489,0.0040544653,0.0044532656,0.011145407,0.0065592085,0.001394925,-0.014720613,-0.007982994,-0.008318826,0.015518213,-0.039852,-0.008024973,-0.013440256,0.01038279,0.024935488,-0.019100415,-0.012635659,-0.016287826,-0.003031229,-0.0048520654,0.009179394,0.013678136,-0.014916515,0.021227349,0.018120907,-0.017729104,-0.0014456495,-0.021591166,0.004474255,-0.024795558,-0.012369793,-0.014076936,0.007640166,0.034478698,0.010249857,-0.010109927,-0.025677115,0.034730572,-0.0072203767,-0.0035507183,-0.025803052,-0.013957996,0.01630182,-0.0009471497,-0.023424245,-0.015154395,0.020513706,0.012467744,-0.01686154,0.0034860007,0.015476234,-0.0134892315,0.0037501182,-0.003977504,-0.00084701244,0.020317804,0.015252346,0.007724124,-0.005863058,-0.008647661,0.02602694,0.0011343058,0.00986505,-0.007118928,-0.0036416727,-0.021031447,-0.00984406,-0.014720613,0.0029280307,0.013769091,0.0037151359,0.0059085353,-0.0133842835,-0.036241814,0.035430223,0.011726116,-0.038172845,9.182892e-06,-0.009900033,0.0076611554,-0.017883027,0.0037431216,-0.015993975,0.023690112,0.0144407535,0.018036949,-0.008661654,0.01207594,-0.006552212,-0.006212882,-0.011628165,-0.017183378,-0.013391281,0.0011526716,0.010697632,0.005075953,0.01921236,-0.015112417,0.01743525,-0.014342803,0.013314319,-0.02546722,-0.030532679,0.007703135,0.005208886,-0.01959017,0.017952992,-0.002030731,0.016035954,0.010970495,0.026306799,0.01701546,0.012992481,0.0021129397,-0.03828479,0.021759082,0.029301297,0.0165397,0.021045439,-0.029497199,-0.00932632,-0.021227349,-0.008143913,-0.0073463134,0.013748101,0.005936521,0.018246844,0.010704628,0.010039962,0.014664642,-0.005306837,0.012516719,0.0043238304,-0.011257351,0.031680103,-0.028825535,0.0004915034,-0.00695451,0.019338297,0.021227349,-0.005723128,-0.017491223,-0.025523193,0.017309314,-0.0017395021,0.0050094863,0.024921494,-0.019324303,-0.023732092,0.016847545,-0.012229864,0.0052263774,0.001931031,0.018736597,0.016133904,-0.0018068433,0.0049675074,-0.6703196,-0.021871025,0.0038795532,-0.025257327,0.015462241,0.016987476,-0.0020622152,-0.016259842,-0.032659613,0.012362797,-0.021157384,0.0067691035,0.028027935,-0.028909493,-0.0073463134,-0.026138883,-0.003057466,-0.033247318,0.009718124,0.0028528185,-0.018708613,0.015938003,-0.019198366,-0.009053457,-0.0015112417,0.028657619,0.0016424259,-0.016805567,0.018764583,0.010130917,-0.009375296,0.033667106,0.005373304,0.0156021705,0.04363011,-0.020989468,-0.00703497,0.0156021705,0.00015971673,0.05040271,-0.033051416,-0.011908025,0.0048975423,0.00052998407,-0.01118039,0.0037816025,0.0223188,0.002602694,0.020121902,0.010627667,0.012068944,0.015700122,0.009620173,0.00843077,0.02010791,-0.020513706,0.023144387,-0.011411274,0.011474242,0.008262854,0.012628663,0.0052263774,-0.017043447,-0.006447265,-0.00715391,0.026236834,-0.02114339,0.013902024,-0.004691146,-0.045840997,-0.006877549,0.017127406,-0.021521201,0.005436272,-0.011082439,0.025970967,0.01536429,0.016511714,0.017813062,0.018932499,-0.0004119183,-0.03072858,0.004148918,0.020415755,0.03383502,-0.0007438143,-0.033135373,-0.008871548,-0.004701641,0.0026726588,0.0077171274,0.019338297,-0.016581679,-0.01954819,0.0014893776,0.036437716,-0.00986505,0.016567687,-0.01620387,-0.015084431,-0.0023788062,-0.010732614,0.009753106,-0.0072273733,-0.010438762,0.0052123843,0.0004906288,0.027734084,0.020051938,-0.020373777,0.010249857,0.019184373,-0.011866046,0.014566691,-0.012271842,-0.033667106,0.040887482,-0.014258845,0.00087499846,-0.0073603066,0.0033495692,0.01277559,0.0077311206,-0.018344795,0.007626173,0.03302343,-0.014342803,-0.031176357,-0.013923014,0.008339815,0.022766575,-0.018246844,0.014300824,-0.012299828,0.017701117,-0.00058333226,-0.00055709545,0.002048222,0.0042398726,-0.022500709,-0.0045407214,0.011313323,0.0015182381,0.017952992,-0.025928989,-0.004001992,-0.008038966,0.008129921,-0.005488746,-0.008864552,-0.010802579,-0.021157384,-0.012397779,-0.020331798,0.005310335,0.008486741,0.015378283,-0.031232327,-0.025803052,-0.027678112,0.010676643,0.025663123,-0.015686128,0.017561188,-0.015560192,0.0068880436,-0.0016476732,0.03419884,0.0073603066,-0.022444738,0.014776585,-0.027804049,0.009571197,0.01313241,-0.0027811045,0.0024924993,0.0050549633,-0.013209372,-0.021311305,-0.014860543,0.0008955506,-0.00085619534,0.01171912,-0.00043924834,0.014482733,0.00908844,0.024627643,0.010928516,-0.01672161,0.035122376,-0.006307335,0.011950004,-0.018148893,-0.010172895,-0.0005356687,-0.0078850435,0.0085147275,-0.016637651,0.0024645133,0.015728109,0.016707616,0.019744093,0.008045963,-0.0072203767,0.0070699523,-0.018400766,-0.0011273093,-0.014062943,0.019156387,0.014153898,0.02626482,-0.040047903,-0.021255335,-0.0068425667,0.011922018,0.009816075,0.00018125279,0.011810074,-0.021493215,0.015686128,-0.035346262,0.00096289185,0.012551702,-0.000268053,-0.018750591,0.010704628,-0.00348775,0.019884022,0.014300824,-0.01484655,0.006090444,0.026964469,-0.0005898915,0.031596147,0.021059433,-0.018008962,0.010368797,0.0059295245,0.0021409257,0.0024924993,-0.0049465178,0.0069685034,-0.01512641,0.0056986404,0.036045913,-0.00920738,0.033667106,0.019240346,-0.02700645,-0.0015934504,-0.011901028,0.009424271,-0.0035717078,-0.009137415,0.009165401,0.004806588,0.014265842,-0.0061464156,-0.003918034,0.020499714,0.0069859945,0.020023951,0.03335926,-0.012243856,0.027888006,-0.0047681076,-0.012460747,-0.03226781,-0.022738589,0.0031851516,-0.013615168,-0.00040688957,0.0059260265,-0.028013943,0.025984962,0.017057441,0.017155392,0.014734606,0.034226824,0.01616189,-0.034086894,-0.026936483,0.018946493,0.0053278264,-0.008990489,0.004918532,-0.022024948,0.010711625,-0.010284839,0.0074302717,0.021535194,0.017351294,-0.0037816025,-0.0048555634,-0.018484725,0.0039250306,0.031372257,-0.011600179,-0.001157919,-0.006090444,0.0073882923,0.019646142,-0.0051109353,-0.041727062,0.017057441,-0.031344272,0.031176357,-0.0071469136,-0.01691751,-0.019254338,0.006594191,-0.025271319,0.02236078,-0.01851271,0.014167891,0.0016835302,0.00815091,-0.017239349,0.030028932,0.018106913,0.0056881458,-0.026250828,-0.024221845,0.008920523,0.0635841,0.052697558,-0.005803588,0.01954819,-0.0023350783,-0.0070839454,-0.0137061225,-0.005450265,0.006762107,-0.0040229815,-0.010186888,-0.01903045,0.018302815,-0.01090053,0.005131925,0.007808082,0.018204864,-0.014370789,-0.02269661,-0.039628115,-0.007076949,0.0075142295,0.041279286,0.031959962,0.008920523,0.006412282,0.02861564,0.014006971,-0.013391281,-0.018246844,0.016035954,0.015770087,0.009690138,0.006016981,0.0029052922,0.037864998,0.00052036386,0.014321813,0.020555684,0.012019969,0.015392276,0.008724622,0.0074442644,-0.005254363,-0.014804571,-0.0070629558,-0.011292334,-0.0011281839,-0.0015348548,-0.013027463,-0.00026302427,-0.01630182,-0.043853994,-0.008080945,0.01101947,0.0010555953,-0.01761716,-0.008465752,-0.0048730546,-0.0003609751,-0.026488708,-0.02381605,-0.0035524673,0.0035682095,0.018204864,-0.016511714,-0.006702637,0.0047960933,-0.03039275,-0.008640664,-0.012397779,-0.035877995,-0.019758085,-0.0051424196,0.034114882,0.018330801,0.024417747,-0.0070699523,-0.013825063,0.0066011874,-0.0051074373,-0.0028125886,-0.011397281,-0.0028370763,0.017449245,-0.0074722506,0.0012576189,-0.0032498692,-0.005565707,0.013741105,-0.0012278839,0.007996988,-0.0038795532,-0.020709608,-0.021773074,0.01038279,0.02170311,0.033247318,-0.009935015,-0.025355278,0.007395289,-0.030056918,-0.021101411,-0.009004481,-0.005663658,-0.006331823,0.004348318,-0.008073948,-0.010130917,0.003202643,0.031820033,-0.01249573,0.011936011,0.0035961955,0.005548216,0.03030879,0.001394925,0.009452257,-0.01897448,-0.024249831,0.011348305,-0.02457167,0.005981998,0.003802592,-0.033527177,0.012621666,0.01761716,0.006076451,-0.033247318,0.015196375,-0.013629161,0.04816383,-0.01620387,-0.0017526206,-0.016245848,-0.00029625758,-0.013160396,-0.0034580147,-0.012404775,-0.003291848,0.006548714,-0.020023951,-0.010473744,-0.009921022,0.0034667605,-0.033527177,-0.01247474,0.024221845,0.0047751036,0.010655653,0.002760115,-0.007409282,-0.0056881458,-0.0072203767,0.00054834987,-0.019618155,-0.0045372234,0.007864054,0.011474242,0.027076414,0.021171376,-0.007724124,0.016497722,0.010942509,-0.014734606,0.00019579238,0.0008089691,0.021031447,-0.013391281,0.035598136,-0.0034580147,-0.007626173,-0.014412767,0.0070594577,0.026600651,0.007451261,-0.017715111,-0.018638648,-0.02935727,-0.02861564,0.016651643,0.012999477,-0.008990489,-0.0037711076,-0.021731095,0.0027076413,0.0028773062,0.004519732,-0.001709767,-0.01064166,0.0060309735,-0.0075422153,0.023382267,-0.0022248835,0.018288823,-0.017701117,-0.030616637,-0.028531684,0.010256853,0.03114837,-0.018540697,0.026362771,0.017938998,-0.008640664,0.003960013,-0.0028370763,0.002403294,0.008290839,-0.0047401213,-0.013230361,0.016581679,-0.023032442,-0.025733087,-0.007843064,0.004001992,0.012523715,-0.011663147,0.013076439,0.0068740505,-0.021339292,0.020317804,-0.0037851005,0.04866758,0.022850534,0.0231164,0.025075417,0.0013345804,0.0037536165,0.0016983978,0.0039285286,0.013468241,0.01931031,0.009823071,-0.010277842,-0.021857033,0.0043028407,0.017603166,-0.024725594,-0.017183378,-0.011187386,0.001987003,0.0024767572,-0.0025239834,-0.008297836,0.011950004,-0.0034807534,-0.010991485,0.008395787,0.018036949,-0.011929014,-0.0031903991,0.026656624,0.018246844,0.02724433,-0.01024286,0.0030697095,0.004131427,0.009410278,0.02353619,0.013510221,-0.020177875,0.029469213,-0.009221373,-0.005894542,0.02438976,-0.0054152827,0.015490227,-0.007192391,0.0042958446,0.030504692,-0.014748599,0.012138909,-0.0065382193,0.006492742,0.0070069837,-0.0073812963,-0.0014482733,-0.008710629,-0.009669148,0.023606155,0.0126426555,0.0083118295,-0.031064412,-0.0031221833,-0.002074459,-0.012292831,-0.0013022216,0.0061114333,-0.00116579,-0.03358315,-0.027230335,-0.008290839,0.016259842,0.03660563,-0.005446767,-0.023606155,0.012047955,0.017533202,-0.03204392,0.016287826,0.019016458,-0.012586684,-0.0191284,0.011684137,-0.018568682,-0.035961956,0.010795583,-0.01751921,-0.038648605,-0.025355278,0.0016266837,-0.004533725,0.0022248835,-0.022024948,-0.005877051,-0.0056146826,0.0033723079,0.0035297289,-0.02560715,0.016763588,0.009634166,0.0028423236,0.015965989,-0.01418888,0.018456738,-0.020177875,-0.016973482,-0.0022406257,-0.0442458,-0.02682454,-0.022346787,-0.008717625,-0.008542714,-0.0021968975,-0.009424271,-0.007090942,-0.01442676,0.0072413664,0.0017779828,-0.0063563106,-0.004918532,0.009011478,0.0036381744,0.012404775,-0.021409256,-0.00815091,-0.0022686117,0.022402758,-0.027496202,-0.014356796,-0.014888529,0.04083151,0.017085427,-0.015168388,-0.0064857453,-0.0062863454,-0.031400245,0.0023385766,0.004806588,0.00057283754,-0.007703135,0.007507233,0.012019969,0.036241814,-0.0032586148,-0.006562707,0.0029367763,0.009997983,-0.021017453,-0.020023951,0.005964507,0.0033478201,-0.021073425,0.0026569169,-0.0021269326,-0.015546199,0.022486717,-0.0054572616,-0.01695949,-0.017911013,0.0089415135,0.031372257,0.029944973,0.023941986,0.021507207,-0.022710605,-0.0136991255,0.020401763,-0.015168388,-0.014748599,-0.023368275,0.010368797,0.0015628408,0.012404775,-0.0024855027,-0.029021436,0.012404775,0.004113936,-0.005362809,0.0032131376,0.029637128,0.032995444,0.014692627,-0.019408261,-0.003981002,0.025579164,-0.023270324,-0.004316834,0.022206856,-0.030000946,0.0060589598,-0.01620387,-0.019856036,-0.018540697,-0.016049946,-0.011824067,-0.0017246346,-0.0046386723,0.014139905,0.01903045,-0.023284316,0.025187362,0.009816075,0.0015567188,-0.018260837,-0.0045127356,0.0071714013,-0.019534199,0.0036241815,0.005922528,-0.019184373,-0.010564699,0.006604686,0.017295321,0.017966984,0.010725618,0.23172373,-0.018694619,-0.013335308,0.012033962,0.018008962,0.0025344782,0.023298308,0.019240346,0.0001742563,0.010718621,0.009095436,0.019939994,0.00472263,-0.007584194,0.022752583,-0.017463237,-0.022542689,-0.00838879,0.0046526655,0.017743096,0.013992978,-0.009193387,-0.0047576125,-0.022528695,0.042902473,-0.011096432,-0.009872046,0.0028370763,0.005995991,0.006982496,-0.0075422153,-0.00304872,0.021073425,0.0012182636,-0.014293827,-0.00044143473,0.02170311,-0.008661654,0.012649653,0.0015094925,0.037053406,-0.02499146,-0.0016695373,-0.012145905,0.012782586,0.02287852,-0.019912008,-0.020387769,0.028181858,0.015560192,-0.016595673,-0.0052823494,0.0027706097,0.029049423,0.0083118295,-0.009816075,-0.011600179,0.0025099905,0.012334811,-0.01982805,-0.024207853,0.008038966,-0.008423773,0.022682618,-0.0013923014,-0.0015820811,-0.0067970892,-0.010137913,0.0181349,-0.015672136,-0.01550422,-0.015378283,-0.0075562084,-0.012845554,-0.02955317,-0.0157421,0.029049423,-0.0003662225,0.022794561,0.028965466,-0.020611657,-0.0008282094,-0.0010923268,-0.01442676,-0.009074447,-0.02124134,0.03551418,-0.006121928,-0.0064717527,-0.0069475137,-0.016147897,0.014111918,-0.011929014,0.009956004,-0.00092616025,0.00018136212,0.01050173,0.012628663,0.0053837984,0.0011867795,-0.025942981,0.07634569,0.0070734504,-0.003060964,0.00036053784,0.010200881,0.0021269326,0.023088414,0.0056111845,-0.011341309,0.0019817555,-0.018092921,0.00083564315,-0.02138127,-0.012229864,0.0027950974,0.023564175,-0.0061779,0.01564415,0.001622311,-0.030420735,-0.013034459,-0.008521724,0.011222369,0.0037851005,-0.0065976894,0.0070279734,-0.0019065433,-0.0173373,-0.00695451,0.0047296267,-0.019772079,0.008822572,0.015560192,-0.010417772,-0.022542689,-0.0173373,-0.008920523,0.017869033,-0.005114434,0.0020359783,0.016133904,-0.0057686055,-0.011257351,-0.013447252,-0.009942011,-0.012278838,0.009102432,0.0067271246,0.00038590012,-0.0048905457,0.012803575,-0.009830067,-0.015770087,0.006107935,-0.012306824,0.016007967,0.002329831,0.0028930483,-0.0050234795,-0.023592161,0.004687648,0.009494236,-0.01865264,-0.014181884,-0.018498717,-0.18235649,0.008934516,0.022374772,-0.037697084,0.010921519,0.0009655155,0.028741578,-0.012362797,-0.044189826,0.015658142,0.034926474,-0.012957498,-0.03030879,-0.0026516693,-0.0053138337,-0.012789582,-0.008815576,-0.0028493202,0.003517485,0.0137061225,0.04768807,-0.02024784,-0.0025729588,0.007097938,-0.017869033,-0.0030329782,0.0043448196,0.023088414,0.015336304,-0.03086851,-0.008990489,-0.0034457708,0.017813062,-0.0057266266,-0.008479745,-0.0038865497,0.004386799,-0.021899011,-0.021115404,-0.0008054708,0.020289818,0.016847545,0.0149724865,-0.0017351293,-0.015532206,0.0025327292,0.023410253,-0.013195379,0.005436272,-0.028825535,0.002459266,-0.007076949,0.011705127,-0.006552212,0.0020254836,0.005534223,-0.0063283243,-0.019226352,0.0044567636,-0.0046421704,0.0021391765,-0.005373304,0.011991982,0.018526703,0.0051983916,0.006212882,0.000114020906,0.014916515,-0.04091547,0.0093613025,-0.008773598,-0.005275353,-0.011250354,-0.0048555634,0.0021409257,0.035877995,-0.01847073,-0.009501233,0.0033775552,-0.0221229,-0.008612678,0.018246844,-0.0074722506,-0.0017578679,-0.004190897,-0.0045547145,-0.00046308013,0.03792097,-0.007955008,-0.013475238,0.020597665,-0.047436196,-0.0044847494,-0.014510718,-0.001450897,0.018386774,0.01418888,-0.021437243,0.0151823815,-0.0047576125,0.01365015,0.00026542932,-0.0016135654,-0.0002708953,0.030588651,0.0032568658,0.002959515,0.015098424,0.03369509,-0.006310833,-0.026754575,-0.021843038,5.5234003e-05,0.003932027,0.014384782,0.028125886,-0.0074722506,0.009914025,0.009809078,-0.0067341207,0.06599089,0.0018995468,-0.013825063,0.0144407535,-0.009081443,-0.022822548,-0.116309635,-0.046344746,-0.00454422,-0.003074957,-0.008360805,0.024263825,-0.008073948,0.0016336802,-0.028881507,0.031736076,-0.016931504,-0.030112889,0.023914,0.0018540696,-0.004306339,-0.03274357,0.0030959465,-0.006562707,-0.027832033,0.033247318,-0.012159898,-0.021437243,0.006408784,-0.021017453,0.012320817,0.0043238304,-0.033611134,-0.008339815,0.0036381744,-0.007024475,0.01024286,-0.01062067,0.014580684,1.0146276e-05,-0.003732627,-0.02349421,-0.0048870477,-0.01038279,0.020359784,-0.017883027,0.011194383,-0.003732627,-0.00072807213,-0.008906531,-0.039488185,-0.02203894,-0.0072413664,0.020793566,0.030140875,-0.021353286,-0.036913477,0.011991982,-0.019506212,0.004418283,0.009536215,-0.0028073413,-0.0034387745,0.0047925953,0.004533725,0.012803575,-0.018848542,0.0070874435,-0.009459253,-0.001508618,0.010837561,-0.029777057,-0.0034790041,-0.015756093,0.011411274,-0.020555684,-0.0051039387,-0.0032883498,-0.009060454,0.011789084,-0.015616164,-0.014006971,-0.011991982,-0.021059433,0.0054572616,-0.0044602617,-0.0056951423,-0.011789084,-0.009228369,-0.01430782,0.018218858,-0.0036381744,-0.025439234,-0.017911013,0.011117421,-0.008451759,0.0005531599,0.032071907,0.010298832,-0.027524188,0.019170381,0.014552698,-0.02827981,-6.712257e-05,0.008521724,0.010438762,-0.027454223,-0.0070454646,-0.047100365,0.028055921,-0.0030976955,-0.034114882,-0.015658142,-0.004932525,0.008738615,-0.008143913,-0.01247474,0.020163883,-0.016343798,0.010760601,-0.014300824,-0.0030627132,-0.017281327,-0.012243856,0.018848542,-0.011936011,-0.003617185,-0.0050444687,0.015378283,-0.0015890776,0.012229864,0.011495232,-0.012369793,0.0009620173,-0.0105227195,0.012691631,-0.012103926,-0.013020466,-0.0036731567,-0.022136891,0.0034685095,0.023060428,-0.00075124804,0.0012829812,-0.013181386,0.032967456,0.02720235,0.022066927,-0.0034405235,-0.03260364,-0.0006799713,-0.018932499,-0.0036276795,-0.0105227195,-0.005737121,-0.007668152,-0.0075562084,-0.0017744845,0.024865523,0.006489244,-0.0072413664,-0.03974006,0.006622177,0.020177875,-0.009809078,-0.017952992,-0.0065312227,0.0047506164,0.043909967,-0.012208873,-0.0045687077,-0.0009655155,0.006702637,-0.009081443,-0.0031973955,0.010487737,0.018484725,-0.0038235814,0.0074442644,0.008437766,-0.003132678,0.017603166,-0.009004481,-0.02048572,0.009452257,0.0018418258,0.0030207343,0.032911487,0.012901526,0.0013975487,-0.009662151,-0.00010811762,0.00472263,0.004719132,-0.010697632,0.008717625,-0.00880858,0.004848567,0.028713591,0.0140209645,-0.014412767,0.011852053,-0.015490227,-0.018568682,-0.0045547145,-0.009494236,0.015378283,0.022584667,-0.007269352,-0.0014089181,-0.0068425667,-0.030280804,-0.02560715,0.023102406,-0.012670642,-0.037864998,-0.0048275776,0.033331275,0.032799542,-0.0020692116,0.0014386531,0.009256355,-0.018260837,0.024235839,-0.011551203,-0.0231164,-0.036213826,0.020135896,0.025928989,0.0011124418,-0.0026639132,-0.008605681,0.01167714,0.032967456,0.024697607,-0.009494236,0.006247865,0.029469213,0.00055053626,0.0013188382,-0.005096942,-0.008262854,-0.0181349,-0.025663123,-0.018302815,0.0077171274,0.015210368,0.06862157,0.01588203,-0.008682643,0.01987003,-0.022206856,0.020471727,0.034366757,-0.0046561635,-0.024123894,-0.012243856,-0.012306824,0.010354804,-0.014132909,0.005821079,0.0024382765,0.017267335,-0.00840978,0.00354722,-0.018050943,0.017799068,0.008451759,-0.0031431727,0.02343824,-0.0027566168,-0.017687125,0.015210368,0.0061289244,0.0068565593,0.0027846028,-0.01616189,0.025733087,0.014237856,-0.02480955,-0.022192864,-0.008227872,0.011831063,-0.0060309735,-0.034982447,-0.002931529,0.0028090903,-0.0066991383,-0.021745088,-0.01747723,0.0033845517,-0.009879042,0.0089415135,-0.010473744,-0.019520205,-0.015714115]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011416124,0.0045209257,-0.0021571573,-0.01470789,-0.0025196017,0.024527159,-0.015324221,0.01759344,-0.011325076,-0.034486502,0.00473454,0.016024597,-0.01606662,0.013580286,-0.0029941064,-0.025101466,0.027987015,0.00641194,-0.011584215,-0.014224632,-0.0036349501,0.017705498,-0.00704578,-0.038744785,0.0070983083,0.03375811,0.02790297,-0.015408266,0.022804234,0.009097881,-0.005998718,0.015310214,-0.037680216,-0.024233,0.0012028953,-0.00015922605,0.010183464,-0.0008789716,0.004041168,0.0044438844,0.011142978,0.0065169963,0.0013771139,-0.014791936,-0.008040314,-0.008278442,0.015548342,-0.039893404,-0.008047317,-0.013384181,0.010393576,0.024975399,-0.019134266,-0.012648786,-0.016304748,-0.0029678422,-0.004853604,0.009181926,0.013664331,-0.014918003,0.021235393,0.018111717,-0.017691491,-0.001459408,-0.021669626,0.0044964124,-0.02475128,-0.012326613,-0.0140635455,0.0076621105,0.034486502,0.010274513,-0.010113426,-0.025689783,0.034710623,-0.007248889,-0.00352289,-0.025787836,-0.013916466,0.016318755,-0.0009157413,-0.023434572,-0.015198153,0.02052101,0.012480696,-0.016879056,0.0034983768,0.015534334,-0.013475229,0.0036944821,-0.0039956435,-0.0008378245,0.020338912,0.015240177,0.007739152,-0.0058131185,-0.008642637,0.026039971,0.0011433634,0.009819268,-0.0071543385,-0.0036314484,-0.021053296,-0.009812265,-0.0147499135,0.0029713442,0.013804406,0.003754014,0.0058691488,-0.013342158,-0.03619542,0.03546703,0.011731294,-0.038128454,-4.07367e-05,-0.009903314,0.007634096,-0.017859582,0.0037049877,-0.015982574,0.023686707,0.014455755,0.018083703,-0.008607618,0.012067474,-0.0065415096,-0.006177314,-0.011633242,-0.017243251,-0.0134192,0.0011993934,0.010729756,0.005074222,0.01921831,-0.015086094,0.017425349,-0.014371711,0.013293132,-0.025437647,-0.030536383,0.007704133,0.00520029,-0.01962453,0.017943626,-0.002024086,0.016080627,0.010995899,0.026292106,0.0169631,0.013012981,0.002134395,-0.038296547,0.021739664,0.029303722,0.016542876,0.021053296,-0.029499827,-0.009364024,-0.02119337,-0.008159378,-0.0073189265,0.013783394,0.005953194,0.018223777,0.010750768,0.0100644,0.014665868,-0.005284335,0.012480696,0.004310813,-0.011255038,0.03174103,-0.028883496,0.0005064592,-0.0069687385,0.019386401,0.021179363,-0.0057115643,-0.017467372,-0.025521692,0.017271265,-0.0017439356,0.005042705,0.024961391,-0.019330371,-0.023714723,0.016865049,-0.012263579,0.005175777,0.0019155276,0.018728048,0.016136657,-0.0018034675,0.004990177,-0.6701195,-0.021893745,0.0039045948,-0.025353603,0.015492312,0.016991116,-0.0020818668,-0.01623471,-0.03258148,0.012403655,-0.021221384,0.0067446185,0.028001023,-0.02885548,-0.0072979154,-0.026081992,-0.0030116157,-0.033281855,0.009665186,0.0028995557,-0.018700033,0.015968567,-0.019246325,-0.009041851,-0.0014734155,0.028673382,0.0016266226,-0.016795011,0.018798085,0.010127434,-0.009350017,0.033618037,0.0053578746,0.015618379,0.043647416,-0.020955242,-0.0070387763,0.015576357,0.0001509091,0.050427053,-0.033057734,-0.011885377,0.004885121,0.0005830628,-0.011206012,0.003782029,0.022384008,0.0025511186,0.020100784,0.010638707,0.012074478,0.015758455,0.0096371705,0.008404509,0.020100784,-0.020492995,0.023154423,-0.011409121,0.0115001695,0.008299452,0.01259976,0.0052072937,-0.017033137,-0.0064504608,-0.007192859,0.02620806,-0.021165356,0.013881448,-0.004650495,-0.04583259,-0.0068601803,0.017145198,-0.021543559,0.005403399,-0.011086948,0.02598394,0.015338229,0.016444823,0.017775537,0.018952169,-0.00042613488,-0.030760502,0.004191749,0.020352919,0.033842158,-0.00071394554,-0.03314178,-0.008887769,-0.004661001,0.0026596768,0.0077321483,0.019358385,-0.016598905,-0.019512469,0.0014944267,0.036391523,-0.009868294,0.01662692,-0.01617868,-0.015072086,-0.0023602662,-0.010778783,0.009735223,-0.007241885,-0.010372565,0.0052177995,0.00047625552,0.027720872,0.020002732,-0.020408949,0.010267508,0.019204304,-0.011822343,0.0145117855,-0.012263579,-0.033702083,0.040817898,-0.014280662,0.00079361326,-0.0073469416,0.0034143317,0.0127678495,0.007746156,-0.018335838,0.0076481034,0.033057734,-0.014322684,-0.031236758,-0.0139304735,0.00831346,0.02272019,-0.018265799,0.0142876655,-0.0123056015,0.017705498,-0.00057605904,-0.0005165271,0.002024086,0.004247779,-0.0225521,-0.004538435,0.011290058,0.0015767209,0.01792962,-0.02592791,-0.0040271604,-0.008005295,0.008103347,-0.005546976,-0.008894772,-0.010841817,-0.021151347,-0.012480696,-0.020380935,0.0053193537,0.008418516,0.015352236,-0.031236758,-0.025801843,-0.027664842,0.010673727,0.025619745,-0.015646394,0.017551417,-0.015562349,0.006870686,-0.001619619,0.034234367,0.0073189265,-0.022482062,0.014735905,-0.02790297,0.009588144,0.013146053,-0.0027874955,0.002540613,0.0050357017,-0.013167064,-0.021333445,-0.014875981,0.00090260926,-0.000845266,0.011661257,-0.0004480216,0.014497778,0.009090877,0.024569182,0.01090485,-0.016724972,0.03507482,-0.0062753665,0.011934402,-0.01815374,-0.010197471,-0.00052571954,-0.007844209,0.008502562,-0.016598905,0.0024723264,0.015702425,0.01668295,0.019736588,0.008061325,-0.0072348816,0.0070983083,-0.018419882,-0.0011346088,-0.014105568,0.019134266,0.014154594,0.026250083,-0.040005464,-0.021291424,-0.006849675,0.0119624175,0.009826272,0.00017772034,0.01178032,-0.021501536,0.015646394,-0.035326954,0.0009498846,0.012564741,-0.0002836522,-0.018700033,0.010701741,-0.0034791166,0.019932695,0.014280662,-0.014889988,0.006068756,0.026950458,-0.0005651157,0.031600952,0.021039288,-0.01804168,0.010407584,0.005967201,0.002139648,0.0024618208,-0.0049376492,0.0069652367,-0.015100101,0.0057115643,0.0359713,-0.009216945,0.033674065,0.019260334,-0.026992481,-0.0015968567,-0.01189238,0.009399042,-0.0035579088,-0.009139904,0.009167919,0.004801076,0.01425965,-0.006156303,-0.0039326097,0.02046498,0.0069722407,0.020044753,0.033393916,-0.012263579,0.027930984,-0.0047065252,-0.012410658,-0.03230133,-0.02272019,0.0031621966,-0.013650323,-0.00038805194,0.0059636994,-0.028029038,0.025997948,0.017061153,0.01713119,0.014721898,0.034178335,0.016192688,-0.034094293,-0.026936451,0.018924152,0.005315852,-0.00902084,0.0048956266,-0.022019813,0.010764775,-0.010330542,0.0074590016,0.021515543,0.017369319,-0.0038065421,-0.004829091,-0.018503927,0.003936112,0.031348817,-0.011633242,-0.0011950161,-0.006096771,0.0074169794,0.01966655,-0.0051372563,-0.041742396,0.017103177,-0.031376835,0.031152714,-0.0071683456,-0.016935086,-0.019316364,0.0065730265,-0.025227534,0.022341987,-0.018517936,0.014189613,0.0016914074,0.008103347,-0.017215235,0.030060127,0.018125724,0.0056695417,-0.026278099,-0.02424701,0.008859754,0.06376221,0.052724287,-0.0058096168,0.01955449,-0.0023445077,-0.007077297,-0.013762384,-0.0054419194,0.0067551243,-0.0040831906,-0.010183464,-0.019078236,0.018321829,-0.010883839,0.0051687732,0.007746156,0.018223777,-0.014357703,-0.02266416,-0.03964127,-0.0070387763,0.007543047,0.041322168,0.031993166,0.008929791,0.0063979323,0.028645368,0.0140635455,-0.013398188,-0.018307822,0.016052613,0.015772462,0.009686196,0.005984711,0.002918816,0.037848305,0.0005392893,0.014343696,0.020591047,0.011990433,0.015478304,0.008719678,0.0074309865,-0.0052423123,-0.014819951,-0.007070293,-0.011346087,-0.0010820805,-0.0015530832,-0.013033993,-0.00022521458,-0.016318755,-0.04381551,-0.008103347,0.011065937,0.0010838314,-0.017663477,-0.008432524,-0.004909634,-0.00036901046,-0.026488211,-0.023812776,-0.003580671,0.0035666635,0.018223777,-0.01651486,-0.006650068,0.004794072,-0.030396307,-0.008635633,-0.012445677,-0.03585924,-0.019764604,-0.0050672186,0.034122307,0.01837786,0.024485135,-0.0070983083,-0.0138114095,0.0066360603,-0.005133754,-0.0027997522,-0.01138811,-0.0028732915,0.017467372,-0.007423983,0.0012720574,-0.0032742566,-0.0056170137,0.01375538,-0.0011897633,0.007991287,-0.0039115986,-0.020717114,-0.0218097,0.010407584,0.02169764,0.03330987,-0.009854287,-0.025395624,0.007395968,-0.030116158,-0.021067303,-0.009048855,-0.005659036,-0.006320891,0.0043493332,-0.00803331,-0.010106422,0.0032514944,0.031825073,-0.012452681,0.011955414,0.0036314484,0.005511957,0.030312262,0.0013972496,0.009504099,-0.018980183,-0.024233,0.011283053,-0.024611203,0.006037239,0.0038205497,-0.03353399,0.012606763,0.017607447,0.0061002728,-0.033225827,0.015240177,-0.013608301,0.048213866,-0.016206695,-0.0017728261,-0.016248718,-0.00030882194,-0.013132045,-0.0035018788,-0.012466689,-0.0033092755,0.0065765283,-0.02001674,-0.010463614,-0.009938332,0.0034791166,-0.033590022,-0.012466689,0.024261016,0.004801076,0.010715749,0.0027542277,-0.0074590016,-0.0057115643,-0.0072348816,0.00055548555,-0.01961052,-0.0045209257,0.007844209,0.011458147,0.027118549,0.021221384,-0.007711137,0.016500853,0.010988896,-0.014693883,0.0001996071,0.0008281943,0.021067303,-0.013384181,0.03557909,-0.0034686108,-0.0076621105,-0.01442774,0.007021267,0.026614279,0.007451998,-0.017691491,-0.018629994,-0.029387766,-0.028603345,0.016640928,0.013012981,-0.008985821,-0.0037435084,-0.021739664,0.0026964466,0.002892552,0.0045279292,-0.0017273017,-0.010645712,0.006033737,-0.0075570545,0.023420565,-0.0022131873,0.018293815,-0.017733514,-0.030620428,-0.0285193,0.010211479,0.031236758,-0.018517936,0.026348136,0.017943626,-0.008642637,0.0039151004,-0.0028417746,0.0023602662,0.00825743,-0.004762555,-0.013307139,0.016584897,-0.023042362,-0.025745813,-0.007865219,0.004048172,0.012473692,-0.011696275,0.013062008,0.0068881954,-0.021375468,0.020296888,-0.003785531,0.048662107,0.022804234,0.023098392,0.025059445,0.0013420951,0.0037785273,0.0016782754,0.003901093,0.013461222,0.019302355,0.009868294,-0.010274513,-0.021781687,0.0043143146,0.017635461,-0.024765287,-0.017201228,-0.011163989,0.001992569,0.002510847,-0.002542364,-0.008320464,0.011864365,-0.00346686,-0.010953877,0.008453535,0.018055687,-0.01189238,-0.0032269813,0.026670309,0.01820977,0.027314654,-0.010225486,0.0030799024,0.004076187,0.009406046,0.023532625,0.013496241,-0.020212844,0.029443797,-0.009202938,-0.005914673,0.024471128,-0.0054419194,0.015478304,-0.007241885,0.0043213186,0.030536383,-0.014777929,0.012102493,-0.0065415096,0.006488981,0.007073795,-0.0073679527,-0.0014427741,-0.008726682,-0.009700204,0.02356064,0.012613767,0.008243423,-0.031040654,-0.0031166722,-0.0020993764,-0.012298598,-0.0012554235,0.006065254,-0.0011284804,-0.033562005,-0.027258623,-0.008306457,0.01617868,0.036615644,-0.0054734363,-0.023644686,0.012067474,0.017551417,-0.032049194,0.01629074,0.01899419,-0.01259976,-0.01916228,0.011682267,-0.018587973,-0.035943285,0.010757771,-0.017509393,-0.03860471,-0.02536761,0.0016117397,-0.004506918,0.0022359495,-0.022033822,-0.0058201225,-0.0055679874,0.0033670564,0.003500128,-0.025577722,0.016724972,0.009602152,0.0028225144,0.01601059,-0.014266654,0.018517936,-0.02018483,-0.01690707,-0.0022306968,-0.044263747,-0.02682439,-0.022370001,-0.008705671,-0.008530577,-0.0022341986,-0.009427058,-0.007077297,-0.014413733,0.007248889,0.0017588186,-0.0063699177,-0.004934147,0.009034847,0.0036314484,0.0124386735,-0.021389475,-0.008124359,-0.0022622137,0.022426032,-0.027482744,-0.014385718,-0.014889988,0.040817898,0.017061153,-0.015156131,-0.0064749736,-0.006268363,-0.031376835,0.0023164928,0.004762555,0.0005493572,-0.007627092,0.0074660056,0.012018448,0.036223434,-0.003325034,-0.006552015,0.00294508,0.009980354,-0.020927228,-0.02001674,0.0059601977,0.003321532,-0.02113734,0.002629911,-0.0021308933,-0.015534334,0.022496069,-0.0054489234,-0.016935086,-0.017901605,0.008901776,0.031320803,0.029948067,0.023924835,0.021487528,-0.022790227,-0.013748376,0.020408949,-0.015156131,-0.014763921,-0.02339255,0.010428595,0.0015670907,0.012466689,-0.0024915868,-0.028995557,0.012403655,0.0040831906,-0.005333361,0.0031727022,0.029639902,0.033001706,0.0147499135,-0.019400408,-0.0040341644,0.025563715,-0.023322513,-0.0043213186,0.02220191,-0.030004097,0.0060617523,-0.016206695,-0.019834641,-0.018503927,-0.01606662,-0.011794328,-0.0017596941,-0.0046084723,0.014133583,0.018980183,-0.023308504,0.025129482,0.009791253,0.0015557096,-0.018223777,-0.0045524426,0.0071683456,-0.01955449,0.0036279464,0.0059216768,-0.01916228,-0.010575674,0.006590536,0.017257258,0.017943626,0.010736761,0.23174033,-0.01865801,-0.013384181,0.012046463,0.01804168,0.0024898357,0.023238467,0.01921831,0.00016918452,0.010687734,0.009090877,0.019932695,0.004713529,-0.0075990767,0.022706183,-0.017411342,-0.022566106,-0.008404509,0.0046855137,0.017747521,0.014000512,-0.009160914,-0.004738042,-0.022566106,0.042947043,-0.011058933,-0.009896309,0.002831269,0.006047745,0.0069197123,-0.007564058,-0.003064144,0.02108131,0.001200269,-0.014336691,-0.00043160655,0.021669626,-0.008663648,0.012690809,0.0015163135,0.03703587,-0.025003415,-0.0016581396,-0.012144515,0.012795865,0.022874271,-0.019904679,-0.020408949,0.028141098,0.015576357,-0.016584897,-0.0052773315,0.0027927484,0.029023571,0.008306457,-0.009833275,-0.011654252,0.0025073453,0.012326613,-0.019806627,-0.024218993,0.008047317,-0.008446531,0.022692174,-0.0014033779,-0.0015767209,-0.0067656296,-0.010057396,0.018167747,-0.015716432,-0.015506319,-0.015380251,-0.007592073,-0.012816876,-0.029499827,-0.015758455,0.029079601,-0.00038761421,0.022790227,0.029023571,-0.02063307,-0.00085839804,-0.0010899598,-0.014385718,-0.009146907,-0.0212494,0.035495043,-0.006156303,-0.0064539625,-0.006898701,-0.01617868,0.01409156,-0.0119624175,0.010001366,-0.00095951476,0.0001753128,0.01045661,0.012585753,0.00542441,0.0011766313,-0.025955925,0.076312944,0.007052784,-0.0030361288,0.00033771244,0.010190467,0.0020923726,0.023042362,0.0055574817,-0.011402117,0.0019452936,-0.018139731,0.00082863204,-0.021403482,-0.012193542,0.0028172615,0.02356064,-0.006215835,0.015618379,0.0016152415,-0.030424323,-0.013083019,-0.008579603,0.011248034,0.003785531,-0.0065765283,0.0070282705,-0.0018665014,-0.017341303,-0.0069967536,0.004710027,-0.01972258,0.008838742,0.015590364,-0.010449606,-0.022566106,-0.017327296,-0.008894772,0.017901605,-0.0051197466,0.0020468482,0.01612265,-0.005767594,-0.011283053,-0.013426203,-0.009966347,-0.012298598,0.00902084,0.006720105,0.00033771244,-0.0048641097,0.012788861,-0.00986129,-0.015814485,0.0061352914,-0.012347625,0.01595456,0.0022902286,0.0029258197,-0.004969166,-0.023602663,0.0046329857,0.009539118,-0.01865801,-0.014217628,-0.018517936,-0.182658,0.0089367945,0.022355994,-0.037792277,0.010960881,0.0009805261,0.028743422,-0.012368636,-0.044179704,0.015632387,0.034934744,-0.012949947,-0.030284248,-0.0026789373,-0.0053508705,-0.012816876,-0.008845746,-0.0028452764,0.0035649126,0.013734369,0.04768158,-0.020254867,-0.0026088997,0.007077297,-0.017817559,-0.003029125,0.004363341,0.023070376,0.015338229,-0.030900579,-0.008978817,-0.003440596,0.017859582,-0.005743081,-0.008502562,-0.0038905872,0.00438085,-0.021893745,-0.021151347,-0.00082863204,0.020310897,0.016865049,0.0149880415,-0.001748313,-0.015562349,0.002596643,0.023434572,-0.01321609,0.005406901,-0.028827466,0.0024478133,-0.007108814,0.011696275,-0.0065064905,0.0020153313,0.0055399723,-0.00635591,-0.019204304,0.004419371,-0.004643491,0.0021484026,-0.005413905,0.012011444,0.018573964,0.005140758,0.0062123328,9.9639394e-05,0.014875981,-0.04087393,0.009336009,-0.008866757,-0.005273829,-0.011255038,-0.004881619,0.002136146,0.03585924,-0.018461905,-0.009511103,0.0033688073,-0.02215989,-0.008600614,0.018265799,-0.0074169794,-0.0017194225,-0.004216262,-0.0045279292,-0.0004548065,0.03793235,-0.007949265,-0.013475229,0.020661084,-0.047429446,-0.0044754012,-0.0145117855,-0.0014427741,0.018363852,0.014231635,-0.021431498,0.015226169,-0.004811581,0.01364332,0.0002854031,-0.0016616415,-0.00029984835,0.030592414,0.0032865133,0.0029625895,0.015072086,0.033730097,-0.0063103857,-0.026768362,-0.021823708,0.000102648824,0.003936112,0.014399725,0.028169112,-0.0074940207,0.009903314,0.009826272,-0.006783139,0.06605944,0.0018840107,-0.013832421,0.014441748,-0.009006832,-0.02283225,-0.11643046,-0.04633686,-0.004499914,-0.0030851553,-0.008418516,0.024275023,-0.008075332,0.0016318755,-0.028883496,0.031769045,-0.016921079,-0.030116158,0.023882814,0.0018227278,-0.004300307,-0.03269354,0.0030851553,-0.0065940376,-0.027860947,0.03330987,-0.012130508,-0.021431498,0.006429449,-0.02102528,0.012312606,0.004307311,-0.033674065,-0.008292449,0.003666467,-0.007010761,0.010246498,-0.010603689,0.014553808,-2.8897338e-07,-0.0037084897,-0.023476595,-0.0048466003,-0.010379569,0.020338912,-0.01792962,0.011177997,-0.0037470104,-0.00071438326,-0.008859754,-0.03944516,-0.022047829,-0.00721387,0.02080116,0.030144172,-0.02136146,-0.036951825,0.011990433,-0.019526476,0.0044754012,0.009616159,-0.0028785444,-0.0034143317,0.0048080795,0.0045209257,0.012760846,-0.018840108,0.007042278,-0.009441065,-0.0014944267,0.010876835,-0.029723946,-0.0034878713,-0.015800476,0.011430132,-0.02057704,-0.005081226,-0.0032199775,-0.009062862,0.011822343,-0.015632387,-0.014021522,-0.011969422,-0.02108131,0.0054384177,-0.004503416,-0.005718568,-0.0117382975,-0.009202938,-0.014343696,0.018307822,-0.003725999,-0.025437647,-0.017971642,0.01107294,-0.008502562,0.00056599115,0.03202118,0.010323538,-0.027496751,0.01916228,0.014581823,-0.028323196,-0.000103579005,0.008530577,0.01040058,-0.027468737,-0.0070317728,-0.047149297,0.028043045,-0.0031096684,-0.034122307,-0.015646394,-0.004969166,0.00874069,-0.0081313625,-0.012480696,0.0201288,-0.016332762,0.010799794,-0.014308677,-0.0030869062,-0.017313289,-0.012256576,0.018868122,-0.011941407,-0.0036174408,-0.0050707203,0.015310214,-0.0015784719,0.012207549,0.011430132,-0.012333617,0.0009656431,-0.010554663,0.0126768015,-0.01209549,-0.013069011,-0.0037084897,-0.022089852,0.0035106335,0.023084385,-0.00079711515,0.0012773103,-0.013181072,0.033001706,0.027258623,0.022061836,-0.003465109,-0.03258148,-0.00061370427,-0.018896138,-0.003638452,-0.01051264,-0.005715066,-0.007655107,-0.007564058,-0.0017325545,0.024835324,0.0065240003,-0.0072068665,-0.03972531,0.006587034,0.02018483,-0.00978425,-0.017943626,-0.0064749736,0.0047450457,0.043871537,-0.012186538,-0.0045279292,-0.00094900915,0.006727109,-0.009034847,-0.0032147246,0.010491629,0.018461905,-0.0038450628,0.0074590016,0.008460539,-0.003060642,0.01757943,-0.008992825,-0.020450972,0.009462076,0.0018262297,0.0030063628,0.03291766,0.01287991,0.0013701101,-0.009679193,-9.15413e-05,0.0047520497,0.00473454,-0.010750768,0.008670651,-0.00879672,0.0048571057,0.028715406,0.0140495375,-0.014399725,0.0118573615,-0.015464297,-0.018531943,-0.004562948,-0.00946908,0.015380251,0.022594122,-0.0073189265,-0.0014033779,-0.0068076523,-0.030284248,-0.025563715,0.023126407,-0.012683805,-0.037792277,-0.004853604,0.033281855,0.03274957,-0.002048599,0.0014664117,0.009230953,-0.018279808,0.024261016,-0.011563203,-0.023140416,-0.03619542,0.020142807,0.025955925,0.0010488126,-0.0026194053,-0.008628629,0.011675264,0.032945674,0.024681242,-0.00952511,0.006268363,0.02947181,0.00053316104,0.0012843141,-0.005091732,-0.0082504265,-0.018069694,-0.025619745,-0.018307822,0.0077181407,0.0152121615,0.068692856,0.015940553,-0.008684659,0.019890672,-0.022187904,0.020478986,0.034374442,-0.004611974,-0.024134949,-0.012277587,-0.0123056015,0.010372565,-0.01409156,0.0057921074,0.0024338057,0.017285274,-0.0084745465,0.0035999313,-0.01804168,0.017803552,0.008495558,-0.0031324306,0.02344858,-0.0027489748,-0.017649468,0.0152121615,0.006117782,0.0068076523,0.0027489748,-0.016206695,0.025717797,0.014210624,-0.0247933,-0.02221592,-0.008222411,0.011822343,-0.0060022203,-0.034934744,-0.002948582,0.002857533,-0.0067236074,-0.021739664,-0.017509393,0.0033723093,-0.00986129,0.008929791,-0.010435599,-0.019512469,-0.015758455]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.7751790543147501
0.8035834943263529
0.7754398183840793
0.7934465954370915
0.7718847752010625
0.763653923882888
0.7605665662062044
0.7636447899989841
0.7707312078126828
0.7841727230692863
0.777923876457802
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011758567,0.004514309,-0.0021783556,-0.014765188,-0.0025058093,0.024515254,-0.015311528,0.01758094,-0.011333052,-0.03448946,0.004748955,0.015997956,-0.01605399,0.013560438,-0.002992612,-0.02511763,0.027989417,0.006405486,-0.011529174,-0.014246865,-0.003656275,0.017735036,-0.0070463847,-0.03877613,0.007130437,0.03376101,0.027905364,-0.015423598,0.0228202,0.009126679,-0.0060272506,0.01528351,-0.037711468,-0.02424909,0.0011793588,-0.00014741985,0.010191342,-0.0008917424,0.0040730345,0.004416248,0.011164947,0.006486036,0.0013658499,-0.014723161,-0.008041004,-0.008195099,0.0155636845,-0.03984079,-0.008048008,-0.013427355,0.010352442,0.024935516,-0.019135907,-0.012670885,-0.016320156,-0.0029610926,-0.0048575224,0.009182714,0.013679512,-0.014905275,0.021251224,0.018071245,-0.01769301,-0.0014586577,-0.021643467,0.004489794,-0.024767412,-0.012313662,-0.014071756,0.007655764,0.034545496,0.010282398,-0.010072268,-0.025720004,0.0347136,-0.007242507,-0.00353545,-0.025818065,-0.013931669,0.016292138,-0.0008746693,-0.023422575,-0.01517144,0.020536778,0.012474762,-0.016866496,0.0034513976,0.0155636845,-0.013497399,0.0037088078,-0.003974973,-0.00084752735,0.020340657,0.015255493,0.007718803,-0.005838133,-0.008608356,0.026070222,0.001182861,0.009848128,-0.0071619567,-0.003614249,-0.02106911,-0.009834119,-0.014751179,0.002950586,0.013763565,0.003729821,0.0058696526,-0.0133433025,-0.03622654,0.035442054,0.011725296,-0.03813173,-3.603414e-05,-0.009925176,0.0076697725,-0.017819088,0.003729821,-0.01594192,0.023702748,0.014456996,0.018085254,-0.008601353,0.012082518,-0.006542071,-0.006191853,-0.0116412435,-0.017286757,-0.013378325,0.001221385,0.010709664,0.005085164,0.019163925,-0.015087388,0.017440852,-0.01441497,0.013287268,-0.025467847,-0.030539002,0.0076697725,0.0051867273,-0.019626213,0.017987192,-0.0020470237,0.016110025,0.010947812,0.026266344,0.016992575,0.01300009,0.0021450848,-0.03832785,0.02172752,0.029278219,0.016572312,0.021055102,-0.029558392,-0.009378836,-0.021195188,-0.0081530735,-0.007347572,0.013763565,0.0059572067,0.018211331,0.01075169,0.010037245,0.014709153,-0.0053093038,0.012481767,0.004314685,-0.011284022,0.031715736,-0.028857958,0.0005073782,-0.006976341,0.019360047,0.021195188,-0.0056945435,-0.017482879,-0.025509873,0.01724473,-0.0017108145,0.0050291293,0.0249075,-0.019346038,-0.023716757,0.016852487,-0.012271636,0.0052042385,0.0019437094,0.01877168,0.01615205,-0.001796618,0.0049485792,-0.67017704,-0.021853598,0.0038944234,-0.025257716,0.015493641,0.016992575,-0.0020943033,-0.01627813,-0.032584276,0.012446745,-0.021223206,0.006720682,0.028017433,-0.028885974,-0.0072705243,-0.026084231,-0.0030363894,-0.033284713,0.009666014,0.0029155642,-0.01867362,0.015969938,-0.019247977,-0.009021614,-0.001525199,0.0286058,0.001632891,-0.01681046,0.018799698,0.010114294,-0.009413858,0.033676956,0.005333819,0.015633728,0.043595128,-0.02095704,-0.0070393803,0.0155917015,0.00021604069,0.050403364,-0.033004537,-0.011928422,0.004920562,0.00056997966,-0.011213978,0.00379286,0.022343904,0.0025705996,0.020130526,0.010625612,0.012047497,0.01573179,0.0096379975,0.00840523,0.020116517,-0.020466736,0.023156408,-0.011396091,0.011487148,0.00829316,0.01261485,0.0051867273,-0.01702059,-0.00644401,-0.0071794675,0.026238326,-0.021153163,0.013882639,-0.004633383,-0.045864537,-0.0068817823,0.01714667,-0.021545406,0.0054073646,-0.011087899,0.025958152,0.015325536,0.016460242,0.017777061,0.018925777,-0.00041785376,-0.03079116,0.0042096195,0.020396693,0.03384506,-0.0007253889,-0.03320066,-0.008881526,-0.0046964223,0.0026896736,0.007753825,0.019346038,-0.016572312,-0.01954216,0.0014691642,0.03639465,-0.009890154,0.016614338,-0.016180068,-0.015045362,-0.0023359535,-0.010765699,0.009750067,-0.007249511,-0.010331429,0.0052112425,0.00045966104,0.027779285,0.020018457,-0.020382684,0.010268389,0.019191943,-0.0118443705,0.014513031,-0.012306658,-0.033704974,0.040877435,-0.014267879,0.00082695205,-0.007410611,0.0033901094,0.012768946,0.007753825,-0.01833741,0.0076347506,0.033004537,-0.014295896,-0.031155387,-0.013966691,0.008321178,0.022708131,-0.018267367,0.014281887,-0.012292649,0.017679,-0.0005454644,-0.0005012494,0.0020435215,0.0042341347,-0.022526016,-0.0045738462,0.011305034,0.0015812339,0.017931158,-0.02588811,-0.0040275063,-0.007991973,0.008090034,-0.005508928,-0.008881526,-0.010842747,-0.02118118,-0.012488771,-0.020396693,0.005298797,0.008419239,0.015339545,-0.031239439,-0.025790049,-0.027695233,0.0106466245,0.025677979,-0.015633728,0.01758094,-0.0155776935,0.006864271,-0.0016495264,0.03426532,0.0073055457,-0.022455974,0.014765188,-0.027891355,0.009602975,0.013189207,-0.0027807304,0.0025635953,0.00504664,-0.013175198,-0.021293249,-0.014905275,0.00085102953,-0.0008488407,0.011662257,-0.00042901695,0.014499022,0.009126679,0.024599306,0.010919794,-0.016726408,0.035105843,-0.006272403,0.011942431,-0.018169306,-0.0101563195,-0.00054940436,-0.007851886,0.008475274,-0.016656365,0.002444521,0.01571778,0.016614338,0.019724274,0.008033999,-0.0072705243,0.0071199303,-0.018407455,-0.0011119419,-0.014127791,0.019135907,0.014197835,0.026280353,-0.040008895,-0.021279242,-0.0068152407,0.011998466,0.00982011,0.0001967787,0.011788336,-0.02150338,0.01560571,-0.035329983,0.00096835254,0.01256582,-0.00027513996,-0.018743664,0.010695656,-0.003477664,0.019892378,0.0143239135,-0.014863249,0.0060692765,0.026952771,-0.0005594731,0.031631682,0.021027084,-0.018071245,0.010415481,0.0059291893,0.0021590935,0.0024497744,-0.00496609,0.0069728387,-0.0151013965,0.0057155564,0.035974383,-0.009238749,0.03373299,0.01920595,-0.027008805,-0.0016031226,-0.011851374,0.009427867,-0.0035512098,-0.009126679,0.009168705,0.004829505,0.014274882,-0.00617084,-0.0039189383,0.020466736,0.006976341,0.020032465,0.033368763,-0.012250623,0.02794739,-0.004748955,-0.012425732,-0.0323041,-0.022708131,0.0031712232,-0.013609469,-0.00038677192,0.0059572067,-0.028031442,0.026014186,0.017076626,0.017160678,0.014765188,0.034237303,0.01616606,-0.034097217,-0.026952771,0.018897759,0.0053093038,-0.008979588,0.0048575224,-0.022063728,0.010779708,-0.010275394,0.0074176155,0.021517389,0.0173568,-0.003831384,-0.0048260028,-0.018491507,0.003974973,0.031351507,-0.011571201,-0.0012012474,-0.0061288136,0.0074176155,0.01965423,-0.0050746575,-0.041745976,0.017048609,-0.031351507,0.031099351,-0.0071549523,-0.016964557,-0.01931802,0.0065770927,-0.025271725,0.022315886,-0.018491507,0.01419083,0.0017143168,0.008111048,-0.017202705,0.030090723,0.018169306,0.0056560193,-0.026280353,-0.024263097,0.008867518,0.063823715,0.05270079,-0.005799609,0.01952815,-0.0023114383,-0.0070709,-0.013784577,-0.0054458887,0.006738193,-0.0040275063,-0.01020535,-0.019065864,0.018309394,-0.010898782,0.0051692165,0.007732812,0.018197324,-0.014400961,-0.022708131,-0.03964467,-0.0070428825,0.00758572,0.04126968,0.031967893,0.0089025395,0.006349451,0.02861981,0.014064752,-0.013413346,-0.018295385,0.01605399,0.015759807,0.009701037,0.005964211,0.002913813,0.03787957,0.00055159326,0.014330917,0.020578805,0.011991462,0.015451615,0.008692409,0.0074316245,-0.0052497666,-0.014835231,-0.007091913,-0.011319043,-0.0011031865,-0.0015278257,-0.013028107,-0.00021385182,-0.016320156,-0.04379125,-0.008097039,0.011080896,0.0010988087,-0.017664991,-0.008433248,-0.0049135573,-0.0003600678,-0.026462466,-0.023814818,-0.003593236,0.0035722228,0.01822534,-0.016502269,-0.006657643,0.0047944835,-0.030398916,-0.008650383,-0.012418727,-0.035862315,-0.01975229,-0.0050711557,0.034125235,0.018407455,0.024473228,-0.007105922,-0.013826604,0.0066891625,-0.0051236884,-0.0027719748,-0.011424108,-0.002856027,0.017440852,-0.0074386285,0.0012826731,-0.0032675331,-0.005620998,0.013777573,-0.0011977453,0.00797096,-0.0039329473,-0.020704884,-0.021797564,0.010415481,0.021769546,0.033284713,-0.0098971585,-0.025411813,0.007389598,-0.030146759,-0.02106911,-0.009042627,-0.005631504,-0.006314429,0.004356711,-0.008076025,-0.0101563195,0.0032377646,0.031827804,-0.012467758,0.011921418,0.0035827293,0.0054669017,0.03034288,0.001377232,0.009518923,-0.01898181,-0.02423508,0.011256004,-0.024585297,0.0060237483,0.003831384,-0.033508852,0.0126078455,0.017608957,0.006118307,-0.033228677,0.015255493,-0.013609469,0.048218004,-0.016222095,-0.0017528407,-0.016250111,-0.00031979274,-0.013119163,-0.0034864193,-0.01245375,-0.0033043062,0.0065630837,-0.020018457,-0.01047852,-0.009918172,0.0034724106,-0.033564884,-0.012467758,0.02423508,0.004797986,0.010709664,0.0027614683,-0.007445633,-0.0057155564,-0.007242507,0.0005476533,-0.01964022,-0.0045213136,0.007844881,0.011473139,0.02709286,0.021237215,-0.007711799,0.016446233,0.010968826,-0.01473717,0.00020378306,0.00078186154,0.021055102,-0.013385329,0.035610158,-0.0034636552,-0.00769779,-0.014400961,0.0070533887,0.02664458,0.007445633,-0.01769301,-0.018617585,-0.029390289,-0.0286058,0.016614338,0.012993085,-0.0090006,-0.0037403274,-0.021741528,0.0026721628,0.0028875468,0.0045668418,-0.0016976814,-0.010674642,0.006076281,-0.00758572,0.02336654,-0.0022361414,0.018267367,-0.017707018,-0.030623056,-0.028521748,0.010191342,0.031183403,-0.018519524,0.02630837,0.017931158,-0.0086433785,0.00398548,-0.0028122498,0.0023377046,0.008307169,-0.004748955,-0.013287268,0.01658632,-0.023058347,-0.025734013,-0.007879904,0.004062528,0.012460753,-0.01168327,0.013070133,0.00687828,-0.021377303,0.020284623,-0.0038033666,0.048638266,0.022806192,0.023086365,0.025075603,0.0013535923,0.0037893578,0.001679295,0.0038944234,0.013448368,0.019304011,0.009855133,-0.010261385,-0.021797564,0.004318187,0.017622966,-0.024739394,-0.017188696,-0.011164947,0.0020137532,0.0025268223,-0.0025460843,-0.008335186,0.011865383,-0.003460153,-0.010989838,0.008468269,0.018029219,-0.011921418,-0.0032150005,0.026672596,0.018267367,0.02728898,-0.010254381,0.003045145,0.0041395756,0.009427867,0.023534644,0.013511407,-0.020172553,0.029446322,-0.009210732,-0.0058906656,0.024417194,-0.005414369,0.01550765,-0.007207485,0.004293672,0.03056702,-0.014807214,0.01211754,-0.0065490752,0.0064930404,0.0070428825,-0.007382594,-0.0014534044,-0.00872743,-0.00965901,0.023562662,0.0126218535,0.008230121,-0.031099351,-0.0031344504,-0.0020978053,-0.012292649,-0.00126166,0.0060832854,-0.0011495904,-0.03353687,-0.027246954,-0.008307169,0.016180068,0.036618788,-0.005470404,-0.023618696,0.012061506,0.017510897,-0.032023925,0.01627813,0.019009829,-0.012670885,-0.019149916,0.011662257,-0.01854754,-0.03591835,0.010772703,-0.017524906,-0.038608022,-0.025383795,0.0016039981,-0.0045213136,0.00225015,-0.021993686,-0.0058661504,-0.005596482,0.0033743498,0.0034724106,-0.025579916,0.016740417,0.009602975,0.0028122498,0.016025972,-0.014225852,0.018575558,-0.020144535,-0.016894512,-0.0022256349,-0.044267546,-0.026812684,-0.022385929,-0.008692409,-0.008531309,-0.0022396436,-0.00943487,-0.0070638955,-0.014386952,0.007207485,0.0017817337,-0.006370464,-0.004980099,0.009070644,0.0036527729,0.012439741,-0.021433337,-0.008125056,-0.0022413947,0.022385929,-0.027443076,-0.014386952,-0.014905275,0.040793385,0.017048609,-0.015157431,-0.0064790314,-0.00625139,-0.031407543,0.0023184426,0.004748955,0.0005358334,-0.0076277466,0.007466646,0.012054501,0.03622654,-0.003300804,-0.006601608,0.002891049,0.00998121,-0.020915015,-0.019990439,0.0059467005,0.0033550877,-0.021139154,0.0026248833,-0.002152089,-0.01550765,0.022512008,-0.0054213735,-0.01692253,-0.01790314,0.008895535,0.031323493,0.029950637,0.02391288,0.021489372,-0.022778174,-0.013728542,0.020368675,-0.015157431,-0.014765188,-0.023394557,0.010457507,0.0015716029,0.012425732,-0.0025145647,-0.028998043,0.012404718,0.0041080564,-0.0053408234,0.0031554634,0.029670462,0.033004537,0.014723161,-0.019402074,-0.003999489,0.0255519,-0.023296496,-0.0043497067,0.022147782,-0.030062707,0.006132316,-0.016250111,-0.019822335,-0.018519524,-0.016067998,-0.011774327,-0.0018036223,-0.0046403874,0.0141418,0.019037846,-0.023310505,0.02513164,0.00977108,0.0015716029,-0.01822534,-0.0045633395,0.0071689608,-0.019556168,0.003614249,0.005925687,-0.019177934,-0.01059059,0.0066331276,0.017272748,0.017945167,0.010730677,0.23153608,-0.018687628,-0.013413346,0.012061506,0.018071245,0.0025618442,0.023268478,0.01921996,0.00020411138,0.010681647,0.009119675,0.019948414,0.004727942,-0.00758572,0.022694122,-0.01745486,-0.022540025,-0.0084122345,0.004647392,0.017735036,0.01402973,-0.009175709,-0.004727942,-0.022554034,0.04292271,-0.011031864,-0.0098971585,0.0028262585,0.0060447613,0.006934315,-0.0075577027,-0.0030626557,0.021055102,0.001231016,-0.014288891,-0.00041763487,0.021643467,-0.008657387,0.012684893,0.0015392078,0.037067063,-0.024949525,-0.0016565308,-0.012110536,0.012817976,0.022834208,-0.019906387,-0.020382684,0.028143512,0.0155776935,-0.016558303,-0.0052672774,0.0027824815,0.02905408,0.00829316,-0.009841124,-0.0116412435,0.002502307,0.012369697,-0.019794317,-0.024221072,0.008055013,-0.008391221,0.022708131,-0.0014385202,-0.0015225725,-0.006818743,-0.010100285,0.018183315,-0.015675753,-0.015535667,-0.015381571,-0.0076277466,-0.012824981,-0.029502358,-0.015759807,0.029082097,-0.00040472057,0.022792183,0.028970027,-0.020620832,-0.0008076901,-0.0010550315,-0.014386952,-0.009119675,-0.021251224,0.03549809,-0.006177844,-0.0064720274,-0.0069308127,-0.016194077,0.0140787605,-0.01195644,0.010037245,-0.0009788591,0.00023464601,0.010436494,0.012628858,0.0054213735,0.0011513415,-0.025958152,0.07631949,0.0070288735,-0.003029385,0.0003524068,0.01020535,0.0021363294,0.022988304,0.0055369455,-0.011396091,0.0019629714,-0.01812728,0.00085278065,-0.021391312,-0.012208597,0.0027999922,0.023604687,-0.006191853,0.01560571,0.0016223845,-0.030426932,-0.013091146,-0.008531309,0.011199969,0.0038138733,-0.00660511,0.0070638955,-0.0018526528,-0.017328782,-0.0069868476,0.004741951,-0.019738283,0.008825492,0.015633728,-0.010429489,-0.022624077,-0.017342791,-0.008909544,0.017861115,-0.0050746575,0.0020207574,0.01615205,-0.005789102,-0.011305034,-0.013427355,-0.009904163,-0.012271636,0.009021614,0.006706673,0.00035941115,-0.0048925444,0.012747932,-0.0098691415,-0.015815841,0.0061393203,-0.012348684,0.015983947,0.002248399,0.002913813,-0.0050116186,-0.023604687,0.004591357,0.009511919,-0.01865961,-0.014239861,-0.018491507,-0.18267366,0.008944565,0.022357913,-0.0377675,0.010926799,0.0010103787,0.02871787,-0.012383706,-0.044183493,0.0155917015,0.03493774,-0.012930046,-0.030286847,-0.0026476474,-0.0053233122,-0.0128389895,-0.008804479,-0.0028752892,0.003552961,0.013770569,0.04768567,-0.020242596,-0.0026038704,0.0070428825,-0.017833097,-0.0030206295,0.0043847286,0.023072356,0.01528351,-0.030931247,-0.008958574,-0.0034548999,0.017861115,-0.0056805345,-0.008475274,-0.0038804146,0.004395235,-0.021881616,-0.021139154,-0.0007862392,0.020284623,0.016838478,0.015017345,-0.0017440852,-0.015535667,0.0025916125,0.023450593,-0.013203216,0.0054423865,-0.028801922,0.0024637831,-0.0071094236,0.0116412435,-0.0065140533,0.002015504,0.005526439,-0.0063564554,-0.01921996,0.004433759,-0.0046614003,0.0021363294,-0.0053828494,0.011998466,0.01856155,0.005183225,0.00625139,0.00010938838,0.014863249,-0.040905453,0.009329805,-0.008846505,-0.0052497666,-0.011248999,-0.0048505184,0.0021573424,0.035890333,-0.018477498,-0.009483902,0.003379603,-0.022175798,-0.008608356,0.01823935,-0.00742462,-0.0017475875,-0.004223628,-0.0045773485,-0.0004410557,0.037935607,-0.007998978,-0.013490395,0.020676866,-0.047433514,-0.004479287,-0.014513031,-0.0014280136,0.01833741,0.014225852,-0.021419328,0.015213466,-0.004833007,0.013623477,0.00029746635,-0.0016854238,-0.0002935264,0.03056702,0.0032727865,0.0029435817,0.015129414,0.03376101,-0.006314429,-0.026770659,-0.021825582,0.00010194625,0.0039329473,0.014372944,0.028115494,-0.0074946634,0.009890154,0.00982011,-0.0067697125,0.066009074,0.0018526528,-0.0138476165,0.014442987,-0.009049631,-0.022848217,-0.11644045,-0.046368852,-0.0044652787,-0.0030626557,-0.0084122345,0.024291115,-0.008069021,0.0016626596,-0.028885974,0.031715736,-0.01692253,-0.030062707,0.023884863,0.0018386442,-0.004283165,-0.032696344,0.0031344504,-0.006580595,-0.027821312,0.033284713,-0.012110536,-0.021419328,0.0064159925,-0.021013075,0.012306658,0.0043251915,-0.033648938,-0.008321178,0.0036597773,-0.0070393803,0.010275394,-0.0106466245,0.014555057,1.8194916e-05,-0.0037088078,-0.023464601,-0.0048820376,-0.0103594465,0.020312639,-0.01790314,0.011185961,-0.0037543362,-0.0007363332,-0.008895535,-0.039476566,-0.022021703,-0.0072214934,0.020774927,0.030146759,-0.021349285,-0.03689896,0.011998466,-0.019486126,0.0044722827,0.009539937,-0.0028840445,-0.0033831052,0.0048014876,0.004514309,0.012810972,-0.018841725,0.0071024196,-0.009448879,-0.0014936795,0.010828738,-0.02969848,-0.0034934238,-0.015759807,0.011417104,-0.020592814,-0.0050676535,-0.0031624679,-0.009049631,0.011837366,-0.015619719,-0.014022726,-0.011942431,-0.021125145,0.005452893,-0.004479287,-0.005722561,-0.011739305,-0.009210732,-0.014344926,0.018309394,-0.0036632796,-0.025425822,-0.017931158,0.011073891,-0.008440252,0.00060500146,0.032051943,0.01031742,-0.02752713,0.01910789,0.0145830745,-0.028297609,-0.00011743245,0.008552321,0.010401472,-0.027485102,-0.007035878,-0.047153343,0.02805946,-0.0031029307,-0.034097217,-0.015689762,-0.005015121,0.00872743,-0.00813206,-0.012509785,0.020144535,-0.016320156,0.010807725,-0.014295896,-0.003108184,-0.017272748,-0.012222606,0.01888375,-0.011928422,-0.0036107467,-0.0050641512,0.015269501,-0.0015724784,0.012222606,0.011480143,-0.012313662,0.0009420862,-0.010520547,0.012691897,-0.012089523,-0.01304912,-0.003691297,-0.022119764,0.003456651,0.023128392,-0.00077835936,0.0012642867,-0.013168194,0.0329485,0.027246954,0.022035712,-0.0034671575,-0.032612294,-0.0006128814,-0.01886974,-0.003614249,-0.010569577,-0.0056945435,-0.0076697725,-0.007564707,-0.001700308,0.024823446,0.006521058,-0.0071654585,-0.039784756,0.0065981057,0.020172553,-0.009813107,-0.017945167,-0.006475529,0.0047594616,0.043903317,-0.012187583,-0.0045423266,-0.0009543438,0.0067311884,-0.009007605,-0.0032202539,0.01047852,0.018477498,-0.0038348862,0.0074736504,0.008426243,-0.0030521492,0.017594948,-0.008979588,-0.020480745,0.00943487,0.0018053734,0.0029943632,0.0329485,0.01288802,0.0013614722,-0.00970804,-7.639128e-05,0.004766466,0.0047559594,-0.010758694,0.008622365,-0.008797474,0.0048715314,0.02871787,0.014050743,-0.014428979,0.011879392,-0.015437606,-0.018575558,-0.0045633395,-0.009462888,0.015409589,0.022624077,-0.00731255,-0.0013991205,-0.006839756,-0.030258829,-0.025579916,0.023128392,-0.012670885,-0.037823536,-0.004822501,0.03331273,0.032724362,-0.0020487749,0.0014604088,0.009231744,-0.018295385,0.024263097,-0.011578204,-0.023156408,-0.03622654,0.020144535,0.025944144,0.001025263,-0.0026108746,-0.008608356,0.011662257,0.03297652,0.024697367,-0.009518923,0.0062794075,0.02947434,0.00053408236,0.0012651623,-0.005081662,-0.008251134,-0.01812728,-0.025635952,-0.018309394,0.007711799,0.015199458,0.06869875,0.015913902,-0.008692409,0.019878369,-0.022189807,0.020494753,0.034349374,-0.004626379,-0.024123011,-0.012299653,-0.012320667,0.010380459,-0.014162812,0.0058101155,0.0024760407,0.017300766,-0.008447256,0.0036037425,-0.018057236,0.017735036,0.008510295,-0.0031362015,0.02347861,-0.002752713,-0.017664991,0.015199458,0.006121809,0.0068677734,0.002757966,-0.016250111,0.025734013,0.014183826,-0.024823446,-0.022231834,-0.008258139,0.011802344,-0.0059677134,-0.034965757,-0.0029961143,0.002852525,-0.006738193,-0.021755537,-0.017510897,0.0033533366,-0.009890154,0.008965579,-0.010422485,-0.019514143,-0.01571778]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.7354786005583592
0.7021139037793317
0.7551110160916688
0.8166447796641078
0.7296966927165327
0.753919722138209
0.7584999874065034
0.7195872847461879
0.7969271617518574
0.7783068799826146
0.7810577543435335
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011370644,0.004471228,-0.0021480802,-0.014761704,-0.0025419823,0.02448146,-0.01529391,0.017604804,-0.011302368,-0.034481324,0.0047513363,0.01599418,-0.016064208,0.013578247,-0.003019917,-0.02512571,0.02799682,0.0064144786,-0.011561468,-0.014250507,-0.003609895,0.01770284,-0.0070552262,-0.03876698,0.0071287546,0.033809066,0.027884776,-0.015391948,0.022856833,0.009145535,-0.006078349,0.01529391,-0.037674557,-0.024229363,0.0011965875,-0.00014661916,0.0101469215,-0.00089809706,0.0040720734,0.004429212,0.011155311,0.0065230206,0.0013672784,-0.014733694,-0.008025101,-0.008242185,0.0155740185,-0.039859403,-0.008039107,-0.013424188,0.010335994,0.024957644,-0.019131392,-0.01265389,-0.016330311,-0.0029463887,-0.0049053957,0.009166542,0.013704296,-0.014915764,0.021260215,0.018108997,-0.017716847,-0.0014460589,-0.021652367,0.004471228,-0.024761569,-0.0123247625,-0.01402642,0.00763295,0.034537345,0.010258964,-0.010097902,-0.025685927,0.034733422,-0.0072267926,-0.0035381173,-0.025783964,-0.013928383,0.0163023,-0.0008989724,-0.023431055,-0.0151818665,0.020489918,0.0124858245,-0.016904533,0.0034961011,0.015517997,-0.013515223,0.0037149356,-0.004016052,-0.0008591445,0.020293843,0.015237888,0.0077589983,-0.0058227503,-0.008662348,0.026064072,0.0011790807,0.009845804,-0.0071707712,-0.0036239005,-0.02103613,-0.009831799,-0.01477571,0.0029463887,0.0137883285,0.003728941,0.0058962787,-0.013340156,-0.036217995,0.035489716,0.011680514,-0.038122732,-3.9417577e-05,-0.009943843,0.0076679634,-0.0178569,0.0037359437,-0.015980175,0.023683151,0.01443958,0.018108997,-0.008571312,0.012058659,-0.006505514,-0.006176387,-0.011638498,-0.017240662,-0.013389174,0.0012114681,0.010721143,0.0051224795,0.01917341,-0.015097834,0.017450744,-0.014369553,0.013305142,-0.025447834,-0.0305318,0.0077099795,0.005196008,-0.019663598,0.017968943,-0.0020395382,0.016092218,0.010980243,0.026302164,0.01700257,0.012997023,0.0021008118,-0.03834682,0.0217364,0.029299323,0.016568402,0.021050135,-0.029523408,-0.009355616,-0.02124621,-0.008172158,-0.007317828,0.013767321,0.0059663057,0.018249052,0.010749154,0.010034878,0.014691678,-0.0053290594,0.012478822,0.0042996616,-0.011253349,0.031736266,-0.02885115,0.00051338586,-0.0070167114,0.019369485,0.02124621,-0.0057142084,-0.01749276,-0.02548985,0.017296685,-0.0017524272,0.005027943,0.024929633,-0.019369485,-0.023725169,0.01684851,-0.01224073,0.005196008,0.0019677605,0.018739242,0.016106224,-0.0018137009,0.0049754228,-0.6700189,-0.02186245,0.0039040085,-0.025265764,0.015475981,0.01700257,-0.0020868063,-0.016260283,-0.032576587,0.012457814,-0.021204194,0.0067716166,0.028038835,-0.02885115,-0.007268809,-0.026120095,-0.0030321716,-0.03322084,0.009691745,0.002890367,-0.018711232,0.016008187,-0.019243436,-0.009033491,-0.0015493487,0.028655073,0.00164301,-0.016834505,0.018795263,0.010076894,-0.009376624,0.03366901,0.0053710756,0.015616034,0.043584842,-0.020952096,-0.0070727332,0.015602029,0.00017835016,0.050419483,-0.033052772,-0.0119046,0.004919401,0.00056065415,-0.011204329,0.003788464,0.022394653,0.0025892507,0.020139784,0.0106651215,0.012058659,0.015686061,0.009635723,0.008438261,0.02008376,-0.020461908,0.023150947,-0.011407408,0.011470432,0.008277198,0.012611873,0.0051714983,-0.017030582,-0.0064319856,-0.007177774,0.026218131,-0.021134168,0.013893369,-0.004649797,-0.04585372,-0.0069081695,0.017128618,-0.021512313,0.005392084,-0.011078281,0.025938023,0.015321921,0.016442355,0.017786874,0.018907307,-0.00042869692,-0.030839918,0.0041596075,0.020377874,0.033865087,-0.000710337,-0.03319283,-0.008900439,-0.0047093197,0.0026837871,0.007716982,0.01938349,-0.016582409,-0.019579567,0.001482823,0.036442082,-0.009887821,0.01661042,-0.016218267,-0.0150558185,-0.0023634133,-0.010749154,0.00970575,-0.007261806,-0.010385013,0.005213515,0.00047487102,0.027800743,0.020013735,-0.020377874,0.010286976,0.01920142,-0.011834573,0.014523612,-0.012310757,-0.03369702,0.040867794,-0.014250507,0.0008578315,-0.007387855,0.0033928112,0.012765933,0.0077379905,-0.018389106,0.0076819686,0.03302476,-0.014285521,-0.031176047,-0.013977401,0.008347225,0.022730784,-0.018277062,0.014278518,-0.012303755,0.017660825,-0.00057641027,-0.0005374577,0.0020395382,0.004236637,-0.022548713,-0.0045587616,0.011316373,0.0015327173,0.017954938,-0.025882002,-0.0040195533,-0.008011096,0.008144147,-0.0054936227,-0.008907442,-0.010798173,-0.021204194,-0.012471819,-0.02036387,0.005322057,0.008445264,0.0153779425,-0.031232068,-0.025797969,-0.027660688,0.0106091,0.02564391,-0.01563004,0.017562786,-0.015560013,0.0068591507,-0.0016578906,0.034257237,0.0073318332,-0.022478687,0.014733694,-0.027856765,0.0095727,0.013186095,-0.0028010823,0.0025734946,0.005038447,-0.013179093,-0.021344248,-0.014887753,0.0008503911,-0.000826757,0.011673511,-0.00044532833,0.014537618,0.009110521,0.02460751,0.010910216,-0.016708456,0.03509756,-0.006270923,0.011939614,-0.018137008,-0.010174932,-0.0004989428,-0.007843031,0.008480277,-0.016652435,0.00248421,0.01575609,0.01666644,0.019733626,0.008039107,-0.007275812,0.0071287546,-0.018403111,-0.0011423164,-0.0141104525,0.019131392,0.0141454665,0.02628816,-0.039971445,-0.021302233,-0.0068416437,0.011953619,0.009803789,0.00019213675,0.011813565,-0.021540323,0.015616034,-0.03534966,0.0009725008,0.012555852,-0.00026851002,-0.018739242,0.010693132,-0.0034925996,0.019901691,0.0143065285,-0.014845737,0.0060818503,0.026974425,-0.0005785986,0.03162422,0.02103613,-0.018038971,0.010385013,0.005920788,0.0021830937,0.002489462,-0.0049824254,0.0069781966,-0.015111839,0.0057387175,0.035965897,-0.009222564,0.033725034,0.01920142,-0.02701644,-0.0016036197,-0.011890595,0.009425642,-0.0035713802,-0.009152537,0.009173545,0.0048248647,0.014278518,-0.0061938935,-0.0039250166,0.020475913,0.006981698,0.019971717,0.0333889,-0.012254735,0.027884776,-0.004740832,-0.01239479,-0.03229648,-0.022730784,0.0032142422,-0.013620263,-0.00036611024,0.005941796,-0.028010825,0.026022056,0.017072598,0.017142624,0.014761704,0.034173205,0.016176252,-0.034061164,-0.026890391,0.018893301,0.005346566,-0.008977469,0.0048878887,-0.022058524,0.010763159,-0.010293978,0.0074018603,0.021512313,0.017408727,-0.0038129734,-0.004856377,-0.01850115,0.0039810385,0.03128809,-0.011617489,-0.001169452,-0.006088853,0.0074158655,0.019663598,-0.005115477,-0.04173613,0.017086603,-0.031400133,0.031120026,-0.007139259,-0.016988564,-0.019271446,0.0065790424,-0.02527977,0.022310622,-0.018487144,0.014173477,0.0017357958,0.008137144,-0.017170636,0.030111637,0.018179026,0.0056932,-0.026274154,-0.024229363,0.008900439,0.06375264,0.05271637,-0.005812246,0.019551555,-0.0023126437,-0.007083237,-0.013774323,-0.0054130917,0.0067786197,-0.0040405616,-0.010174932,-0.019061366,0.018361095,-0.010882205,0.0051609944,0.0077800066,0.018179026,-0.01441157,-0.022688767,-0.039691336,-0.007030717,0.0075139035,0.041287955,0.032016374,0.008900439,0.0063619586,0.028669078,0.014075439,-0.013438193,-0.018263057,0.016106224,0.015770094,0.009712754,0.005990815,0.0029096245,0.037898645,0.0005527761,0.014369553,0.020587957,0.012051657,0.0153779425,0.008725372,0.007450879,-0.0052695363,-0.014817726,-0.0070622293,-0.01135839,-0.0011151809,-0.0015458474,-0.0130390385,-0.00025297276,-0.0163023,-0.04380893,-0.008109134,0.011078281,0.0010775414,-0.017688835,-0.00841025,-0.0049334066,-0.00037748963,-0.026484234,-0.0238092,-0.0035766321,0.0035486214,0.018207036,-0.016498376,-0.0066805817,0.004789851,-0.030363733,-0.008606326,-0.012415798,-0.035853855,-0.019747632,-0.005087466,0.034173205,0.0183751,0.024439445,-0.007111248,-0.013809336,0.0066490695,-0.005087466,-0.0027835758,-0.011421414,-0.0028763616,0.017478755,-0.007464885,0.0012359776,-0.003263261,-0.005584658,0.013774323,-0.0011677012,0.007983085,-0.00390751,-0.020699998,-0.021792421,0.010434032,0.021778416,0.03330487,-0.009901826,-0.025405819,0.007387855,-0.030111637,-0.02106414,-0.009047496,-0.0056301756,-0.0063129393,0.0043801926,-0.008025101,-0.01011891,0.0032334996,0.031848308,-0.0124858245,0.011918606,0.0035853856,0.0054901214,0.030279702,0.0013926632,0.009481664,-0.018977333,-0.024243368,0.011260351,-0.024593504,0.005990815,0.0038129734,-0.033528958,0.012625879,0.017618809,0.0061413734,-0.03327686,0.015209878,-0.013648274,0.048206627,-0.016232273,-0.0017296684,-0.016246278,-0.00031249577,-0.01314408,-0.0035083557,-0.012464817,-0.003273765,0.006558034,-0.020013735,-0.01045504,-0.009964851,0.003490849,-0.03358498,-0.012471819,0.024229363,0.0048073577,0.010700135,0.0027310555,-0.007457882,-0.0057072053,-0.007205785,0.0005536515,-0.019621583,-0.0045692655,0.007857036,0.011477435,0.027030446,0.021176184,-0.007723985,0.016428348,0.010980243,-0.014733694,0.00018699413,0.000775112,0.02106414,-0.013389174,0.035629768,-0.0034435808,-0.0076679634,-0.014397563,0.0070657306,0.026652299,0.0074298712,-0.01770284,-0.018655209,-0.029411366,-0.028613057,0.01666644,0.013018031,-0.008956461,-0.0037254395,-0.021722395,0.0027082965,0.0028973697,0.0045447564,-0.0016683948,-0.010679127,0.0060538393,-0.0075909332,0.023375032,-0.0021988498,0.018263057,-0.017730853,-0.03061583,-0.02854303,0.010251962,0.031204058,-0.01852916,0.02637219,0.017940933,-0.0086833555,0.0040090494,-0.0028483507,0.0023826708,0.008270196,-0.0048038564,-0.0132701285,0.016596414,-0.023066914,-0.025755953,-0.007836028,0.004068572,0.012464817,-0.011666508,0.013081055,0.006915172,-0.021344248,0.020307848,-0.0037779598,0.048654802,0.022758795,0.023066914,0.02512571,0.001363777,0.0037639546,0.0016578906,0.0038830005,0.013438193,0.019271446,0.009831799,-0.010265967,-0.021806426,0.0042716507,0.017660825,-0.024719553,-0.017198646,-0.011162314,0.0020202808,0.0024597005,-0.0025559878,-0.008347225,0.011862584,-0.0034593367,-0.010994249,0.008438261,0.018052977,-0.011897597,-0.0031914832,0.026652299,0.01829107,0.02732456,-0.0102729695,0.0030619332,0.004124594,0.009453653,0.023543097,0.013487212,-0.020223815,0.029467387,-0.00918755,-0.005920788,0.024439445,-0.005406089,0.015503991,-0.007177774,0.0042821546,0.0305318,-0.014747699,0.012093673,-0.006565037,0.0064985114,0.0070202127,-0.007380852,-0.0014399315,-0.008725372,-0.009670737,0.023613125,0.012632882,0.008249188,-0.031092016,-0.0031039496,-0.002083305,-0.01231776,-0.0012508584,0.0060818503,-0.001125685,-0.03358498,-0.02722652,-0.008312212,0.016204262,0.03663816,-0.0054936227,-0.02359912,0.012065663,0.01754878,-0.03198836,0.0163023,0.018991338,-0.012646887,-0.0191454,0.011673511,-0.01855717,-0.035937887,0.010798173,-0.01754878,-0.038626928,-0.025363801,0.0016036197,-0.004534252,0.0022706275,-0.022016509,-0.005857764,-0.0056266743,0.003382307,0.0034838463,-0.025545873,0.016750474,0.009614715,0.002830844,0.016036198,-0.014229499,0.018515155,-0.020125777,-0.016932543,-0.0022548714,-0.044313125,-0.026806358,-0.022408659,-0.008739377,-0.008501285,-0.0022268605,-0.0093976315,-0.0071042455,-0.014397563,0.0072548036,0.0017690586,-0.006326945,-0.004940409,0.009047496,0.003630903,0.012436806,-0.021414274,-0.008179161,-0.0022268605,0.022422666,-0.027450608,-0.014383558,-0.014873748,0.04078376,0.017016577,-0.015139851,-0.0064564953,-0.006309438,-0.031400133,0.0022706275,0.004800355,0.0005628425,-0.007625947,0.007464885,0.012023646,0.036189985,-0.0032947732,-0.006614056,0.0028938684,0.009971853,-0.020980107,-0.019985722,0.005990815,0.003333288,-0.021106156,0.0026382694,-0.0021463295,-0.015546008,0.022478687,-0.005455108,-0.016960554,-0.017898917,0.008914445,0.031372122,0.02994357,0.023921244,0.021498308,-0.022786805,-0.013718301,0.02036387,-0.015167861,-0.014719688,-0.023361027,0.010420026,0.0015756089,0.012450811,-0.002543733,-0.028991204,0.012422801,0.0041105887,-0.0053325607,0.0031844806,0.029635452,0.03299675,0.014733694,-0.0194115,-0.004044063,0.025573883,-0.023291001,-0.004331174,0.022170568,-0.030027604,0.0060818503,-0.016232273,-0.019845668,-0.01852916,-0.016092218,-0.011771549,-0.0017961941,-0.0046252874,0.0141104525,0.019033356,-0.023333017,0.02515372,0.0097897835,0.0015677308,-0.018235046,-0.004562263,0.007177774,-0.019551555,0.003609895,0.0058857743,-0.01917341,-0.010581089,0.006628061,0.0173387,0.017912922,0.010735149,0.23170555,-0.018697225,-0.013389174,0.012072666,0.017996954,0.0025244756,0.023234978,0.019243436,0.00020373498,0.010679127,0.00908251,0.019971717,0.0047268267,-0.007604939,0.0227728,-0.017422732,-0.02256272,-0.008403247,0.0046357913,0.017716847,0.014005412,-0.009145535,-0.0047548376,-0.022534708,0.042940594,-0.011057273,-0.009901826,0.0028395974,0.005997818,0.0069396817,-0.0075139035,-0.0030619332,0.02106414,0.0012158449,-0.014320534,-0.00044554716,0.021666372,-0.008655345,0.012660893,0.0015309666,0.03708633,-0.024971649,-0.0016412593,-0.012114681,0.012856969,0.02289885,-0.019929701,-0.020377874,0.028192895,0.015588024,-0.016554397,-0.00528004,0.0027835758,0.029047225,0.00825619,-0.009866813,-0.011638498,0.0024982153,0.0123597765,-0.019845668,-0.024229363,0.008025101,-0.008438261,0.022702774,-0.0013699044,-0.0015519748,-0.0067996276,-0.010139919,0.018151015,-0.015672056,-0.015489986,-0.0153779425,-0.007618944,-0.012807949,-0.029495398,-0.01575609,0.029103247,-0.00040812648,0.02274479,0.029047225,-0.020587957,-0.0008447014,-0.0011003002,-0.014425575,-0.009138531,-0.021274222,0.035545737,-0.006169384,-0.006445991,-0.006901167,-0.016204262,0.014096447,-0.011953619,0.009971853,-0.0009707501,0.00020843993,0.010448038,0.012569858,0.0054200944,0.0011668259,-0.025952028,0.076357506,0.007083237,-0.0030356732,0.00038383584,0.010167929,0.0020990612,0.023038903,0.005556647,-0.0113864,0.0019940205,-0.018123003,0.00084120006,-0.021428281,-0.012233728,0.0027958304,0.023585115,-0.006190392,0.015616034,0.0016298798,-0.030447766,-0.01309506,-0.008515291,0.011190324,0.0038199762,-0.0065930476,0.007027216,-0.0018609691,-0.0173387,-0.006971194,0.004744333,-0.019733626,0.00882341,0.015616034,-0.010462043,-0.022534708,-0.017324695,-0.008914445,0.017898917,-0.0051119756,0.0019957712,0.016162246,-0.0057457206,-0.011295365,-0.013459201,-0.00993684,-0.012268741,0.0090755075,0.006712094,0.0003521048,-0.0048738834,0.012772936,-0.009880818,-0.01581211,0.006130869,-0.0123247625,0.015980175,0.0022653753,0.002895619,-0.0049999324,-0.023585115,0.0046287887,0.009516678,-0.018641204,-0.014222496,-0.01850115,-0.18263057,0.008949459,0.022338632,-0.037758593,0.010910216,0.0009996362,0.028767116,-0.012380784,-0.04414506,0.015616034,0.0349295,-0.012983017,-0.030307712,-0.0026452723,-0.005297547,-0.012772936,-0.008830412,-0.0028378468,0.0035171092,0.013746312,0.047674425,-0.020223815,-0.0025734946,0.0070447223,-0.017842894,-0.0030006596,0.004362686,0.023080919,0.01529391,-0.03089594,-0.008942456,-0.0034068166,0.017842894,-0.0057002027,-0.008501285,-0.0038759978,0.0043661874,-0.02191847,-0.02112016,-0.000821505,0.020335859,0.01684851,0.014999797,-0.0017795627,-0.015517997,0.0025892507,0.023473071,-0.013242117,0.005406089,-0.02882314,0.0024036788,-0.0070727332,0.011673511,-0.006544029,0.0020010234,0.0055286363,-0.0063619586,-0.019187415,0.0044082035,-0.0046953144,0.002158584,-0.005385081,0.011988633,0.01852916,0.005199509,0.0062219044,8.490781e-05,0.014887753,-0.040923815,0.00934161,-0.00885142,-0.005266035,-0.011267354,-0.0048633795,0.0021288227,0.035909876,-0.018445129,-0.009495669,0.0033648002,-0.022142557,-0.008585318,0.018235046,-0.0074228686,-0.0017462998,-0.0041701114,-0.0045762686,-0.0004831867,0.037982676,-0.007990087,-0.013487212,0.020657983,-0.047450338,-0.0044502197,-0.014537618,-0.001412796,0.01834709,0.014229499,-0.021414274,0.015195873,-0.004810859,0.01361326,0.00032168682,-0.001650888,-0.0002628203,0.03061583,0.003247505,0.0029393858,0.015111839,0.033781055,-0.0063339476,-0.026750337,-0.021848444,8.255534e-05,0.003928518,0.014397563,0.028122868,-0.0074998983,0.0099158315,0.009824797,-0.006722598,0.0659935,0.0018644705,-0.013816339,0.014453585,-0.0090404935,-0.022884844,-0.11663707,-0.046357915,-0.004513244,-0.0030776893,-0.00841025,0.024313396,-0.008102131,0.0016368825,-0.02890717,0.031764276,-0.016946549,-0.030111637,0.023907239,0.0018119502,-0.004275152,-0.032716643,0.0031687245,-0.0065615354,-0.02784276,0.03324885,-0.012100676,-0.021442287,0.0064214817,-0.021008119,0.012303755,0.004331174,-0.033641,-0.00833322,0.0036624153,-0.0070587276,0.010258964,-0.010623105,0.014607645,1.8901836e-05,-0.0036869247,-0.023473071,-0.0048633795,-0.010364005,0.02036387,-0.017912922,0.011211333,-0.0037499492,-0.00072828145,-0.008893437,-0.039495263,-0.022044519,-0.0072127874,0.020770026,0.030139647,-0.021386264,-0.03697429,0.012030649,-0.019523544,0.0044572223,0.009530683,-0.0028851149,-0.0034050657,0.0048038564,0.004523748,0.012814952,-0.018865291,0.007093741,-0.009460656,-0.0014810724,0.0108261835,-0.029719485,-0.003501353,-0.01575609,0.011414411,-0.020587957,-0.0050839647,-0.0031967354,-0.009026488,0.011813565,-0.015602029,-0.014019418,-0.011960622,-0.02112016,0.0054481053,-0.0044467184,-0.0057072053,-0.011785555,-0.0092015555,-0.0143415425,0.018305074,-0.0036869247,-0.025433829,-0.017912922,0.011085284,-0.008431259,0.0005829753,0.032044385,0.0103079835,-0.027534641,0.019117387,0.014565629,-0.028276928,-0.00011062087,0.008550304,0.01042703,-0.027464613,-0.0070587276,-0.04711421,0.028066846,-0.003095196,-0.034145195,-0.01565805,-0.004947412,0.008739377,-0.00815115,-0.012471819,0.020153789,-0.016316306,0.010798173,-0.014299526,-0.0030916948,-0.01731069,-0.012219722,0.018851284,-0.011932611,-0.003658914,-0.00509797,0.015307915,-0.0015598527,0.01224073,0.01146343,-0.012387787,0.0009830049,-0.01053207,0.0127169145,-0.012093673,-0.013046041,-0.003690426,-0.022142557,0.0034680902,0.023080919,-0.00080881256,0.0012657391,-0.013193098,0.03296874,0.027282543,0.022142557,-0.0034680902,-0.032660622,-0.0006678831,-0.018893301,-0.003609895,-0.010539073,-0.0057282136,-0.007625947,-0.0075559197,-0.001728793,0.024845602,0.006526522,-0.007205785,-0.03974736,0.0065895463,0.0201818,-0.009817794,-0.017926928,-0.0065020127,0.004730328,0.04389296,-0.012191711,-0.0045062415,-0.00095324335,0.0067015896,-0.009033491,-0.0031967354,0.010476048,0.018487144,-0.0038024695,0.007464885,0.008431259,-0.0030514293,0.017618809,-0.008991474,-0.020489918,0.009418639,0.0018031969,0.0030146649,0.03291272,0.0128779765,0.001350647,-0.00967774,-8.9558045e-05,0.0047338293,0.0047338293,-0.010721143,0.008648342,-0.008788397,0.0048633795,0.028739106,0.014068437,-0.01441157,0.011848579,-0.015489986,-0.018543165,-0.0045762686,-0.009474661,0.015363937,0.022576725,-0.007317828,-0.0013996658,-0.006824137,-0.030307712,-0.025615899,0.023164952,-0.0126819005,-0.037814613,-0.00483887,0.03330487,0.032772664,-0.0020360367,0.0015143352,0.009229567,-0.018305074,0.024243368,-0.011568471,-0.023150947,-0.036189985,0.020153789,0.025952028,0.0010495306,-0.002668031,-0.008578315,0.011666508,0.03294073,0.024733558,-0.009495669,0.006267422,0.029495398,0.0005418344,0.0013270128,-0.005087466,-0.00825619,-0.018123003,-0.025685927,-0.018333085,0.0077309874,0.015195873,0.068682544,0.015924154,-0.008697361,0.019901691,-0.022198578,0.020503923,0.034369282,-0.0046392926,-0.024145331,-0.012275744,-0.0123597765,0.010371008,-0.014131461,0.0058052433,0.0024754566,0.017296685,-0.008452266,0.0035661282,-0.018038971,0.017758863,0.0084872795,-0.0031582206,0.02344506,-0.002771321,-0.017632814,0.0151818665,0.006088853,0.00683114,0.0027590662,-0.016218267,0.025727943,0.014222496,-0.024775574,-0.022226589,-0.008277198,0.011806563,-0.0059943167,-0.03495751,-0.002998909,0.0028606055,-0.006705091,-0.021722395,-0.017506765,0.0033525454,-0.009901826,0.008991474,-0.010462043,-0.019523544,-0.015728079]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.7541100752966835
0.7480738968378944
0.7732204856076925
0.7883087714264704
0.7358481266247275
0.7203674791777436
0.7145416845428434
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011646466,0.004546584,-0.0021192892,-0.014798273,-0.002549797,0.024514453,-0.015302283,0.017584326,-0.011312209,-0.03449664,0.0047320877,0.016016297,-0.016100299,0.013601252,-0.003022306,-0.025116464,0.028000519,0.006380618,-0.011557214,-0.014231264,-0.0036435674,0.017710328,-0.00702813,-0.03878072,0.0071471324,0.033796627,0.027916517,-0.015386284,0.022764422,0.009093168,-0.005999111,0.015302283,-0.0376887,-0.024234448,0.0012180225,-0.00010762699,0.010150188,-0.00088682893,0.004007574,0.0044205817,0.011116206,0.006541621,0.0013729004,-0.014756273,-0.008001148,-0.008260153,0.015540288,-0.039844736,-0.008036149,-0.013433249,0.010416193,0.024920462,-0.019138355,-0.012677235,-0.016268302,-0.002976805,-0.0048930906,0.00920517,0.013685253,-0.014882275,0.021210393,0.018088335,-0.017710328,-0.0014227764,-0.0216304,0.004497583,-0.024766458,-0.012362229,-0.014084261,0.0076511414,0.03452464,0.01027619,-0.010101187,-0.025718477,0.03469264,-0.0072101336,-0.0035263153,-0.025774477,-0.013930257,0.016324302,-0.00088332884,-0.023436433,-0.01517628,0.02051038,0.0124742305,-0.016884312,0.0034755643,0.015526287,-0.01350325,0.003727569,-0.0039725737,-0.0008684536,0.020314375,0.015274283,0.007735143,-0.005848608,-0.008638159,0.026040481,0.0011471462,0.009870183,-0.0071121315,-0.003629567,-0.021028388,-0.009814181,-0.014742273,0.0029523047,0.013825255,0.003727569,0.005887109,-0.013370248,-0.03620467,0.035476655,0.011697216,-0.038136706,-2.3953568e-05,-0.0099471845,0.007665142,-0.01783633,0.003727569,-0.016002296,0.023688437,0.014462268,0.018060334,-0.008596159,0.012089224,-0.0065451213,-0.006223115,-0.011613214,-0.017234318,-0.013377247,0.0012127724,0.010724198,0.0050575933,0.019166354,-0.015106279,0.017416323,-0.014350265,0.013342246,-0.02545247,-0.030576566,0.007665142,0.0052360967,-0.019614363,0.017990332,-0.0020265374,0.016058298,0.010934202,0.026306486,0.017010314,0.01299924,0.0021385395,-0.03830471,0.021770403,0.029260542,0.016562307,0.02107039,-0.029540546,-0.009331172,-0.021252394,-0.008162151,-0.007357136,0.013734254,0.0059746103,0.018242337,0.010738199,0.0100521855,0.014672271,-0.0052780975,0.012502232,0.00431558,-0.011270208,0.031668585,-0.028868534,0.00050007174,-0.006972129,0.01939036,0.021238392,-0.0056911055,-0.017472323,-0.025494471,0.017234318,-0.001729907,0.0050400933,0.024934461,-0.019348359,-0.02374444,0.016828312,-0.012278227,0.005201096,0.0019250356,0.018760348,0.0161843,-0.0018112835,0.0049735922,-0.6702204,-0.021896405,0.0038885719,-0.025228467,0.015470286,0.016954314,-0.0020982889,-0.0162543,-0.032648604,0.01241823,-0.021196391,0.006755125,0.028014518,-0.028924536,-0.007287135,-0.026124483,-0.0030188058,-0.033236615,0.009674179,0.0029033036,-0.018718347,0.015946295,-0.019278357,-0.009016166,-0.0014884025,0.02858853,0.0016511555,-0.01680031,0.018760348,0.010129187,-0.009401174,0.033628624,0.0053235986,0.015610289,0.043596808,-0.021014389,-0.00703513,0.015596288,0.0001999412,0.05040093,-0.03301261,-0.011949221,0.004903591,0.0005530102,-0.011172207,0.0038045703,0.022358414,0.002549797,0.020118373,0.010633197,0.012047223,0.015722292,0.009625178,0.008428156,0.020076372,-0.02049638,0.023156429,-0.011459212,0.011480212,0.008302154,0.012621233,0.0052080965,-0.017024314,-0.0064646197,-0.0071646324,0.026250485,-0.021168392,0.013867256,-0.0046620863,-0.04586485,-0.0069126277,0.017136317,-0.021518398,0.0053971,-0.011046205,0.02595648,0.015330284,0.016464304,0.01779433,0.01892835,-0.00043335176,-0.030772569,0.004158077,0.020384377,0.033852626,-0.00070045044,-0.033208616,-0.008883164,-0.0046970868,0.0026740495,0.0077001425,0.019362358,-0.016562307,-0.019544361,0.0014560269,0.036400672,-0.009863183,0.016576307,-0.0161843,-0.015050278,-0.0023660439,-0.010724198,0.009765181,-0.0072521344,-0.010388192,0.0052150963,0.00047469628,0.027804514,0.020034371,-0.020412378,0.01026919,0.019222356,-0.011823218,0.01454627,-0.012292228,-0.033712626,0.040908758,-0.014252264,0.00082601525,-0.0073991367,0.0033933127,0.012775237,0.007770144,-0.01834034,0.007630141,0.03301261,-0.0143082645,-0.031192577,-0.013937258,0.008281154,0.022722421,-0.018256338,0.014301265,-0.0123342285,0.017696327,-0.00063394924,-0.00057138555,0.0020387878,0.0042665787,-0.022568418,-0.0045675845,0.01132621,0.0015225281,0.01790633,-0.02590048,-0.0040810755,-0.008064149,0.00809215,-0.005519602,-0.008883164,-0.0108292,-0.021182392,-0.01242523,-0.020342376,0.0052745976,0.008491157,0.015386284,-0.031220578,-0.025774477,-0.027664512,0.010619196,0.025676476,-0.01566629,0.017556325,-0.015582289,0.006853127,-0.0016476555,0.034244634,0.0073711365,-0.022456415,0.014756273,-0.027860515,0.009597178,0.013181244,-0.0027825516,0.0025690475,0.0050505935,-0.013209244,-0.021308394,-0.014910276,0.00086232845,-0.0009082668,0.011655215,-0.00046069603,0.014476268,0.009114169,0.024640456,0.010899202,-0.016716309,0.03508465,-0.006303617,0.011949221,-0.018144336,-0.010178188,-0.0004956967,-0.007847145,0.008477157,-0.016646309,0.0024465453,0.015764292,0.016660308,0.019768367,0.008036149,-0.0072661345,0.007080631,-0.01838234,-0.0011156456,-0.014105261,0.019124353,0.0142382635,0.026306486,-0.040040743,-0.021280393,-0.0068741273,0.011942221,0.009828182,0.0002384419,0.0117812175,-0.021504398,0.015582289,-0.03530865,0.000973018,0.012579232,-0.00028219272,-0.018718347,0.010717198,-0.0034965647,0.019894369,0.014315265,-0.014854275,0.006058612,0.026964499,-0.00055388524,0.031668585,0.02104239,-0.018046334,0.010395193,0.00596061,0.0021350395,0.0024605456,-0.004980592,0.0069651287,-0.01512028,0.0057016057,0.035980664,-0.00920517,0.033712626,0.019250356,-0.026978498,-0.0016082798,-0.01187922,0.009415174,-0.0035823162,-0.009114169,0.00917017,0.0048160893,0.014287264,-0.006209115,-0.003934073,0.020524379,0.0069931294,0.02004837,0.03337662,-0.012236226,0.027902516,-0.004746088,-0.01239723,-0.0322846,-0.02273642,0.0032130594,-0.0136152515,-0.0004108201,0.00595011,-0.027972518,0.026054483,0.017080316,0.017150316,0.014728272,0.034244634,0.016170299,-0.03407663,-0.026936498,0.01890035,0.0053165983,-0.008974166,0.00487559,-0.022036407,0.010717198,-0.010332191,0.007392137,0.021518398,0.01734632,-0.0038220708,-0.0048825904,-0.018508343,0.003983074,0.03133258,-0.011578214,-0.0011716466,-0.0061251135,0.0074271373,0.019642364,-0.005082094,-0.041748773,0.017066315,-0.03138858,0.031164577,-0.0071646324,-0.016996315,-0.019292356,0.006548621,-0.025270468,0.022316413,-0.018508343,0.014154262,0.0017080316,0.008134151,-0.017234318,0.030100556,0.018102335,0.0056666047,-0.026250485,-0.02424845,0.008904165,0.06378518,0.052696973,-0.005764607,0.019572362,-0.0023450435,-0.00701063,-0.013762254,-0.005449601,0.006762125,-0.004049575,-0.010178188,-0.019068353,0.01838234,-0.010892201,0.0051555955,0.007770144,0.018144336,-0.014420267,-0.02269442,-0.039648734,-0.0070526307,0.0075391396,0.041244764,0.03200459,0.008904165,0.006373618,0.02860253,0.01404226,-0.013405248,-0.018284338,0.016072297,0.015764292,0.009681179,0.006013111,0.0029085537,0.0378567,0.00051144697,0.014329265,0.02056638,0.011984222,0.015386284,0.008743161,0.0074481377,-0.005281598,-0.014798273,-0.0070666308,-0.011312209,-0.0011060204,-0.0014989027,-0.013020241,-0.00021733214,-0.016310303,-0.04387681,-0.008085149,0.011046205,0.00107802,-0.017640326,-0.008449157,-0.004914091,-0.00037997577,-0.02648849,-0.02381444,-0.0035770661,0.0035945666,0.018242337,-0.016506305,-0.006653623,0.0048160893,-0.030408563,-0.00868016,-0.0124042295,-0.035840664,-0.019782366,-0.0050925943,0.034160633,0.01841034,0.02440245,-0.00703863,-0.013832256,0.0066396226,-0.0051030945,-0.0028018018,-0.011417211,-0.0028525528,0.017486323,-0.0074411375,0.0012783987,-0.0032603103,-0.0056001036,0.013783255,-0.0012215226,0.007966148,-0.0038535714,-0.020720383,-0.021798404,0.010423193,0.021742402,0.033264615,-0.009933184,-0.02539647,0.007420137,-0.030128557,-0.021126391,-0.008995166,-0.005624604,-0.0063351174,0.0043610805,-0.008085149,-0.010129187,0.0032078093,0.031836588,-0.012502232,0.011956221,0.0036260672,0.005519602,0.03026856,0.0014000259,0.009457175,-0.018984351,-0.024262449,0.011284209,-0.024612455,0.006013111,0.0038045703,-0.03348862,0.012600233,0.017584326,0.0061251135,-0.033264615,0.015204282,-0.013608252,0.04818889,-0.0162403,-0.0017657827,-0.0161843,-0.00030888073,-0.013139243,-0.003452814,-0.01242523,-0.0032830606,0.006541621,-0.020034371,-0.010472193,-0.009961184,0.0034860645,-0.033544622,-0.012481231,0.02424845,0.0047635883,0.010710198,0.0027388006,-0.0074341376,-0.0056981053,-0.007238134,0.00058669836,-0.019614363,-0.0045255837,0.007868146,0.011473212,0.0270205,0.021196391,-0.0077071427,0.016492305,0.010955202,-0.014756273,0.00019884743,0.0008142026,0.02108439,-0.013363247,0.03561666,-0.0034510638,-0.007672142,-0.014364266,0.0070421305,0.026628492,0.007406137,-0.017696327,-0.018592345,-0.029372543,-0.02860253,0.016660308,0.012985241,-0.009002167,-0.0037660697,-0.021728402,0.0026897998,0.0029085537,0.004536084,-0.0017097816,-0.010633197,0.0060341116,-0.0075811404,0.023380432,-0.002215541,0.01829834,-0.017724328,-0.030604566,-0.028504528,0.010206189,0.031164577,-0.018522343,0.026348487,0.017920332,-0.008694161,0.0039515733,-0.0028455527,0.0023817942,0.008323154,-0.0047320877,-0.013293246,0.016604308,-0.023002425,-0.025732476,-0.007861146,0.0040250747,0.012530232,-0.011648215,0.013076242,0.006867127,-0.021378396,0.020314375,-0.0037660697,0.0486649,0.022820422,0.023100428,0.025088465,0.001352775,0.0037520693,0.0016931563,0.003885072,0.013468249,0.019264357,0.009814181,-0.010241189,-0.021798404,0.00432608,0.017584326,-0.024696456,-0.017164318,-0.0111582065,0.001993287,0.0024972963,-0.0025637974,-0.008316154,0.011914221,-0.003458064,-0.010997203,0.008449157,0.018032333,-0.01192822,-0.0032025592,0.026670493,0.018256338,0.027286505,-0.010290191,0.003081807,0.0041370764,0.009415174,0.023548435,0.01352425,-0.020216374,0.029428544,-0.009212171,-0.0059186094,0.024374451,-0.0053690993,0.015498287,-0.0071541322,0.00432258,0.030548565,-0.014784274,0.012131224,-0.006534621,0.00649962,0.006982629,-0.007392137,-0.0014271514,-0.008729162,-0.00973018,0.023576437,0.012635234,0.008302154,-0.031052575,-0.0031518084,-0.002103539,-0.012278227,-0.0012591482,0.006111113,-0.0011462712,-0.03351662,-0.027258504,-0.008295153,0.0161983,0.036624677,-0.005463601,-0.023632437,0.012075223,0.017542325,-0.032060593,0.016296301,0.019012352,-0.012628234,-0.019124353,0.011704217,-0.018592345,-0.035980664,0.010780199,-0.017556325,-0.038640715,-0.02535447,0.0016459054,-0.004539584,0.0022400415,-0.021994406,-0.005848608,-0.0055931034,0.0033775624,0.0034755643,-0.025578473,0.01675831,0.009590178,0.0028368025,0.015988296,-0.014196263,0.018522343,-0.020146372,-0.016898314,-0.0022487915,-0.04426882,-0.026810495,-0.022428416,-0.008701161,-0.008533157,-0.0022400415,-0.009415174,-0.0070701307,-0.014364266,0.007245134,0.0017727828,-0.0063456176,-0.004910591,0.009009167,0.0036050668,0.01243923,-0.021392396,-0.00810615,-0.0022575418,0.022428416,-0.02749651,-0.014392266,-0.014924276,0.040824756,0.017010314,-0.015162281,-0.0064961202,-0.0062581156,-0.03138858,0.002324043,0.004770588,0.00056044786,-0.007623141,0.007511139,0.012047223,0.036260672,-0.0032585603,-0.0065871216,0.0028788033,0.010003185,-0.020958388,-0.01999237,0.0059151095,0.0033740625,-0.02108439,0.0026512991,-0.0021262893,-0.015540288,0.022456415,-0.005453101,-0.016912313,-0.017878331,0.0089111645,0.03136058,0.029960554,0.023912443,0.021490397,-0.022764422,-0.013706254,0.020384377,-0.01517628,-0.014728272,-0.023380432,0.010416193,0.0015531537,0.012460231,-0.002488546,-0.029008538,0.012411229,0.0040845755,-0.0053305984,0.003190309,0.029596547,0.03301261,0.014742273,-0.01940436,-0.0039655734,0.025564473,-0.02331043,-0.00432608,0.02219041,-0.030016555,0.0061006127,-0.0161843,-0.019838367,-0.018536342,-0.016058298,-0.011830219,-0.0017762829,-0.004665586,0.014147262,0.019040352,-0.023282431,0.025144465,0.009814181,0.0015855293,-0.018228337,-0.004539584,0.0072241337,-0.019586362,0.003615567,0.0059256097,-0.019194355,-0.010591196,0.006597622,0.017276319,0.017976332,0.010724198,0.23162028,-0.018676346,-0.013363247,0.012047223,0.018046334,0.0025095465,0.02331043,0.019236356,0.00018998788,0.010717198,0.009051167,0.019908369,0.0047250874,-0.007623141,0.02273642,-0.017458323,-0.022526417,-0.008407156,0.0046340856,0.017752329,0.014014259,-0.009142169,-0.004756588,-0.022554418,0.042924795,-0.011109206,-0.009891183,0.002812302,0.0060376115,0.006923128,-0.0075461394,-0.003080057,0.021028388,0.0012337728,-0.014280264,-0.00044669578,0.021686401,-0.00868016,0.012712236,0.001517278,0.037044685,-0.025004463,-0.0016441554,-0.012103224,0.012838238,0.022876423,-0.019908369,-0.020412378,0.02815452,0.015540288,-0.016576307,-0.0052780975,0.0027615512,0.029008538,0.008309154,-0.009814181,-0.011648215,0.0025042964,0.012348228,-0.019810367,-0.024220448,0.008057149,-0.008386156,0.022666419,-0.0013904007,-0.0015496537,-0.0068076258,-0.010101187,0.018158335,-0.01569429,-0.015526287,-0.0154142855,-0.0075811404,-0.012831237,-0.029540546,-0.015736291,0.02909254,-0.00039966364,0.022764422,0.028980536,-0.020622382,-0.000865391,-0.0011033954,-0.014392266,-0.009135169,-0.021280393,0.035504658,-0.006146114,-0.00647162,-0.0069126277,-0.016156299,0.014091261,-0.011935221,0.009989185,-0.00097039295,0.00019808179,0.010493194,0.012649234,0.0053935996,0.0012022723,-0.02592848,0.07632941,0.007087631,-0.0030555564,0.0003574441,0.010164188,0.0021122892,0.023002425,0.0055476027,-0.011361211,0.0019670364,-0.018088335,0.00084176555,-0.021406395,-0.012222226,0.0027860515,0.023604436,-0.006174114,0.015624289,0.0016091547,-0.030408563,-0.0130622415,-0.008484157,0.011214208,0.00378707,-0.006594122,0.0070526307,-0.0018690346,-0.01730432,-0.0069651287,0.0047495877,-0.019754365,0.008827163,0.015582289,-0.010465194,-0.022526417,-0.017332321,-0.008939166,0.01786433,-0.0051170946,0.0020300376,0.0161423,-0.0057996074,-0.011291209,-0.013440249,-0.009933184,-0.012285227,0.009058167,0.0066816234,0.00037581945,-0.004924591,0.012796237,-0.009807182,-0.015820293,0.0061286134,-0.0123342285,0.015918294,0.002327543,0.0028805532,-0.004952592,-0.023604436,0.0046200855,0.009492176,-0.018634345,-0.0142032625,-0.018480342,-0.18245138,0.008939166,0.022372413,-0.037744697,0.010948203,0.0010027685,0.028784532,-0.012355229,-0.044156816,0.015596288,0.034944646,-0.01295024,-0.03029656,-0.0026057982,-0.0053305984,-0.012796237,-0.008785162,-0.0028350526,0.0035280653,0.013741254,0.04771288,-0.020244375,-0.0025462972,0.007080631,-0.01785033,-0.0030310561,0.004375081,0.023058427,0.015344284,-0.030940572,-0.008981166,-0.0034335635,0.017822329,-0.005687605,-0.008470157,-0.0038710716,0.004378581,-0.021910405,-0.021168392,-0.0008264528,0.020314375,0.016856313,0.014980277,-0.0017710328,-0.015498287,0.002593548,0.023422433,-0.013174243,0.005463601,-0.028812533,0.002429045,-0.0070701307,0.011655215,-0.0064786198,0.0020387878,0.0055266023,-0.0063911183,-0.019222356,0.0044555822,-0.0046760864,0.002115789,-0.0054146,0.011984222,0.018550344,0.0051835957,0.006212615,7.858739e-05,0.0148962755,-0.040964756,0.0093591735,-0.0088061625,-0.0052605974,-0.011249208,-0.0048790905,0.0021350395,0.035868663,-0.018466342,-0.009506176,0.003402063,-0.02216241,-0.00862416,0.018242337,-0.0074341376,-0.0017369072,-0.0041825776,-0.0045570843,-0.00046594613,0.0378847,-0.007980147,-0.013468249,0.020650381,-0.047432877,-0.0044625825,-0.014532269,-0.0014805273,0.01834034,0.0142382635,-0.021392396,0.015204282,-0.004809089,0.0136152515,0.0002618486,-0.0016677808,-0.00028284898,0.030548565,0.00324106,0.0029138038,0.015092279,0.033740625,-0.0063071167,-0.026740495,-0.021840405,7.421231e-05,0.0039095725,0.014322265,0.02814052,-0.0074831382,0.009884183,0.009793181,-0.0067411247,0.06602522,0.0018830348,-0.013811256,0.014462268,-0.009037167,-0.022848424,-0.11648215,-0.046312857,-0.004508083,-0.0030678068,-0.008344155,0.02429045,-0.00809915,0.001675656,-0.028868534,0.031724587,-0.016926313,-0.030100556,0.023884442,0.0018532843,-0.00431558,-0.032732606,0.0031168077,-0.006601122,-0.027846515,0.033292618,-0.012103224,-0.021434397,0.006419119,-0.021000389,0.0122992275,0.0043435805,-0.033656623,-0.008302154,0.0036855682,-0.0070036296,0.010227189,-0.0106051965,0.01457427,-2.8711469e-05,-0.0037450693,-0.023492435,-0.00487559,-0.010360192,0.020356376,-0.01789233,0.011200207,-0.0037555695,-0.00072801346,-0.008862164,-0.03945273,-0.022036407,-0.007259134,0.020804385,0.030128557,-0.021322394,-0.036932684,0.011998222,-0.019516362,0.0044625825,0.009534176,-0.002864803,-0.0034178132,0.004795089,0.0045010834,0.0128172375,-0.01884435,0.007091131,-0.009436174,-0.0014787774,0.0108222,-0.02973655,-0.0034930645,-0.01575029,0.011452212,-0.02056638,-0.005075094,-0.0032078093,-0.009044168,0.011795218,-0.015624289,-0.014014259,-0.011984222,-0.02108439,0.005439101,-0.0044520823,-0.005663105,-0.011732217,-0.009233171,-0.014336266,0.018256338,-0.0036575678,-0.02538247,-0.01790633,0.011053205,-0.008421156,0.00058013573,0.03200459,0.010332191,-0.02755251,0.019138355,0.01454627,-0.028280523,-0.00010910358,0.008568158,0.010409192,-0.027482508,-0.0070316303,-0.04712487,0.02811252,-0.0031150577,-0.03413263,-0.01569429,-0.0049420916,0.008687161,-0.008190151,-0.01245323,0.020216374,-0.016296301,0.010787199,-0.014280264,-0.0031080574,-0.01729032,-0.012292228,0.01890035,-0.011963221,-0.0036435674,-0.005075094,0.015302283,-0.0015601539,0.012201225,0.011473212,-0.012362229,0.0009563927,-0.010507194,0.012705235,-0.012096223,-0.013041241,-0.0036925683,-0.02213441,0.003452814,0.023100428,-0.00081201503,0.0012993991,-0.013146243,0.03298461,0.027244505,0.022050409,-0.0034493138,-0.032620605,-0.0006593247,-0.01890035,-0.003615567,-0.010549195,-0.005736606,-0.0076441416,-0.0075951405,-0.0017640326,0.02486446,0.00648562,-0.007196133,-0.039760735,0.0066151223,0.020146372,-0.009786181,-0.017976332,-0.0065206205,0.0047495877,0.04390481,-0.012145225,-0.0045255837,-0.0009677679,0.0067306245,-0.009058167,-0.00323581,0.010479194,0.018508343,-0.0038430712,0.0074411375,0.008456157,-0.0031063075,0.017584326,-0.008981166,-0.020454379,0.009443175,0.0018042834,0.0029925553,0.03292861,0.012894238,0.0014192762,-0.009674179,-7.404824e-05,0.0047845887,0.0047355876,-0.010682197,0.008687161,-0.0088061625,0.00485109,0.028728532,0.01404226,-0.014420267,0.011851219,-0.0154842865,-0.018578343,-0.0045570843,-0.009464175,0.015400285,0.022596419,-0.007294135,-0.001401776,-0.006870627,-0.03026856,-0.025564473,0.023114428,-0.012705235,-0.0378007,-0.004812589,0.033320617,0.032760605,-0.0020265374,0.0014490267,0.009261171,-0.018228337,0.024220448,-0.011564214,-0.023128428,-0.03620467,0.020146372,0.025914479,0.0011200208,-0.0026722995,-0.008568158,0.011676216,0.03292861,0.024696456,-0.009520176,0.0062441155,0.029456545,0.0005215097,0.0012565232,-0.0050925943,-0.008246153,-0.018158335,-0.025648475,-0.018284338,0.0077421432,0.015190281,0.06865727,0.015904294,-0.00868016,0.019852368,-0.022176411,0.020482378,0.034384634,-0.0046690865,-0.024136446,-0.0123342285,-0.012306227,0.010409192,-0.014126262,0.0057541067,0.0024657957,0.01731832,-0.008393155,0.0035753162,-0.018046334,0.017766329,0.008484157,-0.0031553083,0.023464434,-0.002759801,-0.017668327,0.015204282,0.0061251135,0.0068356264,0.0027755513,-0.0162123,0.025746476,0.014217263,-0.02483646,-0.022218412,-0.008239153,0.011830219,-0.0060481117,-0.034916647,-0.0029715549,0.0028490527,-0.006713124,-0.021756403,-0.017514324,0.003351312,-0.009870183,0.008974166,-0.010423193,-0.01950236,-0.015736291]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011845612,0.0044860984,-0.0021625026,-0.014722528,-0.002573991,0.0245142,-0.015310869,0.017622208,-0.011318556,-0.03445996,0.0047452487,0.016011275,-0.016109332,0.013594875,-0.0030029896,-0.02510254,0.027974205,0.006359684,-0.011563699,-0.014267265,-0.00365962,0.017706256,-0.007070596,-0.038746443,0.0070776,0.03378757,0.027890155,-0.015394918,0.022847235,0.009154303,-0.006005979,0.015296861,-0.037709843,-0.024234038,0.0012134529,-0.00014883622,0.010162887,-0.0009105274,0.004041341,0.004395046,0.011143455,0.006478753,0.0013570361,-0.014778561,-0.008040657,-0.0082507795,0.015563015,-0.039839078,-0.00809669,-0.013440786,0.010401025,0.024948452,-0.0191631,-0.012663336,-0.016305445,-0.0029837284,-0.004878326,0.009168311,0.013692932,-0.014946658,0.021264318,0.018098485,-0.017734272,-0.0014384582,-0.02161452,0.0044790944,-0.024724321,-0.012327141,-0.014043135,0.0076274183,0.034515996,0.010302968,-0.010127867,-0.025732907,0.034712106,-0.0072562033,-0.003551057,-0.025802948,-0.01389605,0.01633346,-0.0008619368,-0.023421567,-0.015156779,0.020521889,0.012495238,-0.016851762,0.0034792654,0.015520991,-0.0134898145,0.0037016443,-0.0039572925,-0.0008448644,0.02035379,0.015268845,0.0077464874,-0.005799359,-0.008657015,0.026041085,0.0011626735,0.009847704,-0.0071476405,-0.0036281017,-0.021068204,-0.009847704,-0.014736536,0.0029136878,0.013762972,0.0037226565,0.00588691,-0.013370745,-0.03619697,0.035524577,0.0117387995,-0.038130086,-2.998612e-05,-0.00987572,0.0076344223,-0.01783233,0.0037471706,-0.015955241,0.02370173,0.014456374,0.01804245,-0.008621994,0.012089003,-0.0065522953,-0.0061950884,-0.011640743,-0.017272005,-0.013377749,0.0012064489,0.010716207,0.0050709373,0.019149093,-0.015100747,0.017426094,-0.01441435,0.013286697,-0.025466751,-0.030509673,0.007676447,0.005186504,-0.01961136,0.017930387,-0.002067948,0.016067307,0.011003374,0.026293231,0.016977835,0.01296451,0.0021852658,-0.038270168,0.021712577,0.029304976,0.0165716,0.02109622,-0.029529106,-0.009343413,-0.021180268,-0.008159727,-0.007326244,0.013833013,0.006012983,0.018224556,0.010765236,0.010008798,0.01463848,-0.0053195814,0.012495238,0.004275977,-0.011262524,0.031742387,-0.0288287,0.0005213645,-0.0070285713,0.01940124,0.021166261,-0.0056907963,-0.017496135,-0.025508776,0.017243989,-0.0017405082,0.005032415,0.024976468,-0.019345205,-0.023743754,0.016907794,-0.012264105,0.0051830024,0.0019121076,0.018742858,0.016137348,-0.001836814,0.0049833865,-0.6701482,-0.021880675,0.0038872517,-0.025270639,0.015464959,0.016991843,-0.002067948,-0.016249413,-0.032582875,0.012439205,-0.021194277,0.0067589153,0.028030237,-0.028856715,-0.0072702114,-0.026055092,-0.0030362587,-0.03328328,0.009693615,0.0028751655,-0.018686825,0.015955241,-0.01924715,-0.009056246,-0.0014699765,0.028618578,0.0016153107,-0.016809737,0.01879889,0.010127867,-0.00939244,0.033647493,0.00538612,0.01560504,0.04359325,-0.020998163,-0.0070460816,0.015563015,0.00016678411,0.050401196,-0.033031132,-0.011948922,0.004913346,0.00053230836,-0.011234508,0.0037541746,0.022342943,0.0025442238,0.02012966,0.010667179,0.012074995,0.01574512,0.009567542,0.008411873,0.02012966,-0.020465855,0.023155414,-0.01140961,0.01147965,0.008271792,0.0126213115,0.0052250265,-0.016991843,-0.0064332266,-0.0071861628,0.026181165,-0.021138245,0.01389605,-0.004657698,-0.04583455,-0.006839462,0.017173948,-0.021530472,0.005375614,-0.011087422,0.025985053,0.015310869,0.016473543,0.017734272,0.018910954,-0.00042265106,-0.030733803,0.004184924,0.020381806,0.033843603,-0.00076913304,-0.033171214,-0.008860133,-0.0047102286,0.0027088192,0.0077394834,0.019359214,-0.016543584,-0.019555328,0.0014577194,0.03639308,-0.00987572,0.0165716,-0.016179372,-0.015058723,-0.0023568652,-0.010744223,0.009756652,-0.0072351913,-0.010344992,0.0052355328,0.00045395046,0.027764082,0.020031603,-0.020409822,0.010267948,0.019261157,-0.011885885,0.014540423,-0.0122571,-0.033703525,0.040847663,-0.014232244,0.00083260733,-0.007333248,0.0033969677,0.01281042,0.0077394834,-0.01835063,0.0076484303,0.033031132,-0.014323297,-0.031182062,-0.0139730945,0.00832082,0.022707153,-0.018294597,0.014281273,-0.012320137,0.01769225,-0.0005502562,-0.00053799915,0.0020311766,0.0042374544,-0.02251104,-0.004545633,0.01129054,0.0015837924,0.017944394,-0.025886996,-0.004009823,-0.008026649,0.00809669,-0.0055262013,-0.008846125,-0.010835277,-0.021194277,-0.01244621,-0.020409822,0.005270553,0.008439889,0.015366902,-0.03121008,-0.025802948,-0.02770805,0.010674183,0.02563485,-0.015675081,0.017594192,-0.015549007,0.0069130044,-0.0016424514,0.034291863,0.007326244,-0.022469016,0.014792569,-0.027918171,0.0096025625,0.013160624,-0.0028033738,0.0025197095,0.0050849454,-0.013167627,-0.02132035,-0.014918642,0.0008838245,-0.000827792,0.01170378,-0.0004355648,0.014470383,0.009140295,0.0245142,0.010891309,-0.016739696,0.035104334,-0.006268631,0.011955925,-0.018140508,-0.010218919,-0.0005292441,-0.007879565,0.008460901,-0.01664164,0.0024671792,0.015731113,0.01664164,0.019737434,0.008026649,-0.0072351913,0.007123126,-0.018378647,-0.0011346573,-0.014106171,0.019121077,0.014204228,0.026279222,-0.040007174,-0.021292334,-0.006846466,0.01196293,0.009826692,0.00020235158,0.011801836,-0.021502456,0.015549007,-0.03535648,0.00097443943,0.012586291,-0.00029066837,-0.018742858,0.010695196,-0.0034792654,0.01990553,0.014281273,-0.014890626,0.0060550077,0.027007645,-0.0006290519,0.031602304,0.021040188,-0.018070467,0.010380013,0.005953449,0.0021502455,0.0024829383,-0.0049658767,0.006976041,-0.015100747,0.0056767883,0.036000855,-0.00921734,0.03373154,0.019219132,-0.02696562,-0.0015969251,-0.011864873,0.009399445,-0.0035895794,-0.0091192825,0.009168311,0.0048292973,0.014281273,-0.0061705746,-0.003915268,0.020437839,0.0069865473,0.020073628,0.03336733,-0.012278113,0.027876148,-0.0047592567,-0.012411189,-0.03233073,-0.022721162,0.003169336,-0.013643904,-0.00037778134,0.005960453,-0.028058253,0.026013069,0.0170899,0.017145932,0.014764553,0.034207817,0.016165365,-0.03409575,-0.026937604,0.018882938,0.0053300876,-0.008993209,0.004892334,-0.022034764,0.010751228,-0.010267948,0.0074383086,0.021516465,0.017356053,-0.003796199,-0.0048152893,-0.018476702,0.0039187702,0.031378176,-0.011598718,-0.0012213325,-0.0060970318,0.007452317,0.019667393,-0.0050884476,-0.04174418,0.017131925,-0.031350162,0.03112603,-0.007221183,-0.016949818,-0.019345205,0.006566304,-0.02525663,0.022342943,-0.018462695,0.014148195,0.001701986,0.008110698,-0.01722998,0.030061414,0.018140508,0.0056697843,-0.026265215,-0.024248047,0.008846125,0.06376494,0.052726544,-0.005778347,0.01954132,-0.0023463592,-0.0070776,-0.013748964,-0.0054736705,0.0067764255,-0.004037839,-0.010211916,-0.019051036,0.018322613,-0.0108562885,0.00514448,0.0077394834,0.01819654,-0.0143723255,-0.022707153,-0.039642964,-0.007070596,0.0075713857,0.04129592,0.03202255,0.008867136,0.006377194,0.028604569,0.014029127,-0.013426778,-0.018322613,0.016067307,0.015773136,0.009721631,0.006012983,0.0029189407,0.037849925,0.000518738,0.0143723255,0.020591928,0.012018962,0.015394918,0.0087060435,0.0073962845,-0.005260047,-0.014792569,-0.007098612,-0.011332565,-0.0010935084,-0.0015347641,-0.013041555,-0.00022872625,-0.01633346,-0.043817382,-0.008068674,0.011108435,0.0010541106,-0.01769225,-0.008411873,-0.004871322,-0.00031715247,-0.026503352,-0.023799786,-0.0035965834,0.0035738202,0.018224556,-0.016529575,-0.0066608586,0.004776767,-0.030425625,-0.0086780265,-0.012432202,-0.035860773,-0.019779457,-0.0050884476,0.034123767,0.018406663,0.024500191,-0.007091608,-0.013826009,0.0066853724,-0.0051234677,-0.0028103779,-0.011423618,-0.0029014307,0.017440103,-0.0074102925,0.0012922486,-0.0032551356,-0.0056207557,0.013762972,-0.0012318386,0.007942601,-0.0038872517,-0.02073201,-0.02183865,0.010394021,0.021712577,0.03328328,-0.009903737,-0.025396712,0.0074032885,-0.03008943,-0.02109622,-0.009035233,-0.005631262,-0.006366688,0.0043670298,-0.008068674,-0.010127867,0.0032288705,0.03185445,-0.012467222,0.011920906,0.0036316037,0.005529703,0.030369593,0.0013684176,0.009504505,-0.018980995,-0.024206022,0.011262524,-0.024584241,0.0060585095,0.0038417254,-0.033535425,0.0126073025,0.017594192,0.0060725175,-0.033227246,0.015156779,-0.013594875,0.048187915,-0.016179372,-0.0018017937,-0.016221397,-0.0002978913,-0.013139611,-0.0034810165,-0.012453213,-0.0032726456,0.006590818,-0.01998958,-0.010520094,-0.0099877855,0.0034862694,-0.033591457,-0.01244621,0.024262054,0.004783771,0.010688191,0.0027736067,-0.0074383086,-0.0057153106,-0.007207175,0.0005515695,-0.019625368,-0.0044860984,0.007844544,0.011451634,0.027049668,0.021236302,-0.007669443,0.01648755,0.010982362,-0.014722528,0.00018834347,0.000765631,0.021082211,-0.013377749,0.035608627,-0.0034862694,-0.007669443,-0.014442366,0.007102114,0.026629426,0.0074383086,-0.017664231,-0.018616784,-0.029389024,-0.028632585,0.01664164,0.012971514,-0.008965193,-0.0037261585,-0.021782618,0.002696562,0.0029084347,0.004521119,-0.001712492,-0.010702199,0.0060725175,-0.007592398,0.02339355,-0.0022500535,0.018294597,-0.017720265,-0.030621737,-0.02852052,0.010211916,0.031154046,-0.018504718,0.026349263,0.017958403,-0.008636002,0.0039713006,-0.002805125,0.002332351,0.008271792,-0.0047277384,-0.013265684,0.016599616,-0.023043348,-0.025718898,-0.007858552,0.0041043777,0.012495238,-0.011675763,0.0130485585,0.00688849,-0.021348367,0.020255733,-0.0037716848,0.048692204,0.02281922,0.023099381,0.025060516,0.0013386505,0.0037576768,0.001655584,0.0039327783,0.013419773,0.01931719,0.009854709,-0.01028896,-0.021782618,0.004303993,0.017650224,-0.024724321,-0.017201964,-0.011178475,0.0020014094,0.0024934444,-0.002570489,-0.008306812,0.011892889,-0.0034810165,-0.010975358,0.008439889,0.01804245,-0.011892889,-0.0032323725,0.026629426,0.018238565,0.027301814,-0.010218919,0.0031062993,0.004146402,0.00939244,0.023533633,0.013496818,-0.020213708,0.029445056,-0.009182319,-0.0059149265,0.024416143,-0.005414136,0.015492975,-0.007214179,0.004289985,0.03053769,-0.014764553,0.012159043,-0.0065347855,0.006510271,0.0070776,-0.007340252,-0.0013920564,-0.0087340595,-0.00970062,0.023589665,0.012642323,0.0082858,-0.031041982,-0.0031203076,-0.0021134743,-0.012271108,-0.0012773649,0.0060865255,-0.0011136452,-0.033535425,-0.027231775,-0.008292804,0.016221397,0.036617212,-0.0054491563,-0.023659706,0.012053982,0.01753816,-0.032050565,0.016305445,0.018995004,-0.012628315,-0.0191631,0.011682767,-0.018602775,-0.035944823,0.010793252,-0.017524151,-0.038606364,-0.025368696,0.0016153107,-0.0045106127,0.0022185352,-0.022006748,-0.005900918,-0.0055752294,0.0034004697,0.003428486,-0.025592824,0.016753705,0.009651591,0.0028033738,0.016011275,-0.014253257,0.018504718,-0.02014367,-0.016921801,-0.002199274,-0.044237625,-0.02681153,-0.022384968,-0.008713047,-0.008558958,-0.0022272903,-0.009469485,-0.0070811016,-0.014400342,0.007214179,0.001772902,-0.006398206,-0.0049483664,0.009021225,0.0036351057,0.012425197,-0.021446424,-0.008159727,-0.0022430492,0.022398975,-0.02748392,-0.0143723255,-0.01493265,0.040819645,0.017061884,-0.015142771,-0.006513773,-0.006244117,-0.031378176,0.002344608,0.004804783,0.00050604314,-0.0076134102,0.007466325,0.012046979,0.036253,-0.0032673927,-0.0065522953,0.0028856716,0.010036814,-0.020928122,-0.020045612,0.005960453,0.0033286782,-0.021124236,0.0026090113,-0.0021414906,-0.015577023,0.022483023,-0.0054246425,-0.01693581,-0.017916378,0.008909161,0.031350162,0.029921332,0.023897843,0.02147444,-0.022749178,-0.013720948,0.02035379,-0.015156779,-0.014778561,-0.023421567,0.010422037,0.0015470211,0.012425197,-0.00246893,-0.029024813,0.012404186,0.0041008755,-0.0053405934,0.003169336,0.029613154,0.03305915,0.014722528,-0.019373221,-0.004048345,0.025578817,-0.023309503,-0.0043285075,0.022146828,-0.03000538,0.00611104,-0.016263422,-0.019863507,-0.018504718,-0.016053298,-0.011822849,-0.001774653,-0.004629682,0.014141192,0.019051036,-0.023351526,0.025144566,0.009784668,0.0015522742,-0.018224556,-0.0045666452,0.0071651507,-0.019569336,0.0036140934,0.005953449,-0.019149093,-0.010576126,0.006622336,0.017201964,0.017958403,0.010758232,0.23152612,-0.018686825,-0.013384753,0.01203297,0.01804245,0.0024829383,0.023295494,0.019219132,0.00020793294,0.010688191,0.0091192825,0.019975571,0.0047347425,-0.0075853937,0.022707153,-0.017440103,-0.022539057,-0.008425881,0.004629682,0.017762288,0.013994106,-0.0091472985,-0.0047942773,-0.02258108,0.04300491,-0.011059406,-0.009910741,0.002824386,0.0060445014,0.0069305147,-0.0075363657,-0.003064275,0.021054195,0.0012353406,-0.0143162925,-0.00043534592,0.02168456,-0.008685031,0.012663336,0.0015023702,0.037037455,-0.024976468,-0.001643327,-0.012131027,0.012824429,0.022889258,-0.01990553,-0.020395815,0.028114285,0.015563015,-0.0165716,-0.005263549,0.0027963698,0.028996797,0.008306812,-0.009833696,-0.011682767,0.0024864404,0.012369165,-0.019779457,-0.024192013,0.008068674,-0.008432885,0.022707153,-0.0014235746,-0.0015233825,-0.006814948,-0.01006483,0.018140508,-0.015661072,-0.015520991,-0.015408926,-0.0076204143,-0.012824429,-0.029473072,-0.01575913,0.029108861,-0.0003734038,0.022791201,0.028996797,-0.02064796,-0.00083654706,-0.001097886,-0.01441435,-0.009056246,-0.021264318,0.035468545,-0.0061775786,-0.006478753,-0.0069060004,-0.016151356,0.014120179,-0.011948922,0.00999479,-0.0009560538,0.00024951954,0.01047807,0.012614307,0.005410634,0.0012011958,-0.02592902,0.07637224,0.0070460816,-0.0030152467,0.0003094918,0.010190903,0.0021187272,0.023043348,0.0055577196,-0.011388597,0.0019733931,-0.018112492,0.0008374226,-0.021348367,-0.0121660475,0.0028313901,0.023603672,-0.0061845826,0.015619048,0.0016442024,-0.030453641,-0.013090583,-0.008523937,0.0112205,0.003796199,-0.006608328,0.0070355753,-0.0018735853,-0.017328037,-0.006983045,0.0047452487,-0.019779457,0.00883912,0.015563015,-0.0104570575,-0.022567073,-0.017356053,-0.008916165,0.017888362,-0.00514448,0.0020434337,0.016151356,-0.0057958574,-0.01129054,-0.013398762,-0.009931753,-0.012299124,0.009021225,0.006706385,0.00036815077,-0.004909844,0.012775401,-0.009847704,-0.01582917,0.0061845826,-0.012355157,0.01598326,0.002318343,0.0029049327,-0.0049763825,-0.023617681,0.0045876573,0.0095325215,-0.018672816,-0.01422524,-0.018490711,-0.18266581,0.008972197,0.02235695,-0.037765875,0.010961349,0.0010304719,0.028772667,-0.012341149,-0.044181593,0.015619048,0.034936238,-0.012887465,-0.030313559,-0.0026317744,-0.0053160796,-0.012824429,-0.008790092,-0.0028524024,0.0035808242,0.013748964,0.047711637,-0.020241726,-0.0025407218,0.007070596,-0.017874354,-0.0030117447,0.00438454,0.023071364,0.015268845,-0.030929917,-0.008993209,-0.0034705102,0.017818322,-0.0057293186,-0.008488918,-0.0039467863,0.004409054,-0.021880675,-0.021138245,-0.0008080931,0.020311765,0.016823746,0.015030707,-0.0017343797,-0.015534999,0.0025477258,0.023449583,-0.013202648,0.0054351483,-0.028800683,0.0024234038,-0.007063592,0.011668759,-0.0065242792,0.0019909032,0.005529703,-0.0063246638,-0.0191631,0.004416058,-0.0046051675,0.0021204783,-0.005400128,0.012018962,0.018560752,0.005172496,0.006233611,9.4445335e-05,0.014890626,-0.040875677,0.009336408,-0.008825112,-0.005246039,-0.011213495,-0.0048748236,0.0020977152,0.035832755,-0.01843468,-0.009504505,0.003326927,-0.022188853,-0.008572966,0.018266581,-0.0074383086,-0.0017772795,-0.0042024343,-0.0045771515,-0.0004780269,0.037905958,-0.007956609,-0.013496818,0.020633953,-0.04740346,-0.0044825966,-0.014512407,-0.0014498398,0.01835063,0.01426026,-0.021404399,0.015184796,-0.0048398036,0.013650907,0.0002959214,-0.0016906043,-0.00030008008,0.030593721,0.0032691436,0.0029311979,0.015100747,0.03373154,-0.0063001495,-0.02674149,-0.021768609,0.00015627802,0.003943284,0.014400342,0.028100278,-0.007466325,0.009910741,0.009798676,-0.0067939353,0.066062264,0.0018875934,-0.013819004,0.014442366,-0.009014222,-0.022833226,-0.11654751,-0.04636686,-0.004542131,-0.003071279,-0.008376853,0.02429007,-0.00806167,0.0016958574,-0.028856715,0.031742387,-0.016893785,-0.030117447,0.023869827,0.00182981,-0.004282981,-0.03275097,0.0031413196,-0.006625838,-0.02777809,0.03328328,-0.012089003,-0.021432415,0.0063877003,-0.020984156,0.012285116,0.004300491,-0.033647493,-0.008306812,0.003680632,-0.006983045,0.010232927,-0.010583131,0.014582447,2.992456e-06,-0.0037261585,-0.023477599,-0.0048678196,-0.010359,0.020325774,-0.017888362,0.011192484,-0.0037646808,-0.00069909246,-0.008888149,-0.03944685,-0.022034764,-0.0071686525,0.020774033,0.030117447,-0.021348367,-0.036981422,0.011976938,-0.019457271,0.0044650864,0.009553534,-0.0028891736,-0.003414478,0.0047872732,0.004514115,0.012775401,-0.01886893,0.0070776,-0.009490497,-0.0014944907,0.0108702965,-0.029725218,-0.0034810165,-0.015731113,0.011444629,-0.020619944,-0.0050569293,-0.0032201153,-0.00906325,0.011836857,-0.015647063,-0.014008114,-0.012018962,-0.021068204,0.00542114,-0.004528123,-0.0056872945,-0.0117668165,-0.009182319,-0.014302284,0.018294597,-0.003680632,-0.025396712,-0.017916378,0.011108435,-0.008467905,0.00060409994,0.032050565,0.010309972,-0.02755396,0.019107068,0.014610464,-0.02829639,-9.482837e-05,0.008558958,0.010373008,-0.027441896,-0.0070075593,-0.04717933,0.028072262,-0.0031185565,-0.034123767,-0.015689088,-0.005018407,0.008741063,-0.008145719,-0.012439205,0.020157676,-0.016319454,0.01080726,-0.014309289,-0.0031308136,-0.01730002,-0.012236088,0.018882938,-0.011941917,-0.003568567,-0.0050569293,0.015282853,-0.0015496477,0.01222208,0.011472646,-0.012355157,0.00096218236,-0.010534102,0.012726372,-0.012074995,-0.013055563,-0.0036981422,-0.022090796,0.0035072817,0.023127398,-0.00080415333,0.0012922486,-0.01322366,0.033003118,0.027231775,0.022076787,-0.003437241,-0.032638907,-0.00064087124,-0.018910954,-0.0036386077,-0.010527098,-0.005736323,-0.0076484303,-0.0075783897,-0.0017562674,0.024822379,0.0065277815,-0.0071861628,-0.039755028,0.006566304,0.020171685,-0.009826692,-0.017986419,-0.006482255,0.0047347425,0.043873414,-0.012173051,-0.004528123,-0.0009989537,0.006727397,-0.00906325,-0.0032393765,0.010520094,0.018476702,-0.0038207131,0.0074383086,0.008453897,-0.003067777,0.017594192,-0.008993209,-0.020451847,0.009462481,0.001826308,0.0030397607,0.032919068,0.012915482,0.0013885543,-0.00970062,-7.742766e-05,0.0047347425,0.004741747,-0.010779244,0.008636002,-0.008797096,0.004871322,0.02867461,0.014071151,-0.0143863335,0.011808841,-0.015464959,-0.018532736,-0.0045631435,-0.009455477,0.015422934,0.022623105,-0.007312236,-0.0014226991,-0.006856972,-0.030285543,-0.025564808,0.02318343,-0.0126493275,-0.037821908,-0.0048012813,0.03328328,0.03275097,-0.002076703,0.0014043135,0.009224343,-0.01828059,0.024248047,-0.011570702,-0.02316942,-0.036224984,0.02012966,0.025957037,0.0010348494,-0.0026335255,-0.008643007,0.011640743,0.032947086,0.024640273,-0.009483494,0.006237113,0.029473072,0.0005686419,0.0012773649,-0.005098954,-0.008229767,-0.018098485,-0.025606833,-0.018266581,0.007718471,0.015184796,0.06875183,0.01589921,-0.0086780265,0.019877514,-0.022244886,0.02049387,0.034403928,-0.004657698,-0.024121974,-0.012299124,-0.012271108,0.010387016,-0.014120179,0.005792355,0.002447918,0.01730002,-0.008460901,0.003559812,-0.018014435,0.017776297,0.008516934,-0.0031185565,0.023463592,-0.0027701047,-0.01767824,0.015198804,0.006125048,0.006839462,0.0027490924,-0.016207388,0.02570489,0.014183216,-0.024822379,-0.02221687,-0.008271792,0.011829853,-0.0059499466,-0.034936238,-0.0029959856,0.0028611573,-0.006737903,-0.021768609,-0.017510142,0.0033707025,-0.00987572,0.008965193,-0.010464061,-0.019513303,-0.015773136]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011651411,0.004559096,-0.0021675825,-0.0147794485,-0.0025279715,0.024506452,-0.015311284,0.017578587,-0.011287523,-0.034485377,0.0047060507,0.015997073,-0.016081048,0.013582816,-0.0029565895,-0.02509427,0.027977383,0.0063645397,-0.011539446,-0.014233616,-0.0036143868,0.017732538,-0.007039832,-0.038712077,0.0071447995,0.033729613,0.027851421,-0.015381263,0.02282697,0.009139185,-0.0059691616,0.015283293,-0.037676398,-0.02425453,0.0011415235,-0.00012749198,0.010209856,-0.00089834834,0.0041182316,0.0043981452,0.011119575,0.006497499,0.0013584566,-0.014695474,-0.00801953,-0.008208472,0.015549211,-0.03983173,-0.008033526,-0.01344286,0.010342815,0.024982305,-0.01909012,-0.012715084,-0.016318973,-0.002932097,-0.0048565045,0.009146183,0.013666791,-0.014877418,0.021231461,0.018110422,-0.017718542,-0.0014433055,-0.02162334,0.004475122,-0.024800362,-0.0123022115,-0.014065668,0.007676636,0.03451337,0.010307825,-0.010069898,-0.02568209,0.03470931,-0.0072427695,-0.0035304127,-0.025822047,-0.013939707,0.01633297,-0.00090971985,-0.023414789,-0.01522731,0.02051768,0.012442168,-0.016906792,0.0034586848,0.015549211,-0.013463853,0.0037333502,-0.0039432854,-0.0009009725,0.020335738,0.01522731,0.0077186227,-0.005825706,-0.008649336,0.026045978,0.0011896336,0.009810979,-0.0071378015,-0.00360389,-0.021049516,-0.009824974,-0.014751457,0.002958339,0.01379975,0.0037578426,0.0058851875,-0.013302903,-0.03627683,0.035437085,0.011735385,-0.038040284,-4.589602e-05,-0.009887954,0.007655642,-0.017774526,0.0037193545,-0.015983077,0.023722693,0.014457547,0.018054439,-0.008565362,0.012050289,-0.0065954686,-0.006179097,-0.01162342,-0.017200703,-0.013393875,0.0011773874,0.010636724,0.005108427,0.019188091,-0.015157332,0.017410638,-0.0143735735,0.013295905,-0.025472155,-0.030510603,0.00766264,0.0052098953,-0.019649949,0.01795647,-0.001983889,0.016095042,0.011000612,0.026311897,0.016990768,0.013050981,0.0021535868,-0.038264215,0.02169332,0.029278982,0.016570896,0.021049516,-0.029530905,-0.009377112,-0.021161482,-0.0081734825,-0.0073267436,0.0137577625,0.005913179,0.018222388,0.01074869,0.010013916,0.014667483,-0.0053043664,0.012449166,0.004314171,-0.011252535,0.031770214,-0.028859112,0.00048503812,-0.0069663543,0.01938403,0.021161482,-0.005668254,-0.017508607,-0.025556128,0.017256685,-0.0017188456,0.005034949,0.024926323,-0.019300057,-0.023694701,0.016878802,-0.012246229,0.0051679085,0.001892917,0.018796211,0.016081048,-0.0017608327,0.0049159857,-0.6704495,-0.021875262,0.0039537824,-0.025234228,0.015451241,0.016962776,-0.0020976039,-0.01630498,-0.032553975,0.012421175,-0.021189474,0.006724929,0.027921401,-0.028887102,-0.007256765,-0.026087966,-0.0029880798,-0.03328175,0.009657025,0.0029460927,-0.018684246,0.015955087,-0.019202085,-0.009062209,-0.001509785,0.028649177,0.0016243748,-0.016836815,0.018726233,0.010104888,-0.009398106,0.033617646,0.0053148633,0.015675172,0.043666553,-0.021021526,-0.0070713223,0.01564718,0.00017636755,0.05038448,-0.033001836,-0.011910331,0.0048914934,0.0005449572,-0.011210548,0.0038208233,0.022379108,0.0026014487,0.0201258,0.010580741,0.012071283,0.015689168,0.009629034,0.008355427,0.020083815,-0.020433707,0.023162866,-0.01132951,0.011532448,0.00827845,0.012624112,0.005185403,-0.016962776,-0.006452013,-0.0071622944,0.026255913,-0.021147488,0.013834739,-0.004639571,-0.04587787,-0.0069243675,0.017130723,-0.02149738,0.0053918394,-0.011056595,0.025948009,0.015311284,0.016374957,0.01776053,0.018922172,-0.00037460338,-0.030734533,0.004139225,0.020405715,0.033841576,-0.0007618904,-0.033169784,-0.008852273,-0.004646569,0.0026871725,0.0077256206,0.019342043,-0.0165569,-0.019537983,0.0014520527,0.0363608,-0.009894952,0.016654871,-0.016179018,-0.01503137,-0.002347777,-0.010734694,0.009768992,-0.007298752,-0.010384802,0.0052133943,0.00045136097,0.027767448,0.020013835,-0.020377724,0.0102378465,0.019174095,-0.011875343,0.014527526,-0.0123022115,-0.03367363,0.040923398,-0.014289599,0.000806939,-0.0073967217,0.0033939548,0.012750073,0.007767608,-0.018362345,0.007571668,0.03302983,-0.014359578,-0.031098422,-0.013946705,0.008292446,0.022687012,-0.018320357,0.014240614,-0.012323204,0.017732538,-0.00057119905,-0.0005353351,0.0020416211,0.004237195,-0.022533061,-0.004552098,0.011287523,0.0015508974,0.01792848,-0.02590602,-0.0040237606,-0.007998536,0.008068515,-0.0054863105,-0.008922252,-0.010790677,-0.021161482,-0.012491153,-0.02039172,0.0053393557,0.008432403,0.015339276,-0.031238379,-0.02575207,-0.027669478,0.010643722,0.025654098,-0.015661176,0.017564591,-0.015549211,0.0068228985,-0.0016095043,0.03423346,0.007347737,-0.022463081,0.01470947,-0.027907405,0.009559056,0.013162946,-0.0028061357,0.0025332198,0.0050734375,-0.013190937,-0.021287443,-0.014877418,0.0008204973,-0.00085767335,0.01165841,-0.00043649058,0.01441556,0.009111194,0.024576431,0.010916638,-0.016696857,0.0350732,-0.006357542,0.011945321,-0.01815241,-0.01009789,-0.00050690636,-0.007837586,0.008425405,-0.016668865,0.0024614919,0.015703164,0.016696857,0.01970593,0.008068515,-0.007214778,0.007165793,-0.018390335,-0.0011012858,-0.014135647,0.019174095,0.014149643,0.026255913,-0.0399437,-0.021273447,-0.0068368944,0.011945321,0.009782987,0.00023748935,0.011728388,-0.02152537,0.015605194,-0.03532512,0.0010076896,0.012554133,-0.00024907955,-0.018810207,0.010692707,-0.0035304127,0.019915866,0.014303595,-0.014863422,0.006046138,0.026927706,-0.0005672628,0.031602267,0.021035522,-0.018096427,0.0103918,0.0059446692,0.002158835,0.0024719886,-0.004943977,0.006952359,-0.015087353,0.005727736,0.035996914,-0.009244153,0.03370162,0.019202085,-0.026969694,-0.001600757,-0.011875343,0.009349121,-0.00360389,-0.009160179,0.0092091635,0.0048110182,0.01425461,-0.0061511057,-0.003869808,0.020433707,0.006987348,0.020027831,0.033365723,-0.012246229,0.027963387,-0.0047060507,-0.012407179,-0.03227406,-0.022784982,0.0032190087,-0.013631802,-0.00036979237,0.0059656627,-0.02801937,0.026045978,0.017074741,0.017130723,0.0147794485,0.034205467,0.016165022,-0.034037516,-0.02688572,0.018880185,0.0053393557,-0.008971237,0.0048460076,-0.022071203,0.010741692,-0.010328819,0.0073967217,0.02152537,0.017382646,-0.0038138253,-0.004779528,-0.018488307,0.0039502834,0.031350344,-0.011595429,-0.0011712642,-0.0061161164,0.0074107177,0.019663943,-0.0050734375,-0.041763138,0.017032754,-0.031350344,0.031126413,-0.0071413005,-0.016976772,-0.01931405,0.006553482,-0.02526222,0.02233712,-0.018516297,0.014128649,0.0017100984,0.008110502,-0.017186707,0.030090732,0.018138414,0.005664755,-0.026241917,-0.024226539,0.008880265,0.06382035,0.052651785,-0.0058047124,0.019523988,-0.0022777985,-0.0070888167,-0.013750765,-0.00545482,0.006724929,-0.004006266,-0.010160871,-0.019048134,0.018264376,-0.010902642,0.0051189233,0.0077746054,0.018222388,-0.014387568,-0.022645026,-0.039635792,-0.007025836,0.007578666,0.041287284,0.031994145,0.008978235,0.0063610408,0.028593194,0.014107655,-0.013372881,-0.018306362,0.016067052,0.015731156,0.009713009,0.005986656,0.0028918593,0.03790033,0.0005585155,0.014310593,0.020545673,0.012022297,0.015479232,0.008733311,0.0074037197,-0.0052518826,-0.0147934435,-0.0070643243,-0.011336508,-0.0010881649,-0.0015290291,-0.013022989,-0.00021048205,-0.016374957,-0.04380651,-0.0081175,0.011049597,0.0010750439,-0.017648565,-0.008446398,-0.0048530055,-0.00036017032,-0.026521832,-0.023806669,-0.0035479073,0.0035566546,0.0181804,-0.016444935,-0.0066514513,0.0048005213,-0.030426629,-0.008607349,-0.012351196,-0.03585696,-0.019719927,-0.005038448,0.034149483,0.01834835,0.024436474,-0.00707832,-0.013827741,0.0066829417,-0.005094431,-0.0027449047,-0.011378496,-0.0028463732,0.01743863,-0.007508687,0.0013505841,-0.0033222267,-0.005664755,0.01376476,-0.0011800115,0.00798454,-0.0038593113,-0.020699624,-0.021805285,0.010384802,0.021791289,0.03328175,-0.009922944,-0.025346193,0.0073827263,-0.030174706,-0.021063512,-0.009013224,-0.0056297663,-0.0063400473,0.004321169,-0.008047521,-0.010125881,0.0032347539,0.031770214,-0.012477158,0.011931325,0.0035496568,0.00545482,0.030314663,0.0013304652,0.009426096,-0.019006146,-0.024198547,0.0112805255,-0.024618417,0.005948168,0.0038033286,-0.03347769,0.012617114,0.017592581,0.006091624,-0.033225767,0.01522731,-0.013589814,0.048201155,-0.016221004,-0.0017547095,-0.016248995,-0.00033698996,-0.013120959,-0.003493674,-0.01243517,-0.0033414708,0.006549983,-0.020041827,-0.010447782,-0.009957933,0.0034849267,-0.033533674,-0.012463162,0.02425453,0.004779528,0.0107137,0.002730909,-0.0074667004,-0.0057067424,-0.007249767,0.00055764074,-0.019635953,-0.004552098,0.007851582,0.011455472,0.027053667,0.021231461,-0.007739616,0.016542906,0.01090964,-0.014751457,0.00020282816,0.00076451455,0.021063512,-0.013393875,0.035605036,-0.003448188,-0.007606657,-0.014443551,0.0070643243,0.026619801,0.0073897243,-0.017718542,-0.018642258,-0.029362956,-0.028593194,0.016612884,0.012932017,-0.0089922305,-0.0037578426,-0.0217493,0.00272741,0.0029111034,0.0045451,-0.0017678306,-0.010671713,0.0060496368,-0.0075996593,0.023358805,-0.0022603038,0.018264376,-0.01766256,-0.030678552,-0.02853721,0.010223852,0.031210387,-0.018530292,0.026339889,0.017970465,-0.008649336,0.003974776,-0.0028148831,0.0023775178,0.008334433,-0.0047445386,-0.013302903,0.016640875,-0.023064896,-0.025724078,-0.007907565,0.0040307585,0.012442168,-0.011707394,0.013050981,0.0068788812,-0.021315435,0.020279754,-0.0037788362,0.048621025,0.022798978,0.023120878,0.025052285,0.0013794502,0.0038068276,0.0017232193,0.0038523136,0.013435862,0.019258069,0.0098179765,-0.010307825,-0.021777293,0.004314171,0.017648565,-0.024744378,-0.017228695,-0.011196552,0.0020276255,0.002555963,-0.0025384682,-0.008334433,0.011910331,-0.003470931,-0.010979619,0.008439401,0.018026449,-0.011931325,-0.0032347539,0.026661789,0.01825038,0.027291594,-0.010265838,0.0031245376,0.0041847113,0.009489077,0.023512758,0.013456856,-0.020251762,0.029446932,-0.0092021655,-0.005913179,0.024436474,-0.0053813425,0.015549211,-0.0071343025,0.00431767,0.030510603,-0.01470947,0.012092276,-0.0065219915,0.006490501,0.007043331,-0.0074177156,-0.0014389318,-0.008733311,-0.009678019,0.023582736,0.012582125,0.008257457,-0.031098422,-0.0031472808,-0.0020766105,-0.012288216,-0.0012788562,0.006084626,-0.0011756379,-0.03356166,-0.027179629,-0.008299444,0.016221004,0.036612723,-0.0054723145,-0.023624724,0.012029295,0.017508607,-0.031966154,0.01630498,0.019006146,-0.012638108,-0.019118112,0.0116724055,-0.018516297,-0.03594093,0.010762685,-0.017522603,-0.0386281,-0.025346193,0.0015465237,-0.004506612,0.002200822,-0.022001224,-0.005829205,-0.005598276,0.0033712117,0.00347443,-0.025612112,0.016738845,0.0096150385,0.002802637,0.016025065,-0.014205625,0.01857228,-0.020153793,-0.016920788,-0.0022235652,-0.044282362,-0.026829736,-0.02233712,-0.008719315,-0.008495384,-0.00224106,-0.009433094,-0.0070573264,-0.014359578,0.007249767,0.0017713294,-0.0063400473,-0.004954474,0.009062209,0.0036248835,0.012428172,-0.021399409,-0.00815249,-0.0022603038,0.022393104,-0.027459543,-0.0143735735,-0.014849426,0.040755447,0.017032754,-0.015185324,-0.006476505,-0.0062070885,-0.031350344,0.002318036,0.0047515365,0.0004981591,-0.0076906313,0.007487694,0.012085278,0.036220845,-0.0032714924,-0.006630458,0.0028883605,0.009978927,-0.020895565,-0.020041827,0.005920177,0.0033764602,-0.021091504,0.002613695,-0.00214309,-0.015465237,0.022463081,-0.005451321,-0.016920788,-0.017914483,0.008943246,0.031322353,0.029894793,0.023904638,0.021511374,-0.022715004,-0.0137577625,0.020377724,-0.015143336,-0.014737461,-0.023344811,0.0104407845,0.00154215,0.012449166,-0.0025472154,-0.028915094,0.012407179,0.004076245,-0.0053778435,0.0031840194,0.02964287,0.03302983,0.014639491,-0.019342043,-0.004062249,0.025598116,-0.023358805,-0.004335165,0.022127185,-0.030034749,0.00613711,-0.016248995,-0.0198039,-0.018516297,-0.016025065,-0.011791368,-0.0017459623,-0.004646569,0.014121651,0.01896416,-0.023274831,0.025108267,0.009782987,0.0015334027,-0.018208392,-0.004566094,0.007165793,-0.01957997,0.003600391,0.005902682,-0.019216081,-0.010629727,0.0066689462,0.01727068,0.017970465,0.010720698,0.23154469,-0.018726233,-0.013386877,0.012057287,0.017998457,0.002477237,0.02324684,0.019244073,0.00021398097,0.010706702,0.009076205,0.01990187,0.004737541,-0.007578666,0.022673016,-0.017410638,-0.022561051,-0.008362425,0.0046255756,0.017718542,0.013981693,-0.009139185,-0.0047480376,-0.022547055,0.04296677,-0.0110635925,-0.009824974,0.0028008875,0.006081127,0.006955858,-0.007571668,-0.003065056,0.021063512,0.0012272471,-0.014240614,-0.00043824004,0.021707315,-0.008691323,0.0127220815,0.0015386511,0.037032593,-0.02496831,-0.0016182516,-0.012148258,0.012848043,0.022854961,-0.01990187,-0.020349734,0.028131336,0.015563207,-0.016542906,-0.0053043664,0.002757151,0.029055052,0.008334433,-0.009838969,-0.0116864005,0.0024894832,0.012379187,-0.019789904,-0.024240535,0.008033526,-0.008432403,0.022687012,-0.0014669232,-0.0015998823,-0.006812402,-0.010111886,0.018138414,-0.015675172,-0.01552122,-0.015367267,-0.007585664,-0.012813054,-0.029502913,-0.015759146,0.02902706,-0.00037460338,0.022742996,0.028999068,-0.020587659,-0.0008253083,-0.0011074089,-0.014429556,-0.009118192,-0.021231461,0.03552106,-0.006126613,-0.006476505,-0.006896376,-0.016221004,0.014128649,-0.011903334,0.010020914,-0.0009945687,0.0002479861,0.010482771,0.012589123,0.005412833,0.0012150008,-0.025864035,0.0763045,0.007036333,-0.003068555,0.00034355043,0.010160871,0.002113349,0.023008913,0.0055492907,-0.011350504,0.0019454008,-0.018124418,0.0008428029,-0.0214274,-0.012148258,0.002837626,0.023610728,-0.0061581032,0.015591199,0.0016654871,-0.030426629,-0.013099966,-0.008565362,0.011210548,0.0038033286,-0.0065989676,0.0070503284,-0.0018001955,-0.01734066,-0.0069698533,0.0047060507,-0.019691935,0.008838278,0.015591199,-0.010447782,-0.022575047,-0.017298672,-0.008894261,0.017886491,-0.005090932,0.0020538673,0.01613703,-0.0057837185,-0.0112805255,-0.013435862,-0.009950935,-0.012253226,0.009062209,0.0066794427,0.0004122168,-0.0048914934,0.012806056,-0.009894952,-0.01581513,0.006095123,-0.0123372,0.015997073,0.002276049,0.002958339,-0.0050244527,-0.023596732,0.0046255756,0.009524067,-0.018628262,-0.014212622,-0.018432323,-0.18239182,0.008957242,0.02230913,-0.03778836,0.010944629,0.001003316,0.028747147,-0.012379187,-0.044114415,0.015591199,0.03496123,-0.0129180215,-0.030258682,-0.002590952,-0.0053113643,-0.012764069,-0.008803288,-0.0027746453,0.0035269137,0.013715776,0.0477253,-0.020265758,-0.0026276908,0.0070538274,-0.017844504,-0.0030510603,0.0044366335,0.023008913,0.015283293,-0.030958464,-0.008922252,-0.0034394406,0.0178585,-0.005671753,-0.008481388,-0.003911795,0.0043946467,-0.021875262,-0.021133492,-0.0008191852,0.020363728,0.016836815,0.015017374,-0.0017179709,-0.015507224,0.0026031982,0.023414789,-0.013183939,0.0054268287,-0.028803129,0.0024754875,-0.0070678233,0.011616422,-0.0064590108,0.0019681437,0.0055667856,-0.0063365484,-0.019174095,0.004454128,-0.004650068,0.0021290942,-0.0053463536,0.012001304,0.018530292,0.0051504136,0.0061930926,0.000115245755,0.014835431,-0.040923398,0.009349121,-0.008866269,-0.005283373,-0.01120355,-0.0048285127,0.0021693318,0.035884947,-0.01847431,-0.00948208,0.0033659632,-0.022169173,-0.008551367,0.018236384,-0.007487694,-0.0017512107,-0.0042057047,-0.0045346036,-0.0005060317,0.03790033,-0.007991538,-0.013491845,0.02071362,-0.047445387,-0.0044436315,-0.01451353,-0.0014520527,0.01834835,0.014226618,-0.021413404,0.015241306,-0.0048460076,0.013596812,0.00027510276,-0.0016716102,-0.00029718972,0.030594578,0.0032330044,0.0029495915,0.015101349,0.03370162,-0.006315555,-0.026731767,-0.021791289,9.0479945e-05,0.003915294,0.014429556,0.028159328,-0.007487694,0.009873959,0.009775989,-0.0067529203,0.06600367,0.0018264375,-0.013841737,0.014457547,-0.009048213,-0.022756992,-0.1165561,-0.046325732,-0.004475122,-0.003045812,-0.008418407,0.024338504,-0.008054519,0.0016576145,-0.028887102,0.031742223,-0.016906792,-0.030118724,0.02386265,0.0018299364,-0.0042756833,-0.032749914,0.0031122915,-0.006574475,-0.02779544,0.03325376,-0.01207828,-0.021455392,0.0064590108,-0.021021526,0.0123092085,0.004331666,-0.033645637,-0.008271453,0.0036668708,-0.007022337,0.0102448445,-0.010615731,0.0146115,1.1309993e-05,-0.0037578426,-0.02347077,-0.0048320116,-0.010335817,0.020321742,-0.017900487,0.011175558,-0.0036983609,-0.00070853176,-0.008887263,-0.039467845,-0.022029215,-0.0071867867,0.02071362,0.030202698,-0.021343427,-0.036892638,0.012008302,-0.019468004,0.0044891173,0.009559056,-0.002876114,-0.003379959,0.0047585345,0.0045136097,0.012764069,-0.018824203,0.00710981,-0.00948208,-0.0014712969,0.010818668,-0.029726844,-0.0034919246,-0.015773142,0.011497459,-0.020601654,-0.005038448,-0.0032067623,-0.009062209,0.011805364,-0.015605194,-0.013981693,-0.011917329,-0.0211055,0.005437325,-0.004422638,-0.005727736,-0.011791368,-0.009132188,-0.014345582,0.018292366,-0.003649376,-0.025374185,-0.017914483,0.011091584,-0.008411409,0.0005952542,0.031994145,0.010342815,-0.02752952,0.019118112,0.014597504,-0.028341271,-9.463492e-05,0.008558365,0.010342815,-0.027487535,-0.0070153396,-0.047109492,0.028047362,-0.0030773021,-0.03412149,-0.015731156,-0.0050174547,0.008705319,-0.008138494,-0.012421175,0.020167788,-0.01630498,0.010741692,-0.014275603,-0.0030860496,-0.01727068,-0.012288216,0.018936168,-0.011931325,-0.0035723997,-0.00503145,0.015311284,-0.001581513,0.012218237,0.011469468,-0.0123022115,0.0009342123,-0.010517761,0.012680095,-0.012008302,-0.013078972,-0.0037823352,-0.022099193,0.0034149482,0.023092888,-0.00073958474,0.0012316207,-0.013204933,0.03288987,0.027193625,0.022029215,-0.0034499376,-0.03260996,-0.00065254903,-0.018852193,-0.0035566546,-0.010524758,-0.005594777,-0.007592662,-0.0075646704,-0.0017748284,0.02487034,0.006542985,-0.007179789,-0.03977575,0.006584972,0.020153793,-0.009796983,-0.01792848,-0.006473006,0.004720046,0.0438345,-0.012239231,-0.004548599,-0.0009543311,0.006728428,-0.0089922305,-0.0032557473,0.010475773,0.018530292,-0.00383132,0.0074597024,0.008418407,-0.003068555,0.017606577,-0.008978235,-0.020461699,0.00944709,0.0017966967,0.0029775829,0.03291786,0.012883033,0.0013628303,-0.009699013,-8.1185935e-05,0.00477253,0.0046745604,-0.0107137,0.008628342,-0.008775298,0.0048705,0.028649177,0.014037676,-0.0143735735,0.011840354,-0.015479232,-0.018544288,-0.0045905863,-0.009468084,0.015437245,0.022589043,-0.007340739,-0.0013855733,-0.006815901,-0.030286672,-0.025542133,0.023092888,-0.012638108,-0.03776037,-0.0048565045,0.03328175,0.032805897,-0.0020398716,0.0014835431,0.009265146,-0.018334353,0.02425453,-0.011595429,-0.023106884,-0.036192853,0.0201258,0.025948009,0.001071545,-0.0026714273,-0.008621344,0.0116864005,0.03291786,0.024688397,-0.00948208,0.00626657,0.02941894,0.0005357725,0.0012482406,-0.0051504136,-0.008215469,-0.018096427,-0.025612112,-0.018306362,0.0076836334,0.015185324,0.068690844,0.015899103,-0.008684325,0.019845888,-0.022197163,0.020489689,0.03431743,-0.0046255756,-0.02412857,-0.012358194,-0.01227422,0.010377804,-0.014107655,0.005752228,0.0024562436,0.017326664,-0.008460394,0.0036318814,-0.018054439,0.017704546,0.008502382,-0.0031892678,0.02344278,-0.0027676476,-0.01766256,0.015241306,0.0061196154,0.006864886,0.0027781443,-0.016207008,0.025710082,0.014191629,-0.024814358,-0.022197163,-0.008271453,0.011791368,-0.0059586647,-0.03490525,-0.0030143217,0.0028691164,-0.006707434,-0.0217493,-0.017494611,0.0034306934,-0.009873959,0.008950244,-0.010426789,-0.019495996,-0.01571716]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.7812757354989531
0.7726467530341432
0.8145846560700646
0.7232727758290125
0.7730431986803207
0.7643268106802689
0.7068667064954275
0.7065185730333946
0.7159893914208475
0.7933957316921871
0.6866050472956006
0.7574185840537798
0.7032083674733071
0.7230898739315375
0.7487402375541312
0.7246739988125795
0.7026392263716479
0.7048929023005296
0.7034652767887029
0.72641221637992
0.754052013522355
0.746793221410078
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011710991,0.0045058434,-0.0021391378,-0.014746397,-0.0025645148,0.024521312,-0.015334573,0.017659266,-0.011294368,-0.034450274,0.004768422,0.016006773,-0.016118806,0.013577049,-0.0030231513,-0.025095483,0.027994348,0.0063719,-0.011567449,-0.014228242,-0.0036585908,0.017701278,-0.0070616053,-0.03873555,0.0071106204,0.033722054,0.02786831,-0.015404593,0.022798797,0.009144727,-0.006056806,0.0152365435,-0.037643224,-0.024213219,0.0011842281,-0.00015590586,0.010139023,-0.00089976826,0.004050708,0.004379806,0.011112314,0.006525946,0.0013575298,-0.0147323925,-0.007975378,-0.008192442,0.015544635,-0.039827876,-0.008024393,-0.013444008,0.010384096,0.024927434,-0.019129705,-0.0126317665,-0.016272852,-0.0029863904,-0.0048349416,0.009235754,0.01371709,-0.014900443,0.021202322,0.018149411,-0.017729286,-0.0014529332,-0.021594439,0.0044918396,-0.024759382,-0.012337679,-0.014081199,0.0076042674,0.034506287,0.01023005,-0.010118017,-0.025711667,0.034702346,-0.007205148,-0.0035763164,-0.025767684,-0.013920151,0.01632887,-0.0009286519,-0.023400977,-0.015138514,0.020502113,0.01247772,-0.016847024,0.0034975428,0.015474614,-0.01351403,0.0037146076,-0.003977186,-0.00085600524,0.020362072,0.015264551,0.0077303047,-0.0058047306,-0.0086125685,0.02608978,0.0011273362,0.009788919,-0.0071386285,-0.003662092,-0.021062281,-0.009809925,-0.014746397,0.002944378,0.013801116,0.0037181086,0.0058852546,-0.013373988,-0.0362148,0.035486583,0.011644472,-0.038091358,-1.2212626e-05,-0.009886948,0.007660284,-0.017855324,0.003746117,-0.015950756,0.023695065,0.014424301,0.018037379,-0.008661583,0.012099608,-0.006550453,-0.006217854,-0.011595458,-0.017211132,-0.013387992,0.0012271159,0.0107131945,0.00509752,0.019143708,-0.015096501,0.017421195,-0.0143682845,0.0133179715,-0.025459591,-0.030529102,0.0077092987,0.005192048,-0.019591842,0.01793935,-0.002062115,0.016062789,0.010937261,0.026271833,0.016959056,0.0129748685,0.002200406,-0.0382314,0.02173448,0.029268727,0.016608952,0.021020267,-0.029492794,-0.009312777,-0.02116031,-0.008101416,-0.0073521924,0.013773107,0.005979783,0.018233437,0.010727199,0.010083007,0.014634363,-0.0053005805,0.012505729,0.0042887786,-0.011266359,0.031649437,-0.028820593,0.0005430994,-0.0069950856,0.019395784,0.021202322,-0.0057032006,-0.01747721,-0.0254876,0.01723914,-0.0017855323,0.0050485055,0.024941437,-0.019297754,-0.023751082,0.016847024,-0.01223965,0.005195549,0.0019483309,0.0187796,0.016146814,-0.0018240439,0.0049749836,-0.6704079,-0.021874523,0.0038651524,-0.025235524,0.015474614,0.016945053,-0.0020743685,-0.016286856,-0.03262973,0.012372689,-0.021132302,0.006778021,0.028008351,-0.02887661,-0.0073031774,-0.026103783,-0.0030336545,-0.033245914,0.009690889,0.0028445981,-0.018695574,0.015950756,-0.019213729,-0.009018689,-0.0015369583,0.028596526,0.0016481164,-0.01680501,0.0187796,0.010118017,-0.009396802,0.03363803,0.005377603,0.0156006515,0.043665018,-0.020978255,-0.0070546037,0.01555864,0.00018555533,0.05041503,-0.033049855,-0.011917554,0.0049119648,0.00054616283,-0.01120334,0.0037321127,0.022364669,0.002562764,0.020124,0.010622167,0.012057595,0.01569868,0.009613867,0.008395503,0.020095993,-0.020516118,0.023148902,-0.011406401,0.011490426,0.008262464,0.012596756,0.0052305595,-0.017043082,-0.006452424,-0.0071841422,0.026229821,-0.021174314,0.01385013,-0.0046563884,-0.04584967,-0.006858545,0.017155115,-0.021524418,0.0054266183,-0.011028288,0.025977746,0.015306564,0.016454907,0.017785303,0.018975658,-0.00044550785,-0.03072516,0.0041907495,0.020432092,0.033862095,-0.0007654157,-0.033189896,-0.008885649,-0.004715906,0.0026712965,0.0077303047,0.019311758,-0.01656694,-0.019535825,0.001418798,0.036466874,-0.00985894,0.016580945,-0.01623084,-0.015096501,-0.0023807099,-0.010727199,0.009753908,-0.007247161,-0.010384096,0.0052200565,0.00049102143,0.02777028,0.020067984,-0.020376075,0.010272062,0.019213729,-0.011868539,0.014536334,-0.012281662,-0.033694047,0.040864184,-0.014235244,0.0008573181,-0.007331186,0.0034397757,0.012736797,0.0077583133,-0.018331466,0.007660284,0.033021845,-0.014298263,-0.031173294,-0.013941157,0.008311478,0.022728777,-0.01824744,0.014305266,-0.012295666,0.017701278,-0.0005798604,-0.0005737336,0.0020271044,0.004211756,-0.022518715,-0.0045303507,0.011287366,0.0015500872,0.017967358,-0.025921728,-0.004075215,-0.008045399,0.008101416,-0.00550014,-0.008836634,-0.010825228,-0.02116031,-0.012428706,-0.020348066,0.0053110835,0.008416509,0.01536258,-0.031201303,-0.02579569,-0.027686255,0.01066418,0.02565565,-0.01572669,0.017617254,-0.0156006515,0.0068690483,-0.0016726237,0.034254212,0.007331186,-0.022462698,0.014774405,-0.02779829,0.009571854,0.013149921,-0.0028095876,0.0024909927,0.0050064926,-0.013226944,-0.021272343,-0.014872435,0.0008682589,-0.00082580873,0.011700489,-0.00040743398,0.01452233,0.009102714,0.024605338,0.010937261,-0.016748995,0.035094462,-0.006308881,0.01197357,-0.018121403,-0.01023005,-0.00052034267,-0.007821332,0.008437516,-0.01663696,0.002441978,0.015712686,0.01670698,0.019745888,0.008031394,-0.0072121504,0.007086113,-0.018401487,-0.0011063298,-0.014095203,0.019143708,0.01418623,0.026215816,-0.04005194,-0.021244334,-0.0068690483,0.01197357,0.009809925,0.00021629887,0.01180552,-0.02149641,0.01562866,-0.03531853,0.0010310574,0.012547742,-0.00028358455,-0.018751591,0.0106921885,-0.003450279,0.019871926,0.014291261,-0.01485843,0.006060307,0.026958039,-0.0005785475,0.03159342,0.021062281,-0.018051382,0.010384096,0.005951775,0.0021391378,0.002475238,-0.004957478,0.006963576,-0.015096501,0.0056891963,0.035934716,-0.009214748,0.033750065,0.019227734,-0.02702806,-0.0015964761,-0.01190355,0.009445816,-0.0035360544,-0.0091377245,0.009186739,0.0048069335,0.014263253,-0.006147833,-0.0039281715,0.02048811,0.006991585,0.020011967,0.033329938,-0.012232647,0.027896319,-0.0047614197,-0.012351683,-0.03229363,-0.022756785,0.0032122077,-0.013591052,-0.0004264709,0.005923766,-0.028022356,0.026005754,0.017085094,0.017155115,0.014760401,0.0341982,0.016132811,-0.034086164,-0.026888017,0.018905638,0.0053180857,-0.0089766765,0.0048524467,-0.022042572,0.0107131945,-0.010342084,0.0074362173,0.021552427,0.017351173,-0.003760121,-0.0048174364,-0.018471507,0.0039211693,0.03139736,-0.011588455,-0.0011947312,-0.006060307,0.0073872027,0.019633854,-0.0050695115,-0.041704435,0.01707109,-0.031285327,0.031173294,-0.0071316264,-0.016945053,-0.019325763,0.0065854634,-0.025235524,0.022350665,-0.018471507,0.014172226,0.0017102599,0.008129424,-0.017267149,0.030080969,0.01817742,0.0057102027,-0.026271833,-0.024227224,0.008899653,0.063803025,0.052711718,-0.005762718,0.01954983,-0.0023421983,-0.0070581045,-0.013745098,-0.0054616285,0.006795526,-0.0040121963,-0.010167032,-0.019031676,0.018317461,-0.010881244,0.0051465346,0.007744309,0.018163417,-0.0143682845,-0.022630747,-0.039603807,-0.0070441,0.0075342464,0.0412563,0.03195753,0.008934664,0.006389405,0.02863854,0.0140251815,-0.013423002,-0.018219432,0.016034782,0.015782706,0.009697892,0.0060217953,0.002911118,0.037867293,0.0005238437,0.014333274,0.020586139,0.011987574,0.015390589,0.008759612,0.0074362173,-0.005279574,-0.014802414,-0.007089614,-0.011315374,-0.0010721947,-0.0015535882,-0.012995875,-0.00025645146,-0.016286856,-0.043805063,-0.008122422,0.011042292,0.001080072,-0.017631257,-0.008416509,-0.0048979605,-0.0003614828,-0.0264959,-0.023793094,-0.003562312,0.0035465574,0.018191423,-0.016524928,-0.006686994,0.004792929,-0.030389061,-0.00865458,-0.012414701,-0.035822682,-0.019745888,-0.0050870166,0.0341982,0.018387483,0.024451291,-0.007100117,-0.01385013,0.0066554844,-0.005104522,-0.0028078372,-0.0114204055,-0.0028533507,0.017463207,-0.0074502216,0.001213987,-0.003240216,-0.005591167,0.013759103,-0.0012288664,0.007989382,-0.0038791567,-0.02072618,-0.021832509,0.010419107,0.021720476,0.03330193,-0.009942965,-0.025375566,0.0073731984,-0.030080969,-0.021020267,-0.009025691,-0.005661188,-0.006291376,0.0043623005,-0.008052401,-0.010167032,0.0032244613,0.03181749,-0.012484723,0.01193856,0.0036200795,0.0055351504,0.030305035,0.0013820371,0.009480827,-0.018961653,-0.024269236,0.011315374,-0.024577329,0.0060533048,0.0038021337,-0.033554006,0.012617762,0.017589245,0.0060708104,-0.033217903,0.015208535,-0.013605056,0.048174363,-0.016188826,-0.0017470209,-0.016272852,-0.00027745773,-0.013114911,-0.0034975428,-0.012379691,-0.0032787276,0.0065294467,-0.020039976,-0.010496129,-0.009949967,0.0034537797,-0.033554006,-0.0124497125,0.024227224,0.00479643,0.01066418,0.0027850803,-0.0074432194,-0.005717205,-0.007205148,0.00057635934,-0.019605845,-0.0045198477,0.007842339,0.011497429,0.027056068,0.021202322,-0.0077092987,0.01639889,0.01096527,-0.0147323925,0.00018435184,0.0008004262,0.021006264,-0.013387992,0.035542596,-0.0034922913,-0.0076392777,-0.014396292,0.007079111,0.02659393,0.007429215,-0.017687274,-0.018653562,-0.029352752,-0.028568517,0.016664969,0.0129748685,-0.0089976825,-0.0037286119,-0.02173448,0.0026730471,0.0028761076,0.0045093447,-0.0017575241,-0.010657177,0.0060463026,-0.007555253,0.023400977,-0.002223163,0.018275449,-0.017743291,-0.030641137,-0.028512502,0.010216046,0.03111728,-0.018541528,0.026313847,0.017911341,-0.008626572,0.003970184,-0.0028113383,0.002354452,0.008297474,-0.0047299103,-0.013240948,0.016552936,-0.023050873,-0.025767684,-0.007821332,0.004061211,0.012561746,-0.011644472,0.01304489,0.0068865535,-0.021384377,0.020306055,-0.0037846286,0.048678514,0.022826806,0.023120893,0.025095483,0.0013444008,0.0037216097,0.0016586195,0.0038686534,0.0134790195,0.019311758,0.009802923,-0.01019504,-0.021776494,0.0043307915,0.017603248,-0.02471737,-0.017183123,-0.011189336,0.0020131003,0.00248224,-0.002559263,-0.00831848,0.011875541,-0.0034467778,-0.010979273,0.008416509,0.018093394,-0.011896547,-0.0032052058,0.026635943,0.018233437,0.027280135,-0.010251056,0.0030756672,0.004145236,0.0093898,0.023527015,0.01354904,-0.020194022,0.029464785,-0.009214748,-0.0059202653,0.024353262,-0.005405612,0.015516627,-0.0072191525,0.004295781,0.030529102,-0.014746397,0.012127616,-0.0065749604,0.006455925,0.007019593,-0.0073802005,-0.0014459311,-0.008766614,-0.0096628815,0.023527015,0.012638768,0.00828347,-0.031033253,-0.0031316837,-0.0020918737,-0.01227466,-0.0012349932,0.0060988185,-0.0011649723,-0.033525996,-0.02726613,-0.008304476,0.016244844,0.036606915,-0.0054441234,-0.02361104,0.012078602,0.017519224,-0.031985536,0.01630086,0.018975658,-0.012638768,-0.019157711,0.011651474,-0.018597545,-0.035906706,0.010769211,-0.017561236,-0.03859551,-0.02538957,0.0016288607,-0.004551357,0.0022284144,-0.02200056,-0.0058572465,-0.0056401817,0.0033942622,0.0034695345,-0.025585629,0.016762998,0.009641875,0.0028480992,0.015978765,-0.0142072365,0.018499516,-0.020152008,-0.016959056,-0.002226664,-0.044281203,-0.026846005,-0.022378672,-0.008696593,-0.0086125685,-0.002233666,-0.009452819,-0.007100117,-0.014396292,0.0072191525,0.0017872829,-0.0063683987,-0.004939973,0.009025691,0.003669094,0.012421704,-0.021440392,-0.008129424,-0.0022949344,0.022392677,-0.027476193,-0.0143682845,-0.014914447,0.040836178,0.017015073,-0.015194531,-0.0064769313,-0.006294877,-0.03142537,0.0023369468,0.004775424,0.00055622833,-0.0076112696,0.007492234,0.012050593,0.036242805,-0.0033224907,-0.006536449,0.0029006149,0.009984978,-0.020964252,-0.019997964,0.0059657786,0.0033417465,-0.021132302,0.002636286,-0.00211288,-0.015544635,0.022462698,-0.0054581272,-0.016931048,-0.017869327,0.008892652,0.031341344,0.029940927,0.023933137,0.02149641,-0.022812802,-0.013710088,0.02039008,-0.015138514,-0.014760401,-0.023358965,0.0103700925,0.0015369583,0.0124497125,-0.0024472298,-0.028988644,0.0124077,0.004075215,-0.0053671002,0.0032139583,0.02957682,0.033021845,0.014690381,-0.019395784,-0.0040191985,0.025571624,-0.023288945,-0.0043342924,0.022196619,-0.029996945,0.006074311,-0.016216835,-0.019815909,-0.018527525,-0.016048785,-0.011847532,-0.0017277652,-0.0046388833,0.014151219,0.019003667,-0.023302948,0.025179507,0.009795921,0.0015693429,-0.018233437,-0.004554858,0.007163136,-0.019577838,0.0036305825,0.005958777,-0.019171717,-0.010608163,0.006616973,0.017253144,0.017953353,0.010776213,0.23146102,-0.018667566,-0.013366986,0.012057595,0.01800937,0.0025277536,0.02324693,0.019241737,0.00020426403,0.01069919,0.009081708,0.019927941,0.0047334116,-0.0075972653,0.022714773,-0.017435199,-0.02250471,-0.008381499,0.0046668914,0.017743291,0.013990171,-0.009172735,-0.0047439146,-0.022532718,0.042908795,-0.0110562965,-0.009872944,0.0028130887,0.0060007893,0.006928566,-0.0075342464,-0.0030809187,0.021020267,0.001237619,-0.01431927,-0.0004352235,0.021720476,-0.008661583,0.012638768,0.001559715,0.03705505,-0.024969446,-0.0016726237,-0.012134618,0.012827825,0.022840811,-0.019899935,-0.020404084,0.028162397,0.0156006515,-0.016594948,-0.005262069,0.0027343153,0.029016651,0.008325483,-0.009837934,-0.011623465,0.0024927433,0.012365687,-0.0197879,-0.024269236,0.008066406,-0.008423512,0.022644753,-0.0013837876,-0.0015518377,-0.006795526,-0.010167032,0.01817742,-0.01572669,-0.015502622,-0.015390589,-0.0075972653,-0.012827825,-0.029436776,-0.015768701,0.029100677,-0.0003916793,0.022812802,0.028960636,-0.020642156,-0.0008472526,-0.0011194588,-0.014424301,-0.009060701,-0.02125834,0.03551459,-0.006119825,-0.0065049394,-0.006883052,-0.016160818,0.014116209,-0.011980573,0.009949967,-0.00095928606,0.0002095156,0.010454117,0.012638768,0.0054091127,0.0012253653,-0.025949737,0.07629475,0.007072109,-0.003021401,0.00037942565,0.010202042,0.0021181316,0.023050873,0.005556157,-0.011350384,0.0019903434,-0.018135408,0.00081924425,-0.021412384,-0.012260656,0.0027885814,0.023569027,-0.00623886,0.015642663,0.0016192328,-0.03041707,-0.013051892,-0.008486531,0.011189336,0.003760121,-0.0065889647,0.007026595,-0.0018958153,-0.017323166,-0.0069740796,0.004712405,-0.019773897,0.008843637,0.015544635,-0.01043311,-0.022574732,-0.017351173,-0.008885649,0.017827315,-0.0051290295,0.0020183518,0.016160818,-0.0057872254,-0.011280363,-0.013437007,-0.009956969,-0.012281662,0.009067704,0.0067395098,0.0003746117,-0.004883956,0.012771809,-0.009837934,-0.01579671,0.0061443322,-0.012281662,0.015978765,0.002310689,0.002911118,-0.005027499,-0.023597036,0.0046668914,0.009473825,-0.01861155,-0.014221241,-0.018457504,-0.18261445,0.008941666,0.022378672,-0.037727248,0.010937261,0.0009802923,0.028764578,-0.012365687,-0.04419718,0.015614656,0.034898404,-0.012960864,-0.030305035,-0.0026450388,-0.0053916075,-0.012806819,-0.008808627,-0.0028533507,0.003558811,0.0137030855,0.047698222,-0.020180017,-0.00254876,0.0070476015,-0.01784132,-0.0030003947,0.004386808,0.023050873,0.015320568,-0.030893212,-0.0089976825,-0.0034327735,0.017883332,-0.005671691,-0.008458522,-0.0038931607,0.0043973112,-0.02193054,-0.021146305,-0.0007802952,0.020306055,0.016861027,0.014998472,-0.0017478962,-0.015516627,0.0025312547,0.023414982,-0.013226944,0.0054721315,-0.028792584,0.0024034667,-0.0070476015,0.01167248,-0.006522445,0.0020131003,0.00556666,-0.006378902,-0.019199725,0.004418317,-0.0046528876,0.0021338863,-0.005377603,0.01200858,0.018527525,0.005181545,0.006210852,0.00013325848,0.014928451,-0.040864184,0.00935479,-0.008801624,-0.005255067,-0.011273362,-0.0048909583,0.0021076284,0.035822682,-0.018485513,-0.009480827,0.0033715053,-0.022154605,-0.008647579,0.018233437,-0.0074502216,-0.001740894,-0.004215257,-0.004533852,-0.0004722033,0.037979323,-0.007954372,-0.013472017,0.020642156,-0.047446147,-0.0044883383,-0.014508326,-0.0014214239,0.018373478,0.0142072365,-0.02139838,0.015180526,-0.0048069335,0.013612059,0.0002816152,-0.001640239,-0.0002614842,0.03055711,0.0032822287,0.0029548812,0.015082497,0.033722054,-0.0063053803,-0.026761979,-0.021762488,9.299648e-05,0.0038931607,0.014382289,0.028120385,-0.0074642254,0.0098659415,0.009774915,-0.0067535136,0.065931655,0.001874809,-0.013808117,0.014480318,-0.0090537,-0.022826806,-0.11640271,-0.046409838,-0.0044918396,-0.0030774176,-0.008332484,0.024269236,-0.008094413,0.0017163868,-0.028904619,0.03176147,-0.016931048,-0.030052962,0.023905128,0.0018503017,-0.004274775,-0.032741763,0.003108927,-0.006620474,-0.027812293,0.033245914,-0.012148622,-0.021440392,0.006378902,-0.020992259,0.01230967,0.004320288,-0.03363803,-0.00828347,0.003662092,-0.0070300964,0.010244055,-0.010587157,0.014592351,-2.4356872e-05,-0.0037776264,-0.023470998,-0.004876954,-0.0103700925,0.020362072,-0.017897336,0.011182334,-0.0037356138,-0.0007146506,-0.008913658,-0.039463766,-0.022042572,-0.0072191525,0.020768192,0.030108977,-0.02132836,-0.036943015,0.012050593,-0.019507816,0.00446033,0.009522839,-0.002837596,-0.0034135177,0.0048139356,0.0045058434,0.012764806,-0.01887763,0.007019593,-0.009466823,-0.0014949457,0.01083223,-0.02974487,-0.003450279,-0.015740693,0.0114204055,-0.020586139,-0.005083516,-0.003226212,-0.00908871,0.01180552,-0.015614656,-0.014004176,-0.012015583,-0.021090288,0.0054651294,-0.004456829,-0.0056786933,-0.0117635075,-0.009179737,-0.014326272,0.018275449,-0.0036445868,-0.025445588,-0.017897336,0.011091307,-0.008465524,0.00057242066,0.032013547,0.010286067,-0.027532209,0.019171717,0.014536334,-0.028288435,-9.5841075e-05,0.008514538,0.0103981,-0.02743418,-0.007033597,-0.047166064,0.028050363,-0.0031176796,-0.034030147,-0.015670672,-0.004939973,0.008703595,-0.008136426,-0.01247772,0.020194022,-0.016370881,0.010762209,-0.014305266,-0.0030984238,-0.017281152,-0.012232647,0.01887763,-0.011917554,-0.0036375846,-0.005034501,0.01529256,-0.0015877234,0.012176631,0.011483424,-0.012337679,0.0009864192,-0.010489128,0.012687783,-0.012092605,-0.012995875,-0.0037076054,-0.022126598,0.0034327735,0.023078881,-0.0007798575,0.0012805068,-0.013226944,0.03299384,0.027224118,0.02209859,-0.0034975428,-0.03260172,-0.0006616973,-0.018961653,-0.0036585908,-0.010510134,-0.0057732216,-0.0076112696,-0.0076182717,-0.001754023,0.024843408,0.0065084407,-0.0072261547,-0.039743852,0.006613472,0.020152008,-0.009816927,-0.01793935,-0.0065119416,0.0046703927,0.043889087,-0.012169628,-0.004544355,-0.0009846686,0.0067360085,-0.009067704,-0.003229713,0.010482126,0.01851352,-0.0038371442,0.0074782297,0.008437516,-0.0030896713,0.017603248,-0.008990681,-0.020418089,0.009459821,0.0017899087,0.0029776378,0.032881804,0.012925854,0.0013479019,-0.009697892,-8.479091e-05,0.0047264094,0.0047299103,-0.010706192,0.008689591,-0.008808627,0.004869952,0.028680552,0.014011178,-0.014382289,0.011875541,-0.015432602,-0.018541528,-0.0045723636,-0.009480827,0.015390589,0.022588735,-0.0073031774,-0.0013689082,-0.006865547,-0.03024902,-0.02555762,0.023120893,-0.012687783,-0.037811276,-0.004792929,0.033329938,0.03276977,-0.002062115,0.0014450558,0.009228752,-0.018261446,0.024241228,-0.011560447,-0.02310689,-0.0362148,0.020138005,0.025907725,0.00107307,-0.002625783,-0.008640576,0.011665478,0.032909814,0.024675358,-0.009508835,0.006217854,0.029492794,0.000540036,0.0013330225,-0.005111524,-0.00824846,-0.0181074,-0.025627641,-0.018303458,0.007723303,0.015194531,0.06867648,0.015894739,-0.008675586,0.019871926,-0.022182614,0.0204601,0.034366246,-0.0046738936,-0.024143199,-0.012246652,-0.0122886645,0.010391098,-0.0140882,0.005797729,0.002424473,0.017295158,-0.008444518,0.003548308,-0.017981362,0.017785303,0.008472526,-0.0031316837,0.023456994,-0.0027553216,-0.017687274,0.015152518,0.006133829,0.0068235346,0.0027535711,-0.016188826,0.025739675,0.014193232,-0.024829403,-0.022182614,-0.008241457,0.011791516,-0.0060147936,-0.034898404,-0.0029548812,0.0028323445,-0.0067325076,-0.021748485,-0.01750522,0.0033224907,-0.009851937,0.008941666,-0.010412104,-0.019479807,-0.015754698]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.7600488518241297
0.7791188801487826
0.7549443454923773
0.7784654725597346
0.7399165202181673
0.7247782597476149
0.7636354206196764
0.7850509783165369
0.8301895778548362
0.7008807470772479
0.8126392682880714
0.7857294395546659
0.7035671337062019
0.8250970820392154
0.7763710399317562
0.6899451865109762
0.7958195091495958
0.7961182031448817
0.6972978280973889
0.7321706145301308
0.7929266408697888
0.749756530472268
0.760812714257102
0.8027043372129073
0.8307142070184032
0.7918392281451472
0.7244051356691771
0.7705928090830152
0.7820135448348272
0.8088937362410468
0.7125117585604838
0.7144896088411302
0.8016042127224691
0.7119951745323705
0.7279825438021867
0.7889367040086367
0.7235528638979469
0.7970182432476953
0.7708251333121686
0.7037091258437744
0.7243738322147676
0.7533679821870467
0.7562966073657249
0.7576440550692688
0.7155810872538002
0.7057336813493706
0.7059214656703926
0.7310375964880219
0.7993988107208015
0.7664129769894996
0.8000230823131512
0.7458203701333025
0.7012842530577259
0.7361556358547191
0.7879456510581733
0.7894451792055567
0.7561747026358762
0.7858182732777778
0.7575994991540052
0.7492659810090981
0.7868459413366394
0.7302074372996199
0.7386724242896576
0.7499197978056484
0.7833215159544269
0.7798125740305778
0.7811830345262235
0.784981457191766
0.716791685228013
0.7659123740821048
0.6043565198955196
0.7690972264059006
0.7953823011992895
0.732347758348225
0.772679739806859
0.7706373549818266
0.7489401654668592
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011819376,0.00448611,-0.002141496,-0.014750581,-0.0025617403,0.024500255,-0.015324916,0.017580228,-0.011325589,-0.03446005,0.004738257,0.016025323,-0.016095364,0.013608918,-0.0030292624,-0.025102604,0.028030308,0.0063912184,-0.011535712,-0.014225276,-0.0036351148,0.017734317,-0.0070566055,-0.038774557,0.00711614,0.033731624,0.027904235,-0.01536694,0.022819275,0.009126309,-0.0060200025,0.0152969,-0.037681922,-0.024262115,0.0012178335,-0.0001429269,0.010183925,-0.00091315625,0.004020339,0.004416069,0.011136479,0.0065067858,0.0013780517,-0.014750581,-0.008012662,-0.008201771,0.015535038,-0.03989521,-0.008040678,-0.0134548275,0.010429068,0.024948515,-0.019107116,-0.012649359,-0.01627747,-0.0029819848,-0.00486433,0.00916133,0.013650942,-0.014890663,0.021222347,0.01809853,-0.01772031,-0.001395562,-0.021614576,0.004479106,-0.024738392,-0.012285147,-0.014078191,0.0076344414,0.03451608,0.010324006,-0.010113884,-0.025718963,0.034712195,-0.0072282054,-0.0035020374,-0.02581702,-0.013917097,0.016319495,-0.00091578276,-0.023421627,-0.015156818,0.020493923,0.012495269,-0.016851803,0.003461764,0.015507022,-0.013489848,0.0037156616,-0.0039573023,-0.00083392265,0.020339834,0.015254875,0.0077324985,-0.005820386,-0.008636024,0.026027143,0.0011863152,0.009833721,-0.0071371524,-0.0036176047,-0.021068256,-0.0098477295,-0.014694549,0.0029469645,0.013777015,0.0037226658,0.005890427,-0.013419807,-0.03619706,0.035552684,0.011745834,-0.038130183,-1.14842205e-05,-0.00991777,0.007655454,-0.017832374,0.0037331718,-0.015969291,0.023687782,0.014470419,0.018056504,-0.008601004,0.012068021,-0.006552312,-0.0062196185,-0.011612756,-0.017272048,-0.013377783,0.0011994478,0.010702226,0.0050709504,0.019205173,-0.015128802,0.017440146,-0.01438637,0.013293734,-0.025480824,-0.030537765,0.007662458,0.0051900195,-0.019625418,0.01794444,-0.0020206757,0.01605334,0.011003401,0.026307305,0.01694986,0.0129855545,0.002160757,-0.038242247,0.021712633,0.029221,0.016557632,0.021110281,-0.029501162,-0.00938546,-0.021208338,-0.008152743,-0.0073682866,0.013791024,0.0059639695,0.018224603,0.010730242,0.010043844,0.014652524,-0.005340607,0.012481261,0.004311008,-0.011269556,0.031686436,-0.028828772,0.0005362495,-0.0069830627,0.019387279,0.021166313,-0.0057048188,-0.01748217,-0.02557888,0.017216016,-0.001725629,0.0050324276,0.024962522,-0.019317238,-0.023729805,0.016865812,-0.012236118,0.005133987,0.0018963532,0.018756913,0.016151397,-0.0018560798,0.0049343705,-0.67014986,-0.021908745,0.003911776,-0.025242686,0.015493014,0.016991885,-0.0020819611,-0.016263463,-0.03261097,0.012390208,-0.021222347,0.0067554303,0.027974274,-0.028884804,-0.00730525,-0.026083175,-0.0030222584,-0.033283364,0.009679631,0.0029312053,-0.018658856,0.015941273,-0.01923319,-0.009028252,-0.0015085026,0.028632658,0.0016485841,-0.016837796,0.018798936,0.010134896,-0.0093924645,0.03361956,0.005358117,0.015619087,0.043649394,-0.020998217,-0.0070531033,0.015563054,0.00019578577,0.050401323,-0.033031218,-0.011955956,0.0049133585,0.0005476311,-0.011192512,0.0037962086,0.022357007,0.0025722466,0.02012971,0.010611174,0.012061017,0.015731152,0.009574571,0.008432906,0.020171735,-0.020493923,0.02316948,-0.011458666,0.011514699,0.008306833,0.012593326,0.0052110315,-0.017005894,-0.0064262385,-0.007200189,0.026251273,-0.021138297,0.013896084,-0.0047067385,-0.0458907,-0.0068885074,0.017145975,-0.02157255,0.0053896355,-0.01108745,0.025957102,0.015352932,0.016445568,0.017762333,0.018896993,-0.00043250163,-0.030789914,0.0041709268,0.020395866,0.033871707,-0.00074987375,-0.0331713,-0.008832138,-0.0047102403,0.0026843117,0.0077324985,0.019345256,-0.016571641,-0.019541368,0.0014997475,0.036393173,-0.009854733,0.016599657,-0.016193422,-0.0150727695,-0.002339361,-0.010709231,0.009770684,-0.0072422135,-0.0104010515,0.005228542,0.0004106139,0.027764153,0.020059671,-0.020395866,0.01029599,0.019177157,-0.011829883,0.014512443,-0.012292151,-0.033675592,0.040903796,-0.014225276,0.00081553694,-0.007382295,0.0034092334,0.012768429,0.0077955355,-0.018364685,0.0076274374,0.0330032,-0.014344345,-0.031154124,-0.013931105,0.008334849,0.02270721,-0.018238612,0.014288313,-0.012285147,0.017692294,-0.0005940331,-0.00047365055,0.0020329328,0.0042794896,-0.02248308,-0.004507122,0.011262552,0.0015514026,0.01794444,-0.025901068,-0.004051857,-0.008005657,0.008068694,-0.0055647376,-0.008888171,-0.010828299,-0.021166313,-0.012495269,-0.020381859,0.0052845743,0.008418898,0.015380949,-0.031210158,-0.02580301,-0.027652087,0.010667206,0.025676938,-0.015717143,0.017566219,-0.015549046,0.0068850056,-0.0016275719,0.034263935,0.0073542786,-0.02248308,0.01476459,-0.027876219,0.009602587,0.013216689,-0.002805132,0.0024864466,0.005081456,-0.013188673,-0.021334412,-0.014890663,0.0008615012,-0.00085143285,0.011689801,-0.00039945115,0.014442402,0.009119306,0.024598312,0.0109123485,-0.016711723,0.035132438,-0.006289659,0.0119489515,-0.01816857,-0.010211941,-0.0005537597,-0.007886589,0.008460922,-0.016641682,0.002447924,0.015703136,0.01665569,0.019695459,0.00806169,-0.0072422135,0.0071231443,-0.018378692,-0.0011311581,-0.014141227,0.019163148,0.014183251,0.02626528,-0.040007275,-0.02127838,-0.0068815034,0.011955956,0.0098057045,0.00023835742,0.011794862,-0.0214885,0.015633095,-0.035328552,0.0010103378,0.012607335,-0.00025521097,-0.018728897,0.010716234,-0.003458262,0.01991959,0.014281308,-0.014862646,0.0060550226,0.026965689,-0.0005962219,0.0316304,0.021026233,-0.01808452,0.0104010515,0.0059674717,0.0021222348,0.0024846955,-0.0049798973,0.006934034,-0.015128802,0.0056803045,0.036028963,-0.009231371,0.033731624,0.01923319,-0.026979696,-0.0016109372,-0.011892919,0.00938546,-0.0035755802,-0.009105298,0.009147322,0.0047942894,0.014260297,-0.006184598,-0.0039538,0.020465907,0.007021585,0.020059671,0.033339396,-0.012250127,0.02793225,-0.0047347546,-0.012411221,-0.032302793,-0.022763243,0.003171095,-0.013643938,-0.00040492308,0.0059394552,-0.028030308,0.026013134,0.017061926,0.01717399,0.014736573,0.034207903,0.016109372,-0.03406782,-0.02695168,0.018911002,0.005344109,-0.008993232,0.00486433,-0.02203482,0.010730242,-0.01029599,0.0074383277,0.021544535,0.017356098,-0.0037716944,-0.0048223054,-0.018532783,0.0039573023,0.031378254,-0.011591744,-0.0011950702,-0.006069031,0.0074383277,0.019653434,-0.0051059704,-0.041772302,0.017131967,-0.031378254,0.031182142,-0.0071546626,-0.016935853,-0.01930323,0.006538304,-0.025270702,0.022314982,-0.018476749,0.01416224,0.00172738,0.008089706,-0.017230025,0.030089505,0.01809853,0.0056978147,-0.02626528,-0.024248106,0.008888171,0.063709065,0.05269866,-0.005788868,0.01952736,-0.002328855,-0.00708112,-0.013763007,-0.0054876925,0.0067764423,-0.004030845,-0.010232953,-0.01900906,0.01832266,-0.0108843325,0.005144493,0.007760515,0.018196587,-0.01438637,-0.02270721,-0.039615046,-0.0070636095,0.0075994213,0.041296024,0.031994615,0.008923192,0.00637721,0.02861865,0.014078191,-0.013426811,-0.018294644,0.016011314,0.015759168,0.009714652,0.00599899,0.002897936,0.03785002,0.00051042193,0.014344345,0.020535948,0.012004985,0.015436981,0.008720073,0.007417315,-0.0052565583,-0.014806614,-0.0070916256,-0.011318585,-0.0011145234,-0.0015312659,-0.0130135715,-0.00021449979,-0.01634751,-0.043789476,-0.008117722,0.011073442,0.0010628684,-0.017622253,-0.008425902,-0.0049133585,-0.00035283028,-0.026517427,-0.023827862,-0.0035808333,0.003559821,0.018210595,-0.016529616,-0.006664377,0.0048223054,-0.030397685,-0.008664041,-0.012411221,-0.03583285,-0.0197655,-0.005063946,0.034095835,0.018406708,0.024430213,-0.0070846216,-0.013812035,0.006653871,-0.0050954646,-0.002806883,-0.0114096375,-0.0028454054,0.017426139,-0.0074593397,0.0012449743,-0.003270903,-0.005641782,0.013798027,-0.0012117049,0.007998654,-0.0039047718,-0.020718053,-0.021824697,0.010394047,0.021768665,0.03331138,-0.009931779,-0.025410784,0.007410311,-0.030117521,-0.021082265,-0.009035257,-0.005617268,-0.0063386876,0.004342526,-0.008068694,-0.010141901,0.0032201235,0.031826515,-0.0124742575,0.0119349435,0.0035965925,0.005515709,0.030313635,0.001357915,0.00950453,-0.018953027,-0.0242341,0.011276561,-0.024626328,0.006005994,0.0038452372,-0.033507492,0.012572315,0.017580228,0.0061320676,-0.033227332,0.015212851,-0.01359491,0.048244067,-0.016179413,-0.0017904167,-0.016221438,-0.00029811094,-0.013153653,-0.003465266,-0.012439237,-0.003286662,0.0065628183,-0.020017646,-0.010464088,-0.00995279,0.0034722702,-0.03356353,-0.0124742575,0.0242341,0.004769775,0.010695222,0.0027631074,-0.007424319,-0.0057258313,-0.007221201,0.00062423816,-0.019625418,-0.0045176283,0.007858572,0.011486683,0.027077753,0.021250363,-0.0077324985,0.016473584,0.010954373,-0.014708557,0.0001777284,0.00078664516,0.021082265,-0.013377783,0.035552684,-0.0034880294,-0.007641446,-0.01438637,0.0070601073,0.026657509,0.007417315,-0.017664276,-0.018658856,-0.029361082,-0.028632658,0.016641682,0.012978551,-0.009014244,-0.0037331718,-0.021768665,0.0026930668,0.002890932,0.0045421426,-0.0016984881,-0.010660202,0.0060340106,-0.007564401,0.023407618,-0.0022815773,0.018252619,-0.017734317,-0.030649832,-0.028520593,0.010183925,0.031210158,-0.018532783,0.026335321,0.017958447,-0.008650033,0.0039573023,-0.0028261442,0.002332357,0.008306833,-0.0047207465,-0.013272722,0.016557632,-0.023043407,-0.025732972,-0.007844564,0.0040658657,0.012495269,-0.011682797,0.013083612,0.0068780016,-0.02134842,0.020269793,-0.0037681924,0.048664313,0.022833284,0.023141462,0.025018556,0.0013141396,0.0037646901,0.0016634677,0.003911776,0.0134548275,0.019289222,0.009854733,-0.010225949,-0.02181069,0.004304004,0.017594237,-0.024710376,-0.017230025,-0.011150487,0.0020241777,0.0025197158,-0.0025880057,-0.008327845,0.0118789105,-0.003467017,-0.010954373,0.008439911,0.018042497,-0.011899923,-0.0032376335,0.026629493,0.018238612,0.027301883,-0.010253966,0.0030695358,0.0041744285,0.0093784565,0.0235477,0.013482844,-0.020199751,0.029417114,-0.009182342,-0.005890427,0.02437418,-0.0054141497,0.01552103,-0.007186181,0.004275988,0.030537765,-0.014750581,0.012131058,-0.006527798,0.006454255,0.0070250873,-0.0073542786,-0.0014270802,-0.008741085,-0.009707647,0.023589725,0.012642355,0.008271812,-0.031070076,-0.0031535847,-0.0021327408,-0.012278143,-0.0012677376,0.006104051,-0.0011355357,-0.03356353,-0.027245851,-0.0083138365,0.016179413,0.0366173,-0.0054771863,-0.023631748,0.012110045,0.017552212,-0.03207866,0.016305486,0.01899505,-0.012600331,-0.019135132,0.011696805,-0.018588815,-0.035972927,0.010793279,-0.017552212,-0.03860646,-0.025340743,0.0016091862,-0.004514126,0.0022518102,-0.022006802,-0.0058449004,-0.005589252,0.0034127354,0.0034442537,-0.025536858,0.016781764,0.009630603,0.0028348994,0.015941273,-0.014239284,0.01854679,-0.02014372,-0.016935853,-0.0021975285,-0.04429377,-0.02679759,-0.022371015,-0.008734081,-0.008523959,-0.002248308,-0.009448497,-0.007095128,-0.014400378,0.0072422135,0.0017842881,-0.006373708,-0.0049658893,0.009049265,0.0036246087,0.012425229,-0.021446478,-0.008138735,-0.002246557,0.022441056,-0.02748399,-0.014372362,-0.014918679,0.04081975,0.017047917,-0.015156818,-0.006468263,-0.0062441328,-0.031378254,0.0023603733,0.004776779,0.0005498199,-0.0075994213,0.0074803517,0.012075025,0.03628111,-0.003263899,-0.0065242955,0.002897936,0.010001819,-0.020928176,-0.020017646,0.005932451,0.0033549517,-0.021082265,0.0026457892,-0.002155504,-0.015535038,0.022525104,-0.0054421662,-0.016921844,-0.017930431,0.008923192,0.03135024,0.029921407,0.023897903,0.021474494,-0.022791259,-0.01369997,0.020381859,-0.015170826,-0.014778598,-0.023407618,0.0104010515,0.0015514026,0.012397213,-0.0024689364,-0.02899687,0.012404216,0.0041008857,-0.005312591,0.0032166215,0.029585212,0.033059232,0.014680541,-0.019387279,-0.004027343,0.02559289,-0.02332357,-0.0043495307,0.022132877,-0.02997744,0.006090043,-0.016263463,-0.019821532,-0.018532783,-0.016081356,-0.011787858,-0.0018035492,-0.0046296935,0.014148232,0.01900906,-0.02330956,0.02514463,0.009812709,0.0015811699,-0.018224603,-0.0045316364,0.007193185,-0.019583393,0.003559821,0.005932451,-0.019191165,-0.010597166,0.006643365,0.017272048,0.017958447,0.010730242,0.23175083,-0.018658856,-0.013405799,0.012054013,0.018056504,0.0024636833,0.02330956,0.01923319,0.00019283094,0.01063919,0.009056269,0.019975621,0.0047417586,-0.0075994213,0.022693202,-0.017440146,-0.022511097,-0.008418898,0.004626191,0.017734317,0.013952117,-0.009168334,-0.004769775,-0.022553122,0.042977,-0.011059434,-0.0098757455,0.002820891,0.0060375123,0.006941038,-0.007557397,-0.0030800418,0.021068256,0.0012458498,-0.014288313,-0.0004202445,0.021698624,-0.008664041,0.012670372,0.0015382699,0.03700953,-0.025004547,-0.0016494596,-0.012180086,0.012824461,0.022875309,-0.01990558,-0.020409875,0.028142372,0.015549046,-0.016557632,-0.0052705663,0.002803381,0.02899687,0.008334849,-0.009826717,-0.01165478,0.002514463,0.012313164,-0.019751491,-0.024248106,0.008054686,-0.008390882,0.022665186,-0.0014410884,-0.0015408965,-0.006835977,-0.010120888,0.018154562,-0.015731152,-0.015507022,-0.015380949,-0.0075994213,-0.012831465,-0.029501162,-0.015731152,0.029108934,-0.00034385629,0.022749236,0.028968854,-0.020634005,-0.0008142237,-0.0010856315,-0.014428394,-0.009070277,-0.021236354,0.035496652,-0.006156582,-0.0065137898,-0.00690952,-0.01612338,0.014078191,-0.011976968,0.010036839,-0.0009446746,0.00020683909,0.010464088,0.012628347,0.005403644,0.0012099539,-0.025929086,0.0763164,0.0070566055,-0.0030362664,0.00033772775,0.010190929,0.0020994714,0.023043407,0.005536721,-0.0113956295,0.001969896,-0.018140554,0.00082735636,-0.021404453,-0.012208102,0.0027701117,0.02361774,-0.0061881,0.015605079,0.0016266964,-0.030397685,-0.013048591,-0.008537968,0.011234536,0.0037962086,-0.0066223526,0.0070496015,-0.001875341,-0.017314073,-0.006941038,0.0047487626,-0.019723475,0.008832138,0.015563054,-0.010457084,-0.022553122,-0.017356098,-0.008895175,0.017888406,-0.0050989664,0.0020802103,0.016151397,-0.005788868,-0.011269556,-0.013412803,-0.009931779,-0.012271139,0.009077281,0.006650369,0.00032809714,-0.0048993505,0.012747416,-0.009868741,-0.01582921,0.0061250636,-0.012327172,0.015983298,0.0023341079,0.0029417113,-0.0049904035,-0.02361774,0.0046542077,0.009518538,-0.018686872,-0.014190256,-0.018518774,-0.18266627,0.008965216,0.022385024,-0.037793986,0.010933361,0.0010042093,0.028744724,-0.012383204,-0.044153687,0.015591071,0.034936324,-0.012901505,-0.030257603,-0.002619524,-0.005358117,-0.012803448,-0.0087831095,-0.0028226422,0.003549315,0.013748999,0.047683742,-0.020227768,-0.0025774995,0.0070706136,-0.01786039,-0.0030082501,0.0043845507,0.023057414,0.015310908,-0.030901978,-0.009007241,-0.00345476,0.017818367,-0.005701317,-0.008495943,-0.0039012698,0.004402061,-0.021894738,-0.02112429,-0.0008286696,0.020311818,0.016837796,0.015016736,-0.0017370105,-0.01552103,0.0025757486,0.023449643,-0.013174665,0.0054421662,-0.028800756,0.002447924,-0.007035593,0.011689801,-0.006538304,0.0020171735,0.005505203,-0.0063386876,-0.019247198,0.0044335793,-0.0046682158,0.002150251,-0.0053546154,0.011969964,0.018560799,0.005165505,0.0062476345,9.3405906e-05,0.014862646,-0.040847763,0.0093224235,-0.008832138,-0.005246052,-0.011227532,-0.004857326,0.002153753,0.03583285,-0.018476749,-0.009483517,0.0033672089,-0.0221749,-0.008579992,0.018280635,-0.0074453317,-0.0017553963,-0.0041884365,-0.004584167,-0.0004837189,0.03785002,-0.008012662,-0.013503856,0.02067603,-0.047403578,-0.0044650976,-0.014498435,-0.0014358354,0.018364685,0.014260297,-0.021376437,0.015212851,-0.0048012934,0.013601913,0.00026484157,-0.0016687209,-0.00029242013,0.030565783,0.0032253764,0.0029224502,0.0150867775,0.033731624,-0.006296663,-0.02671354,-0.021838706,0.00012530727,0.003925784,0.014344345,0.028128365,-0.007487356,0.00991777,0.00976368,-0.006723912,0.066062436,0.0018613329,-0.013833048,0.014442402,-0.009035257,-0.022833284,-0.11643574,-0.04633896,-0.004493114,-0.0030625318,-0.008383878,0.024276124,-0.00806169,0.0016468331,-0.028884804,0.03174247,-0.016921844,-0.030117521,0.023855878,0.0018578308,-0.004307506,-0.03272304,0.003090548,-0.006618851,-0.027820185,0.033283364,-0.012124053,-0.021460485,0.0063912184,-0.020984208,0.012306159,0.0043390244,-0.03361956,-0.0082508,0.0036806413,-0.0070110788,0.010246961,-0.010583157,0.014568476,-2.970234e-06,-0.0037366739,-0.023477659,-0.004878338,-0.010366031,0.020325825,-0.017888406,0.011199515,-0.0037857024,-0.0007187932,-0.008881167,-0.039474964,-0.022020811,-0.007200189,0.020746069,0.030117521,-0.021320404,-0.036925483,0.011969964,-0.01952736,0.0044475873,0.009546554,-0.0028734216,-0.0034127354,0.0048328117,0.0045491466,0.012775432,-0.018812945,0.007102132,-0.009476514,-0.0014656027,0.010849312,-0.029697277,-0.0034722702,-0.015787184,0.0114376545,-0.020619996,-0.005063946,-0.003185103,-0.009070277,0.011794862,-0.015647104,-0.013980133,-0.0119909765,-0.021068256,0.005445668,-0.004496616,-0.005694313,-0.011766845,-0.009210358,-0.014323333,0.018266628,-0.0036841433,-0.025410784,-0.017916424,0.011115467,-0.008453919,0.0005804627,0.032050647,0.010309998,-0.027582048,0.019135132,0.014582484,-0.02832448,-7.813921e-05,0.00862902,0.010387043,-0.027441965,-0.0070390953,-0.04715143,0.028044315,-0.0031290704,-0.034123853,-0.015661111,-0.0049658893,0.008734081,-0.008159747,-0.012467253,0.02021376,-0.016305486,0.010821296,-0.014309325,-0.0031413275,-0.017286057,-0.012257131,0.018882986,-0.011955956,-0.0035755802,-0.0050849584,0.015282892,-0.0015330169,0.012215107,0.011507695,-0.012327172,0.00095255417,-0.01052012,0.012698388,-0.012103042,-0.0130135715,-0.0037296698,-0.022090852,0.0034722702,0.023127455,-0.0007967135,0.0012519783,-0.013195677,0.032975186,0.027287876,0.022090852,-0.003447756,-0.032582957,-0.00066801364,-0.018896993,-0.003659629,-0.010541133,-0.005715325,-0.00764845,-0.0075503928,-0.0017799105,0.024808433,0.006527798,-0.007193185,-0.039783146,0.0065312996,0.020171735,-0.0098057045,-0.017958447,-0.0065032835,0.0047312523,0.04381749,-0.012173082,-0.0045386404,-0.00096918887,0.0066818874,-0.009070277,-0.0032148703,0.0104851,0.018532783,-0.0038592452,0.0074523357,0.008460922,-0.003088797,0.017566219,-0.009035257,-0.020479916,0.009434489,0.0018088024,0.0030205073,0.032919154,0.012894502,0.001352662,-0.009679631,-8.4213054e-05,0.0047557666,0.004762771,-0.01074425,0.008664041,-0.008811126,0.004878338,0.02868869,0.014057178,-0.014372362,0.011843891,-0.015479005,-0.018560799,-0.0045771627,-0.009462505,0.015408965,0.02262316,-0.007298246,-0.0014069435,-0.0068534873,-0.030257603,-0.025564874,0.023141462,-0.01268438,-0.03785002,-0.0047942894,0.03331138,0.032751054,-0.0020276797,0.0014165741,0.009238374,-0.018252619,0.024262115,-0.011612756,-0.023183487,-0.036225077,0.020101694,0.025957102,0.001077752,-0.0026685526,-0.008601004,0.011668788,0.032919154,0.02466835,-0.00950453,0.006251137,0.02944513,0.0005690811,0.0012712396,-0.005081456,-0.008229788,-0.018112538,-0.025648922,-0.018294644,0.0077254944,0.015170826,0.06869596,0.015927266,-0.008671044,0.01983554,-0.022146884,0.020465907,0.034376,-0.0046401997,-0.024122033,-0.012285147,-0.012264135,0.0103590265,-0.014092199,0.0057853656,0.0024846955,0.017300066,-0.008439911,0.0035930905,-0.018028488,0.017748326,0.008481935,-0.003092299,0.023477659,-0.0027526014,-0.017650269,0.015226859,0.006097047,0.006797455,0.0027683605,-0.016221438,0.025732972,0.014204264,-0.024780417,-0.022216925,-0.008236792,0.011794862,-0.005984982,-0.034936324,-0.003006499,0.0028856788,-0.0067554303,-0.021768665,-0.017510187,0.003379466,-0.00988275,0.008923192,-0.010436071,-0.019555377,-0.015745161]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.6936824975757238
0.735974443230421
0.7299285268790284
0.7526481183510696
0.8139151168208966
0.76642627036185
0.7761883726587957
0.7258367733741924
0.7603009938506465
0.7929696731433992
0.7675349831491649
0.743712205820789
0.7909665731877452
0.6865509460783108
0.7239826675112736
0.7087151720186124
0.7177507636514769
0.7885107144597231
0.752442828273278
0.7734303806992908
0.7336445839670782
0.7540225896325943
0.792126507948664
0.7556330097693659
0.6866700151786491
0.7256205592108761
0.7530130195139239
0.7651825366887077
0.7994890405616731
0.7627877627582171
0.7762319043082209
0.7268646619320756
0.7372520715774963
0.7883327150997707
0.7058161651133295
0.7678333108552
0.756925506353669
0.7617542632530422
0.7494148617043539
0.7770007253650454
0.7473477053503157
0.7576456800329266
0.769537223838172
0.7940251318969487
0.7919794862699371
0.7146253716227435
0.7566727508723374
0.7619626942385472
0.7669776494572278
0.7923834738433331
0.7952874469926855
0.8072100446375341
0.8013681727584823
0.7730642133229265
0.7891023030788705
0.7668623470599776
0.7470630559732969
0.7824838825319567
0.7514404868070834
0.7665637555463664
0.7921189949069474
0.7871894793035693
0.7854453007719839
0.7654049131874822
0.7811234107611978
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.001204917,0.0044696555,-0.002066822,-0.014742513,-0.0025410885,0.024626857,-0.015372535,0.017556611,-0.011263392,-0.0344412,0.004742665,0.016002556,-0.016030557,0.013671475,-0.002987354,-0.025130874,0.028028976,0.006412223,-0.011704408,-0.014196494,-0.0036366265,0.017640613,-0.0069757425,-0.03875335,0.00718225,0.033825178,0.027944973,-0.015456538,0.022918798,0.009163319,-0.0060762116,0.015316533,-0.03766131,-0.024220843,0.001205792,-8.039342e-05,0.010129352,-0.0008487795,0.00402164,0.004441655,0.011151388,0.006440224,0.001352797,-0.014784515,-0.007973277,-0.00835829,0.0155965425,-0.039845385,-0.007987278,-0.013419467,0.010318359,0.024962869,-0.019110665,-0.012796445,-0.016254565,-0.00287535,-0.0048126676,0.009233321,0.013685476,-0.014812515,0.021140736,0.01813063,-0.017682616,-0.0014805516,-0.021504749,0.0043261508,-0.024808863,-0.01233443,-0.014070489,0.007707268,0.0344972,0.010325359,-0.0101153515,-0.025746895,0.034721207,-0.0072872536,-0.003533373,-0.025760897,-0.013909484,0.016338568,-0.000976534,-0.02331081,-0.015050524,0.020580716,0.012425432,-0.016870586,0.0035788745,0.015554541,-0.013587473,0.0037031288,-0.00401814,-0.00070046185,0.020314706,0.015288532,0.007840273,-0.0058277026,-0.008708303,0.026096908,0.0012031669,0.009870344,-0.006954742,-0.0037731314,-0.021014731,-0.009793341,-0.014728513,0.0028508492,0.013678476,0.0037976322,0.005859204,-0.013195459,-0.03617726,0.035561237,0.01176741,-0.038137328,3.6860656e-05,-0.0099473465,0.0077142683,-0.017724616,0.0038641344,-0.01582055,0.023730826,0.014420502,0.01810263,-0.008680302,0.011949416,-0.006664232,-0.0063037192,-0.011613404,-0.017164597,-0.013433468,0.0011419147,0.010731373,0.0051836804,0.019208668,-0.015134526,0.017472608,-0.014420502,0.013405466,-0.025438884,-0.030577064,0.0077142683,0.0051941806,-0.019628683,0.017836621,-0.0021158236,0.015988557,0.010962381,0.026320916,0.017066594,0.012985452,0.0021018232,-0.03822133,0.021784758,0.029233018,0.016436571,0.021042733,-0.02931702,-0.009331325,-0.021280741,-0.0080222795,-0.0073222546,0.013748478,0.0060237097,0.01810263,0.0106473705,0.010073351,0.0147005115,-0.005316685,0.012551437,0.0042771487,-0.011340395,0.031669103,-0.028981008,0.0005145179,-0.00690574,0.01926467,0.021112734,-0.005572194,-0.017458608,-0.02559289,0.0172626,-0.0016013057,0.0050576758,0.024920868,-0.019432677,-0.023814829,0.016926588,-0.012348429,0.0051206783,0.0019985696,0.018760653,0.01611456,-0.0016170563,0.0050751767,-0.67023134,-0.021938764,0.0038816351,-0.025326882,0.015554541,0.016996592,-0.001979319,-0.01635257,-0.03256513,0.012397432,-0.021196738,0.0067447345,0.028014975,-0.028953008,-0.007210251,-0.026082907,-0.0030503562,-0.033237156,0.009639336,0.0028543493,-0.018648649,0.015918555,-0.01925067,-0.00920532,-0.0015138027,0.028672997,0.0016144312,-0.016800584,0.018802654,0.010150353,-0.009436328,0.03360117,0.0053341854,0.015540541,0.043569516,-0.02095873,-0.007010744,0.015582542,0.00015455225,0.05054176,-0.03309715,-0.011879413,0.0048441687,0.00061033375,-0.0112773925,0.0038046325,0.022358779,0.0025235878,0.020020697,0.0106473705,0.011914414,0.015666544,0.009660336,0.008512296,0.0201187,-0.020482713,0.023100805,-0.011452398,0.011424397,0.0082882885,0.0127054425,0.0050716763,-0.017094595,-0.0064822254,-0.007245252,0.026208911,-0.021154735,0.013881483,-0.004718164,-0.04575359,-0.0068042367,0.01698259,-0.021658754,0.0053551863,-0.010955381,0.025872901,0.0153305335,0.01636657,0.017710617,0.018858656,-0.0005053301,-0.03074507,0.004147644,0.02039871,0.03390918,-0.00073808816,-0.03332116,-0.008960312,-0.0047496655,0.0028665997,0.007735269,0.019362673,-0.016604578,-0.019502679,0.0014788015,0.036429267,-0.0097163385,0.016506575,-0.016156562,-0.015106525,-0.0023100805,-0.010745374,0.009779341,-0.007231252,-0.010262357,0.005376187,0.00043685894,0.027762966,0.019936694,-0.02044071,0.010220355,0.01926467,-0.011865413,0.014560507,-0.01237643,-0.03362917,0.04082542,-0.0143014975,0.0008356541,-0.0073712566,0.003473871,0.012614439,0.007917276,-0.018228635,0.0076022646,0.033069152,-0.014336498,-0.031109082,-0.013993487,0.0082882885,0.022694789,-0.018326638,0.014203494,-0.012285427,0.017654615,-0.00055695686,-0.0005718324,0.0021053234,0.0041441442,-0.022610787,-0.0046341615,0.011424397,0.0015190529,0.018032627,-0.0258589,-0.0040566414,-0.008029279,0.0080222795,-0.005572194,-0.008897309,-0.010864378,-0.021224739,-0.01264944,-0.020300707,0.005264183,0.008547298,0.015498539,-0.031249087,-0.025662893,-0.027720965,0.010717373,0.025732895,-0.015666544,0.017612614,-0.015624544,0.0068182372,-0.0015584292,0.034385197,0.0073922575,-0.022386778,0.0147005115,-0.02786097,0.009639336,0.013125457,-0.00287885,0.0023905833,0.0050121746,-0.013286462,-0.021378744,-0.014910519,0.0008767805,-0.0008544672,0.011802411,-0.00038173204,0.014560507,0.009093316,0.024514854,0.011032384,-0.016744582,0.035169225,-0.00631772,0.011879413,-0.018144632,-0.010052349,-0.00056964485,-0.0078892745,0.008498296,-0.016744582,0.002558589,0.015722547,0.016688582,0.019754687,0.008099282,-0.007217251,0.007101747,-0.01838264,-0.0012022918,-0.01408449,0.019096665,0.014021488,0.02640492,-0.04001339,-0.021350743,-0.00689174,0.011886413,0.009814342,0.00019163167,0.011837412,-0.021518748,0.015708547,-0.035253227,0.00087284285,0.012481434,-0.00036554397,-0.018690651,0.010661371,-0.0035823747,0.019796688,0.014224495,-0.014910519,0.00604121,0.026936937,-0.0005066426,0.031697102,0.021042733,-0.018060628,0.010402362,0.0059047053,0.002131574,0.0024588355,-0.004917671,0.007021244,-0.015162528,0.0057962015,0.035981253,-0.00919132,0.033937182,0.019292671,-0.02703494,-0.0014595508,-0.011746408,0.009415328,-0.0036331264,-0.0091843195,0.009233321,0.004826668,0.014231496,-0.0062582176,-0.003913136,0.020496713,0.006986243,0.020104699,0.033237156,-0.012292428,0.027944973,-0.004802167,-0.012481434,-0.032313123,-0.022764793,0.0031256087,-0.013643474,-0.00041170183,0.005890705,-0.028028976,0.026110908,0.017080594,0.017192598,0.014784515,0.03418919,0.016198564,-0.03418919,-0.026796933,0.018886657,0.0053411857,-0.008974312,0.0049106707,-0.021980764,0.010738374,-0.010185354,0.0074272584,0.02153275,0.0172486,-0.003762631,-0.00488267,-0.018480644,0.003906136,0.03133309,-0.011606404,-0.001094663,-0.005999209,0.0073222546,0.019698685,-0.0050576758,-0.041721452,0.017206598,-0.031277087,0.031053081,-0.007115748,-0.01698259,-0.01926467,0.0065697287,-0.025200877,0.022330778,-0.018494643,0.014245496,0.0017141846,0.008141283,-0.0172206,0.030045046,0.01811663,0.005722699,-0.026250914,-0.024192842,0.008827307,0.06373022,0.052669834,-0.005775201,0.01953068,-0.002385333,-0.007063246,-0.013839481,-0.0054671904,0.0067342343,-0.00402164,-0.010031349,-0.019012662,0.018340638,-0.010892379,0.0052466826,0.0077982713,0.018186633,-0.014476504,-0.022554785,-0.039593376,-0.007136748,0.007497261,0.04110543,0.032089118,0.009051315,0.0063947225,0.028700998,0.01407749,-0.013391466,-0.018214634,0.016044559,0.015946554,0.009723338,0.006009709,0.0028280984,0.03788532,0.0004943922,0.014182493,0.020538714,0.011998418,0.015484539,0.008666301,0.0074482593,-0.0052396823,-0.014854517,-0.007073746,-0.011333395,-0.0011279143,-0.00157943,-0.013181458,-0.0002730095,-0.01635257,-0.043765523,-0.008029279,0.01092038,0.0010649121,-0.01752861,-0.008491295,-0.004966673,-0.00030057295,-0.026586926,-0.023870831,-0.003622626,0.003416119,0.018284636,-0.016422572,-0.0066257305,0.00488617,-0.030325055,-0.0086243,-0.01236243,-0.03584125,-0.019754687,-0.00517668,0.03418919,0.018326638,0.024486853,-0.007052745,-0.013874482,0.006758735,-0.005138179,-0.0029418524,-0.0114103975,-0.0028280984,0.017430607,-0.0074552596,0.001033411,-0.0032638635,-0.005659697,0.013832482,-0.0011366645,0.00803628,-0.0038851353,-0.020874726,-0.021658754,0.01033236,0.021658754,0.033209156,-0.009828342,-0.025438884,0.007273253,-0.030241052,-0.021154735,-0.008960312,-0.0057401997,-0.006265218,0.0043506515,-0.00805728,-0.010073351,0.0032341126,0.03183711,-0.012516435,0.01178141,0.003615626,0.0056176954,0.030269053,0.0013667976,0.009527331,-0.018928658,-0.02416484,0.011270392,-0.024612857,0.005974708,0.003878135,-0.033489164,0.012523436,0.017556611,0.006051711,-0.03326516,0.015162528,-0.013524471,0.048161674,-0.016338568,-0.0018410641,-0.016310567,-0.0003215737,-0.013083455,-0.0034003684,-0.012250426,-0.0034371195,0.0066572316,-0.019950693,-0.010493365,-0.010003348,0.0034861213,-0.033489164,-0.012488435,0.024304846,0.0047566653,0.010682371,0.0027160945,-0.007560263,-0.005694698,-0.0071962504,0.00056833227,-0.019698685,-0.004462655,0.007868274,0.011403397,0.027048942,0.021084733,-0.007651266,0.016604578,0.010997383,-0.014840516,0.00019906943,0.00087415543,0.021084733,-0.013419467,0.035561237,-0.0035561237,-0.007707268,-0.014336498,0.0071612494,0.026698928,0.0074832602,-0.017752618,-0.01867665,-0.02934502,-0.028658997,0.016618578,0.013020453,-0.008981313,-0.003822133,-0.021672754,0.0027178447,0.0028806003,0.004623661,-0.0017544361,-0.010619369,0.0059642075,-0.007560263,0.023324812,-0.0022015767,0.018172633,-0.017752618,-0.030661067,-0.02847699,0.010297358,0.031221086,-0.018606648,0.026376918,0.01808863,-0.008645301,0.003993639,-0.0028613496,0.0024710859,0.008183285,-0.004686663,-0.013209459,0.016618578,-0.023114804,-0.025732895,-0.007868274,0.0040111397,0.012425432,-0.011508401,0.013069455,0.006923241,-0.021448746,0.020328708,-0.0036891284,0.04858169,0.022918798,0.023044802,0.025046872,0.0013449218,0.0038081326,0.0017273101,0.0038186328,0.013335464,0.019194668,0.009891344,-0.010276358,-0.021896763,0.004389153,0.017640613,-0.02475286,-0.017066594,-0.011298393,0.0020598217,0.0025970903,-0.0026040906,-0.008197285,0.011739409,-0.0034861213,-0.011046384,0.008400292,0.01808863,-0.011928415,-0.0031956113,0.026614927,0.018312637,0.027272949,-0.010262357,0.003104608,0.0040566414,0.009443329,0.023422815,0.01351747,-0.020272706,0.029513028,-0.009156318,-0.005922206,0.024458852,-0.0053551863,0.015484539,-0.0070562456,0.0042911493,0.030521061,-0.014840516,0.012243426,-0.006576729,0.0063842223,0.00690224,-0.0073642563,-0.0013930484,-0.0088203065,-0.00976534,0.023506818,0.012565437,0.008190285,-0.031193085,-0.0030801073,-0.0020913228,-0.0123064285,-0.0012180423,0.0060237097,-0.0011909164,-0.03360117,-0.02725895,-0.008239287,0.016142562,0.036653277,-0.0053411857,-0.02354882,0.0120754205,0.017556611,-0.032117117,0.016324569,0.019012662,-0.012600439,-0.019110665,0.011746408,-0.018578647,-0.03595325,0.010815376,-0.017514609,-0.03852934,-0.025466885,0.0015584292,-0.004494156,0.0023048301,-0.021938764,-0.0056806975,-0.005488191,0.0034003684,0.0035753744,-0.025704894,0.01671658,0.009653336,0.0028350987,0.016044559,-0.013944485,0.018536646,-0.020216703,-0.016912589,-0.0023433315,-0.04424154,-0.026796933,-0.022358779,-0.0086173,-0.008568298,-0.0022190772,-0.009422328,-0.007154249,-0.014434502,0.0071332483,0.0018480644,-0.00632822,-0.0048791696,0.008974312,0.0036121258,0.012502435,-0.021406746,-0.008197285,-0.0022645788,0.022372779,-0.027496956,-0.014322499,-0.014882518,0.040769417,0.017052593,-0.015148527,-0.0065102265,-0.0062547177,-0.03138909,0.002213827,0.0047846665,0.0005635196,-0.0076372656,0.0075532626,0.012005418,0.03620526,-0.0033443663,-0.0065942295,0.002899851,0.010010349,-0.021028731,-0.019992696,0.0058487034,0.0033426164,-0.021028731,0.002530588,-0.002236578,-0.015582542,0.022372779,-0.00545319,-0.01698259,-0.017864622,0.00890431,0.03130509,0.030045046,0.023870831,0.021420745,-0.02272279,-0.013748478,0.02041271,-0.015036523,-0.014714512,-0.023240808,0.010430363,0.0014140492,0.012320429,-0.002527088,-0.028981008,0.012530436,0.0041196435,-0.005372687,0.0031396092,0.029513028,0.032985147,0.014756514,-0.01926467,-0.004053141,0.025480887,-0.023282811,-0.0043436512,0.022218773,-0.029989043,0.0061007123,-0.016156562,-0.01981069,-0.018578647,-0.01612856,-0.01178141,-0.0017378104,-0.00460266,0.014147492,0.01897066,-0.023366813,0.02529888,0.009828342,0.0016275566,-0.018312637,-0.0045606587,0.0072592525,-0.019516679,0.0034948715,0.0058557037,-0.01922267,-0.010689372,0.0067412346,0.017206598,0.018046629,0.010752374,0.23162407,-0.018606648,-0.013440467,0.0120754205,0.018172633,0.002616341,0.023422815,0.019208668,0.000111457004,0.010745374,0.009107317,0.020034697,0.0047951667,-0.0076232655,0.022806793,-0.017430607,-0.022652788,-0.008386292,0.004543158,0.017682616,0.013972486,-0.009093316,-0.004672663,-0.022624787,0.042925492,-0.011095386,-0.009968347,0.002931352,0.0059397067,0.0068532387,-0.007378257,-0.0030223553,0.021056732,0.0011961666,-0.014434502,-0.0004077642,0.021784758,-0.008589298,0.012740443,0.0014884268,0.03707329,-0.024920868,-0.0017500609,-0.012131422,0.012845447,0.022820795,-0.019880692,-0.020384708,0.02816898,0.015624544,-0.016618578,-0.005201181,0.0027248447,0.029065011,0.0082882885,-0.009877344,-0.011564403,0.0025743395,0.012194424,-0.01983869,-0.024220843,0.00803628,-0.008393292,0.022778792,-0.0014192994,-0.001468301,-0.006839238,-0.010094351,0.01813063,-0.015582542,-0.015498539,-0.015302532,-0.007560263,-0.012747443,-0.029541029,-0.015708547,0.02903701,-0.00045457832,0.022764793,0.029009009,-0.02067872,-0.00086059247,-0.0011419147,-0.014448503,-0.009016314,-0.021168737,0.035505235,-0.006167215,-0.006492726,-0.006947742,-0.016170563,0.014147492,-0.011984417,0.0098843435,-0.00083215395,0.00018824093,0.010472365,0.0126074385,0.005407688,0.0012241676,-0.0258449,0.07616265,0.0070877466,-0.0029751034,0.00032901144,0.010325359,0.0020930727,0.023086803,0.005607195,-0.011340395,0.0019775687,-0.018186633,0.0008325915,-0.021350743,-0.012278427,0.0027738465,0.023492817,-0.006205716,0.015638543,0.0016354319,-0.030409059,-0.013069455,-0.008540297,0.011284392,0.0037871317,-0.0066292305,0.007101747,-0.0018288137,-0.017458608,-0.00689524,0.0047601657,-0.019614682,0.008841308,0.015610543,-0.01033936,-0.022568785,-0.017346604,-0.008967312,0.017780619,-0.005138179,0.0019915693,0.016310567,-0.005652697,-0.0112773925,-0.01349647,-0.009975347,-0.012215425,0.008988312,0.00661173,0.0003106358,-0.0048686694,0.012761444,-0.009835342,-0.015792549,0.006009709,-0.012250426,0.01580655,0.002385333,0.0028946006,-0.0049596727,-0.023702824,0.0046341615,0.009513331,-0.018578647,-0.014196494,-0.018466642,-0.18245435,0.008981313,0.02240078,-0.037801314,0.010948381,0.0010990383,0.028729,-0.012271427,-0.044129536,0.015694546,0.034945216,-0.013034454,-0.030297054,-0.002616341,-0.005337686,-0.01294345,-0.008834307,-0.0027528459,0.0035508736,0.013727478,0.04768566,-0.020202704,-0.0026023407,0.007101747,-0.017892623,-0.0030136048,0.004420654,0.0229888,0.015358535,-0.030885074,-0.009009314,-0.0034878713,0.017724616,-0.0056386963,-0.008526296,-0.0038186328,0.0043611517,-0.021938764,-0.021168737,-0.00085490476,0.020538714,0.016814586,0.01495252,-0.0017080595,-0.015540541,0.0027143445,0.023436816,-0.013188459,0.0054391893,-0.028813003,0.0024010835,-0.007098247,0.011662406,-0.006492726,0.0019670685,0.0055406927,-0.0063037192,-0.019138666,0.004399653,-0.004620161,0.0021718256,-0.005327185,0.01208242,0.018564645,0.0050471756,0.006272218,0.00020683532,0.014756514,-0.040993426,0.009331325,-0.008778306,-0.005232682,-0.011375396,-0.0048686694,0.0020825726,0.035981253,-0.018368639,-0.009569333,0.003216612,-0.022204774,-0.008512296,0.018228635,-0.0073502557,-0.001751811,-0.0041266438,-0.0044766557,-0.0005429564,0.03788532,-0.00803628,-0.013468469,0.020594716,-0.047573656,-0.0044101533,-0.014518505,-0.0013414216,0.018340638,0.014287497,-0.021322742,0.015288532,-0.004739165,0.0136364745,0.0002327581,-0.0016293067,-0.00030276054,0.030549062,0.0032183619,0.0029506027,0.015078525,0.033741172,-0.0063737216,-0.026824933,-0.021896763,0.00016067746,0.0039621377,0.014350499,0.028070977,-0.0075322622,0.009905345,0.009667336,-0.006807737,0.065970294,0.0019040663,-0.013755479,0.014420502,-0.009107317,-0.022918798,-0.11670806,-0.046425615,-0.004511657,-0.0030328555,-0.008365291,0.024388848,-0.008092281,0.0016179313,-0.028813003,0.031669103,-0.01694059,-0.030017044,0.023898832,0.0018725651,-0.0043016495,-0.032593135,0.00315711,-0.0065207267,-0.02787497,0.03326516,-0.012047419,-0.021406746,0.0063632214,-0.02094473,0.0122084245,0.0044696555,-0.033685174,-0.008414293,0.003622626,-0.0069932435,0.010241357,-0.010717373,0.014588508,-0.00017620926,-0.0038081326,-0.023478817,-0.005001674,-0.010374361,0.020370709,-0.017920624,0.011186389,-0.0036086256,-0.00087853055,-0.00891131,-0.039537374,-0.022036767,-0.0072592525,0.02066472,0.030045046,-0.021154735,-0.03676528,0.012012418,-0.019488677,0.0044346545,0.009604334,-0.0028525994,-0.0034108686,0.0046901633,0.0046446617,0.012852447,-0.018788654,0.00718225,-0.009408328,-0.001435925,0.010843378,-0.029681033,-0.0034861213,-0.015750548,0.0115014,-0.020496713,-0.004977173,-0.0032358626,-0.008995313,0.011704408,-0.015778549,-0.013972486,-0.012040419,-0.021126736,0.005369187,-0.004483656,-0.005726199,-0.0119074145,-0.009107317,-0.014259496,0.018172633,-0.0036366265,-0.025438884,-0.018004626,0.011172389,-0.008519297,0.00062477175,0.032033116,0.010262357,-0.027650962,0.019124666,0.014644509,-0.028252983,-0.0001630838,0.008533297,0.010451363,-0.027496956,-0.007073746,-0.04706964,0.028028976,-0.0031256087,-0.03418919,-0.015554541,-0.0050366754,0.008827307,-0.008295288,-0.0126074385,0.020146701,-0.016240565,0.010934381,-0.014406501,-0.002989104,-0.0172486,-0.012285427,0.018900657,-0.011893414,-0.0036296262,-0.005061176,0.015386536,-0.0017211849,0.012250426,0.011452398,-0.012397432,0.00092053204,-0.010374361,0.012726443,-0.012012418,-0.013083455,-0.0036821282,-0.022204774,0.0034353696,0.023072803,-0.0008649676,0.00129417,-0.013195459,0.03301315,0.027230948,0.02212077,-0.0034021183,-0.032621134,-0.000632647,-0.019012662,-0.0036436268,-0.010549367,-0.0057086986,-0.0077492697,-0.0074552596,-0.001813063,0.024794864,0.0065347273,-0.007273253,-0.039593376,0.006545228,0.020062698,-0.009828342,-0.017976625,-0.0065347273,0.0046341615,0.043905526,-0.012320429,-0.0045011565,-0.0008912185,0.006727234,-0.008897309,-0.0032691138,0.010528366,0.018452642,-0.0038676346,0.0073432554,0.008323289,-0.0030136048,0.017556611,-0.008869309,-0.02044071,0.009457329,0.0018288137,0.0029786036,0.032929145,0.0129714515,0.0014508005,-0.009674337,-4.6048477e-05,0.004739165,0.004742665,-0.010871379,0.008792306,-0.008673302,0.0048581692,0.028785001,0.014028488,-0.0143645,0.011963416,-0.015456538,-0.018690651,-0.0046166605,-0.009541332,0.015414536,0.022596786,-0.0072802533,-0.0014096741,-0.0067097335,-0.03021305,-0.02557889,0.023226809,-0.012740443,-0.03774531,-0.004917671,0.033377163,0.03276114,-0.002096573,0.0013667976,0.009275323,-0.018270636,0.024234843,-0.011669406,-0.023198808,-0.03620526,0.020104699,0.025816899,0.0010421613,-0.0026810933,-0.008659301,0.011739409,0.032957148,0.02472486,-0.009506331,0.0062757186,0.029457025,0.0005779576,0.0013186709,-0.005050676,-0.008232286,-0.018144632,-0.025606891,-0.018452642,0.0077002677,0.015092526,0.06871439,0.015848551,-0.008589298,0.01981069,-0.022358779,0.020510715,0.03418919,-0.0046586622,-0.02413684,-0.012313428,-0.0122084245,0.010311359,-0.014196494,0.0057822014,0.0024343347,0.017318603,-0.008435293,0.0037661311,-0.017976625,0.017864622,0.008512296,-0.0031658602,0.023352813,-0.002698594,-0.017598612,0.015148527,0.006065711,0.006758735,0.0027545958,-0.016198564,0.025746895,0.014126492,-0.024808863,-0.022316776,-0.008197285,0.011949416,-0.005967708,-0.03505722,-0.0030346056,0.0029156015,-0.0068042367,-0.021756757,-0.017570611,0.0035001219,-0.0098493425,0.009016314,-0.0102483565,-0.01953068,-0.015638543]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.7441268517875236
0.7760880540132746
0.7649810900427052
0.7965716054540385
0.7765942613025921
0.781599297736514
0.7814818626926217
0.8020208792842687
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011667372,0.0045305085,-0.0021288143,-0.014721529,-0.002527639,0.024517223,-0.0153232645,0.017604262,-0.01130703,-0.034452856,0.0047509116,0.016008964,-0.01610692,0.013609018,-0.0030156744,-0.025104964,0.027987698,0.0063776965,-0.011586906,-0.01421775,-0.0036209084,0.017688224,-0.0070563983,-0.038734972,0.007115872,0.033753164,0.027875748,-0.01537924,0.022823967,0.009123989,-0.006080327,0.0153092705,-0.037699427,-0.02425134,0.0012069695,-0.0001306457,0.01014554,-0.0009244686,0.004005739,0.004411561,0.01112511,0.006510638,0.0013617764,-0.014735523,-0.008004482,-0.008221386,0.015547166,-0.039826494,-0.008074451,-0.013455085,0.010390433,0.024909051,-0.019129591,-0.012608457,-0.016260853,-0.0030104266,-0.00484537,0.009186962,0.013706975,-0.014917443,0.021200681,0.01810804,-0.017730206,-0.0014020087,-0.021620497,0.004488527,-0.024741124,-0.012356568,-0.014070815,0.0076406416,0.03450883,0.010257491,-0.010089565,-0.025720695,0.034704745,-0.0071858414,-0.0035194529,-0.025790663,-0.013888895,0.016330821,-0.0009594533,-0.02341171,-0.015155339,0.020500988,0.012475517,-0.016862588,0.0034984623,0.0155331725,-0.0134690795,0.0037608468,-0.003995244,-0.0008217013,0.020319069,0.015225307,0.007773583,-0.0058214413,-0.008613214,0.026042553,0.0011230063,0.009865663,-0.00709838,-0.0036174098,-0.021046748,-0.009879657,-0.0147075355,0.0029614482,0.013755953,0.0037328592,0.00589141,-0.013371123,-0.03621608,0.0354884,0.011705855,-0.038119245,-2.3026987e-05,-0.009893651,0.0076756263,-0.01785615,0.0037293606,-0.015938994,0.023677593,0.0144976275,0.018094046,-0.008669189,0.012083689,-0.0065596164,-0.0062237643,-0.011628889,-0.017226428,-0.013392113,0.0011816056,0.010712291,0.0050902627,0.019171573,-0.015127351,0.017422343,-0.014385677,0.013315147,-0.02541283,-0.030534578,0.0076686293,0.0051672286,-0.019577395,0.018038072,-0.0020413527,0.016022956,0.010971177,0.026308436,0.017002527,0.012972298,0.002120068,-0.03828717,0.021718454,0.029219156,0.016568717,0.021060742,-0.029527022,-0.009361885,-0.021214675,-0.00814442,-0.0073537678,0.013734963,0.0059438874,0.01821999,0.010719288,0.010047584,0.014637566,-0.005303669,0.01248951,0.0043171025,-0.011265049,0.031654086,-0.028827328,0.00052170816,-0.006993426,0.019395474,0.021242663,-0.005730481,-0.017492311,-0.025482798,0.01726841,-0.0017212434,0.005034287,0.02493704,-0.019395474,-0.023719573,0.0168346,-0.012237621,0.005184721,0.0019031634,0.01872377,0.016134908,-0.0018524358,0.0049538226,-0.67036134,-0.021872386,0.0038832931,-0.025230909,0.015505184,0.016988533,-0.0020763373,-0.016302833,-0.032633655,0.01239855,-0.021158699,0.006797512,0.028057666,-0.028883304,-0.007318783,-0.026182491,-0.0030174237,-0.033277374,0.009683743,0.0028792345,-0.018695783,0.015952988,-0.01926953,-0.009019036,-0.0015148341,0.028603427,0.0016224119,-0.016778626,0.018751757,0.010138543,-0.009375879,0.0336692,0.0053631426,0.01563113,0.043548856,-0.020948792,-0.007017915,0.01556116,0.00017623503,0.050405845,-0.033053473,-0.011929756,0.0049538226,0.0005514451,-0.011223067,0.00375385,0.022348177,0.002557376,0.020165136,0.0105933435,0.012069695,0.015701098,0.009571793,0.008445288,0.020095168,-0.020486996,0.023131832,-0.011453966,0.011474956,0.008305349,0.012629448,0.005223204,-0.01701652,-0.0064091827,-0.007199835,0.026224473,-0.021144705,0.013874901,-0.004691438,-0.045871835,-0.0068919705,0.017142465,-0.021466564,0.0054226164,-0.011041147,0.025944596,0.015337259,0.016484754,0.0177442,0.018961664,-0.00040319777,-0.03075848,0.004184161,0.020417025,0.033837125,-0.0007215578,-0.03316542,-0.008893091,-0.004736918,0.0026780728,0.0077316016,0.019353492,-0.016498748,-0.019535413,0.0015227057,0.03646797,-0.009935632,0.016568717,-0.01621887,-0.015043387,-0.0024156882,-0.010733282,0.0097677065,-0.0072348197,-0.010355448,0.0051952163,0.00050946354,0.027791783,0.020011203,-0.020403031,0.010257491,0.019241542,-0.011838797,0.014539609,-0.012293596,-0.0336692,0.040890027,-0.014273725,0.000821264,-0.0073607643,0.003391759,0.01276239,0.007773583,-0.018331941,0.0076336446,0.03296951,-0.014301714,-0.031150308,-0.013930877,0.008305349,0.02272601,-0.018247979,0.014301714,-0.012314587,0.017674232,-0.0005977997,-0.00054226164,0.0020623435,0.00425413,-0.022516103,-0.0045689917,0.011300033,0.0014929688,0.017912127,-0.025902614,-0.004019733,-0.008011478,0.008137424,-0.0054995827,-0.008907084,-0.010817246,-0.021186687,-0.0124405315,-0.020389037,0.005275681,0.008459281,0.015365246,-0.03123427,-0.025762675,-0.027665839,0.010649319,0.025650725,-0.01567311,0.017576274,-0.01556116,0.006881475,-0.0016477756,0.034256943,0.0073257796,-0.022446133,0.014763511,-0.027819771,0.009585787,0.013175209,-0.0027882743,0.0025101467,0.0050972593,-0.013210193,-0.021312632,-0.014847473,0.0008544994,-0.000849689,0.011705855,-0.00045173895,0.014483633,0.009116992,0.024629174,0.010950186,-0.016750637,0.03512456,-0.0062692445,0.011915762,-0.01817801,-0.0101805255,-0.0005282678,-0.007857546,0.008536248,-0.016652681,0.0024961529,0.015729086,0.016638687,0.01970334,0.008039466,-0.0072488138,0.0070808874,-0.018387917,-0.0011448718,-0.0141058,0.01915758,0.014168772,0.02625246,-0.040050395,-0.02122867,-0.0068604844,0.011936753,0.009830679,0.0002413939,0.0118178055,-0.021466564,0.015603142,-0.03537645,0.00096994865,0.012573473,-0.0002612914,-0.01872377,0.010691301,-0.0035019608,0.019871265,0.014259732,-0.014819486,0.0061048167,0.026938159,-0.00058030745,0.031626098,0.021074736,-0.018038072,0.010404427,0.0059858686,0.0021690466,0.0024996512,-0.0050377855,0.0069444473,-0.015141345,0.0057059918,0.036020167,-0.009179965,0.033725176,0.019199561,-0.026966147,-0.0015795557,-0.011859787,0.009431854,-0.00354919,-0.009096001,0.0091519775,0.0047998903,0.014252735,-0.0062167672,-0.0039322716,0.020528976,0.007000423,0.020039191,0.033389322,-0.0122236265,0.027917728,-0.0047439146,-0.012391553,-0.032269817,-0.022712016,0.0032500713,-0.013616015,-0.0003826443,0.0059508844,-0.02807166,0.026028559,0.017100483,0.017170453,0.014735523,0.034200966,0.016190883,-0.03406103,-0.026938159,0.018933678,0.0053001703,-0.009005042,0.0048558656,-0.022040311,0.010719288,-0.010320463,0.0074307336,0.021480558,0.017366366,-0.0038098253,-0.0048908503,-0.018513862,0.0039602593,0.031318232,-0.011544925,-0.0011614894,-0.006038346,0.007402746,0.019647364,-0.0051287455,-0.04172966,0.017100483,-0.03137421,0.031178296,-0.007129866,-0.016932556,-0.019255536,0.0065666134,-0.025286885,0.022320189,-0.018513862,0.014224747,0.001722118,0.00814442,-0.017226428,0.030058788,0.018205997,0.0056954967,-0.02625246,-0.024237346,0.008879097,0.063588046,0.052700836,-0.005775961,0.019535413,-0.0023369729,-0.007031909,-0.013720969,-0.0055135763,0.0067765214,-0.0040302286,-0.010187522,-0.019045629,0.01835993,-0.01085223,0.0051112534,0.0077665863,0.01817801,-0.014427658,-0.022684028,-0.039602593,-0.007024912,0.007514697,0.04130984,0.03198994,0.008921078,0.006447666,0.028603427,0.014049824,-0.013434095,-0.01821999,0.016050944,0.01574308,0.009676746,0.006017355,0.0029492036,0.037867356,0.00052083354,0.014308711,0.020556964,0.012006722,0.015393234,0.0087321615,0.0074517247,-0.005237198,-0.01483348,-0.007084386,-0.011293036,-0.0011308779,-0.0015043387,-0.01303527,-0.00021089168,-0.016316827,-0.043828733,-0.008109435,0.0110061625,0.0010364194,-0.01763225,-0.008403306,-0.0049013454,-0.000376522,-0.026490355,-0.023803538,-0.0035736791,0.0035929207,0.018192003,-0.016526736,-0.006661072,0.004768404,-0.030422628,-0.008655195,-0.0124335345,-0.035824254,-0.019801296,-0.005058776,0.034117002,0.018387917,0.024475241,-0.0070878845,-0.013811929,0.006608595,-0.0050832657,-0.0027795283,-0.011418981,-0.002859993,0.017478317,-0.0074307336,0.0012594464,-0.0032413253,-0.0055835457,0.013755953,-0.0012174648,0.007983491,-0.0038867914,-0.020710897,-0.021788422,0.01039743,0.021746442,0.033277374,-0.009928635,-0.025384841,0.007388752,-0.030086774,-0.02108873,-0.009012039,-0.0056360224,-0.0063182227,0.0043835733,-0.008095441,-0.010131546,0.0032290807,0.031794023,-0.012482513,0.011922759,0.0036314037,0.0055030813,0.030310677,0.0013950118,0.009466839,-0.018961664,-0.024223352,0.011328021,-0.024587192,0.0060068597,0.0037713423,-0.033501275,0.0126434425,0.017576274,0.0061188103,-0.033221398,0.01519732,-0.013602021,0.048222803,-0.016190883,-0.0017378611,-0.01621887,-0.00032448236,-0.013140224,-0.0034792207,-0.0124335345,-0.0032728114,0.0065911026,-0.020053186,-0.010481393,-0.009949626,0.0034932145,-0.033529263,-0.012461523,0.02425134,0.004820881,0.01067031,0.0027637852,-0.0074517247,-0.0057549705,-0.0072488138,0.0005789955,-0.019647364,-0.0045165145,0.007906524,0.01148895,0.02705011,0.021172693,-0.00768962,0.01647076,0.010978174,-0.014749517,0.00020061494,0.00079196435,0.021046748,-0.013371123,0.035572365,-0.0034652269,-0.0076616323,-0.014343695,0.0070529,0.026616301,0.00741674,-0.017688224,-0.018625813,-0.029359095,-0.028589433,0.016624693,0.012972298,-0.008963061,-0.0037433545,-0.02170446,0.0027078097,0.002900225,0.004534007,-0.0017238673,-0.010684304,0.006048841,-0.0075426847,0.023369728,-0.0022145265,0.018233985,-0.017702218,-0.030646529,-0.02850547,0.010222507,0.031150308,-0.018569838,0.026350418,0.017912127,-0.008669189,0.003974253,-0.0028372528,0.002385951,0.008305349,-0.0047264225,-0.013231184,0.016540729,-0.023047868,-0.025692707,-0.007815565,0.00407221,0.012566476,-0.011628889,0.013049264,0.0068464903,-0.021382602,0.02029108,-0.0037958315,0.048698593,0.02286595,0.023103844,0.025034996,0.0013766448,0.0037818376,0.0016643933,0.0038413114,0.013497068,0.01926953,0.009844673,-0.010229504,-0.02181641,0.004313604,0.017604262,-0.02468515,-0.01715646,-0.0111461,0.002043102,0.0024769113,-0.0025521282,-0.0083263405,0.011894772,-0.003466976,-0.01096418,0.008466278,0.018038072,-0.01194375,-0.003202842,0.026644288,0.018261973,0.027260017,-0.010271485,0.0030943898,0.004131684,0.009431854,0.02356564,0.013532052,-0.020221112,0.029415071,-0.009221947,-0.0059193983,0.024405273,-0.0053806347,0.015505184,-0.0071928385,0.004275121,0.03050659,-0.014777504,0.012118673,-0.0065491213,0.0065071397,0.0070039215,-0.0073537678,-0.0014632319,-0.008725164,-0.009662753,0.023579635,0.012622451,0.008284358,-0.031094331,-0.003148616,-0.0020605943,-0.012293596,-0.0012725657,0.006136303,-0.0011509941,-0.03355725,-0.027288005,-0.008305349,0.01621887,0.036635898,-0.0054855887,-0.023621617,0.012090686,0.017492311,-0.032045912,0.01628884,0.019003646,-0.012622451,-0.019143585,0.011684864,-0.018569838,-0.03596419,0.0107892575,-0.01756228,-0.038651012,-0.02534286,0.001619788,-0.004551499,0.0022652543,-0.022026317,-0.0058704196,-0.0055660536,0.003362022,0.0035019608,-0.025580756,0.016778626,0.009606777,0.0028180112,0.015966982,-0.01421775,0.018485874,-0.020151142,-0.016918562,-0.0022320189,-0.044220563,-0.02679822,-0.022376165,-0.008718167,-0.008487269,-0.002226771,-0.009445848,-0.0070563983,-0.014385677,0.007199835,0.0018034573,-0.006332217,-0.0049223364,0.009012039,0.0036349022,0.0124335345,-0.021396594,-0.008116432,-0.0022670035,0.02243214,-0.027455932,-0.014343695,-0.014889455,0.040806063,0.017030515,-0.0151133565,-0.0064756535,-0.006297232,-0.031402197,0.0023019882,0.004806887,0.00057680893,-0.00768962,0.007486709,0.0120277135,0.03624407,-0.003248322,-0.006584106,0.0029771912,0.0099776145,-0.020990774,-0.020011203,0.0059368904,0.0033777652,-0.021074736,0.002679822,-0.002141059,-0.01556116,0.022488115,-0.005457601,-0.016918562,-0.017898133,0.0088721,0.03134622,0.02991885,0.023901494,0.021480558,-0.022740005,-0.013713972,0.020375043,-0.015183326,-0.014721529,-0.023383722,0.010425418,0.0015349503,0.012391553,-0.0025153942,-0.028995255,0.012377559,0.0041071945,-0.005321161,0.0031853497,0.029610984,0.03296951,0.014735523,-0.019395474,-0.0039847484,0.025580756,-0.023299757,-0.0043031084,0.022222232,-0.030002812,0.0060593365,-0.01621887,-0.019843278,-0.018513862,-0.016050944,-0.011754833,-0.0017737204,-0.0046774438,0.014154778,0.019003646,-0.023285765,0.025188928,0.009802691,0.0015821796,-0.018247979,-0.004541004,0.007220826,-0.019563401,0.0036069145,0.0059089027,-0.019199561,-0.0105863465,0.006636583,0.01731039,0.017982095,0.010698297,0.23151423,-0.018667795,-0.013371123,0.012020716,0.018052066,0.0025153942,0.023243783,0.01926953,0.0002008336,0.010719288,0.009082008,0.019913247,0.004729921,-0.007591663,0.022753999,-0.017450329,-0.022530098,-0.008368322,0.0046144715,0.017674232,0.014014839,-0.00914498,-0.0047788993,-0.022516103,0.042961117,-0.011055141,-0.009844673,0.0028372528,0.0059753736,0.006947946,-0.0075286906,-0.00307165,0.021060742,0.0012410794,-0.014273725,-0.00043074816,0.02170446,-0.00869018,0.01267143,0.0015533172,0.037055712,-0.025021002,-0.0016923811,-0.012118673,0.012804371,0.022879943,-0.019885259,-0.020375043,0.0282116,0.0155191785,-0.01658271,-0.005310666,0.0027760298,0.029023243,0.008277361,-0.009844673,-0.0116009,0.0025241405,0.012335578,-0.01985727,-0.024237346,0.008032469,-0.008410303,0.022698022,-0.0013661495,-0.0015393234,-0.006804509,-0.010138543,0.018164016,-0.01567311,-0.015505184,-0.015337259,-0.007584666,-0.012804371,-0.029527022,-0.015729086,0.029079217,-0.00040953874,0.022809973,0.029023243,-0.020598946,-0.0008593098,-0.001096768,-0.014385677,-0.009096001,-0.021256655,0.035544377,-0.0061153118,-0.0064826505,-0.0069304537,-0.016162895,0.014070815,-0.011978734,0.0099846115,-0.00096470094,0.00017962417,0.010502383,0.012615454,0.0054226164,0.0011947248,-0.02588862,0.076350436,0.0070563983,-0.0030244205,0.00038942258,0.010201516,0.0020710896,0.023033876,0.005548561,-0.011321024,0.0020028695,-0.018122034,0.0008286982,-0.02145257,-0.012244618,0.0027952713,0.023593629,-0.006206272,0.01563113,0.001631158,-0.030450614,-0.01303527,-0.008501263,0.011223067,0.003792333,-0.0066225887,0.007084386,-0.0018821727,-0.017324384,-0.0069654384,0.004747413,-0.019759314,0.008788137,0.015575154,-0.010467399,-0.022530098,-0.017394355,-0.008907084,0.017884139,-0.005132244,0.0020605943,0.016204877,-0.0057479735,-0.011300033,-0.013434095,-0.009942629,-0.012279603,0.009075011,0.0066855615,0.00036908776,-0.0048733577,0.012790378,-0.009816685,-0.015827043,0.0061398013,-0.012321584,0.015952988,0.0023509667,0.0028704882,-0.005016795,-0.023621617,0.004631964,0.009473836,-0.018639807,-0.014189763,-0.018513862,-0.18236783,0.0089420695,0.022348177,-0.037727416,0.010929196,0.0009795694,0.028743366,-0.012363565,-0.044192575,0.015617135,0.034928646,-0.012958304,-0.03028269,-0.002602856,-0.005342152,-0.012783381,-0.008802131,-0.0028862313,0.00352645,0.013748957,0.047691036,-0.020249099,-0.0025626235,0.0071368627,-0.017870145,-0.0029876868,0.0043590837,0.02308985,0.015351253,-0.030898418,-0.008956064,-0.0034564806,0.017814169,-0.005691998,-0.008494266,-0.0038727976,0.0043940684,-0.02192836,-0.02113071,-0.0008330713,0.020277087,0.0168346,0.014987412,-0.0017422342,-0.015477197,0.0025381343,0.023425704,-0.013182205,0.005475093,-0.028771354,0.0024699143,-0.007045903,0.011705855,-0.00655262,0.0020378542,0.0055135763,-0.0063602044,-0.019227548,0.0044395486,-0.004684441,0.0021672973,-0.00539113,0.011992728,0.018569838,0.0051672286,0.0062202658,9.199863e-05,0.014917443,-0.040890027,0.009347891,-0.00878114,-0.005261687,-0.011223067,-0.004859364,0.0021620498,0.035880227,-0.018485874,-0.009473836,0.003346279,-0.022152262,-0.008620211,0.01821999,-0.0074727153,-0.0017282403,-0.0041736653,-0.0045480006,-0.0004386197,0.037895344,-0.007955503,-0.013476077,0.020668915,-0.047439147,-0.004478032,-0.014483633,-0.0014221249,0.018373923,0.014245738,-0.021410588,0.015183326,-0.0047788993,0.013616015,0.00028315678,-0.001642528,-0.00025123332,0.030590553,0.0032255822,0.0029474543,0.0150993625,0.033753164,-0.0063532074,-0.026770232,-0.021830404,9.440382e-05,0.0038658008,0.014385677,0.02814163,-0.0075426847,0.009893651,0.009795695,-0.0067345398,0.06593902,0.0018454388,-0.013811929,0.014427658,-0.009047023,-0.022823967,-0.11665273,-0.046375614,-0.004509518,-0.003096139,-0.008333337,0.024237346,-0.008081447,0.0016696411,-0.028911293,0.03173805,-0.016918562,-0.030086774,0.0238875,0.0018261973,-0.004289115,-0.032745607,0.00311713,-0.006563115,-0.027805777,0.033249386,-0.01212567,-0.021438576,0.006388192,-0.020990774,0.01230759,0.0043240995,-0.03364121,-0.008368322,0.0036418992,-0.007010918,0.010264488,-0.010635325,0.014595584,-1.3782028e-05,-0.0037363577,-0.023481678,-0.004894349,-0.0103764385,0.020333063,-0.017884139,0.01121607,-0.0037608468,-0.0007482336,-0.008907084,-0.03949064,-0.022040311,-0.007213829,0.02079486,0.030086774,-0.021326626,-0.03694376,0.012020716,-0.019535413,0.00443605,0.009522814,-0.0028617422,-0.0034092513,0.0048173824,0.00452701,0.012790378,-0.018877702,0.007066894,-0.009459842,-0.0014868465,0.010845233,-0.029722935,-0.0034792207,-0.015757075,0.0114049865,-0.020556964,-0.005058776,-0.0032045913,-0.009082008,0.011789817,-0.015589148,-0.014007843,-0.012006722,-0.021060742,0.005426115,-0.0044325516,-0.0056640105,-0.011747836,-0.009228943,-0.014329702,0.018261973,-0.0036453977,-0.025440818,-0.017912127,0.011104119,-0.008466278,0.0005601913,0.0320739,0.010313466,-0.027553888,0.019115597,0.014539609,-0.028295562,-5.7232653e-05,0.008550242,0.01039743,-0.027455932,-0.0070214137,-0.04707531,0.028043672,-0.003104885,-0.034089014,-0.015645122,-0.004943327,0.008718167,-0.008158414,-0.012503504,0.020165136,-0.016316827,0.0107892575,-0.0142877195,-0.0031311237,-0.017296398,-0.012258612,0.018877702,-0.011936753,-0.0036628898,-0.005093761,0.0153092705,-0.001601421,0.012202636,0.01148895,-0.012342575,0.0009655756,-0.01048839,0.012706415,-0.012083689,-0.013049264,-0.0037118683,-0.022110282,0.0034477345,0.023117838,-0.0007792825,0.0013162964,-0.013189202,0.032997496,0.027246024,0.022026317,-0.0034110006,-0.032633655,-0.0006795763,-0.018891696,-0.0035999175,-0.010523374,-0.005719986,-0.007647638,-0.0076266476,-0.0017466072,0.024783107,0.0065001426,-0.007213829,-0.039770517,0.0065980996,0.020165136,-0.009809688,-0.017968101,-0.006538626,0.004771902,0.04388471,-0.012174648,-0.0045619947,-0.0009375879,0.0067100506,-0.009047023,-0.003178353,0.010481393,0.018485874,-0.003823819,0.0074447277,0.0084173,-0.0030821452,0.017590268,-0.009019036,-0.020500988,0.00941786,0.0017597264,0.0030139252,0.032913532,0.012916323,0.0013827672,-0.009641762,-7.937136e-05,0.004740416,0.0047194255,-0.010691301,0.008697177,-0.008795134,0.004866361,0.028743366,0.014014839,-0.014413664,0.011859787,-0.015505184,-0.01854185,-0.0045689917,-0.009459842,0.01537924,0.022558084,-0.007297792,-0.0013897641,-0.0068849735,-0.03028269,-0.025566762,0.023103844,-0.012657437,-0.03778339,-0.0048103854,0.033361334,0.032773595,-0.0020763373,0.0014597334,0.009263928,-0.018247979,0.024223352,-0.011586906,-0.023145827,-0.03621608,0.02010916,0.025930602,0.0010644072,-0.002657082,-0.008606217,0.01167087,0.032913532,0.024699144,-0.0095508015,0.00623426,0.029471045,0.0005295797,0.0012909325,-0.0050622746,-0.008263368,-0.01817801,-0.025664719,-0.018303955,0.0076756263,0.015225307,0.06862584,0.01588302,-0.008683183,0.01985727,-0.02218025,0.020473002,0.034340907,-0.0046739457,-0.02413939,-0.0122866,-0.012342575,0.010404427,-0.014161775,0.0057794596,0.0024769113,0.017282404,-0.008410303,0.0035561868,-0.018024078,0.017786182,0.008487269,-0.0031363713,0.023495672,-0.0027672837,-0.017660238,0.015183326,0.0061048167,0.0068185027,0.0027585374,-0.016176889,0.025720695,0.01421775,-0.024755118,-0.022194244,-0.008249374,0.01185279,-0.0060593365,-0.034928646,-0.002989436,0.0028617422,-0.0067170477,-0.021774428,-0.017534293,0.0033847622,-0.009921639,0.008914081,-0.010404427,-0.019507425,-0.015729086]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.7745721947379066
0.7413613295592608
0.7622420588172784
0.7852990106107886
0.7796083901471195
0.7616598240548866
0.7568459044696146
0.7599936015720749
0.7749104157215425
0.7810338124217532
0.7457374417610003
0.7384166447152524
0.7571631278252023
0.7961457267566766
0.753459823258361
0.7902243995400805
0.7789507611379485
0.7750973827497005
0.7980175946852497
0.7470227534094406
0.7624925625023541
0.7889065423298857
0.7774879311833793
0.7907707115360652
0.7926918344056644
0.7570541157010661
0.7945883820425459
0.7677389831609135
[{"sentences":["Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) .","These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) .","These efforts are based on the assumption that more parameters will lead to better performance.","However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data."],"sections":[{"title":"Introduction","number":"1"}],"section_type":"main"},{"sentences":["Following recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017).","We leverage various improvements that were subsequently proposed, and used in different models such as PaLM.","Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):"],"sections":[{"title":"Architecture","number":"2.2"}],"section_type":"main"},{"sentences":["starting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) .","More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) ."],"sections":[{"title":"Related work","number":"7"}],"section_type":"main"}]
0.7904411337827674
0.8193868812531241
[{"sentences":["More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem.","From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) .","Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency."],"sections":[{"title":"Related Work","number":"2"}],"section_type":"main"},{"sentences":["To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input.","Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."],"sections":[{"title":"Related Work","number":"2"}],"section_type":"main"},{"sentences":["In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) ."],"sections":[{"title":"Related Work","number":"2"}],"section_type":"main"}]
0.7814101287065642
0.7522287963302405
{"doc":null,"source":"async def answer(\n    context: str, question: str, answer_model: str = \"chatgpt\", **kwargs\n) -> str:\n    \n    prompt = F(\nf\"\"\"Background text: \"{context}\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"{question}\"\nAnswer: \"\"\"\n    ).strip()\n\n    prompt = prompt\n    answer = await recipe.agent(answer_model).complete(prompt=prompt, stop='\"')\n    return answer\n"}
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) . These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) . These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.","formatted":"Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) . These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) . These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Following recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017). We leverage various improvements that were subsequently proposed, and used in different models such as PaLM. Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):","formatted":"Following recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017). We leverage various improvements that were subsequently proposed, and used in different models such as PaLM. Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):"},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"starting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) . More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) .","formatted":"starting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) . More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) ."}]},"question":"How does the model extend previous work and models?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
{"doc":"Generate an answer to a question given some context.","source":"    async def complete(\n        self,\n        *,\n        prompt: str,\n        stop: Stop = None,\n        verbose: bool = False,\n        default: str = \"\",\n        max_tokens: int = 256,\n    ) -> str:\n        \"\"\"Generate an answer to a question given some context.\"\"\"\n        if verbose:\n            self._print_markdown(prompt)\n        response = await self._complete(prompt, stop=stop, max_tokens=max_tokens)\n        completion = self._extract_completion(response)\n        if verbose:\n            self._print_markdown(completion)\n        return completion\n"}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) . These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) . These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.","formatted":"Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) . These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) . These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Following recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017). We leverage various improvements that were subsequently proposed, and used in different models such as PaLM. Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):","formatted":"Following recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017). We leverage various improvements that were subsequently proposed, and used in different models such as PaLM. Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):"},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"starting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) . More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) .","formatted":"starting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) . More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) ."}]},"formatted":"Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) . These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) . These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.\n\nFollowing recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017). We leverage various improvements that were subsequently proposed, and used in different models such as PaLM. Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):\n\nstarting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) . More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency.","formatted":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) .","formatted":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) .","formatted":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) ."}]},"question":"How does the model extend previous work and models?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
0.7826923687504103
0.7619086268187885
0.7546751225582364
0.773395890877411
{"doc":"Send a completion request to the OpenAI API with the given prompt and parameters.","source":"    async def _complete(self, prompt, **kwargs) -> dict:\n        \"\"\"Send a completion request to the OpenAI API with the given prompt and parameters.\"\"\"\n        kwargs.update(\n            {\n                \"model\": self.model,\n                \"temperature\": self.temperature,\n                \"top_p\": self.top_p,\n                \"n\": 1,\n            }\n        )\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        response = await openai_chatcomplete(messages, **kwargs)\n        if \"choices\" not in response:\n            raise ValueError(f\"No choices in response: {response}\")\n        return response\n"}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) . These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) . These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.","formatted":"Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) . These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) . These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Following recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017). We leverage various improvements that were subsequently proposed, and used in different models such as PaLM. Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):","formatted":"Following recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017). We leverage various improvements that were subsequently proposed, and used in different models such as PaLM. Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):"},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"starting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) . More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) .","formatted":"starting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) . More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) ."}]},"formatted":"Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) . These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) . These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.\n\nFollowing recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017). We leverage various improvements that were subsequently proposed, and used in different models such as PaLM. Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):\n\nstarting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) . More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency.","formatted":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) .","formatted":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) .","formatted":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) ."}]},"formatted":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency.\n\nTo capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) .\n\nIn the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
0.7395289275651982
0.7675508080091882
0.7395396977324088
0.7564371636039703
0.7465781051621391
0.7512038321058001
0.7657151647771037
0.7481275659780242
0.77719886447778
0.8000698932378486
0.766433990122216
0.75995648381911
0.7561273058586099
0.7290144561063752
0.7623639644011563
0.7572302022261114
0.7783136479709052
0.7706181307753186
0.7252282488411388
0.805396190976267
0.7428542762740028
0.7841332149949293
0.7720567378150799
0.7800722755645977
0.8015528348075077
{"doc":"Send a completion request to the OpenAI API and return the JSON response.","source":"@trace\nasync def openai_chatcomplete(\n    messages: list[dict[str, str]],\n    stop: Optional[str] = \"\\n\",\n    top_p: float = 1,\n    temperature: float = 0,\n    model: str = \"gpt-3.5-turbo\",\n    max_tokens: int = 256,\n    logit_bias: Optional[Mapping[str, Union[int, float]]] = None,\n    n: int = 1,\n    cache_id: int = 0,  # for repeated non-deterministic sampling using caching\n) -> dict:\n    \"\"\"Send a completion request to the OpenAI API and return the JSON response.\"\"\"\n    params = {\n        \"messages\": messages,\n        \"stop\": stop,\n        \"top_p\": top_p,\n        \"temperature\": temperature,\n        \"model\": model,\n        \"max_tokens\": max_tokens,\n        \"n\": n,\n    }\n    if logit_bias:\n        params[\"logit_bias\"] = logit_bias  # type: ignore[assignment]\n    response = await _post(\"chat/completions\", json=params, cache_id=cache_id)\n    if isinstance(response, TooLongRequestError):\n        raise response\n    add_fields(total_tokens=extract_total_tokens(response))\n    return response\n"}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) . These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) . These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.","formatted":"Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) . These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) . These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Following recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017). We leverage various improvements that were subsequently proposed, and used in different models such as PaLM. Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):","formatted":"Following recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017). We leverage various improvements that were subsequently proposed, and used in different models such as PaLM. Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):"},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"starting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) . More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) .","formatted":"starting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) . More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) ."}]},"formatted":"Large Languages Models (LLMs) trained on massive corpora of texts have shown their ability to perform new tasks from textual instructions or from a few examples (Brown et al., 2020) . These few-shot properties first appeared when scaling models to a sufficient size (Kaplan et al., 2020) , resulting in a line of work that focuses on further scaling these models (Chowdhery et al., 2022; Rae et al., 2021) . These efforts are based on the assumption that more parameters will lead to better performance. However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest models, but by smaller models trained on more data.\n\nFollowing recent work on large language models, our network is based on the transformer architecture (Vaswani et al., 2017). We leverage various improvements that were subsequently proposed, and used in different models such as PaLM. Here are the main difference with the original architecture, and where we were found the inspiration for this change (in bracket):\n\nstarting from feed forward models (Bengio et al., 2000), recurrent neural networks (Elman, 1990; Mikolov et al., 2010) and LSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2013) . More recently, transformer networks, based on self-attention, have led to important improvements, especially for capturing long range dependencies (Vaswani et al., 2017; Radford et al., 2018; Dai et al., 2019) ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency.","formatted":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) .","formatted":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) .","formatted":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) ."}]},"formatted":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency.\n\nTo capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) .\n\nIn the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
[{"sentences":["Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019).","Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation."],"sections":[{"title":"Introduction","number":"1"}],"section_type":"main"},{"sentences":["Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research.","While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility).","For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics."," Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities.","BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2 ","The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions.","We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly.","A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix."," Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness.","Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv).","By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets.","Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness).","In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation.","Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."],"sections":[{"title":"Related Work","number":"2"}],"section_type":"main"},{"sentences":["In this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways.","First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment.","Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia).","In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness.","Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining.","The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition.","Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small.","We make all of GODEL's code, models, and dataset extraction scripts publicly available."],"sections":[{"title":"Conclusion","number":"7"}],"section_type":"main"}]
0.7461136105765291
0.7371783890803721
0.686574779004509
0.7488092086857412
0.7908013353277639
0.7775923376253611
0.7356645657523315
0.8079664019698972
0.8030965708389883
0.7970642766725088
0.7569236721223469
0.6865535768256982
0.7806291567872548
0.7800688718746326
0.7660321361807195
0.772169794410341
0.7572110192638003
0.7943311142093196
0.6865617849201141
0.7697347950937791
0.7966266142464006
0.7554379384313252
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.001220661,0.004483632,-0.0020493104,-0.014728433,-0.0025340747,0.024626724,-0.015386453,0.017556516,-0.011242331,-0.034441013,0.0047111386,0.016044471,-0.016058473,0.013671403,-0.0030450895,-0.025144741,0.028070826,0.0064331894,-0.011711345,-0.014182418,-0.0035753553,0.017626518,-0.007000206,-0.03878114,0.007203212,0.033796996,0.028000824,-0.0154004535,0.022946676,0.00917027,-0.006051678,0.015344452,-0.037605107,-0.024192711,0.0011952852,-5.611103e-05,0.010122298,-0.00080283615,0.004014618,0.0044416306,0.011116327,0.00645419,0.0013650402,-0.0148264365,-0.007945234,-0.008400247,0.015596459,-0.039845172,-0.0079942355,-0.013419395,0.010339305,0.024990736,-0.019082561,-0.012782376,-0.016212476,-0.0029015853,-0.004784641,0.00918427,0.013643402,-0.014812436,0.021140622,0.018116534,-0.01769652,-0.0014306671,-0.021504633,0.004357628,-0.02480873,-0.012334364,-0.014056413,0.007742228,0.034553017,0.010311304,-0.010108298,-0.02578876,0.03469302,-0.007266214,-0.0035228536,-0.025760759,-0.013895409,0.01633848,-0.0010036546,-0.023310686,-0.015078444,0.020594606,0.012467367,-0.016870497,0.0035193537,0.015554458,-0.0136154005,0.003703109,-0.0039866176,-0.00076170993,0.020300597,0.01530245,0.007861231,-0.0058136713,-0.008694256,0.026040766,0.0012416616,0.009926292,-0.007000206,-0.003776611,-0.021000618,-0.00984229,-0.014742434,0.0028508338,0.013720404,0.0037941118,0.005838172,-0.01324439,-0.036177065,0.035533044,0.011753346,-0.038137123,6.912703e-05,-0.009933293,0.0077282274,-0.017752523,0.0038851143,-0.015834466,0.023646696,0.014392423,0.018088533,-0.008652255,0.011928352,-0.006716698,-0.0062966854,-0.011641343,-0.017234508,-0.013377394,0.0011069076,0.010731316,0.005229154,0.019152563,-0.015190447,0.017500516,-0.014420425,0.013391394,-0.025480751,-0.0305769,0.007707227,0.0051801526,-0.019586576,0.017808525,-0.0021210625,0.01597447,0.010976323,0.026320774,0.017052501,0.012964382,0.0021000619,-0.038221125,0.021770641,0.02923286,0.016436484,0.02111262,-0.029316863,-0.009338275,-0.021266626,-0.008064237,-0.007350216,0.013734404,0.006013177,0.018158535,0.010661314,0.010073297,0.014742434,-0.005302656,0.01256537,0.0043016267,-0.011319333,0.031696934,-0.029008854,0.0005368283,-0.006923204,0.019278567,0.021126622,-0.0055581634,-0.017500516,-0.025620755,0.017234508,-0.0015837966,0.0050401483,0.024906734,-0.019404572,-0.023828702,0.0169685,-0.012348363,0.0051591517,0.0019985589,0.018760553,0.016142474,-0.0016467985,0.005061149,-0.6702277,-0.021938646,0.003927116,-0.025326746,0.015540457,0.0169685,-0.0019793082,-0.01629648,-0.03259296,0.012376364,-0.021210624,0.0067761997,0.028014824,-0.028952852,-0.007259214,-0.026054768,-0.00306084,-0.03318098,0.009653284,0.002819333,-0.018634548,0.015932469,-0.019278567,-0.009247272,-0.001496294,0.028658845,0.0015855466,-0.016772494,0.018760553,0.0101713,-0.009443278,0.033572987,0.005358658,0.015596459,0.043541282,-0.02102862,-0.007059708,0.015596459,0.0001747864,0.05056949,-0.033096973,-0.011942351,0.004858143,0.0006243309,-0.011263331,0.0038606136,0.022302657,0.0025270744,0.02000659,0.010647314,0.011949352,0.01563846,0.009625283,0.00850525,0.020132592,-0.020496603,0.023114681,-0.011501338,0.011438337,0.008295245,0.012698374,0.005064649,-0.017080503,-0.006485691,-0.0072452133,0.026194772,-0.021098621,0.013881409,-0.00475664,-0.045725346,-0.0069057033,0.0169825,-0.021672638,0.0053271567,-0.010941322,0.02581676,0.015386453,0.016394483,0.017710522,0.018830555,-0.0004952646,-0.030772906,0.004119621,0.020412602,0.033908997,-0.00075689727,-0.03329298,-0.008939263,-0.0047986414,0.002821083,0.0077492283,0.01937657,-0.01659049,-0.019502575,0.0014499177,0.036429074,-0.009723286,0.016506486,-0.016142474,-0.015064443,-0.0023205683,-0.010717316,0.009772288,-0.0072102123,-0.010290303,0.005365658,0.00046288862,0.027776817,0.019936588,-0.020412602,0.010241302,0.019264568,-0.011872349,0.014504427,-0.012376364,-0.03360099,0.040853202,-0.01426642,0.00082471175,-0.0073852176,0.003433601,0.012670373,0.007952234,-0.018256538,0.0076162242,0.033040974,-0.014301421,-0.031108916,-0.014028413,0.008281244,0.022666667,-0.01836854,0.014210418,-0.012299362,0.01765452,-0.00056482916,-0.0006072679,0.0020860615,0.0042036236,-0.022554664,-0.0045746346,0.011480338,0.0015435454,0.017934527,-0.025886763,-0.0040916204,-0.008029236,0.008001235,-0.0055966647,-0.00884126,-0.010899321,-0.021224625,-0.012593371,-0.020272598,0.0052711554,0.008547252,0.015540457,-0.03127692,-0.025648756,-0.027678816,0.010724315,0.025760759,-0.01562446,0.017598517,-0.015610459,0.006818201,-0.0015505457,0.034441013,0.007427219,-0.022400659,0.014700432,-0.02787482,0.009667285,0.013160387,-0.0028718344,0.0024185712,0.0050121476,-0.013293391,-0.02139263,-0.014882438,0.0009144019,-0.0009047766,0.011774346,-0.00038894895,0.014504427,0.009051266,0.02448672,0.011025324,-0.016758494,0.035169035,-0.0062966854,0.01188635,-0.018130533,-0.010052296,-0.000610768,-0.0079592345,0.008519251,-0.016716491,0.0025603254,0.015722463,0.016688492,0.01972658,0.008113239,-0.0071892114,0.00713321,-0.01835454,-0.0012197859,-0.014063414,0.019082561,0.014070414,0.026404778,-0.04001318,-0.021378629,-0.0069162035,0.011851349,0.009793288,0.0001701925,0.0118303485,-0.021462632,0.015708463,-0.03530904,0.00089777645,0.012488368,-0.000331416,-0.018718552,0.010675314,-0.0035753553,0.019810583,0.01426642,-0.01496644,0.0060271774,0.026908793,-0.00051101507,0.031724934,0.021014618,-0.018074533,0.010381306,0.0059046736,0.0021263126,0.0024588224,-0.0048896438,0.0070527075,-0.015176447,0.005817171,0.03598106,-0.009198271,0.033880997,0.019292569,-0.027048796,-0.0015024192,-0.011718345,0.009443278,-0.0036121064,-0.00917727,0.009191271,0.004854643,0.01425242,-0.0063036857,-0.0039341156,0.020496603,0.006996706,0.020090591,0.033208977,-0.012278361,0.027944822,-0.0048021413,-0.012523369,-0.032368954,-0.022736669,0.0031115916,-0.013671403,-0.00042241867,0.005911674,-0.028000824,0.026110768,0.017080503,0.017178506,0.0148264365,0.034217007,0.016226478,-0.03418901,-0.02685279,0.018942557,0.0053411573,-0.008953264,0.004886144,-0.021980647,0.010724315,-0.010185299,0.0074132183,0.021504633,0.017234508,-0.003769611,-0.0048686434,-0.018508544,0.0039551165,0.03133292,-0.011599341,-0.0011392835,-0.006055178,0.0073292158,0.01967058,-0.005061149,-0.041749228,0.017164506,-0.03133292,0.031024912,-0.007098209,-0.016996501,-0.019236566,0.006562693,-0.025200741,0.022358658,-0.018536545,0.014287421,0.0017509265,0.0081622405,-0.017220506,0.030016884,0.018102532,0.0057016676,-0.026250772,-0.024192711,0.008890262,0.063673876,0.05261355,-0.005810171,0.019544575,-0.0023695698,-0.007091209,-0.013846408,-0.005467161,0.006720198,-0.0040216185,-0.010087297,-0.01899856,0.01832654,-0.01089232,0.0052851555,0.00781923,0.018158535,-0.0144904265,-0.022554664,-0.039565165,-0.00714721,0.007518221,0.041161213,0.032088943,0.009030266,0.006380688,0.028658845,0.014091414,-0.013426395,-0.018214537,0.016030472,0.01594647,0.009765288,0.0059921765,0.0028053327,0.037857115,0.0004830142,0.014168417,0.020552605,0.012040354,0.015456455,0.0086662555,0.00746922,-0.0052081533,-0.014854438,-0.0070877085,-0.011340334,-0.001153284,-0.0015374202,-0.013160387,-0.00030757155,-0.016380481,-0.04379329,-0.007987235,0.010913321,0.0010430308,-0.017514516,-0.008428248,-0.004956146,-0.00035679174,-0.026614783,-0.023842702,-0.0036576076,0.0033828495,0.01832654,-0.016436484,-0.006653696,0.0048721433,-0.030324893,-0.008645254,-0.012313362,-0.035869054,-0.019740582,-0.0052151536,0.03418901,0.01834054,0.02447272,-0.007056208,-0.01391641,0.0068007,-0.005176652,-0.0029103358,-0.011382335,-0.0028455837,0.017444514,-0.00748322,0.0011034075,-0.0032690961,-0.0056526666,0.013853407,-0.0011174079,0.007966234,-0.0038991147,-0.020874614,-0.02170064,0.010325304,0.021672638,0.03318098,-0.009870291,-0.02545275,0.007350216,-0.030212888,-0.021182623,-0.008946263,-0.0056981677,-0.0062686848,0.0043716286,-0.008050237,-0.010066296,0.0032025944,0.031808935,-0.012516368,0.011788347,0.0035823556,0.0056316657,0.030296892,0.0013519148,0.009478279,-0.018928558,-0.02413671,0.011270332,-0.024584724,0.0059606754,0.0038606136,-0.033488985,0.012516368,0.017570518,0.0061391806,-0.033320982,0.015148446,-0.013510398,0.048161417,-0.016324481,-0.0018200536,-0.016268479,-0.00027278927,-0.013090385,-0.0033828495,-0.012292362,-0.0034703522,0.0066571957,-0.019950587,-0.010500309,-0.010031295,0.0034703522,-0.033488985,-0.012481367,0.024276715,0.00475664,0.0106543135,0.0027318303,-0.0075672227,-0.0056561665,-0.0071892114,0.0005643916,-0.01969858,-0.004452131,0.00781223,0.011389336,0.027034795,0.021126622,-0.007686226,0.01664649,0.010941322,-0.0148264365,0.00019141189,0.0008531501,0.021084622,-0.013398394,0.035589047,-0.0035561046,-0.007707227,-0.014350423,0.007168211,0.026712786,0.00746222,-0.01769652,-0.01867655,-0.029372865,-0.028784847,0.016618488,0.013048384,-0.009002265,-0.0038221125,-0.021714639,0.0027440807,0.002857834,0.004651637,-0.0017544266,-0.010633313,0.0059991768,-0.0076022237,0.023338687,-0.0021980647,0.018186536,-0.017766522,-0.030632902,-0.028448837,0.010290303,0.031220919,-0.018606547,0.026376776,0.018088533,-0.008687256,0.004007618,-0.0029050855,0.0024343217,0.008225242,-0.004690138,-0.01323739,0.01663249,-0.02312868,-0.025704756,-0.007910233,0.0040636198,0.012425366,-0.011466337,0.013083385,0.006895203,-0.02140663,0.020328598,-0.003629607,0.04860943,0.022904674,0.023058679,0.024990736,0.0013554149,0.0038256126,0.001700175,0.0038816142,0.013335393,0.019194566,0.00984229,-0.010276303,-0.021910645,0.0043961294,0.01765452,-0.024752729,-0.017052501,-0.011256332,0.0020808112,0.0025935764,-0.002611077,-0.008204241,0.011739345,-0.0034966029,-0.011004324,0.008407247,0.01801853,-0.01187935,-0.003223595,0.026572783,0.018382542,0.027286803,-0.010290303,0.003122092,0.0040916204,0.009443278,0.02342269,0.013524398,-0.020314598,0.029484868,-0.009121268,-0.0058696726,0.024402719,-0.0053761583,0.015484456,-0.007066708,0.004312127,0.0305209,-0.014868437,0.012250361,-0.0065766936,0.0063771876,0.006863702,-0.0073642167,-0.0013895408,-0.008785259,-0.009772288,0.023506692,0.01258637,0.008218242,-0.03124892,-0.0031378423,-0.0020913116,-0.012313362,-0.0012145358,0.0060306774,-0.0011760346,-0.03360099,-0.027244803,-0.008204241,0.016128475,0.03670908,-0.0053061564,-0.023506692,0.012075355,0.017570518,-0.032088943,0.016366482,0.01902656,-0.0125723705,-0.019138563,0.011746346,-0.018550547,-0.03595306,0.010801318,-0.017528515,-0.038501132,-0.025424749,0.0015820466,-0.004525633,0.0023345686,-0.021896645,-0.0057191686,-0.0054741614,0.00339335,0.0035106034,-0.025676755,0.016730493,0.009639284,0.002824583,0.016016472,-0.013944411,0.018564546,-0.020188594,-0.016940499,-0.002339819,-0.044213302,-0.02681079,-0.022358658,-0.008624254,-0.008561252,-0.0021683138,-0.009429278,-0.00714721,-0.014420425,0.0071297097,0.0018113033,-0.0063386867,-0.004851143,0.008974264,0.0036436073,0.012516368,-0.021378629,-0.008197241,-0.0022558165,0.022386659,-0.02751081,-0.014301421,-0.014910439,0.0407692,0.017066503,-0.015120445,-0.006527692,-0.0062616845,-0.03133292,0.0022645667,0.0047986414,0.0005670167,-0.0076022237,0.0075252214,0.011970352,0.03628907,-0.0033180977,-0.0065451926,0.002852584,0.010038296,-0.021000618,-0.019992588,0.005862673,0.0033740993,-0.021014618,0.0025515752,-0.0022663167,-0.015582459,0.02241466,-0.005404159,-0.0169685,-0.017934527,0.008918262,0.03124892,0.030072885,0.023842702,0.02140663,-0.02275067,-0.013706404,0.020412602,-0.015036442,-0.014742434,-0.023310686,0.010423306,0.0014044164,0.01223636,-0.002509574,-0.028980853,0.012502368,0.0040986207,-0.005379658,0.0031535928,0.029456867,0.03301297,0.014770435,-0.019250566,-0.0040356186,0.02546675,-0.023310686,-0.0043331278,0.022190653,-0.029960882,0.0060971794,-0.016198477,-0.019894585,-0.018564546,-0.016128475,-0.011760347,-0.0017736772,-0.0046306364,0.014168417,0.018984558,-0.02343669,0.025284745,0.00984929,0.0016240478,-0.01831254,-0.0045641344,0.0071962117,-0.019502575,0.0034861027,0.005838172,-0.019180564,-0.010675314,0.006685197,0.017164506,0.01801853,0.010745317,0.23162282,-0.018620549,-0.013405395,0.012096356,0.018172534,0.0026250773,0.023394689,0.019152563,0.00014667619,0.010745317,0.009079267,0.02004859,0.004795141,-0.0076022237,0.022722669,-0.017444514,-0.022666667,-0.008421248,0.0045186332,0.017710522,0.01392341,-0.009093268,-0.004679638,-0.022610666,0.042953264,-0.011137328,-0.009954293,0.0029138357,0.0059361747,0.0068742023,-0.0073782173,-0.0030328394,0.021084622,0.0012495368,-0.014406424,-0.00043138769,0.021812642,-0.008603253,0.012775376,0.0014884188,0.03704509,-0.024948735,-0.0016905498,-0.012124357,0.01290138,0.022820672,-0.019908587,-0.0203986,0.02819683,0.015582459,-0.016604489,-0.0051941527,0.0027405806,0.029064856,0.008246243,-0.00984929,-0.011592342,0.002581326,0.0121663585,-0.019866586,-0.024192711,0.008092239,-0.008386247,0.02275067,-0.0014306671,-0.0014647931,-0.0068742023,-0.010094297,0.018116534,-0.0155684585,-0.015526457,-0.015316451,-0.0075322217,-0.012782376,-0.02959687,-0.015722463,0.029064856,-0.00044757567,0.02276467,0.028952852,-0.020650608,-0.0008662755,-0.001156784,-0.014476426,-0.008988265,-0.021168623,0.035477046,-0.0061951824,-0.006482191,-0.0069092032,-0.016142474,0.014161417,-0.011991353,0.009870291,-0.0008741507,0.00019895898,0.010465308,0.012649372,0.0054216594,0.0012390364,-0.02578876,0.07616224,0.0071087093,-0.0029978382,0.00035701052,0.010325304,0.002105312,0.023072679,0.005642166,-0.011396335,0.0019880584,-0.018200535,0.00083389954,-0.02136463,-0.012264361,0.002751081,0.023520693,-0.006153181,0.01566646,0.0016590488,-0.030408895,-0.013090385,-0.008554252,0.011270332,0.0037801112,-0.006629195,0.0070387074,-0.001865555,-0.017458513,-0.0068462016,0.0047706403,-0.019614577,0.008862261,0.01563846,-0.010325304,-0.022554664,-0.017290508,-0.008967264,0.017752523,-0.005162652,0.0020125592,0.016324481,-0.0056316657,-0.01122833,-0.013524398,-0.009884291,-0.012187359,0.008974264,0.0066396953,0.00032419706,-0.0048686434,0.012775376,-0.009821289,-0.015778465,0.0060376776,-0.012264361,0.015806464,0.0023695698,0.0028805847,-0.0049736463,-0.023674697,0.004655137,0.009534281,-0.018634548,-0.014182418,-0.018508544,-0.18245336,0.008946263,0.02241466,-0.037857115,0.010913321,0.0011007824,0.028700845,-0.012299362,-0.044101298,0.015694462,0.03494503,-0.013020383,-0.030296892,-0.002618077,-0.0053061564,-0.012985382,-0.008792259,-0.00271608,0.0035596048,0.013741405,0.047713406,-0.020216595,-0.0025970764,0.00713321,-0.017850526,-0.0030380895,0.004389129,0.023044677,0.015372452,-0.03094091,-0.009002265,-0.0034843525,0.017752523,-0.005638666,-0.008575252,-0.003836113,0.004389129,-0.021896645,-0.021154623,-0.0008759008,0.020510605,0.016814495,0.01495244,-0.0016940499,-0.0155684585,0.0027213302,0.02343669,-0.013174388,0.005404159,-0.02884085,0.0023625696,-0.007056208,0.011641343,-0.006517192,0.0020003088,0.0055301627,-0.006310686,-0.019166565,0.0043996293,-0.004679638,0.0021560634,-0.005302656,0.012019354,0.018550547,0.005064649,0.006258184,0.00017609894,0.014784435,-0.040993206,0.009317274,-0.008778258,-0.005211653,-0.0113263335,-0.004882644,0.0020475602,0.03595306,-0.01832654,-0.009562282,0.0032323452,-0.022218654,-0.0085332515,0.018172534,-0.007315215,-0.0017955529,-0.0041476223,-0.0045291334,-0.0005748919,0.037829112,-0.008008236,-0.013440396,0.020622607,-0.0475454,-0.0043961294,-0.014504427,-0.0013414145,0.01832654,0.014308421,-0.021322628,0.01530245,-0.0047426396,0.013629401,0.00025725758,-0.001665174,-0.00033272855,0.0305209,0.003193844,0.0029470867,0.015064443,0.03368499,-0.006349187,-0.026768789,-0.021882644,0.0001883493,0.0039446163,0.014336422,0.028084828,-0.007553222,0.009954293,0.009681285,-0.0067902,0.06602594,0.0019145564,-0.013762405,0.014462425,-0.009135269,-0.022932675,-0.11659543,-0.046397366,-0.004490632,-0.0030118388,-0.008386247,0.024402719,-0.008064237,0.0016179227,-0.02884085,0.03166893,-0.016954498,-0.030044885,0.023898704,0.0019233066,-0.004256125,-0.03262096,0.003160593,-0.0065556928,-0.02787482,0.03326498,-0.012061355,-0.021434631,0.0063316864,-0.020986618,0.012208359,0.0044276305,-0.03371299,-0.008386247,0.0036156063,-0.0069792056,0.010227301,-0.010703315,0.014560428,-0.00020366225,-0.0037871115,-0.023492692,-0.0049736463,-0.010353304,0.0203426,-0.017892526,0.01118633,-0.0036716082,-0.0008684631,-0.0088692615,-0.039481163,-0.02203665,-0.0072452133,0.020636607,0.030072885,-0.021140622,-0.036793083,0.011970352,-0.019502575,0.004459131,0.009562282,-0.0028263333,-0.00339685,0.004693638,0.0046446365,0.012824378,-0.018816553,0.0071752113,-0.009450278,-0.0014140416,0.010836319,-0.029708875,-0.003529854,-0.015736463,0.011487338,-0.020496603,-0.004959646,-0.0032218448,-0.008988265,0.011725346,-0.015820466,-0.013958411,-0.012061355,-0.021140622,0.0053516575,-0.0045046327,-0.005705168,-0.01188635,-0.009135269,-0.014238419,0.018172534,-0.0035806054,-0.025410747,-0.017962528,0.011165328,-0.00849125,0.00060376775,0.032032944,0.010241302,-0.027678816,0.019138563,0.01463043,-0.028224831,-0.0001641767,0.008589253,0.010437307,-0.02748281,-0.007045707,-0.047097385,0.028042825,-0.0031413424,-0.034217007,-0.015554458,-0.005019148,0.008792259,-0.008316245,-0.012551369,0.020160593,-0.016184477,0.0109553225,-0.014406424,-0.0029995884,-0.01726251,-0.012299362,0.018928558,-0.011914351,-0.0035876057,-0.0050471486,0.015372452,-0.0016870496,0.01224336,0.011536339,-0.012383364,0.0008925263,-0.010381306,0.012768376,-0.012040354,-0.013055384,-0.003668108,-0.022190653,0.0034353512,0.023044677,-0.0009100268,0.0012976632,-0.01323039,0.033040974,0.027244803,0.02209265,-0.0033793494,-0.03259296,-0.00064620655,-0.018984558,-0.003629607,-0.010563311,-0.0057016676,-0.0077632284,-0.007427219,-0.001834054,0.02483673,0.006562693,-0.007280214,-0.03967717,0.0065311925,0.020090591,-0.00983529,-0.01799053,-0.006489191,0.0046761376,0.04390529,-0.012334364,-0.004459131,-0.00087021315,0.006716698,-0.008911262,-0.003291847,0.0104863085,0.018466543,-0.0038921146,0.007336216,0.0083652465,-0.002992588,0.017556516,-0.008897262,-0.0204406,0.009485279,0.0018305539,0.0029995884,0.03295697,0.013027384,0.0014542928,-0.009667285,-7.459595e-05,0.0047111386,0.0047426396,-0.01087132,0.008764258,-0.008673255,0.0048091416,0.028812848,0.014042414,-0.014364423,0.011970352,-0.015498457,-0.018746551,-0.0046306364,-0.009548281,0.015442454,0.022596665,-0.007280214,-0.0014254169,-0.0067026974,-0.030212888,-0.025606753,0.023212682,-0.012726375,-0.03774511,-0.0049001444,0.033376984,0.032760963,-0.0020965617,0.0013519148,0.009261273,-0.018284539,0.024234714,-0.011655343,-0.023212682,-0.036177065,0.02004859,0.02583076,0.0010754067,-0.0027090798,-0.0086662555,0.011718345,0.032984972,0.024696726,-0.00949928,0.006247684,0.029484868,0.0005919549,0.0012766626,-0.0050821495,-0.008204241,-0.018172534,-0.025620755,-0.018424543,0.0076932264,0.015120445,0.06871402,0.015876468,-0.008589253,0.019824583,-0.022274656,0.020496603,0.034217007,-0.004620136,-0.02413671,-0.012292362,-0.01222236,0.010297303,-0.014182418,0.0057681696,0.0024868231,0.01730451,-0.008421248,0.0037906116,-0.01800453,0.017850526,0.008526251,-0.0031728435,0.023394689,-0.0026915793,-0.017598517,0.015134445,0.0060621784,0.0067691994,0.0027790817,-0.016226478,0.025746757,0.014126416,-0.02480873,-0.022358658,-0.008253243,0.011921351,-0.0059291744,-0.035085034,-0.0030048385,0.0028945853,-0.006818201,-0.021770641,-0.017598517,0.0034931027,-0.009828289,0.009016265,-0.010269302,-0.019558575,-0.01566646]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency.","formatted":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) .","formatted":"To capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) .","formatted":"In the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) ."}]},"formatted":"More broadly, in generic sequence modeling, how to capture long-term dependency has been a long-standing research problem. From this perspective, since the ubiquitous adaption of LSTM, many efforts have been spent on relieving the vanishing gradient problem, including better initialization (Le et al., 2015), additional loss signal (Trinh et al., 2018) , augmented memory structure (Ke et al., 2018) and others that modify the internal architecture of RNNs to ease the optimization (Wu et al., 2016; Li et al., 2018) . Different from them, our work is based on the Transformer architecture and shows that language modeling as a real-world task benefits from the ability to learn longer-term dependency.\n\nTo capture the long-range context in language modeling, a line of work directly feeds a representation of the wider context into the network as an additional input. Existing works range from ones where context representations are manually defined (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2015) to others that rely on document-level topics learned from data (Dieng et al., 2016; Wang et al., 2017) .\n\nIn the last few years, the field of language modeling has witnessed many significant advances, including but not limited to devising novel architectures to better encode the context (Bengio et al., 2003; Mikolov et al., 2010; Merity et al., 2016; Al-Rfou et al., 2018), improving regularization and optimization algorithms (Gal and Ghahramani, 2016) , speeding up the Softmax computation (Grave et al., 2016a) , and enriching the output distribution family (Yang et al., 2017) ."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
0.7754295851345948
0.759626956848701
0.7416497307966804
0.751715693511988
0.7657340989788354
0.7686125427367183
0.7312186563621873
0.7660137833938183
0.7631793047926545
0.7751530140005469
0.7561796985052651
0.7598908166901983
0.7690830415180846
0.7607972148176289
0.757197123790712
0.7782010123214619
0.7563309197258515
0.7713719123557451
0.7339309814732249
0.7262072609637918
0.7787632906763039
0.7588061090722129
0.7777312284163213
0.8006359581412639
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011959667,0.0045282138,-0.0021572928,-0.014764848,-0.0025092538,0.024528699,-0.015297167,0.017580535,-0.011325788,-0.034488667,0.0047103227,0.015997587,-0.016123662,0.013595147,-0.0030205601,-0.025103044,0.02801679,0.0063703177,-0.011556926,-0.014218521,-0.0036316763,0.017734628,-0.0070427204,-0.03874722,0.007063733,0.03376023,0.027862698,-0.015409235,0.02277765,0.009119465,-0.006020108,0.015297167,-0.03768258,-0.02426254,0.0011924646,-0.00012060352,0.010156087,-0.0009070436,0.0040169074,0.0044091423,0.011150682,0.00652441,0.0013456815,-0.014764848,-0.008033815,-0.008222928,0.015549319,-0.039839875,-0.008033815,-0.013462068,0.010408238,0.02494895,-0.019135468,-0.012663589,-0.01622172,-0.0029645266,-0.0049169464,0.0091825025,0.013665189,-0.014890924,0.021250736,0.018098846,-0.017706612,-0.0014034661,-0.021614954,0.0045142053,-0.02479486,-0.0123343915,-0.014057424,0.0076415795,0.034488667,0.010282162,-0.010100053,-0.025677389,0.034712803,-0.007235336,-0.0035336176,-0.025761439,-0.013910336,0.01631978,-0.0009298072,-0.023408027,-0.015171092,0.020536307,0.012488484,-0.016824082,0.0034985966,0.015549319,-0.013476076,0.0037157268,-0.0039573717,-0.00082737085,0.02032618,0.015241134,0.007760651,-0.0058064796,-0.008622167,0.026027597,0.0011819584,0.009833893,-0.007168796,-0.0036246723,-0.02104061,-0.009798872,-0.014722823,0.0029645266,0.013791265,0.0037367393,0.00587302,-0.013335992,-0.03622571,0.035497274,0.011725026,-0.03813085,-1.9234183e-05,-0.009924948,0.0076415795,-0.017818678,0.0037332373,-0.015941553,0.023674188,0.01448468,0.018056821,-0.00864318,0.0120682325,-0.0065524266,-0.00624074,-0.011626968,-0.017258342,-0.013427046,0.0012204814,0.0106884055,0.0050605326,0.019177493,-0.015087041,0.017412435,-0.014358605,0.013335992,-0.025467262,-0.030566318,0.007697613,0.0052251313,-0.01962576,0.017930746,-0.002024213,0.016039612,0.010989586,0.02626574,0.0170202,0.012985782,0.0021853095,-0.038242918,0.021713013,0.029249528,0.016571932,0.021110652,-0.02950168,-0.009357608,-0.02120871,-0.008124869,-0.007305378,0.013791265,0.005992091,0.018196905,0.010723426,0.010001994,0.014666789,-0.0053512068,0.012523505,0.0042795646,-0.011276758,0.031686988,-0.028857294,0.00051349524,-0.0069726785,0.019443652,0.021236727,-0.0057189274,-0.017496485,-0.025523296,0.017244333,-0.0017510494,0.005032516,0.02494895,-0.019331586,-0.023758238,0.0168521,-0.012229329,0.0052321353,0.0019261544,0.018743232,0.016109655,-0.0018053319,0.004941461,-0.6701616,-0.021895122,0.0038838275,-0.025243128,0.01553531,0.016978174,-0.0020960062,-0.016277755,-0.032583527,0.012460467,-0.021222718,0.0067170253,0.027988773,-0.028913327,-0.007312382,-0.026069622,-0.003011805,-0.033283945,0.009686805,0.0028769742,-0.018659182,0.015941553,-0.019247536,-0.009070436,-0.0015225374,0.028619152,0.0015890773,-0.016824082,0.018743232,0.010142078,-0.009413642,0.03359213,0.005358211,0.015619361,0.043650158,-0.020998584,-0.0070427204,0.01553531,0.00020946928,0.050402205,-0.032975763,-0.011928149,0.004899436,0.0005546449,-0.011171695,0.0037892708,0.022371408,0.0025757935,0.020144071,0.010611359,0.012075236,0.015717419,0.009637776,0.008412041,0.020102046,-0.020480273,0.023113852,-0.011402833,0.011465872,0.008306978,0.012621564,0.0052286335,-0.016992183,-0.0064333556,-0.0071407794,0.0261957,-0.021152677,0.013882319,-0.0046647955,-0.045863487,-0.0068325945,0.017132267,-0.021544911,0.0053862277,-0.011059628,0.025985572,0.015367209,0.016473873,0.017692603,0.01892534,-0.00040493018,-0.030762436,0.0041639954,0.02042424,0.033900317,-0.0007927876,-0.03317188,-0.008839297,-0.00468931,0.0026826076,0.00772563,0.019359602,-0.01658594,-0.01955572,0.0014691304,0.036365792,-0.009819885,0.016571932,-0.016165689,-0.015073033,-0.0023236426,-0.01069541,0.009798872,-0.007277361,-0.010401233,0.0052531483,0.00044367212,0.027778648,0.020060021,-0.020396223,0.010254145,0.019205509,-0.011872115,0.014554722,-0.012327388,-0.0337042,0.040904514,-0.014211517,0.0008190533,-0.0073544076,0.0033865294,0.01278266,0.0077536465,-0.018308973,0.00759255,0.033031795,-0.014316579,-0.031238722,-0.013938353,0.008299974,0.022721617,-0.018266948,0.014295567,-0.0123484,0.017692603,-0.00058747706,-0.0005384477,0.0020697403,0.004248046,-0.022539508,-0.0045282138,0.011276758,0.001558434,0.017930746,-0.025915531,-0.00405543,-0.00802681,0.00807584,-0.005564835,-0.008902335,-0.010842497,-0.021166684,-0.012453463,-0.020368205,0.0053021773,0.008475079,0.015423243,-0.031238722,-0.025817472,-0.027680589,0.0106603885,0.02564937,-0.015661385,0.017566528,-0.015563327,0.0068641137,-0.0016354801,0.034264535,0.007347403,-0.022483474,0.01475084,-0.027848689,0.009602754,0.013160887,-0.0027771643,0.0024987475,0.005071039,-0.013195908,-0.021320777,-0.014890924,0.00086852047,-0.00086282956,0.011675998,-0.00044783088,0.014456663,0.0091264695,0.024598742,0.010905536,-0.01675404,0.035133056,-0.0063317944,0.01191414,-0.01815488,-0.010149082,-0.0005380099,-0.007872718,0.008454067,-0.016641973,0.0024584732,0.015717419,0.016712015,0.019737829,0.00802681,-0.007235336,0.0071092607,-0.018393023,-0.0010987835,-0.014120462,0.019149477,0.014190504,0.026251731,-0.040007975,-0.021278752,-0.006853607,0.011956166,0.009805877,0.00021340915,0.01178106,-0.021516895,0.015619361,-0.035301156,0.00096045056,0.012628568,-0.0002418637,-0.018785257,0.0107024135,-0.003472331,0.019877912,0.014295567,-0.014848899,0.0060481247,0.026952151,-0.0006185582,0.031602938,0.021082634,-0.01807083,0.010415242,0.005953568,0.002194065,0.0024637266,-0.004962474,0.006909641,-0.015143075,0.005704919,0.036001574,-0.009224528,0.0337042,0.019247536,-0.02696616,-0.001561936,-0.011921144,0.009385625,-0.003577394,-0.0091544865,0.00916149,0.004829394,0.014260546,-0.0061566895,-0.0039223507,0.020466264,0.006993691,0.020046012,0.03333998,-0.0122643495,0.027890714,-0.004741842,-0.01239743,-0.03230336,-0.022749633,0.0031711503,-0.0136301685,-0.00046446585,0.00595707,-0.028058816,0.026041606,0.017062224,0.017146276,0.014792865,0.034180485,0.01613767,-0.034096435,-0.026910126,0.01892534,0.0053091818,-0.009000394,0.004892432,-0.022049213,0.0107724555,-0.010282162,0.0074384576,0.02155892,0.017356401,-0.0037997772,-0.004825892,-0.018533107,0.0039293547,0.031350788,-0.011619964,-0.0011583192,-0.0060761413,0.0074034366,0.01962576,-0.0050850473,-0.041688982,0.017076233,-0.03132277,0.031182688,-0.0071933107,-0.016964165,-0.019317577,0.0065454226,-0.025285153,0.02234339,-0.018505089,0.014148479,0.0016923893,0.008096852,-0.017272351,0.030090032,0.018084837,0.005669898,-0.026293756,-0.024206506,0.008874319,0.06376621,0.05264355,-0.005785467,0.01954171,-0.0023323977,-0.007028712,-0.013763248,-0.0054842867,0.006776561,-0.0040659364,-0.010205116,-0.019065425,0.018308973,-0.010898531,0.00510606,0.0077816634,0.018168889,-0.014414638,-0.022721617,-0.039643757,-0.0070357164,0.00759255,0.041296747,0.031995174,0.008902335,0.0063773217,0.028605143,0.01405042,-0.01339903,-0.018308973,0.016025605,0.015787462,0.009707818,0.006037618,0.0028979867,0.0378787,0.00053538335,0.014309576,0.020536307,0.012019203,0.015381218,0.008699213,0.0074664745,-0.0052986755,-0.014792865,-0.0071127624,-0.011283762,-0.0011119164,-0.0014840143,-0.013041816,-0.00021505075,-0.016347798,-0.043846276,-0.008082844,0.011038615,0.0010593849,-0.01763657,-0.008433054,-0.00490644,-0.00036553157,-0.026489874,-0.02382828,-0.0036071618,0.0035896513,0.018168889,-0.016501889,-0.006660992,0.00482239,-0.030398218,-0.008699213,-0.012383421,-0.035805456,-0.019765845,-0.005074541,0.034180485,0.018379014,0.024444649,-0.0070812437,-0.013840294,0.006660992,-0.005141081,-0.0027981768,-0.011402833,-0.0028629657,0.01745446,-0.0074384576,0.0012668843,-0.003234188,-0.005634877,0.0137702525,-0.0012791415,0.007984785,-0.0038733212,-0.020732425,-0.021783054,0.010408238,0.021741029,0.033311963,-0.009910939,-0.025411228,0.00737542,-0.03011805,-0.021096643,-0.009000394,-0.00560686,-0.0063598114,0.0043461043,-0.008068835,-0.010177099,0.00318691,0.031799056,-0.012467472,0.011942157,0.0036316763,0.005501797,0.030342184,0.0013360507,0.009483684,-0.019009393,-0.024206506,0.011283762,-0.02461275,0.0060166055,0.0038032793,-0.0335361,0.012656585,0.01762256,0.006058631,-0.033227913,0.015171092,-0.01356713,0.04818888,-0.016207714,-0.0017519249,-0.016263746,-0.00027097488,-0.01309785,-0.0034740819,-0.012425446,-0.0032762133,0.0065769413,-0.020032005,-0.010485284,-0.009980981,0.003475833,-0.0335361,-0.012488484,0.024234524,0.004790871,0.010667393,0.0028069322,-0.007452466,-0.0057014166,-0.007200315,0.000583975,-0.019653779,-0.0045212093,0.007816684,0.011472875,0.027036203,0.021236727,-0.0077536465,0.016487882,0.010954564,-0.014722823,0.00018758116,0.00081686454,0.02104061,-0.013378018,0.035581324,-0.0035371198,-0.0077046175,-0.014386621,0.007028712,0.026657976,0.007417445,-0.01763657,-0.018617157,-0.029361596,-0.028577127,0.016641973,0.012978778,-0.009000394,-0.0037507478,-0.021755038,0.0026896119,0.002866468,0.0045422222,-0.0017142773,-0.0106603885,0.0060060993,-0.007557529,0.023366002,-0.0022395921,0.018266948,-0.017706612,-0.030594334,-0.028493075,0.010233132,0.03115467,-0.018505089,0.026321774,0.017958762,-0.008671196,0.00397138,-0.0028209405,0.002339402,0.008285966,-0.004731335,-0.01326595,0.016599948,-0.02304381,-0.025733422,-0.007865714,0.00403792,0.012523505,-0.011675998,0.013076836,0.006846603,-0.021376811,0.02025614,-0.0038032793,0.048637148,0.022805667,0.023085834,0.02504701,0.0013491835,0.0037682583,0.0016932647,0.003897836,0.013469072,0.019317577,0.009833893,-0.010261149,-0.021783054,0.0043110834,0.01762256,-0.0246968,-0.017174292,-0.011192707,0.0019716816,0.002516258,-0.0025810467,-0.00829297,0.011907136,-0.0035020988,-0.010968573,0.008454067,0.018042812,-0.011900132,-0.003228935,0.026657976,0.018252939,0.027302362,-0.010268154,0.003090602,0.004125472,0.009385625,0.023520095,0.013511097,-0.020200105,0.02941763,-0.0092105195,-0.0059045386,0.024388615,-0.0053512068,0.01553531,-0.007165294,0.004293573,0.030566318,-0.01475084,0.012124266,-0.0065068994,0.006485887,0.007032214,-0.007340399,-0.001420101,-0.008748243,-0.009714822,0.023534104,0.012628568,0.008285966,-0.03107062,-0.003158893,-0.0021047613,-0.012271354,-0.0012379918,0.0060761413,-0.0011653233,-0.033564113,-0.027246328,-0.008264953,0.016165689,0.03664596,-0.005431755,-0.023632163,0.0120962495,0.01755252,-0.03205121,0.01631978,0.018995384,-0.012628568,-0.019177493,0.011683001,-0.01858914,-0.035945542,0.010751443,-0.017566528,-0.038635153,-0.025327178,0.0016065878,-0.004496695,0.0022255837,-0.022007188,-0.005813484,-0.005599856,0.003402289,0.003479335,-0.025621355,0.01675404,0.009616763,0.0028174384,0.015983578,-0.014225525,0.018533107,-0.020130064,-0.01693615,-0.002237841,-0.044294544,-0.026840085,-0.022399424,-0.008685205,-0.008538117,-0.0022185796,-0.009420645,-0.007098754,-0.014372613,0.0071793026,0.0017773152,-0.00637382,-0.0049484656,0.008986386,0.0036246723,0.012425446,-0.021446852,-0.00815989,-0.0022938747,0.022399424,-0.027512487,-0.014358605,-0.014960966,0.040820464,0.017048217,-0.015171092,-0.006461372,-0.006282765,-0.031378806,0.0023499082,0.004748846,0.0005708421,-0.0076135625,0.0074594705,0.012082241,0.036253728,-0.0032709602,-0.0065524266,0.0029154972,0.010001994,-0.02095656,-0.020003987,0.0059465636,0.0033427533,-0.021082634,0.0026388315,-0.0021100144,-0.015563327,0.022483474,-0.0054457635,-0.01692214,-0.017902728,0.008923348,0.031350788,0.029949948,0.023954356,0.021516895,-0.022707608,-0.0137142185,0.020382214,-0.015143075,-0.014736831,-0.02339402,0.010401233,0.001523413,0.012495488,-0.0024934942,-0.028997378,0.012390425,0.0041009574,-0.005361713,0.003155391,0.02966978,0.033031795,0.014708815,-0.019359602,-0.00403792,0.025593339,-0.023351995,-0.0043320963,0.02216128,-0.029977966,0.0061181667,-0.01623573,-0.019863904,-0.018505089,-0.016039612,-0.011823085,-0.0017492983,-0.004636779,0.014127466,0.019009393,-0.023323977,0.02513106,0.00981288,0.0015846997,-0.018196905,-0.004535218,0.007207319,-0.019597745,0.0036141658,0.005932555,-0.019177493,-0.010604355,0.006632975,0.017300367,0.01798678,0.010716422,0.23175488,-0.0186872,-0.013385021,0.012019203,0.018042812,0.002518009,0.023281952,0.019233527,0.0001499336,0.0106884055,0.009091448,0.019961962,0.004713825,-0.00759255,0.022707608,-0.017510494,-0.022581533,-0.008391028,0.0046647955,0.017762644,0.013994386,-0.009147482,-0.004766356,-0.022553517,0.04294974,-0.011059628,-0.009882922,0.0028244427,0.0060131038,0.0069481637,-0.0075295125,-0.003011805,0.021012593,0.0012493738,-0.014281559,-0.00041521757,0.021699004,-0.008657188,0.012684601,0.0015671892,0.037038196,-0.025004985,-0.0016950158,-0.0121662915,0.012824685,0.022889717,-0.019933946,-0.020368205,0.028114848,0.015549319,-0.01658594,-0.00525665,0.0027754132,0.029025394,0.008356008,-0.009819885,-0.011668993,0.0025075027,0.012320383,-0.019779854,-0.024248531,0.008047823,-0.008433054,0.022721617,-0.0014253542,-0.0015417989,-0.006818586,-0.01007904,0.018126864,-0.015689403,-0.015507293,-0.015395226,-0.007557529,-0.012838694,-0.029473662,-0.015745437,0.029109444,-0.0004276938,0.02279166,0.02896936,-0.020620357,-0.0008545121,-0.0011049121,-0.014372613,-0.009105457,-0.021306768,0.03552529,-0.006142681,-0.0064648744,-0.006888628,-0.016179696,0.014078437,-0.011942157,0.009987986,-0.00095519744,0.00022096054,0.010443258,0.012642576,0.0054107425,0.0011767052,-0.025957556,0.076485835,0.0070392187,-0.0030450749,0.00033685812,0.010205116,0.0021415334,0.023015793,0.0055788434,-0.011318783,0.0019524201,-0.018112855,0.0008321862,-0.021418836,-0.0122223245,0.0028296958,0.02357613,-0.0061321747,0.015647378,0.0016197207,-0.03045425,-0.013027808,-0.008552125,0.011206716,0.0038172877,-0.0066119623,0.007014704,-0.001878876,-0.01728636,-0.0069691767,0.004717327,-0.019765845,0.008867314,0.015521302,-0.010443258,-0.022553517,-0.017328385,-0.008916344,0.017818678,-0.005102558,0.0020487278,0.016109655,-0.00573994,-0.011234732,-0.013413038,-0.009938956,-0.012299371,0.00907744,0.0066504856,0.00038544973,-0.0049134446,0.012789665,-0.00981288,-0.015787462,0.0061461832,-0.012320383,0.015983578,0.0023131361,0.0029277545,-0.004976482,-0.023632163,0.0046402807,0.009497692,-0.018617157,-0.014225525,-0.018477073,-0.18266948,0.008965373,0.02232938,-0.0377106,0.010947561,0.0009919695,0.02871721,-0.012327388,-0.04418248,0.015591344,0.034964953,-0.012922744,-0.03028615,-0.00261957,-0.0053301943,-0.012817682,-0.008797272,-0.0028454552,0.0035703897,0.0137282275,0.047684576,-0.02025614,-0.00255303,0.007063733,-0.017860703,-0.0030293155,0.004395134,0.02304381,0.015311176,-0.030930536,-0.008937356,-0.003405791,0.017818678,-0.005652387,-0.008454067,-0.0039048402,0.0043846276,-0.021909129,-0.021152677,-0.0007735261,0.02032618,0.016796065,0.014988983,-0.0017694354,-0.015479277,0.0025827978,0.023422036,-0.013174895,0.0054457635,-0.028829277,0.0024339587,-0.007095252,0.011661989,-0.0064998954,0.002020711,0.005568337,-0.006349305,-0.019191502,0.0044441633,-0.004608762,0.0021082636,-0.005417747,0.011977178,0.018561123,0.0051620933,0.0062232297,0.00010659513,0.014876915,-0.040904514,0.009357608,-0.008783264,-0.0052321353,-0.01121372,-0.0048854277,0.0021362803,0.035805456,-0.018463064,-0.009483684,0.0033375002,-0.02217529,-0.008622167,0.018210914,-0.007452466,-0.001792199,-0.0042025186,-0.0045422222,-0.00047453438,0.037906718,-0.007991789,-0.013518102,0.020634366,-0.04746044,-0.0044511673,-0.014568731,-0.001456873,0.018379014,0.014225525,-0.02139082,0.015227125,-0.0048504067,0.013609156,0.00027163152,-0.0016442353,-0.00030533923,0.030538302,0.0032446946,0.0029592735,0.01510105,0.0337042,-0.006286267,-0.026770042,-0.021783054,0.00012662276,0.0039608735,0.014344596,0.0281989,-0.0074244495,0.009868914,0.009798872,-0.006769557,0.065951526,0.0019436649,-0.013847298,0.014456663,-0.009070436,-0.022833684,-0.11643778,-0.046367787,-0.0045282138,-0.0030363195,-0.008349003,0.024304565,-0.008047823,0.001666999,-0.02888531,0.031715006,-0.01692214,-0.030090032,0.023926338,0.0018648676,-0.004293573,-0.03272361,0.00305383,-0.006632975,-0.02783468,0.033283945,-0.012117262,-0.021446852,0.006426351,-0.020984575,0.0122643495,0.004353109,-0.033648163,-0.008299974,0.0036631953,-0.0070006954,0.010289166,-0.010597351,0.014610756,1.3803194e-05,-0.0037297353,-0.023520095,-0.0048784236,-0.010394229,0.02034019,-0.017846696,0.011157687,-0.0037402415,-0.00072449667,-0.008867314,-0.03944764,-0.022021197,-0.007207319,0.020732425,0.030146066,-0.021320777,-0.036926128,0.011984182,-0.019513695,0.0044721803,0.0095117,-0.002878725,-0.0034145464,0.004766356,0.004535218,0.012838694,-0.0188553,0.0071232687,-0.00946267,-0.0014586241,0.010849502,-0.029697798,-0.0034863392,-0.015759444,0.011437855,-0.020578332,-0.005067537,-0.003234188,-0.00907744,0.011795068,-0.015619361,-0.014022403,-0.011991186,-0.02104061,0.005435257,-0.0044441633,-0.0056944126,-0.011767052,-0.0091965115,-0.014316579,0.018266948,-0.003656191,-0.025369203,-0.017902728,0.011108657,-0.00842605,0.0006006099,0.031995174,0.010303174,-0.027512487,0.019149477,0.014554722,-0.028310966,-9.7237964e-05,0.008566134,0.0103452,-0.027470462,-0.0070112017,-0.04715226,0.028058816,-0.003125623,-0.03412445,-0.015661385,-0.0050150054,0.008706218,-0.00815989,-0.012453463,0.020214114,-0.01631978,0.01077946,-0.014337592,-0.0031098637,-0.01728636,-0.0122503415,0.018883316,-0.011977178,-0.0036316763,-0.0050500263,0.015255142,-0.0015636871,0.012173295,0.0115149,-0.012320383,0.00097270793,-0.010541317,0.012684601,-0.012089245,-0.013055824,-0.0036842078,-0.02209124,0.003444314,0.023085834,-0.00079322536,0.0012590045,-0.013188904,0.032947745,0.02723232,0.022049213,-0.0034303057,-0.03263956,-0.0006548925,-0.018911334,-0.0036666973,-0.010520305,-0.005750446,-0.007662592,-0.0075365165,-0.0017440452,0.024836885,0.006531414,-0.0072143236,-0.039783843,0.0065874476,0.020144071,-0.009805877,-0.018000787,-0.0065349163,0.0046998165,0.04390231,-0.0121382745,-0.0045527285,-0.00094118906,0.00672403,-0.009035415,-0.003263956,0.010485284,0.018547116,-0.0038418022,0.0074244495,0.00842605,-0.003081847,0.017566528,-0.00899339,-0.020438248,0.009455667,0.0017983277,0.0030065519,0.032919727,0.012908736,0.001399964,-0.00972883,-8.481646e-05,0.00475585,0.0047628544,-0.010716422,0.008650184,-0.00881128,0.0048784236,0.028689193,0.01405042,-0.014372613,0.011879119,-0.015437251,-0.018547116,-0.004612264,-0.009490687,0.015409235,0.022595542,-0.0072843656,-0.0013772004,-0.0068641137,-0.030258134,-0.025523296,0.023141868,-0.012691606,-0.037822668,-0.0048083817,0.033311963,0.032751627,-0.0020767446,0.001421852,0.0092525445,-0.018266948,0.024220515,-0.011542917,-0.023099843,-0.03622571,0.020116055,0.025901522,0.0010847751,-0.0026265741,-0.008594151,0.011668993,0.032975763,0.024668783,-0.009560729,0.0062722587,0.029445646,0.00055420713,0.0012712618,-0.005099056,-0.008222928,-0.018084837,-0.025593339,-0.018266948,0.007690609,0.015213117,0.06869717,0.01588552,-0.008692209,0.019863904,-0.022203306,0.02050829,0.034376603,-0.0046577915,-0.024108447,-0.012299371,-0.012257346,0.010373216,-0.014092445,0.005792471,0.0024514692,0.017356401,-0.008489087,0.0036036596,-0.018042812,0.017790662,0.008503096,-0.0031151169,0.02349208,-0.00277016,-0.01772062,0.015199109,0.0061181667,0.006843101,0.0028191896,-0.016207714,0.025705405,0.014155483,-0.02487891,-0.022231324,-0.008264953,0.01186511,-0.0060096015,-0.034964953,-0.002978535,0.0028367,-0.0067100213,-0.021755038,-0.017524501,0.0033585127,-0.009854906,0.008909339,-0.010450263,-0.01945766,-0.015745437]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011335704,0.0044362433,-0.0021340887,-0.014775807,-0.0025822648,0.024537643,-0.015265999,0.01766094,-0.011358464,-0.03442553,0.004754869,0.016036302,-0.01610633,0.013550325,-0.0029884244,-0.025111869,0.027968992,0.006340992,-0.011505522,-0.014369647,-0.003602916,0.017674947,-0.0070622754,-0.038711213,0.007142807,0.033781275,0.027954986,-0.015448071,0.022884993,0.009180608,-0.0060503776,0.015308016,-0.037702817,-0.024215518,0.0012456145,-0.00015088743,0.010132982,-0.00088453514,0.00409661,0.0044852626,0.011155384,0.006509058,0.0014058024,-0.014789812,-0.00806717,-0.0082912585,0.015490088,-0.039859664,-0.008032157,-0.013501306,0.010371076,0.024915792,-0.01915953,-0.012653973,-0.016316412,-0.003035693,-0.004849406,0.009229627,0.01369038,-0.014901857,0.02127436,0.018123122,-0.017716963,-0.0014390656,-0.021610493,0.004460753,-0.024775736,-0.012324844,-0.014033515,0.0076189945,0.034509562,0.0103080515,-0.010069958,-0.025686095,0.03470564,-0.007254851,-0.0035398912,-0.025756123,-0.013935477,0.016316412,-0.00088541047,-0.023431208,-0.01513995,0.020504057,0.012485907,-0.01691865,0.003468113,0.015490088,-0.013522314,0.003742971,-0.0039810645,-0.00082019734,0.02027997,0.015251994,0.007717033,-0.0058087828,-0.008690415,0.026050238,0.001127443,0.009817858,-0.0071708183,-0.0036239242,-0.021050273,-0.009880884,-0.014789812,0.0029586628,0.013774414,0.00371496,0.0058998186,-0.013347246,-0.036190223,0.035489947,0.011701599,-0.03812298,-5.4380747e-05,-0.009901891,0.0076189945,-0.017857017,0.0037359681,-0.016008291,0.023697313,0.01445368,0.018067101,-0.008641396,0.012107759,-0.006519562,-0.00618343,-0.011596558,-0.017184753,-0.013396265,0.0012464898,0.010714211,0.0051190117,0.01918754,-0.015083928,0.017422847,-0.014355642,0.01333324,-0.025433995,-0.030531999,0.007703027,0.00521705,-0.019621711,0.017955055,-0.0020640611,0.016036302,0.010994321,0.026302338,0.016988676,0.01300411,0.0021078284,-0.038263038,0.021750549,0.029299514,0.016540501,0.021022262,-0.029523604,-0.009292652,-0.021260355,-0.008144201,-0.0073108734,0.013837438,0.005983852,0.018277183,0.010728216,0.010020938,0.014649757,-0.005248563,0.012485907,0.0042786817,-0.0112814335,0.03173647,-0.028823327,0.00047618715,-0.007037766,0.019383619,0.021218339,-0.0057002404,-0.017534891,-0.025490018,0.017296799,-0.001753314,0.005076995,0.02501383,-0.019383619,-0.023781346,0.01691865,-0.012282827,0.0052380585,0.0018872417,0.018739365,0.016120335,-0.001852228,0.0050139707,-0.6700233,-0.021848587,0.003865519,-0.025335956,0.015448071,0.017016688,-0.0020167925,-0.016260391,-0.032660834,0.012387868,-0.021162316,0.0067996723,0.02803902,-0.02887935,-0.0072688567,-0.026092254,-0.0030619532,-0.033249065,0.009649793,0.0028658763,-0.018739365,0.015938263,-0.019229557,-0.009054558,-0.001557237,0.028641256,0.0016596522,-0.016862627,0.018809391,0.01012598,-0.009376685,0.033697244,0.0053956206,0.015630143,0.04366916,-0.021064278,-0.007020259,0.015616138,0.00013469356,0.050391804,-0.033024978,-0.011904678,0.004887921,0.00047268576,-0.011183395,0.0037324668,0.022380795,0.0025455004,0.020181932,0.010679197,0.012065742,0.015742186,0.009621781,0.008480333,0.020111904,-0.020448036,0.023151098,-0.011442496,0.011421489,0.008263247,0.012632965,0.005213549,-0.017114727,-0.0064495346,-0.0071918266,0.026274325,-0.021134306,0.013907466,-0.004674337,-0.045769986,-0.006852193,0.017170748,-0.021512454,0.005353604,-0.011078354,0.025966205,0.015350033,0.016456468,0.01778699,0.018907432,-0.000436359,-0.030784098,0.0041946485,0.020434031,0.03386531,-0.0006967738,-0.033221055,-0.008837474,-0.004702348,0.0026873061,0.007745044,0.019383619,-0.016526494,-0.0195937,0.0015152205,0.03641431,-0.009880884,0.016568512,-0.016204368,-0.015111939,-0.0023774344,-0.010791241,0.009754834,-0.0072478484,-0.010385081,0.0052065463,0.000492381,0.027856948,0.020041876,-0.020392014,0.010266035,0.019201547,-0.011841654,0.014551719,-0.012268822,-0.033725254,0.04084005,-0.014292617,0.0008679036,-0.007373898,0.003366573,0.012794028,0.007731038,-0.018403232,0.007576978,0.033024978,-0.014292617,-0.031204263,-0.013949482,0.0083963,0.022758944,-0.018249173,0.014278611,-0.012310838,0.017716963,-0.0005952339,-0.00056634756,0.0020623105,0.0042051524,-0.022534857,-0.0045482875,0.0112814335,0.0015432315,0.017997073,-0.025924189,-0.004079103,-0.0079901405,0.008158206,-0.0054516424,-0.008823467,-0.010819252,-0.021232344,-0.012471901,-0.020335993,0.0053220917,0.008438316,0.015406054,-0.031232275,-0.02582615,-0.027674876,0.010679197,0.025658084,-0.015630143,0.017548896,-0.015560115,0.0068767024,-0.0016955413,0.034285475,0.0073108734,-0.022450823,0.0148038175,-0.027842943,0.009600773,0.013144165,-0.0027240706,0.0025122373,0.0050419816,-0.013179179,-0.021316377,-0.0148738455,0.0008573995,-0.0008350782,0.011673587,-0.0004302316,0.014481692,0.009103578,0.024635682,0.01088928,-0.016736578,0.035069782,-0.006351496,0.011953698,-0.018109117,-0.010217016,-0.0004993838,-0.00791311,0.008452321,-0.016680555,0.0024947305,0.015714176,0.016722571,0.019705744,0.008018151,-0.007240846,0.007142807,-0.018389227,-0.0010854265,-0.014089537,0.01906149,0.014187575,0.02628833,-0.04002773,-0.021330383,-0.0068697,0.0119607,0.009887886,0.00015241928,0.011862662,-0.021540465,0.015588126,-0.035349894,0.00097163185,0.012527923,-0.00022157145,-0.018669337,0.010728216,-0.003450606,0.019943837,0.01429962,-0.014887851,0.0060503776,0.026988607,-0.0005790401,0.03159642,0.021050273,-0.018081106,0.010364073,0.0059348326,0.00213759,0.002445711,-0.0049509457,0.0070447684,-0.015083928,0.0056827334,0.035966136,-0.009201616,0.033725254,0.019215552,-0.026974602,-0.0015896247,-0.0119607,0.009453716,-0.0035854091,-0.009047556,0.009180608,0.0048283977,0.014278611,-0.006165923,-0.0038970315,0.020462042,0.0069852453,0.019943837,0.03338912,-0.012268822,0.027940981,-0.0047058496,-0.012422882,-0.032352716,-0.022702923,0.003119726,-0.0136343585,-0.00040878565,0.0058998186,-0.02806703,0.026064243,0.01710072,0.017156743,0.014775807,0.034229454,0.016176358,-0.034089398,-0.026960596,0.018935442,0.005325593,-0.008970525,0.0049579483,-0.02205867,0.010721213,-0.0102380235,0.0074719363,0.02149845,0.017324809,-0.0038375081,-0.0048283977,-0.018487265,0.0039355466,0.03140034,-0.01160356,-0.0011922185,-0.0061028986,0.007394906,0.019635716,-0.0050980034,-0.041792426,0.017114727,-0.03137233,0.031176252,-0.00714981,-0.016904643,-0.019299585,0.0065720826,-0.02526593,0.02233878,-0.018487265,0.014138556,0.0017314304,0.008130196,-0.017212765,0.030083822,0.018179145,0.0056757308,-0.02628833,-0.024243528,0.008872487,0.06375305,0.052744728,-0.00580178,0.019565688,-0.002379185,-0.0070972894,-0.013732397,-0.0054866564,0.006778664,-0.0040931087,-0.010224018,-0.019075496,0.018319199,-0.010952304,0.005108508,0.0077520465,0.01819315,-0.014306623,-0.0226469,-0.039635576,-0.007030763,0.007548967,0.041260216,0.031988572,0.008865484,0.0064040166,0.02859924,0.014012507,-0.013368254,-0.018249173,0.016050307,0.015770197,0.009775842,0.0059558405,0.0030041807,0.037842873,0.00051207625,0.014334634,0.020616103,0.0119607,0.015392049,0.008760443,0.007394906,-0.0052695707,-0.014789812,-0.007055273,-0.011379472,-0.0010320306,-0.0015397301,-0.013067136,-0.00027070014,-0.016316412,-0.043837227,-0.008053165,0.011113368,0.0011291938,-0.017730968,-0.008466328,-0.004926436,-0.00026982478,-0.026484407,-0.023795351,-0.0035223842,0.00361342,0.018207155,-0.016554506,-0.006628105,0.004831899,-0.030335922,-0.00867641,-0.012464899,-0.03582608,-0.019789778,-0.0051715323,0.034117408,0.018375222,0.024369577,-0.0071393056,-0.013795421,0.0066140993,-0.0051015047,-0.002883383,-0.011456503,-0.0029043914,0.017408842,-0.0074439254,0.001203598,-0.0032282688,-0.0056092045,0.013732397,-0.0011957199,0.007976134,-0.0038515136,-0.020742152,-0.021792565,0.01040609,0.021722537,0.0333331,-0.009880884,-0.025363969,0.0073528895,-0.030083822,-0.021106295,-0.008984531,-0.0056232098,-0.0063094795,0.0043977285,-0.008088179,-0.010167996,0.0032247673,0.031876527,-0.012513918,0.011911681,0.0036239242,0.0055741905,0.030335922,0.0013742901,0.009509738,-0.01900547,-0.024285544,0.0112814335,-0.02457966,0.0060678846,0.003865519,-0.033501167,0.0125559345,0.01760492,0.0061134025,-0.033249065,0.015181966,-0.0136343585,0.048206944,-0.016218374,-0.0018154635,-0.016274396,-0.00028733167,-0.013151169,-0.0034978746,-0.012436887,-0.0032387727,0.0065860883,-0.020055883,-0.010476117,-0.009985925,0.0034593595,-0.033557188,-0.012478904,0.024257533,0.0047653727,0.010728216,0.002760835,-0.0074159144,-0.0056967386,-0.007289865,0.0004704974,-0.019635716,-0.0045027696,0.007843083,0.011463505,0.027002612,0.021190329,-0.0076960246,0.016442463,0.010973313,-0.014705779,0.00013097335,0.00080093974,0.021078283,-0.013389262,0.035630003,-0.0034471047,-0.007689022,-0.01445368,0.0070622754,0.026582448,0.00742992,-0.017674947,-0.018655332,-0.029411558,-0.028669268,0.01663854,0.012983102,-0.008977528,-0.0036344284,-0.021694526,0.0026855555,0.0029166462,0.0045027696,-0.0017130482,-0.010665191,0.0060398737,-0.0075839804,0.023347175,-0.002200615,0.018235166,-0.017772986,-0.030588022,-0.028571228,0.010315054,0.031148242,-0.018543288,0.026358359,0.017969063,-0.008655402,0.003967059,-0.0028186077,0.0024036947,0.008298261,-0.004796885,-0.0132632125,0.016582517,-0.023039054,-0.025742117,-0.007794063,0.0041106157,0.01249291,-0.011687594,0.013109152,0.0069432287,-0.0213724,0.020293975,-0.0037604778,0.048739154,0.022800962,0.023095077,0.025097864,0.0013699133,0.0037744835,0.001661403,0.003956555,0.013459289,0.01928558,0.009838867,-0.010315054,-0.021862593,0.004320698,0.01766094,-0.02476173,-0.017212765,-0.011204403,0.0019992858,0.002429955,-0.0025910183,-0.00831927,0.011876668,-0.0034838691,-0.0109803155,0.008375292,0.018109117,-0.011904678,-0.0032002577,0.02666648,0.01822116,0.027310733,-0.010294045,0.0030024298,0.0041281222,0.009397693,0.023529246,0.013522314,-0.020223947,0.029411558,-0.009166602,-0.0059138243,0.024439605,-0.0054061245,0.015518099,-0.0072478484,0.0042226594,0.030503988,-0.01473379,0.012065742,-0.0065860883,0.0064670416,0.0070797824,-0.007366895,-0.0014268107,-0.008781451,-0.0096708005,0.023543252,0.012681984,0.008235237,-0.030980175,-0.0031004685,-0.002071064,-0.012282827,-0.0012464898,0.006116904,-0.001096806,-0.033557188,-0.027254712,-0.008305264,0.016260391,0.036638398,-0.0054866564,-0.023599274,0.012093753,0.017548896,-0.032044593,0.016316412,0.019019475,-0.012632965,-0.01915953,0.011708601,-0.018543288,-0.03591011,0.010770232,-0.017492875,-0.038683202,-0.02539198,0.0016473974,-0.004562293,0.0022356287,-0.022030657,-0.005906821,-0.0056197084,0.0033998361,0.0035048774,-0.025560046,0.016750583,0.0096357865,0.0028588735,0.015980281,-0.014271609,0.01850127,-0.020139916,-0.016890638,-0.0022373793,-0.044313416,-0.026890568,-0.022408806,-0.008704421,-0.008564366,-0.0021901107,-0.00943971,-0.0071077934,-0.014425669,0.007261854,0.0017209264,-0.0063830083,-0.0049789567,0.008970525,0.003602916,0.012478904,-0.02140041,-0.008158206,-0.0023301658,0.022422813,-0.0274788,-0.014383653,-0.014901857,0.040812038,0.017142737,-0.015167961,-0.0064320276,-0.006351496,-0.031456362,0.0023424206,0.004814392,0.0005768517,-0.0076400023,0.0075069503,0.012037731,0.036218233,-0.0032895429,-0.0065790857,0.002883383,0.009943908,-0.020994252,-0.020097898,0.005997857,0.0032965455,-0.021148311,0.0026365363,-0.002104327,-0.015560115,0.022450823,-0.0054341354,-0.01697467,-0.017927045,0.008872487,0.03137233,0.030027801,0.023963418,0.02152646,-0.022786954,-0.013746402,0.020406019,-0.015167961,-0.014817824,-0.023375187,0.01040609,0.0015686165,0.012499913,-0.0024894783,-0.029019404,0.012443891,0.0041386266,-0.005297582,0.0031547397,0.029551614,0.032940947,0.01473379,-0.019411629,-0.00401958,0.02554604,-0.023235131,-0.0043312022,0.022198724,-0.029943768,0.006025868,-0.016204368,-0.019817788,-0.018571299,-0.016036302,-0.011799637,-0.0017822004,-0.004628819,0.014089537,0.019019475,-0.023375187,0.025153885,0.009824861,0.0015887494,-0.018291188,-0.004562293,0.007177821,-0.019523673,0.0036379297,0.005892816,-0.019173535,-0.010567153,0.0066316063,0.01722677,0.01794105,0.010770232,0.23148297,-0.01872536,-0.013361251,0.011988712,0.017955055,0.0025735113,0.023305159,0.019243563,0.00020472109,0.010672194,0.009068564,0.019985855,0.0046848413,-0.0076049888,0.02277295,-0.017478868,-0.022562867,-0.008375292,0.0046428246,0.01778699,0.013963488,-0.009166602,-0.0048073893,-0.022576872,0.042968888,-0.011113368,-0.009880884,0.0028378654,0.0060223667,0.006953733,-0.0074649337,-0.003091715,0.021078283,0.001234235,-0.014369647,-0.0004048466,0.021638503,-0.00867641,0.012611956,0.0014653258,0.037114587,-0.025027836,-0.001717425,-0.012079747,0.012766017,0.022856982,-0.019915827,-0.020392014,0.028165068,0.0155461095,-0.016582517,-0.0052835764,0.0027590843,0.029019404,0.00834728,-0.009838867,-0.011638574,0.0025122373,0.012408877,-0.019831793,-0.0241735,0.008074173,-0.008466328,0.022702923,-0.0014075532,-0.0015239739,-0.006761157,-0.010160993,0.01816514,-0.015728181,-0.015490088,-0.015392049,-0.0076119914,-0.012906072,-0.029523604,-0.015756192,0.029131448,-0.0004195086,0.022786954,0.029019404,-0.02058809,-0.00080881786,-0.001142324,-0.014369647,-0.009054558,-0.021260355,0.035601992,-0.006155419,-0.006509058,-0.006890708,-0.016204368,0.014124551,-0.011925687,0.009978922,-0.00089503924,0.00024400215,0.010462112,0.0125559345,0.0054411385,0.0012097254,-0.02598021,0.076358005,0.007009755,-0.0030724574,0.00034138418,0.010182002,0.0021638505,0.023095077,0.0055811936,-0.011365467,0.0020167925,-0.018095111,0.00086396455,-0.021316377,-0.0122198025,0.0028238597,0.023571264,-0.0062219454,0.01570017,0.001671907,-0.030419955,-0.013074138,-0.008501341,0.011190398,0.003798993,-0.0065895896,0.007020259,-0.0018784882,-0.017254781,-0.007009755,0.004709351,-0.019761767,0.00883047,0.015518099,-0.010462112,-0.022520851,-0.01738083,-0.008914503,0.01788503,-0.0051435214,0.002071064,0.016176358,-0.005766766,-0.011253423,-0.013417273,-0.009915897,-0.012310838,0.009068564,0.006656116,0.00034094648,-0.004880918,0.012787025,-0.009880884,-0.015812214,0.0062184436,-0.0122548165,0.015952269,0.0023214123,0.0028886353,-0.0049929623,-0.02358527,0.004695345,0.009509738,-0.018641327,-0.014159565,-0.018571299,-0.18263178,0.009005539,0.02233878,-0.037730828,0.0109453015,0.0009952661,0.028739294,-0.012324844,-0.04422938,0.015686166,0.034957737,-0.012941086,-0.030251889,-0.0026575443,-0.005325593,-0.012836045,-0.00883047,-0.002867627,0.003513631,0.013809427,0.047646724,-0.020265965,-0.002547251,0.0070902864,-0.017871024,-0.0030321917,0.0043907254,0.023095077,0.015251994,-0.030868132,-0.008907501,-0.0034943733,0.01788503,-0.0057422565,-0.008501341,-0.0038760232,0.0043312022,-0.021904608,-0.0211203,-0.00080093974,0.020335993,0.016862627,0.014929867,-0.001801458,-0.015560115,0.0025665087,0.023515241,-0.013242204,0.0054726508,-0.028823327,0.0023984425,-0.007058774,0.011687594,-0.0065755844,0.0020290473,0.0055006617,-0.006351496,-0.01915953,0.004366216,-0.004628819,0.002116582,-0.0054061245,0.011988712,0.018571299,0.0051715323,0.006197436,8.414244e-05,0.014915862,-0.040924083,0.009285649,-0.008795457,-0.0052275546,-0.011218409,-0.0048354003,0.0021183325,0.035938125,-0.01850127,-0.009495731,0.0033543182,-0.02211469,-0.008634393,0.018277183,-0.0074369228,-0.0017541894,-0.004180643,-0.004583301,-0.00048537826,0.037982926,-0.007941121,-0.013522314,0.020658119,-0.04747866,-0.0045307805,-0.014593735,-0.0014688272,0.018347211,0.014236595,-0.021470439,0.015251994,-0.004726858,0.013620352,0.00030308787,-0.0016517742,-0.00025975832,0.030616032,0.0032790387,0.0029131449,0.015167961,0.033669233,-0.006333989,-0.026694492,-0.021750549,5.6022018e-05,0.0039250427,0.014439675,0.02809504,-0.0074369228,0.009978922,0.009880884,-0.0067891683,0.065993935,0.0019240062,-0.013802424,0.014481692,-0.0090335505,-0.022913005,-0.11663784,-0.04635822,-0.004562293,-0.0030496984,-0.008312266,0.024327561,-0.008074173,0.0016561509,-0.02887935,0.031792495,-0.016960666,-0.030111834,0.023949413,0.0018732361,-0.00427518,-0.03277288,0.0031039699,-0.0066035953,-0.027842943,0.03327708,-0.012072745,-0.021470439,0.0063830083,-0.021008257,0.01228983,0.004355712,-0.03361321,-0.008389297,0.0036484338,-0.0069887466,0.010231021,-0.010616172,0.014621747,4.8718364e-05,-0.0037849876,-0.023431208,-0.004887921,-0.010357071,0.020364003,-0.017955055,0.011260426,-0.0037394697,-0.0006967738,-0.0089285085,-0.03946751,-0.022030657,-0.0072198375,0.020826185,0.030139845,-0.021330383,-0.03700254,0.011974706,-0.019481657,0.0044467477,0.009544751,-0.0029078927,-0.0034138416,0.004814392,0.004551789,0.012864055,-0.018851409,0.0070797824,-0.009453716,-0.001495963,0.010826254,-0.029747691,-0.0034523567,-0.015756192,0.011393477,-0.02058809,-0.0050804964,-0.0032527784,-0.009012542,0.011813642,-0.015560115,-0.014033515,-0.012002717,-0.021050273,0.0054726508,-0.0044712573,-0.0056687277,-0.011785632,-0.00923663,-0.01429962,0.018291188,-0.0037604778,-0.025405984,-0.01788503,0.011071351,-0.008410305,0.00056022016,0.032072604,0.010315054,-0.027534822,0.019131519,0.014551719,-0.02831913,-3.939048e-05,0.008501341,0.010427098,-0.027436784,-0.007114796,-0.04717054,0.028053025,-0.0030251888,-0.034117408,-0.015658153,-0.0049964637,0.008746438,-0.008116189,-0.012485907,0.020153921,-0.016372435,0.010749225,-0.014285614,-0.0030934657,-0.017296799,-0.012170783,0.018851409,-0.011925687,-0.0036659406,-0.005112009,0.015336027,-0.0015869987,0.012198794,0.011470508,-0.012359858,0.0010285293,-0.010504128,0.012688987,-0.012121764,-0.013060133,-0.0036764448,-0.022100685,0.0034996253,0.02317911,-0.00077161577,0.0012832544,-0.013221196,0.032968957,0.027338743,0.022100685,-0.0034488554,-0.032604814,-0.00066832517,-0.018977458,-0.0036659406,-0.0106091695,-0.0058052815,-0.007682019,-0.0075279586,-0.0017366825,0.024775736,0.006533568,-0.007261854,-0.039775632,0.006645612,0.020167926,-0.00979685,-0.01794105,-0.0064775455,0.004730359,0.043865237,-0.012135769,-0.004513274,-0.0010040196,0.006740149,-0.009075567,-0.0031845015,0.010490122,0.01844525,-0.0038200011,0.0074369228,0.008438316,-0.0030724574,0.01766094,-0.009005539,-0.020448036,0.009432707,0.0018347211,0.0030409452,0.03285691,0.012843047,0.0014110545,-0.009754834,-1.1844499e-05,0.004730359,0.0047933836,-0.010742222,0.008746438,-0.008816465,0.0048354003,0.028711284,0.014033515,-0.014425669,0.011813642,-0.015462076,-0.018529283,-0.004509772,-0.009474724,0.015378044,0.022632895,-0.007317876,-0.0013961737,-0.0068206806,-0.0302799,-0.025602061,0.023123087,-0.012625962,-0.037814863,-0.0048178933,0.03330509,0.03280089,-0.0020570585,0.0014854588,0.009222625,-0.018277183,0.024229523,-0.011561544,-0.023151098,-0.036218233,0.020125909,0.0259522,0.0010206511,-0.0026120266,-0.008606383,0.011673587,0.032968957,0.024677698,-0.009544751,0.0062499563,0.029551614,0.000548403,0.001277127,-0.005108508,-0.0082562445,-0.018123122,-0.025602061,-0.018347211,0.0077240355,0.015167961,0.06868299,0.015924258,-0.008634393,0.019915827,-0.022240741,0.020476047,0.034397516,-0.0046673343,-0.024187505,-0.0122198025,-0.01236686,0.010364073,-0.014075532,0.0057422565,0.0024387084,0.017268786,-0.008445319,0.0034943733,-0.018025083,0.017829007,0.008466328,-0.0030794602,0.023473226,-0.002738076,-0.017716963,0.015181966,0.006078389,0.006834686,0.0028151064,-0.016176358,0.02572811,0.014229592,-0.024831759,-0.022184718,-0.0082562445,0.011855659,-0.005969846,-0.034957737,-0.00295166,0.0028483693,-0.006684127,-0.02177856,-0.017436853,0.0033035483,-0.009852872,0.008977528,-0.01048312,-0.019551683,-0.015714176]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019). Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation.","formatted":"Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019). Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.","formatted":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways. First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment. Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia). In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness. Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining. The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition. Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small. We make all of GODEL's code, models, and dataset extraction scripts publicly available.","formatted":"In this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways. First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment. Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia). In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness. Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining. The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition. Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small. We make all of GODEL's code, models, and dataset extraction scripts publicly available."}]},"question":"How does the model extend previous work and models?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
0.724446510254436
0.7771105329381329
0.7699247786793604
0.7261565279679434
0.7857601452791815
0.7667024830274689
0.759104277481031
0.7583488589872083
0.7657538290006285
0.7771990109448826
0.7571330827691789
0.7842569206409334
0.7536704089187641
0.7441722175928785
0.7591334933013004
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019). Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation.","formatted":"Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019). Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.","formatted":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways. First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment. Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia). In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness. Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining. The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition. Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small. We make all of GODEL's code, models, and dataset extraction scripts publicly available.","formatted":"In this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways. First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment. Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia). In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness. Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining. The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition. Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small. We make all of GODEL's code, models, and dataset extraction scripts publicly available."}]},"formatted":"Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019). Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation.\n\nLarge pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.\n\nIn this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways. First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment. Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia). In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness. Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining. The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition. Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small. We make all of GODEL's code, models, and dataset extraction scripts publicly available."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
0.7610189878959635
0.7713918337860233
0.7869388964438856
0.7406321484113876
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011766687,0.0045420816,-0.002137965,-0.014764391,-0.002526686,0.024555955,-0.015310702,0.01765003,-0.011318432,-0.034459583,0.0047276868,0.016025107,-0.016123163,0.013594726,-0.0030117116,-0.025074251,0.028015923,0.0063876305,-0.011605596,-0.014267108,-0.003652576,0.017706063,-0.0070460043,-0.038774036,0.00709153,0.033759188,0.027875843,-0.015408757,0.02280496,0.009119183,-0.0060199215,0.015310702,-0.037681416,-0.024233773,0.0012274476,-0.00014161173,0.01013476,-0.0008820638,0.004062309,0.004423014,0.011101309,0.0065207058,0.0013578967,-0.014750383,-0.007977534,-0.008250689,0.015562844,-0.039894674,-0.008019558,-0.013426631,0.010379899,0.024962187,-0.019162891,-0.012649189,-0.01627725,-0.0030047076,-0.0048642643,0.009217238,0.013664766,-0.014890463,0.02123607,0.01814031,-0.017720072,-0.0014594544,-0.021628292,0.0045105633,-0.024780083,-0.01229899,-0.014063993,0.007648347,0.0344876,0.010260832,-0.010085732,-0.0256906,0.034711726,-0.007200092,-0.003542263,-0.025760641,-0.013944926,0.016333282,-0.000914895,-0.023435319,-0.015170622,0.020521663,0.012488097,-0.016893601,0.0034879823,0.015520821,-0.013503674,0.0037156118,-0.003988767,-0.0008553611,0.020353567,0.01525467,0.0077604107,-0.005827312,-0.008628904,0.026054807,0.0011477773,0.009833588,-0.0071615702,-0.0036455719,-0.021039957,-0.009847596,-0.014708359,0.002924162,0.0138048455,0.0037576356,0.0058973515,-0.013349587,-0.03622459,0.035440143,0.011689643,-0.03812967,-2.968484e-05,-0.009903628,0.0076693585,-0.01786015,0.0037121098,-0.015997091,0.023617422,0.014470224,0.01807027,-0.008649916,0.012102879,-0.0065137018,-0.0062125307,-0.011661627,-0.017229792,-0.013405619,0.0011644118,0.010730098,0.005098898,0.019190907,-0.015058558,0.017411895,-0.014372168,0.013293555,-0.025466474,-0.030565372,0.0076973746,0.0051899496,-0.01958313,0.017944198,-0.0020661743,0.016053123,0.010947222,0.02625092,0.01697765,0.013062424,0.0021292102,-0.03826975,0.02178238,0.02927664,0.016543401,0.021067973,-0.029500766,-0.009315294,-0.02122206,-0.008117613,-0.007333168,0.013769826,0.0059533836,0.01821035,0.010723094,0.010036704,0.014680344,-0.005312519,0.0125371255,0.004300444,-0.011262401,0.031686008,-0.028828384,0.00047714618,-0.0069864704,0.019387018,0.021250077,-0.0056837304,-0.017481936,-0.025508497,0.017215785,-0.0017256057,0.005035862,0.024920164,-0.019316979,-0.023757502,0.016837569,-0.012249962,0.0051969537,0.0019383517,0.018742653,0.016151179,-0.001805276,0.004990336,-0.67014086,-0.021880435,0.0038591933,-0.025256354,0.015450781,0.016991656,-0.0020819332,-0.016305266,-0.03263855,0.012369029,-0.021208053,0.0067553394,0.02802993,-0.028884416,-0.0072701317,-0.026124848,-0.0030327237,-0.0332549,0.009686505,0.002855873,-0.018714637,0.01594106,-0.019246938,-0.009056147,-0.0015154863,0.028646281,0.001622297,-0.016781537,0.018784676,0.010113748,-0.009357318,0.033675138,0.005389563,0.0156048685,0.043592773,-0.020955909,-0.0070144865,0.0155768525,0.00016218593,0.050400645,-0.03303077,-0.011927779,0.0048642643,0.00051085284,-0.011234385,0.0037646396,0.022384722,0.002549449,0.020115431,0.010639046,0.012060855,0.01573094,0.009630473,0.008411781,0.020073408,-0.020493647,0.023183176,-0.011416488,0.011500536,0.008313725,0.012628177,0.0052319732,-0.017047688,-0.006450666,-0.007147562,0.026222903,-0.021180037,0.013839866,-0.004650643,-0.04589008,-0.006860399,0.017131737,-0.021558251,0.005417579,-0.011059285,0.026012784,0.015310702,0.016501378,0.017748088,0.018910747,-0.0004084196,-0.030761482,0.0041848784,0.020409599,0.033843234,-0.00075424113,-0.033170853,-0.008888051,-0.004689165,0.0026930305,0.0077253906,0.01937301,-0.016613442,-0.019527098,0.0014699604,0.0364207,-0.009875612,0.016599433,-0.01620721,-0.01511459,-0.0023708474,-0.0107651185,0.009756545,-0.0072911438,-0.010358887,0.0052249697,0.00048765214,0.027763778,0.020045392,-0.020381583,0.010253827,0.019218924,-0.011850735,0.0145822875,-0.01229899,-0.033703156,0.040903248,-0.0142531,0.0008400399,-0.0073471754,0.0033916775,0.012726232,0.0077534067,-0.018322414,0.007641343,0.03305879,-0.014274112,-0.031209737,-0.013958933,0.008320729,0.022720912,-0.018280389,0.01428812,-0.012305994,0.017706063,-0.00059796486,-0.00055156345,0.0020381582,0.00418838,-0.022566825,-0.0045665954,0.011304425,0.0015548837,0.017958207,-0.025914729,-0.004055305,-0.008033565,0.008096602,-0.005466607,-0.008860036,-0.010842162,-0.021180037,-0.012418058,-0.020353567,0.005319523,0.0084468005,0.015380741,-0.031181721,-0.025816672,-0.027707746,0.010646051,0.025620561,-0.015646892,0.017551975,-0.015562844,0.006877909,-0.00162755,0.03420744,0.0073611834,-0.022454761,0.014750383,-0.02783382,0.009602457,0.013132463,-0.002803343,0.002521433,0.005042866,-0.013188495,-0.021320118,-0.014862447,0.0008540479,-0.0008330359,0.011689643,-0.00044059416,0.014526255,0.009140194,0.024583971,0.010898193,-0.016725505,0.035075936,-0.0063105864,0.011962798,-0.01814031,-0.0102047995,-0.00051304157,-0.007823446,0.008516841,-0.016655466,0.002458397,0.015716933,0.016669475,0.019751225,0.008054578,-0.0072561237,0.00709153,-0.01840646,-0.0010917454,-0.014085005,0.019134875,0.014190065,0.026264926,-0.04006277,-0.021278093,-0.0068744067,0.011983811,0.009847596,0.00018144687,0.011808711,-0.021488212,0.015632885,-0.035356093,0.0009963162,0.0125511335,-0.00029022744,-0.018728644,0.010730098,-0.0034862314,0.019905312,0.0143231405,-0.014848439,0.006061945,0.026965326,-0.0005804549,0.031629976,0.021067973,-0.018042253,0.010386903,0.0059113596,0.0021362142,0.002475907,-0.004930802,0.0069619566,-0.01511459,0.0057047424,0.03594443,-0.009245254,0.033759188,0.019246938,-0.027035365,-0.0015750201,-0.011920775,0.009427357,-0.0035772831,-0.009133191,0.00916821,0.0048082327,0.014267108,-0.006170507,-0.003943241,0.02047964,0.0069934744,0.020017376,0.033366963,-0.012235954,0.027847826,-0.004752201,-0.012383037,-0.032330375,-0.022720912,0.0032060721,-0.013615739,-0.0003983514,0.0059323716,-0.02802993,0.026026791,0.017089713,0.017131737,0.014736375,0.03420744,0.016193204,-0.034095377,-0.026895285,0.018938763,0.005298511,-0.008986107,0.0049062883,-0.022034522,0.010744106,-0.010309859,0.0074452315,0.021544244,0.017355863,-0.0037681416,-0.0048257424,-0.018518524,0.003939739,0.031377833,-0.011591588,-0.0011722912,-0.006082957,0.0073891995,0.019667177,-0.0050953957,-0.04177174,0.017089713,-0.031349815,0.031153705,-0.007147562,-0.016935624,-0.01930297,0.0065522236,-0.025256354,0.022370715,-0.018504517,0.014162049,0.0017098468,0.008117613,-0.0172438,0.0300891,0.01814031,0.0057047424,-0.02625092,-0.02424778,0.008902059,0.06370821,0.05269795,-0.005785288,0.019527098,-0.0023480845,-0.0070740203,-0.0137908375,-0.005466607,0.006776351,-0.004041297,-0.010176783,-0.01910686,0.01835043,-0.010898193,0.005165436,0.0077323946,0.018182334,-0.014386176,-0.022636864,-0.039614514,-0.0070635146,0.007529279,0.0413515,0.03196617,0.008930075,0.0063841282,0.028604256,0.014014965,-0.013398615,-0.018280389,0.016039116,0.015786972,0.009693509,0.0060094153,0.002896146,0.037849512,0.0005393065,0.014386176,0.020605711,0.012060855,0.015380741,0.008775988,0.007452235,-0.005298511,-0.014806415,-0.007098534,-0.011318432,-0.001085617,-0.0015312453,-0.0130414115,-0.00024229396,-0.016305266,-0.043872934,-0.008096602,0.011024266,0.001075111,-0.017622015,-0.0084468005,-0.0048852763,-0.0003769017,-0.02644703,-0.023827542,-0.003563275,0.003552769,0.01821035,-0.016529394,-0.0066923033,0.0048082327,-0.030397275,-0.00865692,-0.012446074,-0.035832364,-0.019765234,-0.0050883917,0.03415141,0.01835043,0.024429884,-0.0070950324,-0.01381185,0.0066292677,-0.005123412,-0.0027980902,-0.011430496,-0.00286813,0.01745392,-0.007452235,0.001282604,-0.003241092,-0.0056136902,0.01374181,-0.0012108132,0.007984538,-0.0038451853,-0.020703766,-0.02178238,0.010407915,0.021740356,0.033282917,-0.009917636,-0.025396433,0.0074032075,-0.030117117,-0.021053966,-0.009014123,-0.0056522125,-0.0063140886,0.004366982,-0.008026562,-0.010183788,0.003223582,0.031826086,-0.012502105,0.011941787,0.0036315639,0.0055436506,0.030285211,0.0013937921,0.009490394,-0.019022811,-0.024233773,0.011297421,-0.024625996,0.0060199215,0.0038171695,-0.03353506,0.012649189,0.017608007,0.006086459,-0.0332549,0.015198638,-0.013622742,0.048187386,-0.016235227,-0.0017833886,-0.01627725,-0.00029438606,-0.013146471,-0.0035019903,-0.012411053,-0.0032901198,0.006531212,-0.020017376,-0.010512975,-0.009966664,0.0034599665,-0.033563074,-0.012446074,0.024233773,0.004769711,0.010688074,0.0027350544,-0.007466243,-0.005732758,-0.0072561237,0.0005681979,-0.019667177,-0.0045210696,0.007886482,0.011486528,0.027077388,0.021208053,-0.0077113826,0.016445346,0.010975238,-0.014722367,0.00021482521,0.00080458226,0.02102595,-0.013391611,0.035608236,-0.0034301996,-0.007655351,-0.014400184,0.0070495065,0.026615126,0.007466243,-0.017692056,-0.018630588,-0.029388702,-0.028604256,0.016641458,0.012992384,-0.008972099,-0.0037261175,-0.021726348,0.0026965325,0.0028786361,0.0045315754,-0.0016975898,-0.010646051,0.0060304273,-0.007585311,0.023393296,-0.002208005,0.018294398,-0.017762095,-0.030677434,-0.02857624,0.010225812,0.031181721,-0.018518524,0.026320959,0.017930191,-0.008628904,0.003943241,-0.0028120982,0.0023901083,0.008299717,-0.004745197,-0.0133005595,0.01655741,-0.023057103,-0.025760641,-0.007851462,0.0040588067,0.012558137,-0.011668632,0.013104447,0.006860399,-0.021376148,0.020311544,-0.0037961574,0.048663657,0.02281897,0.023113135,0.025102267,0.0013456398,0.0037331216,0.0016897103,0.0039012171,0.013475658,0.019288963,0.009840593,-0.01023982,-0.02178238,0.00432846,0.01765003,-0.024738058,-0.01717376,-0.011164345,0.0019908815,0.002479409,-0.0025844688,-0.008327733,0.011934783,-0.0034739743,-0.011017261,0.0084468005,0.018056262,-0.011899763,-0.0032130762,0.02665715,0.018224357,0.027329532,-0.010246824,0.0030905064,0.0041183406,0.009434362,0.023519367,0.013552702,-0.02019948,0.029444734,-0.0091962265,-0.0059393756,0.024401868,-0.005421081,0.015506813,-0.00717908,0.0042794324,0.030537356,-0.014764391,0.01212389,-0.006576738,0.006503196,0.0070284945,-0.0073541794,-0.0014174306,-0.00876198,-0.009700513,0.023589406,0.012614169,0.008285709,-0.031069657,-0.0031395343,-0.0020854352,-0.012270974,-0.0012607165,0.0061319848,-0.0011574078,-0.033563074,-0.0272735,-0.008299717,0.01620721,0.03661681,-0.0054771127,-0.023617422,0.012081866,0.017537968,-0.032050215,0.016305266,0.018980788,-0.012586153,-0.019148882,0.011696648,-0.018588565,-0.03594443,0.010744106,-0.017551975,-0.03860594,-0.025382426,0.0015986585,-0.0045315754,0.0022447759,-0.021992499,-0.005834316,-0.0056101885,0.0033986815,0.0035072432,-0.025592545,0.016725505,0.009602457,0.0028383632,0.015983084,-0.014239092,0.018476501,-0.020171463,-0.01690761,-0.0022272659,-0.044293173,-0.026839254,-0.022426745,-0.008712952,-0.008544857,-0.002218511,-0.0094413655,-0.0070810243,-0.014400184,0.007207096,0.001791268,-0.00637012,-0.0049413084,0.0089650955,0.003596544,0.012432066,-0.021418173,-0.008103605,-0.0022973057,0.02239873,-0.027469613,-0.014386176,-0.014946494,0.040819198,0.017075704,-0.015198638,-0.006471678,-0.0062895743,-0.031405848,0.0023095626,0.004745197,0.0005752019,-0.0076763625,0.007487255,0.0120188305,0.036252603,-0.003270859,-0.0065732356,0.0029451738,0.0099876765,-0.020969918,-0.020017376,0.0059463796,0.0033006258,-0.021124005,0.0026299946,-0.0020889372,-0.015534828,0.02246877,-0.0054631047,-0.016949633,-0.017888166,0.008895055,0.031377833,0.029921005,0.02391159,0.021516228,-0.022790954,-0.013720798,0.020367576,-0.015170622,-0.014736375,-0.023393296,0.010428927,0.0015837752,0.012432066,-0.002495168,-0.028996479,0.012390042,0.0041008308,-0.0053825593,0.0031552932,0.02961283,0.03303077,0.014764391,-0.019429043,-0.0040237866,0.025564529,-0.023281232,-0.004307448,0.022188611,-0.029977037,0.006068949,-0.01622122,-0.019835273,-0.018504517,-0.016039116,-0.011850735,-0.0017457422,-0.004650643,0.014162049,0.019050827,-0.023239208,0.025186313,0.009805573,0.0015741446,-0.01819634,-0.0045806034,0.00717908,-0.019569121,0.0036210578,0.0059218653,-0.019176899,-0.010604027,0.0066327695,0.017327849,0.017958207,0.0107371025,0.23152359,-0.018672612,-0.013363595,0.012060855,0.018028246,0.0025669588,0.023239208,0.019260947,0.00020650799,0.010723094,0.009119183,0.019961344,0.0047346908,-0.007585311,0.022720912,-0.017467927,-0.022566825,-0.008411781,0.004601615,0.017748088,0.014021969,-0.009182218,-0.004755703,-0.022566825,0.042920392,-0.011045277,-0.00988962,0.0027945882,0.0059849015,0.006944447,-0.0075502913,-0.0030484826,0.021053966,0.0012283231,-0.014295124,-0.00042768056,0.021726348,-0.008684936,0.012670201,0.0015093578,0.037065066,-0.02500421,-0.0016503129,-0.012172918,0.012838297,0.022889009,-0.019919321,-0.020423608,0.028141994,0.015534828,-0.016599433,-0.0052774996,0.0027560664,0.029024495,0.008320729,-0.009819581,-0.011654624,0.0025074251,0.012362026,-0.019821266,-0.024219764,0.008061581,-0.0084327925,0.022650873,-0.0013754066,-0.001587277,-0.0067623435,-0.010127756,0.018154318,-0.0156609,-0.015520821,-0.015408757,-0.007592315,-0.0128453,-0.029500766,-0.015772965,0.029080527,-0.00039112853,0.02280496,0.029024495,-0.020605711,-0.00083960214,-0.0010969985,-0.0144282,-0.009119183,-0.021306109,0.035496175,-0.006142491,-0.00647518,-0.006923435,-0.016193204,0.014120025,-0.011969803,0.0099876765,-0.00095166586,0.00024076183,0.010491963,0.012614169,0.005431587,0.0011871747,-0.025928736,0.07631537,0.0070425025,-0.0030152136,0.00036617686,0.010190791,0.0021222061,0.023029089,0.0055716666,-0.01133244,0.0019611146,-0.018126301,0.00084135315,-0.02136214,-0.012249962,0.0028191023,0.023589406,-0.0062195347,0.015632885,0.0016319274,-0.030425292,-0.013069428,-0.008516841,0.011199365,0.0037856514,-0.0066082557,0.0070354985,-0.0018595569,-0.017299833,-0.0069864704,0.004748699,-0.019751225,0.008825015,0.015548836,-0.0104639465,-0.022552818,-0.017341856,-0.008902059,0.01786015,-0.0051164078,0.0020416602,0.016137172,-0.005760774,-0.011276409,-0.013412623,-0.009945652,-0.01229899,0.009084163,0.0067203194,0.00039222292,-0.0048852763,0.012775261,-0.009882617,-0.01580098,0.006142491,-0.01233401,0.015983084,0.0023183175,0.002890893,-0.005021854,-0.023589406,0.004654145,0.009518409,-0.018630588,-0.01418306,-0.018532533,-0.18266381,0.008937079,0.022412738,-0.03770943,0.010968233,0.0010024448,0.02871632,-0.012355022,-0.04418111,0.015618877,0.034879822,-0.012992384,-0.030285211,-0.0026387498,-0.005340535,-0.012852305,-0.008811007,-0.0028523712,0.003545765,0.01374181,0.047711115,-0.020227496,-0.0026089828,0.007084526,-0.017832134,-0.0030082096,0.0043459698,0.02308512,0.015296694,-0.030901562,-0.0089791035,-0.0034512114,0.017818127,-0.005722252,-0.00848182,-0.0038802053,0.0043914956,-0.02192246,-0.021208053,-0.0007936385,0.020311544,0.016865585,0.015002526,-0.0017553726,-0.015520821,0.002531939,0.023449328,-0.013188495,0.005435089,-0.028800368,0.0023953614,-0.00709153,0.011724664,-0.0064996937,0.0020188973,0.0055366466,-0.0063596144,-0.019176899,0.0044720415,-0.004650643,0.002134463,-0.005414077,0.011997819,0.018532533,0.0051409216,0.006209029,9.302162e-05,0.014918478,-0.040903248,0.009350314,-0.008789996,-0.0052669933,-0.011213372,-0.0048187384,0.0021222061,0.035832364,-0.018504517,-0.009497398,0.0033584086,-0.02213258,-0.008607892,0.018266382,-0.0074242195,-0.0017334851,-0.0041988865,-0.004549085,-0.00046182497,0.03798959,-0.00800555,-0.013468655,0.020647734,-0.047458973,-0.0044650375,-0.0145682795,-0.0014778399,0.01833642,0.0142531,-0.021446189,0.01518463,-0.004804731,0.013657762,0.00026440027,-0.0016581924,-0.00025586417,0.030593388,0.0032831158,0.0029451738,0.0150865745,0.033759188,-0.0063035823,-0.02679723,-0.021796387,7.879478e-05,0.003915225,0.014400184,0.028156001,-0.007459239,0.00988962,0.009819581,-0.0067273234,0.06589345,0.0019103357,-0.013853873,0.014442208,-0.009070155,-0.02280496,-0.11643417,-0.046394367,-0.0044930535,-0.0030554866,-0.008362752,0.024331829,-0.008089597,0.0016844573,-0.028940449,0.031770054,-0.016935624,-0.0300891,0.02391159,0.0018227859,-0.004282934,-0.032694582,0.0030905064,-0.0065942477,-0.027805803,0.03331093,-0.012102879,-0.021460196,0.0064191483,-0.020997934,0.01233401,0.004331962,-0.033647124,-0.008320729,0.0036770897,-0.0070179887,0.010260832,-0.010597022,0.014610304,-1.3775407e-05,-0.0037471296,-0.023505358,-0.0048782723,-0.010386903,0.020381583,-0.017874159,0.011199365,-0.0037121098,-0.00071747025,-0.008902059,-0.039474435,-0.021992499,-0.0072421157,0.02081583,0.030145133,-0.021334125,-0.036953002,0.011997819,-0.019527098,0.0044545317,0.009546425,-0.002866379,-0.0034214444,0.0048082327,0.0045210696,0.012817284,-0.018882731,0.0070635146,-0.0094693815,-0.001465583,0.010849166,-0.02975291,-0.0034652194,-0.015744949,0.011416488,-0.02054968,-0.0050813877,-0.0032603529,-0.009077159,0.011794703,-0.015632885,-0.014035977,-0.012011827,-0.02109599,0.005417579,-0.0044405237,-0.0056837304,-0.011766687,-0.00916821,-0.0143231405,0.018238366,-0.0036875957,-0.025424449,-0.017916182,0.011080298,-0.008474817,0.0006040933,0.0320222,0.010309859,-0.027525643,0.019162891,0.014540263,-0.02831009,-5.2803447e-05,0.008523844,0.010386903,-0.02748362,-0.0070214905,-0.0471508,0.028085962,-0.0030800004,-0.034123395,-0.0156609,-0.004958818,0.008712952,-0.008159637,-0.012495101,0.02019948,-0.016333282,0.010758114,-0.0143371485,-0.0030922573,-0.017271817,-0.012235954,0.018854715,-0.01194879,-0.003666584,-0.005063878,0.015282686,-0.0015601367,0.012221946,0.011500536,-0.012411053,0.0009726778,-0.010484959,0.012712224,-0.012095874,-0.0130274035,-0.0037086078,-0.02211857,0.0034704723,0.023113135,-0.00077963056,0.0012703469,-0.013216511,0.03297474,0.027217468,0.022104563,-0.0034512114,-0.032610532,-0.0006474304,-0.018952772,-0.00365958,-0.010540991,-0.0057572722,-0.007634339,-0.007564299,-0.0017133488,0.024836116,0.0065207058,-0.0072141,-0.03978261,0.0065872436,0.02019948,-0.009826585,-0.017958207,-0.006534714,0.0047276868,0.04390095,-0.012137898,-0.0045315754,-0.0009840593,0.006723821,-0.009063151,-0.003223582,0.0104779545,0.018490508,-0.0038311773,0.007480251,0.0084327925,-0.0030887555,0.017579991,-0.0089650955,-0.020465631,0.009490394,0.001826288,0.0029924507,0.03291871,0.012943356,0.0013780332,-0.009672497,-7.003981e-05,0.004752201,0.0047136787,-0.010723094,0.008705948,-0.008796999,0.0048887786,0.028688304,0.014056989,-0.014400184,0.011829724,-0.015464789,-0.01856055,-0.004563093,-0.009504402,0.015408757,0.022622857,-0.007305152,-0.0013920411,-0.006839387,-0.030257195,-0.025536513,0.023099128,-0.012684208,-0.037821494,-0.0048362487,0.03333895,0.032750614,-0.0020486643,0.0013911657,0.0092242425,-0.018280389,0.024205757,-0.011549564,-0.023127144,-0.03622459,0.02012944,0.025942745,0.0010812395,-0.0026405007,-0.00858688,0.011696648,0.03297474,0.024640003,-0.009560433,0.006230041,0.02947275,0.0005406198,0.0012992384,-0.0051339176,-0.008243685,-0.01807027,-0.025648577,-0.018322414,0.0076833665,0.015198638,0.06869504,0.015927052,-0.008663924,0.019891305,-0.022216626,0.020465631,0.03440355,-0.004664651,-0.024149725,-0.0122639695,-0.012320002,0.010393907,-0.014134033,0.00577128,0.0024671522,0.017271817,-0.008425789,0.0035842871,-0.01807027,0.017804118,0.008474817,-0.0031325303,0.023463335,-0.0027473115,-0.017720072,0.015170622,0.006128483,0.006856897,0.0027543153,-0.01622122,0.025746632,0.014239092,-0.024780083,-0.022244642,-0.008257693,0.011836727,-0.0060199215,-0.034935854,-0.0029521778,0.002847118,-0.0067063114,-0.021726348,-0.017509952,0.0033514048,-0.009854601,0.0089510875,-0.010456943,-0.019485073,-0.015716933]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019). Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation.","formatted":"Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019). Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.","formatted":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways. First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment. Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia). In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness. Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining. The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition. Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small. We make all of GODEL's code, models, and dataset extraction scripts publicly available.","formatted":"In this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways. First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment. Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia). In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness. Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining. The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition. Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small. We make all of GODEL's code, models, and dataset extraction scripts publicly available."}]},"formatted":"Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019). Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation.\n\nLarge pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.\n\nIn this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways. First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment. Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia). In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness. Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining. The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition. Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small. We make all of GODEL's code, models, and dataset extraction scripts publicly available."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
0.7177130950698729
0.7621671649139953
0.8244986920060383
0.772736044221006
0.7253181034308342
0.7391351854503784
0.7363636565573263
0.7271269980252336
0.7456507183433921
0.7438974129986473
0.7846738832086255
0.7238891081913282
0.7576193436746615
0.7213124027066209
0.7414712044291766
0.7815030762910252
0.7689357096804822
0.762156607750433
0.7836802041530108
0.7390078787788825
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.001174144,0.004525091,-0.0021540555,-0.014754667,-0.0025372708,0.024525784,-0.015328615,0.017610408,-0.011338976,-0.03446489,0.0047000754,0.015972557,-0.016126543,0.013613771,-0.003067473,-0.025099732,0.028039467,0.00642542,-0.011534958,-0.014215716,-0.0036151735,0.017736398,-0.007016866,-0.038804494,0.0071323556,0.03376495,0.027927477,-0.015342614,0.02281794,0.009197169,-0.006029955,0.015286619,-0.037740592,-0.02425981,0.0012537617,-0.00010947449,0.01018408,-0.0008994188,0.0040001385,0.0044201007,0.011177991,0.0065129115,0.0013631269,-0.014740668,-0.008049273,-0.008231256,0.015552595,-0.0398404,-0.008070271,-0.013466784,0.01040806,0.02490375,-0.019122273,-0.0126688555,-0.016336525,-0.0029834805,-0.0049100565,0.00919017,0.013697763,-0.014908654,0.021236083,0.018086366,-0.0177224,-0.0014462443,-0.02158605,0.0045145922,-0.024735766,-0.012304888,-0.014033732,0.007594314,0.034492884,0.010261073,-0.010121086,-0.02570168,0.03466087,-0.007230347,-0.0035276813,-0.025827667,-0.013928742,0.016308527,-0.00092129176,-0.023433883,-0.015188628,0.020494148,0.012472874,-0.016840478,0.0034856852,0.015524598,-0.01350178,0.0037166644,-0.0039476436,-0.0008547978,0.020298166,0.015216625,0.0077343015,-0.005809475,-0.008609222,0.02600965,0.0011487713,0.009911105,-0.007174352,-0.0035784268,-0.021082096,-0.009869109,-0.014712671,0.002944984,0.013802753,0.003720164,0.0058829687,-0.013361793,-0.036228728,0.03552879,0.01173094,-0.038104557,-3.0594892e-05,-0.0098901065,0.007671307,-0.017848387,0.0037586605,-0.015972557,0.02369986,0.014488691,0.018072367,-0.008588225,0.012087909,-0.006568907,-0.0062084394,-0.01161895,-0.01727444,-0.013361793,0.0012301389,0.010709032,0.005071042,0.01916427,-0.015146632,0.017456423,-0.014362703,0.013340795,-0.0254497,-0.03054524,0.0076993047,0.005190031,-0.019598229,0.018002374,-0.0020560643,0.016028551,0.011010005,0.026303625,0.016994465,0.012990827,0.002136557,-0.03830054,0.021726038,0.029257357,0.016532507,0.021082096,-0.029537331,-0.0093161585,-0.021194085,-0.008175261,-0.00730734,0.013774755,0.0059599616,0.01826835,0.010730031,0.010002096,0.014698672,-0.0052845227,0.012465874,0.0043326085,-0.011254983,0.031721134,-0.028837396,0.0005284523,-0.007037864,0.01937425,0.021236083,-0.0057324823,-0.017442424,-0.025477698,0.017316436,-0.0017542165,0.005004548,0.02491775,-0.01937425,-0.023727857,0.016868476,-0.0122838905,0.0052005304,0.001893329,0.018758306,0.01616854,-0.0018408337,0.0049555525,-0.6701475,-0.021852026,0.003909147,-0.025309714,0.0154966,0.016994465,-0.002070063,-0.016252533,-0.032617055,0.012437876,-0.021180088,0.0067648888,0.028081464,-0.028865393,-0.0073003406,-0.026107641,-0.0029922298,-0.033316992,0.009659127,0.0029064876,-0.018674314,0.015972557,-0.019234262,-0.009057182,-0.0015363612,0.028641412,0.0016544756,-0.016798483,0.018744307,0.010135084,-0.009407151,0.03365296,0.0053405175,0.01560859,0.043564066,-0.020970106,-0.0070133666,0.015566594,0.00015901688,0.050395448,-0.033065014,-0.011940922,0.004959052,0.000509204,-0.011198988,0.0037901576,0.022341982,0.0025862665,0.02015818,0.010646039,0.01205991,0.01573458,0.009582135,0.0084062405,0.020130182,-0.020494148,0.023153909,-0.011443966,0.011457965,0.008294251,0.012577863,0.0051970305,-0.01703646,-0.006446418,-0.0071673524,0.02623363,-0.02115209,0.013893745,-0.0046860767,-0.04585986,-0.006852381,0.017134452,-0.021544054,0.005393013,-0.011045002,0.025953656,0.015342614,0.01649051,0.017806392,0.01892629,-0.0004448973,-0.030825216,0.0042101196,0.020410156,0.03387694,-0.00074018317,-0.033177003,-0.0088542,-0.0047245733,0.0027315032,0.0077343015,0.01937425,-0.016532507,-0.019542234,0.0014733669,0.03642471,-0.00984811,0.0166025,-0.016182538,-0.015090637,-0.0024042828,-0.010723031,0.009799114,-0.007230347,-0.010429058,0.00520403,0.0004470846,0.027773492,0.02004619,-0.020382158,0.010247074,0.019248262,-0.011856929,0.014544686,-0.012325887,-0.033680957,0.0409323,-0.01427871,0.00081498886,-0.0073983315,0.0034121918,0.012752848,0.007741301,-0.01838034,0.00763631,0.03300902,-0.014292709,-0.031161185,-0.013942741,0.008329248,0.022747945,-0.018240353,0.014271711,-0.012297889,0.017680403,-0.0006207564,-0.00056476146,0.0020438153,0.0042451164,-0.022509966,-0.00453909,0.011275982,0.0015188628,0.017918382,-0.025911659,-0.0040246365,-0.008049273,0.0081192665,-0.005501503,-0.008910195,-0.010814023,-0.021166088,-0.012493871,-0.020410156,0.0053020213,0.008497233,0.015342614,-0.031245178,-0.02579967,-0.0276755,0.010660037,0.02568768,-0.015650587,0.017554414,-0.015524598,0.0068873777,-0.0017017213,0.034296904,0.007349336,-0.02246797,0.014768666,-0.027829487,0.009610132,0.01317281,-0.0027595006,0.0025372708,0.0050780415,-0.013186809,-0.021348072,-0.014852659,0.00089591905,-0.0008766708,0.011667946,-0.00043374207,0.014488691,0.009099178,0.024651773,0.010898015,-0.016742488,0.035164822,-0.006236437,0.011940922,-0.018170359,-0.010163082,-0.0005590745,-0.007888287,0.008455236,-0.016658496,0.002469027,0.01573458,0.016658496,0.019724218,0.008028274,-0.0072793425,0.0071113575,-0.01836634,-0.0011207737,-0.014124724,0.019122273,0.01417372,0.026275627,-0.040008385,-0.021278078,-0.006834883,0.011975918,0.009834112,0.00024891502,0.011807933,-0.021544054,0.015594591,-0.03533281,0.00094141497,0.012577863,-0.00024672772,-0.01871631,0.010695034,-0.0034839353,0.019906202,0.014264711,-0.014894655,0.006057953,0.026947565,-0.0005358891,0.031609144,0.021040099,-0.018058369,0.010394061,0.0059599616,0.002148806,0.002523272,-0.0049310545,0.006943373,-0.015146632,0.0056939856,0.036032744,-0.009197169,0.033680957,0.019220265,-0.026933568,-0.0016518508,-0.011891926,0.009393152,-0.0035696775,-0.009106178,0.009176171,0.004836563,0.01428571,-0.0061909407,-0.0039231456,0.02046615,0.0069678705,0.020018192,0.033372987,-0.012248893,0.02789948,-0.0047315727,-0.012437876,-0.032365076,-0.022775942,0.0031654641,-0.013648767,-0.00037184142,0.005966961,-0.028025469,0.025995651,0.017078457,0.01716245,0.014768666,0.03421291,0.016140543,-0.03407292,-0.026961565,0.018898293,0.0053020213,-0.009008186,0.0048855585,-0.022076005,0.01074403,-0.01028907,0.0074123302,0.021502057,0.017386429,-0.0037656599,-0.0048540616,-0.01849233,0.0039826403,0.03135717,-0.011604952,-0.001206516,-0.006068452,0.007405331,0.01969622,-0.0051340363,-0.041772228,0.017120454,-0.03135717,0.031133188,-0.007139355,-0.016980466,-0.019304257,0.0065479088,-0.025253719,0.022341982,-0.018506328,0.014215716,0.0016868477,0.008161263,-0.017232444,0.030097282,0.01815636,0.005669488,-0.026261628,-0.024189815,0.0088612,0.06366625,0.05269124,-0.005826974,0.019542234,-0.002358787,-0.007065862,-0.013753758,-0.00554,0.0068033854,-0.004038635,-0.010219077,-0.01903828,0.018310346,-0.010877018,0.0051550344,0.0077902963,0.018226353,-0.014404699,-0.02270595,-0.03964442,-0.0069888686,0.0075033223,0.04129627,0.032029107,0.008910195,0.0064149206,0.028655412,0.014054731,-0.013438786,-0.018310346,0.016070548,0.01573458,0.009701123,0.005987959,0.0029799808,0.037796587,0.000553825,0.014299708,0.020550143,0.0120459115,0.015384611,0.008728212,0.0074123302,-0.0052180286,-0.014838659,-0.0070728613,-0.011303979,-0.0011216487,-0.0015354863,-0.013032823,-0.00022529215,-0.016336525,-0.043872036,-0.008091269,0.01108,0.0010376562,-0.017666405,-0.008399242,-0.004924055,-0.00038124682,-0.026499607,-0.023797851,-0.003587176,0.0036221729,0.018212356,-0.016518507,-0.0066703977,0.0048295637,-0.03043325,-0.008651218,-0.01239588,-0.035836764,-0.019780213,-0.0051515345,0.034128916,0.018408338,0.024483789,-0.0070763608,-0.01384475,0.0066389004,-0.0051200376,-0.0028067464,-0.01140897,-0.002888989,0.017456423,-0.0074473275,0.0012765097,-0.003275704,-0.005620492,0.0137677565,-0.0012432627,0.007965281,-0.0039056472,-0.020746127,-0.02179603,0.010429058,0.021740036,0.033288993,-0.009904105,-0.025393706,0.007433329,-0.030041287,-0.021082096,-0.009036183,-0.005637991,-0.006344927,0.0043221097,-0.008070271,-0.010135084,0.0031759632,0.031833123,-0.012465874,0.011940922,0.0035941754,0.005557498,0.030377256,0.0013666266,0.009477144,-0.018954288,-0.02425981,0.011303979,-0.024623776,0.005970461,0.0038006566,-0.033512972,0.012584863,0.017624408,0.0061384453,-0.033232998,0.015230624,-0.01362077,0.048211645,-0.016196538,-0.0017507168,-0.016224535,-0.00028806773,-0.0130958175,-0.003476936,-0.012465874,-0.0032704545,0.0065829055,-0.02004619,-0.010457056,-0.009946101,0.0034839353,-0.03354097,-0.012444876,0.024231812,0.004784068,0.010709032,0.00277,-0.0074123302,-0.005721983,-0.007251345,0.0005358891,-0.019668223,-0.0045425897,0.007825294,0.011464965,0.027059555,0.021208085,-0.0076923054,0.01649051,0.010940012,-0.014712671,0.00015672021,0.0007690555,0.021096094,-0.013410789,0.035612784,-0.003487435,-0.007657308,-0.014404699,0.007062362,0.026653592,0.007433329,-0.017750397,-0.018646317,-0.029369347,-0.028627414,0.016616499,0.013011824,-0.008987188,-0.0037446618,-0.021726038,0.0027157548,0.0029204863,0.0045215916,-0.0017113454,-0.01063204,0.0060719517,-0.0075873146,0.02336389,-0.0022450471,0.018240353,-0.017680403,-0.030601235,-0.028515425,0.0102260765,0.031161185,-0.018520327,0.026317623,0.017988374,-0.0086932145,0.0039476436,-0.0028382437,0.002369286,0.008294251,-0.004728073,-0.013270801,0.016588502,-0.023069916,-0.025715677,-0.007853291,0.0040666326,0.0125708645,-0.011702943,0.01306082,0.006908376,-0.021348072,0.020298166,-0.0037901576,0.048687603,0.022845937,0.023097914,0.02502974,0.0013666266,0.0037936573,0.0016763486,0.0038601514,0.013445785,0.01926226,0.009799114,-0.0102750715,-0.02181003,0.004325609,0.017582411,-0.02467977,-0.01716245,-0.011177991,0.002047315,0.0024882753,-0.0026002652,-0.008350246,0.011870928,-0.0034961842,-0.011003006,0.008441238,0.01804437,-0.011926923,-0.003198711,0.026653592,0.018282348,0.027297534,-0.010303069,0.0030972203,0.0041926214,0.009372153,0.023559872,0.013515779,-0.020200176,0.029425342,-0.009176171,-0.0058969674,0.024399797,-0.005414011,0.015510599,-0.007209349,0.0042486163,0.03054524,-0.014768666,0.012094907,-0.006540909,0.0064919135,0.0070238654,-0.0073983315,-0.0014374951,-0.008707213,-0.009666127,0.023559872,0.0126688555,0.0083082495,-0.031049196,-0.0031392165,-0.002068313,-0.0122838905,-0.0012380132,0.0061244466,-0.0011592703,-0.03354097,-0.027227541,-0.008294251,0.016210536,0.036676686,-0.005456007,-0.023629865,0.01206691,0.017512418,-0.032001108,0.016294528,0.019066278,-0.012682854,-0.019136272,0.011695944,-0.018562322,-0.03597675,0.0108000245,-0.017526416,-0.03866451,-0.025365708,0.001626478,-0.004525091,0.0022292987,-0.022048008,-0.005833973,-0.005623992,0.0034139417,0.0034331898,-0.025547693,0.016784484,0.009617131,0.002845243,0.015986556,-0.014236714,0.01849233,-0.02015818,-0.016896473,-0.0022310484,-0.044264,-0.026807578,-0.022313984,-0.008700214,-0.008581225,-0.0022187997,-0.009470144,-0.0070693614,-0.0143907005,0.007188351,0.0018005874,-0.0063519264,-0.004959052,0.009015186,0.0036501703,0.012374883,-0.021404067,-0.008154264,-0.0022572961,0.022411976,-0.027479518,-0.014362703,-0.014880656,0.040876307,0.01705046,-0.01516063,-0.006467416,-0.006264434,-0.031413164,0.0023220403,0.004794567,0.0005328269,-0.0076643075,0.0074893236,0.01205991,0.036284722,-0.0032669548,-0.0065724063,0.0028872392,0.010002096,-0.020928109,-0.02004619,0.005931964,0.0033509473,-0.021096094,0.0026737584,-0.002113809,-0.015552595,0.022495968,-0.0054315096,-0.01692447,-0.017904382,0.008896196,0.03135717,0.029957294,0.023895841,0.02148806,-0.022761945,-0.01372576,0.020396158,-0.01516063,-0.014768666,-0.023419885,0.010380062,0.0015521098,0.012444876,-0.0024830257,-0.02900538,0.012388881,0.0041051293,-0.005337018,0.0031479658,0.029649321,0.03300902,0.014698672,-0.01937425,-0.003993139,0.025589688,-0.023307895,-0.0043116105,0.022173997,-0.029957294,0.0060824505,-0.016224535,-0.019878205,-0.018562322,-0.016070548,-0.011807933,-0.0017900883,-0.004612583,0.014138723,0.019010283,-0.023391888,0.025141729,0.009799114,0.0015976056,-0.018282348,-0.004528591,0.0071673524,-0.019542234,0.0036396713,0.0058969674,-0.01916427,-0.010541048,0.0066144024,0.017288439,0.01794638,0.010716032,0.23159508,-0.018688312,-0.013368793,0.012031913,0.018058369,0.002502274,0.0232519,0.019248262,0.00018526452,0.010681035,0.009113177,0.019948198,0.0047070747,-0.0075873146,0.022719948,-0.017470421,-0.022523966,-0.008427239,0.004626582,0.017736398,0.014019733,-0.009197169,-0.004805066,-0.022537963,0.04297612,-0.011059001,-0.0098901065,0.0028679909,0.005970461,0.006960871,-0.007573316,-0.0030692227,0.021054098,0.0012283891,-0.014299708,-0.00046108334,0.021712039,-0.008679216,0.012689854,0.0015529847,0.03709665,-0.025001742,-0.0016807232,-0.012136904,0.012822841,0.022887932,-0.019892203,-0.02036816,0.028193453,0.015594591,-0.016574502,-0.0053055207,0.002778749,0.02900538,0.00830125,-0.0098411115,-0.0116609465,0.00254602,0.012346885,-0.019780213,-0.02424581,0.008000277,-0.008399242,0.022677952,-0.0014182469,-0.0015118634,-0.006838382,-0.010114087,0.018128363,-0.015692582,-0.015538597,-0.015356613,-0.007517321,-0.012808843,-0.029481336,-0.01573458,0.02911737,-0.00038102808,0.02281794,0.028977383,-0.020648135,-0.0008670467,-0.0010814023,-0.014418698,-0.009085179,-0.02126408,0.03552879,-0.0061594434,-0.0064569167,-0.006922375,-0.016182538,0.014089727,-0.011982918,0.0099880975,-0.0009676626,0.00021074658,0.0105130505,0.012633859,0.0054035117,0.0011671446,-0.025925659,0.07643309,0.0070763608,-0.003077972,0.00038824618,0.010205078,0.0021120592,0.023055917,0.0055260006,-0.011366974,0.0019633227,-0.018128363,0.0008272378,-0.021390067,-0.012164901,0.0028032467,0.023601867,-0.0061699427,0.015650587,0.0016404769,-0.03043325,-0.013081818,-0.00852523,0.011212987,0.0038391533,-0.0065794056,0.007065862,-0.0018793303,-0.017358432,-0.006960871,0.004735072,-0.01971022,0.008826203,0.015580593,-0.010401061,-0.02256596,-0.017358432,-0.008924194,0.017848387,-0.005127037,0.0020543144,0.016196538,-0.0058059758,-0.011240984,-0.013424788,-0.0099601,-0.012297889,0.009071181,0.0066389004,0.00035259314,-0.004917056,0.012780845,-0.00984811,-0.015860567,0.006155944,-0.012311888,0.015958559,0.0022747945,0.002944984,-0.0050325454,-0.023615867,0.0046405806,0.009526139,-0.018660314,-0.014222715,-0.018520327,-0.18243152,0.008952191,0.022327984,-0.037768587,0.010912014,0.0010227826,0.028725406,-0.012367883,-0.044208005,0.01560859,0.034940843,-0.012934832,-0.030293263,-0.0026090143,-0.005337018,-0.012801844,-0.0087912055,-0.0028732405,0.0035451797,0.013760757,0.047679693,-0.020228174,-0.0025722675,0.0070728613,-0.017848387,-0.0030307262,0.0044166013,0.023083914,0.015328615,-0.030909209,-0.008945192,-0.0034506882,0.01782039,-0.0057079843,-0.008539229,-0.0038461527,0.0044166013,-0.02190802,-0.021082096,-0.0007992403,0.020284168,0.016812481,0.014978647,-0.0017253441,-0.015510599,0.0026212633,0.023447882,-0.013186809,0.0054490077,-0.028781401,0.0024410295,-0.0070518632,0.011646948,-0.00653041,0.0020088186,0.005494504,-0.0063134297,-0.019192267,0.0043921033,-0.004693076,0.0021838027,-0.005393013,0.0119969165,0.018576322,0.005144535,0.00619794,6.507225e-05,0.014866658,-0.040904306,0.009344156,-0.008826203,-0.0052390266,-0.011212987,-0.004857561,0.0021418065,0.035920754,-0.018464332,-0.00951914,0.0033596966,-0.02216,-0.008630221,0.018212356,-0.0074473275,-0.0017437175,-0.004217119,-0.004584586,-0.00044795952,0.037880577,-0.007944282,-0.013445785,0.020690132,-0.047455713,-0.0044900943,-0.014558685,-0.001472492,0.01836634,0.014257712,-0.021404067,0.015202627,-0.004773569,0.013606771,0.00034012552,-0.0016606,-0.0002567893,0.030573238,0.0032162096,0.002944984,0.015076638,0.03373695,-0.0063099302,-0.026765583,-0.021852026,9.049964e-05,0.003933645,0.014348704,0.028123459,-0.0074893236,0.009904105,0.009764118,-0.00675439,0.06607403,0.0019090775,-0.01384475,0.014404699,-0.009022185,-0.022831937,-0.11646948,-0.046363812,-0.0045600883,-0.0030622233,-0.008371244,0.02425981,-0.00808427,0.0016474762,-0.02889339,0.03177713,-0.016910473,-0.030097282,0.023937838,0.0018495829,-0.0043326085,-0.03275704,0.0030832216,-0.0065829055,-0.027815487,0.033260997,-0.012094907,-0.021404067,0.006386923,-0.020998104,0.012297889,0.0043361085,-0.033680957,-0.008329248,0.0036571696,-0.006995868,0.010261073,-0.010597043,0.014516689,1.0724617e-05,-0.0037376625,-0.02346188,-0.0048225643,-0.010373063,0.020354161,-0.017876385,0.011205988,-0.0037691595,-0.000686813,-0.0088542,-0.03950443,-0.02203401,-0.0071813515,0.020774124,0.030153276,-0.021334073,-0.03695666,0.012010915,-0.019528236,0.004469096,0.009540138,-0.002901238,-0.003419191,0.0047770683,0.0045425897,0.012780845,-0.018842299,0.0070798607,-0.009456146,-0.0015101136,0.010884017,-0.029677318,-0.0034576876,-0.01573458,0.011443966,-0.020620137,-0.005050044,-0.003233708,-0.009015186,0.011793935,-0.015594591,-0.014012734,-0.012003915,-0.021054098,0.005414011,-0.0044795955,-0.0057184836,-0.011772936,-0.009225166,-0.014362703,0.01826835,-0.0036256725,-0.025435703,-0.017848387,0.011121996,-0.008455236,0.000558637,0.032085102,0.010352065,-0.02756351,0.019122273,0.014558685,-0.02833344,-0.000114833376,0.008560227,0.010401061,-0.027437521,-0.007041364,-0.047119744,0.02801147,-0.00309897,-0.034128916,-0.015678585,-0.00498005,0.0086932145,-0.008147264,-0.012465874,0.020186177,-0.016322525,0.010793025,-0.014306707,-0.0031129688,-0.017246442,-0.012276891,0.018856296,-0.011947921,-0.0036046745,-0.005081541,0.015314616,-0.0016089797,0.012206897,0.011492962,-0.012304888,0.00096591277,-0.010541048,0.012689854,-0.01206691,-0.0130538205,-0.003720164,-0.022118002,0.003510183,0.023097914,-0.00078217936,0.0012913834,-0.013165811,0.03298102,0.02724154,0.02203401,-0.00343144,-0.03267305,-0.0006736891,-0.018856296,-0.0036081742,-0.010583044,-0.0057079843,-0.007706304,-0.0075873146,-0.001782214,0.024833757,0.006519911,-0.007251345,-0.039784405,0.006589905,0.02015818,-0.009827113,-0.017960377,-0.0065024127,0.00475957,0.043900035,-0.012171901,-0.004532091,-0.000908168,0.006691396,-0.009057182,-0.0031829625,0.010506051,0.01847833,-0.0038041563,0.007461326,0.008511231,-0.0030692227,0.017582411,-0.009008186,-0.02048015,0.009449147,0.0018023372,0.0030097282,0.032925025,0.0129068345,0.0013692513,-0.009694125,-7.294654e-05,0.0047210734,0.00475957,-0.010751029,0.0086442195,-0.008798205,0.004882059,0.028781401,0.014040732,-0.0143907005,0.0118989255,-0.0154966,-0.018548325,-0.0045880857,-0.009456146,0.015398609,0.02256596,-0.007272343,-0.0013902495,-0.006841882,-0.030265266,-0.02557569,0.023125911,-0.012682854,-0.03785258,-0.0048295637,0.033316992,0.03278504,-0.0020630637,0.0014497441,0.009253164,-0.018282348,0.024287807,-0.011534958,-0.023167908,-0.03620073,0.020130182,0.025925659,0.0010612791,-0.0026947565,-0.008651218,0.011695944,0.032953024,0.024735766,-0.009491143,0.0062679336,0.029509334,0.0005857596,0.0012773846,-0.0050955396,-0.008231256,-0.018114364,-0.025645683,-0.018282348,0.007741301,0.015244623,0.06859381,0.015902564,-0.008665217,0.019892203,-0.022215994,0.020522146,0.0343529,-0.0046335813,-0.024105823,-0.012304888,-0.012346885,0.010436057,-0.014110725,0.005788477,0.0024497786,0.01727444,-0.008448237,0.0035941754,-0.01804437,0.017764395,0.008532229,-0.0031374665,0.02346188,-0.0027245039,-0.017680403,0.015188628,0.006096449,0.0068453816,0.0027630003,-0.016196538,0.025715677,0.014208716,-0.024833757,-0.022243991,-0.008231256,0.011800934,-0.005987959,-0.034940843,-0.0030237269,0.0028522424,-0.006691396,-0.021782033,-0.01748442,0.0033526972,-0.009883108,0.008945192,-0.010422058,-0.019556234,-0.015776575]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019). Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation.","formatted":"Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019). Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.","formatted":"Large pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways. First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment. Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia). In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness. Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining. The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition. Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small. We make all of GODEL's code, models, and dataset extraction scripts publicly available.","formatted":"In this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways. First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment. Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia). In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness. Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining. The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition. Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small. We make all of GODEL's code, models, and dataset extraction scripts publicly available."}]},"formatted":"Our approach seeks to address a long-standing obstacle to general-purpose open-ended conversation models, namely a lack of robust automated evaluation criteria that can drive development (Gao et al., 2019). Recent state-of-the-art models that leverage large PLMs (e.g., Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Bao et al., 2021; Thoppilan et al., 2022; Gao et al., 2022) offer the potential for substantive open-ended conversational interactions, yet they resist meaningful comparison owing to the lack of consensus on evaluation.\n\nLarge pre-trained language models (PLMs) for dialog (Zhang et al., 2019b;Freitas et al., 2020; Roller et al., 2021; Peng et al., 2021; Bao et al., 2021; Thoppilan et al., 2022) have had significant impact in Conversational AI, as these models have brought strong performance gains in competitions such as DSTC (Gunasekara et al., 2020) and ConvAI (Aliannejadi et al., 2020), and have been widely adopted in both task-oriented and chitchat research. While the applications of these dialog models are numerous, empirical evaluation of dialog pre-training has mostly been restricted to intrinsic evaluation (i.e., agnostic to any notion of utility). For example, DialoGPT (Zhang et al., 2019b) offered Reddit-based pre-trained models that are evaluated on Relevance, Informativeness, and Humanness and various string overlap based automated evaluation metrics.  Meena (Freitas et al., 2020) 's evaluation is focused on Sensibleness and Specificity, while also offering a new automated evaluation (SSA) that measures these two qualities. BlenderBot (Roller et al., 2021) contributes a variety of models that capitalize on skills including personality, empathy, and knowledge, but evaluation in this work centers mostly on measures of Humanness and Engagingness. 2  The discussion of our largest model in this paper relates to GODELXL which is based on GPT-3, but which we are unable to release owing to licensing restrictions. We therefore release GODEL GPT\u2212J XL a substitute model based on GPT-J that performs similarly. A comparison of GODEL models initialized from GPT-3 and GPT-J is provided in the Appendix.  Plato-XL (Bao et al., 2021) focuses on intrinsic evaluation with measures of Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness. Plato-XP does however provide some extrinsic evaluation on DSTC9-Track1 (Kim et al., 2020), MultiWOZ 2.2 (Zang et al., 2020), and DuConv (Wu et al., 2019), but is based on taskspecific automated metrics (ROUGE-L for DSTC9, Goal-Accuracy for MultiWOZ, and Knowledge-F1 for DuConv). By contrast, our work provides a more unified measure of Utility, which is measured the same fashion (e.g., same annotation instructions) across dialog tasks and datasets. Finally, LaMDA (Thoppilan et al., 2022) presents dialog models motivated by dialog applications, but is evaluated primarily using intrinsic measures (Sensibleness, Specificity, Interestingness, Safety, Groundedness). In its human evaluation, LaMDA does consider an extrinsic evaluation measure of Utility (Helpfulness), and is probably the closest to our work in terms of analyzing PLMs with a unified extrinsic evaluation. Our works seeks to go further by contrasting intrinsic and extrinsic measures, and analyzing their correlates with automatic evaluation on specific tasks and datasets.\n\nIn this paper, we presented a new large-scale pretrained model for dialogue (GODEL) that improves on (Zhang et al., 2019b) in two main ways. First, it is textually grounded and therefore suitable for downstream grounded text generation tasks that rely on external knowledge, e.g., provided by the dialog's environment. Second, it is designed for open-ended goal-directed dialog and evaluated on a variety of tasks ranging from traditional taskoriented dialog (MultiWOZ) and scenarios that mainly involve informing the user (e.g., Wizard of Wikipedia). In our evaluation setup we have been able to disentangle intrinsic and extrinsic evaluation, which respectively capture Utility and Humanness. Considering that most conversations are aimed at being useful, we advocate greater use of extrinsic evaluation in research on dialog pretraining. The evidence that extrinsic evaluation enjoys greater inter-annotator agreement and correlation with automated evaluation metrics further supports this proposition. Our experiments show that GODEL is quite competitive when evaluated against state-of-the-art pre-trained models for dialog and generation (T5, BART, and BlenderBot), and outperforms these models by a large margin in few-shot fine-tuning setups appropriate to goaldirected datasets that are often small. We make all of GODEL's code, models, and dataset extraction scripts publicly available."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
0.7398255998825074
0.7831808680495628
0.746945475879978
0.7323484932033542
0.777323691050472
0.7596864464751446
0.7906985872769607
0.7435433047007038
0.7643140597245148
0.7527313737486274
0.7391963580332497
0.7201135733480863
0.738164617536302
0.7576373705505594
0.7768540336724505
0.7024948995084793
0.8009056958117765
0.7801185245792724
0.7581690187856973
0.7399127298212028
0.7770375801609903
0.7267493981791028
0.7616728139877837
0.756442956778184
0.741021653086993
0.7989140775873965
0.7944033473364179
0.7670823662544676
0.796185330176855
0.7347115434481414
0.781386069359891
0.7784237825522944
0.7494698666840951
0.7142015688697114
0.7832348377885514
0.7564349884432352
0.7458356492031584
0.7825919488307534
0.7564808329758828
0.7689311774270292
0.7558200333424931
0.7752249233660152
0.7864689371775483
0.774240647921423
0.790407882820948
0.7117733195021178
0.739842731408543
0.8007641429313683
0.7651411627288378
0.7285976207663597
0.7531877887220729
0.7963900366826353
0.7873688675262385
0.7285398850576784
0.7158877291574582
0.7839665230872026
0.778166875501801
0.7408750395028593
0.7397505105201893
0.7430070221799525
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0012320876,0.00449782,-0.002094899,-0.014757049,-0.002516679,0.024641752,-0.015373093,0.017543247,-0.011228799,-0.03444245,0.0047323364,0.016017139,-0.016003137,0.013685973,-0.003039966,-0.025117787,0.028071996,0.006440458,-0.011690832,-0.014190009,-0.0035877551,0.017627254,-0.0069934973,-0.038782757,0.0071895113,0.033826407,0.027959988,-0.0154711,0.022891628,0.009163652,-0.0060764323,0.0153590925,-0.037634674,-0.02420772,0.0012032106,-6.79814e-05,0.010108719,-0.0008518731,0.004007785,0.004441816,0.011144793,0.0064754602,0.0013405953,-0.014813053,-0.007952565,-0.008365595,0.015639111,-0.039874837,-0.00802257,-0.0134059535,0.010332734,0.024949774,-0.01913936,-0.012782909,-0.016241156,-0.002898206,-0.0048268433,0.009198654,0.013657971,-0.014813053,0.021155505,0.01815929,-0.017683258,-0.0014307267,-0.021491528,0.0043858117,-0.024823764,-0.012320876,-0.014042999,0.0077285497,0.034526456,0.010353737,-0.010094718,-0.025761832,0.034666464,-0.007266517,-0.003559753,-0.02573383,-0.01391699,0.01632516,-0.0009914455,-0.023311658,-0.015093073,0.020567462,0.012453886,-0.016899202,0.0035124999,0.0155411055,-0.013601967,0.0036892623,-0.003993784,-0.00072586414,0.02025944,0.015275086,0.007847558,-0.005838415,-0.008694618,0.026041852,0.001238213,0.0098707015,-0.007000498,-0.0037382657,-0.021043496,-0.009814698,-0.014729047,0.0028649538,0.013727976,0.0038012704,0.0058349147,-0.013195938,-0.036178574,0.035534527,0.011732834,-0.038166713,2.9478659e-05,-0.009961708,0.0076935473,-0.017753262,0.0038922767,-0.015849127,0.023703685,0.014407025,0.018089287,-0.008659616,0.011928848,-0.006681975,-0.006314449,-0.011634828,-0.017193222,-0.013412953,0.0011830841,0.010738764,0.0052083703,0.019153362,-0.015135076,0.017487243,-0.014407025,0.01336395,-0.025425809,-0.030578174,0.0076935473,0.0051943692,-0.019615395,0.01783727,-0.0021334018,0.015989138,0.01096978,0.026307872,0.017053213,0.013020926,0.0020878986,-0.03822272,0.021757547,0.029206077,0.016409166,0.021057498,-0.029290082,-0.009331663,-0.021295514,-0.008085575,-0.007287518,0.013720975,0.005992426,0.01815929,0.010647757,0.0100527145,0.014771051,-0.0052783755,0.012537892,0.0042913053,-0.011347807,0.031726256,-0.028926058,0.000499223,-0.006916492,0.01926537,0.021183506,-0.0055653956,-0.01744524,-0.02557982,0.017263228,-0.0015768622,0.005050859,0.024921773,-0.019433381,-0.023801692,0.016955206,-0.012383881,0.005173368,0.0020441453,0.018761335,0.016129147,-0.0016477421,0.0050893617,-0.67025566,-0.02192556,0.0038992772,-0.0253138,0.0155411055,0.01701121,-0.0019881413,-0.01631116,-0.032566316,0.012390881,-0.02123951,0.0067589805,0.028001992,-0.028926058,-0.007245515,-0.026097856,-0.0030189648,-0.033154357,0.0096256845,0.002838702,-0.018649327,0.015933134,-0.019321375,-0.009261658,-0.0014849806,0.028632035,0.0016074893,-0.016787194,0.018747333,0.010178723,-0.009443671,0.033574387,0.005320378,0.015569107,0.0435991,-0.02095949,-0.0070109987,0.015569107,0.00015149514,0.050571594,-0.033098355,-0.011893846,0.0048688464,0.0006107934,-0.011263801,0.0038397731,0.02235959,0.0025341802,0.019993423,0.010647757,0.01195685,0.015695116,0.009660687,0.008519606,0.02009143,-0.020483457,0.023115644,-0.011452815,0.011438813,0.00829559,0.012684902,0.0050368584,-0.017137218,-0.0065069627,-0.007259516,0.026181862,-0.021113502,0.013888988,-0.0047148354,-0.04569925,-0.006863988,0.016969206,-0.021673542,0.005362381,-0.010983781,0.02587384,0.0153590925,0.016395167,0.01771126,0.018873341,-0.0004738462,-0.030746186,0.0041512954,0.02041345,0.03388241,-0.00073242706,-0.03329437,-0.008932635,-0.0047288365,0.0028212005,0.007721549,0.019377379,-0.016605182,-0.01953139,0.00147623,0.036458593,-0.0097166905,0.016479172,-0.016101144,-0.015107074,-0.0023031638,-0.010745764,0.009786696,-0.0072245137,-0.010248729,0.00534138,0.0004154358,0.027749972,0.019909415,-0.020455455,0.0102347275,0.019251369,-0.011844843,0.014533034,-0.012404882,-0.03363039,0.040798903,-0.014316018,0.00081118266,-0.0074065267,0.003445995,0.012684902,0.007952565,-0.018215295,0.007616542,0.033070352,-0.014330019,-0.031138213,-0.013993995,0.008281589,0.022667611,-0.018313302,0.014225012,-0.012292874,0.017683258,-0.0005722907,-0.00061516877,0.002122901,0.0041547953,-0.022625608,-0.0046133283,0.011452815,0.0014858557,0.01799128,-0.025887841,-0.00408129,-0.008057573,0.007987568,-0.0056038983,-0.008883632,-0.010871773,-0.021211509,-0.012649899,-0.02025944,0.005267875,0.008519606,0.015513103,-0.03122222,-0.025621822,-0.027679969,0.0107527645,0.025705827,-0.01561111,0.017557248,-0.015625112,0.006804484,-0.0015436098,0.034414448,0.0073855254,-0.02235959,0.014701045,-0.027875982,0.009667687,0.013146935,-0.002854453,0.0024134216,0.0050018555,-0.013300946,-0.021421524,-0.014883058,0.00093281636,-0.0008842504,0.011753836,-0.00041871727,0.014519032,0.009079645,0.024501743,0.010990782,-0.016759193,0.035198502,-0.0063249497,0.011858843,-0.01815929,-0.010045715,-0.0005517267,-0.007917563,0.008498604,-0.016717188,0.002586684,0.01575112,0.016675185,0.019769406,0.0080995755,-0.0072315144,0.007130007,-0.018355304,-0.001195335,-0.014064,0.019055355,0.014028997,0.02643388,-0.040014844,-0.02136552,-0.0069024907,0.011921848,0.009821698,0.00015663613,0.011865844,-0.021505529,0.015695116,-0.03525451,0.000822996,0.012488888,-0.00033733647,-0.018663326,0.010675759,-0.0036052563,0.019811409,0.014302017,-0.014939062,0.005978425,0.026951917,-0.00049703533,0.031726256,0.021015495,-0.018047282,0.010416741,0.005848916,0.0021351518,0.0024536746,-0.0048828474,0.0070390007,-0.015163078,0.0058349147,0.035954557,-0.009191654,0.033910412,0.019293372,-0.027021922,-0.0014954814,-0.011753836,0.009436671,-0.0036192574,-0.009198654,0.0092266565,0.0048303436,0.014246013,-0.0062829466,-0.003923779,0.020483457,0.0070109987,0.020063426,0.033266366,-0.0122788735,0.027959988,-0.0048443447,-0.012467886,-0.032370303,-0.02277962,0.0031047207,-0.013685973,-0.00041127924,0.005866417,-0.028001992,0.026083855,0.017123217,0.017207224,0.014785051,0.034218434,0.01617115,-0.03419043,-0.026825907,0.018901344,0.005316878,-0.0089536365,0.004931851,-0.021995565,0.010759765,-0.010157722,0.0074065267,0.021477528,0.017263228,-0.0037802688,-0.004896848,-0.018509315,0.0039167786,0.031278223,-0.011641827,-0.0011174545,-0.0060379296,0.0073505226,0.0196994,-0.0050893617,-0.04172297,0.01715122,-0.03133423,0.031054208,-0.007091504,-0.01701121,-0.01926537,0.006541965,-0.025215793,0.02234559,-0.018495316,0.014260014,0.0017124967,0.00815558,-0.017207224,0.030046137,0.018117288,0.0057264073,-0.026209863,-0.02419372,0.00886963,0.063732535,0.05258774,-0.005810413,0.01954539,-0.0023521672,-0.007060002,-0.013874986,-0.0054638884,0.00674848,-0.0040567885,-0.0100527145,-0.019055355,0.018369306,-0.0109067755,0.0053238785,0.0077985544,0.01815929,-0.014477029,-0.022541603,-0.039566815,-0.007126507,0.007469531,0.041134924,0.03209028,0.009051643,0.006359952,0.028674038,0.014085001,-0.01336395,-0.018215295,0.01603114,0.01590513,0.009800697,0.005985426,0.0028509528,0.037886694,0.0005162867,0.014155007,0.020553462,0.012040856,0.015485101,0.008687618,0.007462531,-0.0052398727,-0.014869058,-0.0070670024,-0.011340806,-0.0011209548,-0.0015742369,-0.013195938,-0.00024917396,-0.016353162,-0.043767113,-0.0080085695,0.010927777,0.001055325,-0.01757125,-0.008491604,-0.004949352,-0.00032880463,-0.026531886,-0.023843696,-0.0036332584,0.0034127426,0.018299302,-0.016395167,-0.0066329716,0.0049003484,-0.030354159,-0.008652615,-0.012327877,-0.035870552,-0.019727403,-0.0052083703,0.034218434,0.018341305,0.02445974,-0.0070495014,-0.013888988,0.0067589805,-0.0051628673,-0.0029209577,-0.011417812,-0.002840452,0.017431239,-0.00745553,0.0010693261,-0.0032429807,-0.005684404,0.013818983,-0.0011358308,0.007994569,-0.003906278,-0.020833481,-0.021673542,0.010360736,0.021673542,0.033210363,-0.009814698,-0.025439808,0.00731552,-0.030214148,-0.021169506,-0.008960637,-0.0057614096,-0.006258445,0.0043928125,-0.008043572,-0.0100527145,0.0032377301,0.031838264,-0.012530891,0.011802839,0.0036052563,0.005642401,0.030270152,0.0013379701,0.009506676,-0.018943347,-0.024137717,0.011263801,-0.024585748,0.005946923,0.0038747755,-0.033490382,0.012495888,0.017543247,0.0061114347,-0.033266366,0.015149077,-0.013552964,0.048135422,-0.016367164,-0.0018306301,-0.016269157,-0.00028373892,-0.013048928,-0.00337599,-0.012292874,-0.003416243,0.0066854754,-0.01996542,-0.010500747,-0.010003711,0.0034704967,-0.033490382,-0.0125238905,0.024277726,0.004763839,0.010675759,0.0027039424,-0.007567538,-0.005684404,-0.0072105126,0.0005285376,-0.019713402,-0.004448816,0.007840558,0.011417812,0.027035922,0.021085499,-0.0076795463,0.016619181,0.01097678,-0.0148410555,0.00018988851,0.00086806173,0.0210995,-0.0134059535,0.03559053,-0.0035405017,-0.007749551,-0.014393023,0.0071685095,0.0267279,0.0074765314,-0.01772526,-0.018663326,-0.029346086,-0.028702041,0.016633183,0.013020926,-0.008967638,-0.0038152712,-0.021673542,0.0027179432,0.0028439523,0.00464133,-0.0017702508,-0.010619755,0.0059714247,-0.007602541,0.023283655,-0.002166654,0.018173292,-0.017767264,-0.030606177,-0.028478025,0.010290732,0.031194218,-0.018635325,0.026363874,0.018089287,-0.008659616,0.003993784,-0.0028614535,0.0024991778,0.008169581,-0.0047008344,-0.013244942,0.016619181,-0.023087641,-0.02573383,-0.007896561,0.004018286,0.012418883,-0.011494817,0.013062929,0.0069129914,-0.021463526,0.020315444,-0.0036507596,0.048583455,0.022849625,0.023045639,0.02503378,0.0013414704,0.0038327726,0.0017571249,0.0038432733,0.013272944,0.019167364,0.0098497,-0.010304733,-0.021869555,0.0044068135,0.017669257,-0.024711758,-0.017067214,-0.0112568,0.0020861484,0.002600685,-0.0026111857,-0.0081905825,0.011697832,-0.003486248,-0.011032784,0.0084286,0.018047282,-0.011879845,-0.0032132284,0.026615893,0.018327303,0.02728794,-0.010297732,0.0031047207,0.0041022915,0.009429671,0.023437666,0.013531962,-0.020287443,0.029514099,-0.009121649,-0.005936422,0.024431737,-0.005383383,0.0154711,-0.0070425007,0.0043088063,0.030550173,-0.014869058,0.01222987,-0.0065734675,0.006380954,0.0068884897,-0.0074205277,-0.0013694724,-0.008792625,-0.009758694,0.02347967,0.012565893,0.008197583,-0.03122222,-0.003122222,-0.0020896485,-0.0122788735,-0.0012312125,0.0060414295,-0.0011760836,-0.03360239,-0.027259938,-0.008225585,0.016101144,0.03671061,-0.005386883,-0.023521673,0.012061858,0.01758525,-0.032118283,0.016339162,0.019041354,-0.012600896,-0.019097358,0.0117608365,-0.01855132,-0.03601056,0.010822769,-0.017543247,-0.03853074,-0.02545381,0.0015672365,-0.0045223217,0.0023416665,-0.02192556,-0.005680904,-0.005467389,0.0033847408,0.0035475022,-0.025677826,0.01673119,0.009660687,0.002840452,0.016087145,-0.013944992,0.018537318,-0.020175435,-0.016899202,-0.0023364162,-0.044187143,-0.026797906,-0.02237359,-0.008624613,-0.008568609,-0.0022191578,-0.00942267,-0.0071370075,-0.014435027,0.007158009,0.001786877,-0.0063389507,-0.0048548453,0.008960637,0.0035947557,0.012488888,-0.02139352,-0.008211584,-0.0022734117,0.02234559,-0.027511956,-0.014288016,-0.014869058,0.040714893,0.017039211,-0.015107074,-0.006513963,-0.0062899473,-0.03133423,0.002236659,0.004742837,0.0005740408,-0.007623542,0.007553537,0.012033856,0.03626258,-0.0033217361,-0.0065734675,0.0028527027,0.010003711,-0.021043496,-0.020007422,0.0058349147,0.0033672394,-0.021015495,0.0025446808,-0.0022384091,-0.01561111,0.02237359,-0.005467389,-0.016997209,-0.017893272,0.008890633,0.031278223,0.030046137,0.023829695,0.021407522,-0.022737617,-0.013727976,0.020399451,-0.015051071,-0.014715047,-0.023283655,0.010430742,0.0014368522,0.012292874,-0.002506178,-0.028954059,0.01250989,0.0040567885,-0.0053658816,0.003122222,0.029486097,0.032958344,0.014757049,-0.019251369,-0.0040042847,0.02545381,-0.023283655,-0.0043123066,0.02221958,-0.029990133,0.0061079343,-0.01617115,-0.019839412,-0.01855132,-0.016115146,-0.011788839,-0.001786002,-0.0046203285,0.014148006,0.019013353,-0.023395663,0.025271798,0.009856701,0.0016389915,-0.018299302,-0.0045538237,0.0072385147,-0.019475386,0.0034844978,0.0058279145,-0.019167364,-0.010675759,0.006716978,0.017221225,0.018033283,0.010724762,0.23163247,-0.018635325,-0.013398953,0.012068858,0.018187294,0.002630437,0.023395663,0.019209366,0.00012589958,0.010745764,0.009093647,0.020049425,0.00477784,-0.0076445434,0.02276562,-0.017473243,-0.022681613,-0.008421599,0.0045223217,0.017697258,0.013951992,-0.009093647,-0.0046343296,-0.022597607,0.04289905,-0.011123791,-0.009975709,0.0029174574,0.0059224213,0.0068884897,-0.0073645236,-0.003050467,0.021085499,0.0012487138,-0.014449027,-0.00041827976,0.02178555,-0.0086176125,0.012768908,0.0014806053,0.037074637,-0.02489377,-0.001715997,-0.012152865,0.0128879165,0.022821622,-0.019881414,-0.020399451,0.028156003,0.015597109,-0.016633183,-0.0051943692,0.0027301942,0.029038064,0.008288589,-0.009863702,-0.011592824,0.0026111857,0.012194867,-0.01982541,-0.024165718,0.008057573,-0.008407597,0.022737617,-0.0014184759,-0.0014867308,-0.006846487,-0.010087717,0.018103287,-0.0155411055,-0.015513103,-0.015317089,-0.0075325356,-0.012761908,-0.029542102,-0.015723119,0.029066067,-0.00045459482,0.022723615,0.02898206,-0.020665469,-0.00087506225,-0.0011489567,-0.014435027,-0.009016641,-0.021211509,0.035506524,-0.0061674383,-0.0065174634,-0.006937493,-0.016199151,0.014148006,-0.011970852,0.009884703,-0.0008523106,0.00017949713,0.010451743,0.012621897,0.0054463875,0.001195335,-0.025817836,0.07622142,0.007084504,-0.0029839622,0.00038458986,0.010283731,0.0021124003,0.023087641,0.0056143994,-0.011368808,0.0019618894,-0.018173292,0.0008396222,-0.021323517,-0.01223687,0.0028054495,0.02347967,-0.0061919405,0.015653113,0.0016748691,-0.030354159,-0.013062929,-0.008512605,0.011277802,0.0037802688,-0.0066329716,0.0070810034,-0.0018218795,-0.017459242,-0.0068989904,0.004791841,-0.019587392,0.00885563,0.015625112,-0.010332734,-0.022583606,-0.01730523,-0.009009641,0.017767264,-0.0051698675,0.0019811408,0.01632516,-0.0056178994,-0.011270802,-0.0134689575,-0.009905704,-0.01222987,0.008960637,0.0066469726,0.00030780313,-0.0048723463,0.012768908,-0.009856701,-0.015765121,0.006034429,-0.0122788735,0.015765121,0.0023276655,0.0028877053,-0.004945852,-0.023689685,0.0046203285,0.009534678,-0.018607324,-0.014169008,-0.018495316,-0.18257298,0.0089536365,0.022401594,-0.03783069,0.010955779,0.0011174545,0.028702041,-0.012292874,-0.044075135,0.015667114,0.034946486,-0.013020926,-0.030270152,-0.0026059353,-0.0053098775,-0.012985923,-0.008834628,-0.0027319442,0.0035387517,0.013762979,0.047687393,-0.020175435,-0.002602435,0.007088004,-0.01786527,-0.0030312156,0.0044453163,0.02305964,0.015401095,-0.0309422,-0.00900264,-0.0035054993,0.01773926,-0.005635401,-0.008554609,-0.0038187716,0.004329808,-0.02192556,-0.021141503,-0.00085537334,0.020469455,0.016801195,0.014925062,-0.0017256227,-0.015597109,0.002728444,0.023451667,-0.013146935,0.005428886,-0.02881405,0.0023504172,-0.007098505,0.011620826,-0.0064929617,0.0019776407,0.0055198926,-0.006342451,-0.01912536,0.0043928125,-0.004655331,0.0021579035,-0.0053448803,0.012061858,0.018523317,0.005047359,0.0062514446,0.00015444848,0.014757049,-0.041022915,0.009331663,-0.008785625,-0.0052223713,-0.011340806,-0.0048828474,0.0020581463,0.035954557,-0.018369306,-0.009513676,0.0032324798,-0.022233581,-0.008533607,0.018201293,-0.0073225205,-0.0017895022,-0.004119793,-0.0045083207,-0.0005530393,0.037914697,-0.008078574,-0.013433956,0.020637468,-0.04754738,-0.004389312,-0.014533034,-0.0013764729,0.018299302,0.014337019,-0.021337517,0.015303088,-0.0047183353,0.013622968,0.00027214436,-0.0016573678,-0.0003150224,0.030550173,0.0031887267,0.0029507098,0.015065071,0.0337144,-0.0063634524,-0.026797906,-0.021883557,0.00012721217,0.0039727823,0.0143230185,0.028085997,-0.0075255353,0.009940707,0.009674688,-0.0067554805,0.06597269,0.0018971349,-0.01378398,0.014435027,-0.009100647,-0.022975633,-0.11660029,-0.0463993,-0.0045188214,-0.003025965,-0.008393597,0.024417736,-0.008064574,0.0016626182,-0.028870054,0.031726256,-0.016927203,-0.030074138,0.023899699,0.0018813838,-0.004319307,-0.03259432,0.0031659752,-0.006538465,-0.027903983,0.033238363,-0.012040856,-0.02139352,0.006356452,-0.020987492,0.012215869,0.004448816,-0.033686396,-0.008400598,0.0036227575,-0.007003998,0.010220727,-0.01069676,0.014589038,-0.00016888701,-0.0037872694,-0.02347967,-0.0049423515,-0.010381739,0.020371448,-0.017907273,0.011158793,-0.00365426,-0.00085974863,-0.008841629,-0.039482806,-0.022023566,-0.007259516,0.02067947,0.030074138,-0.021141503,-0.036794618,0.011998854,-0.019503387,0.0044768183,0.009611684,-0.002854453,-0.00337424,0.004697334,0.0046448302,0.012859914,-0.018817337,0.0071755103,-0.009387667,-0.0014219761,0.010822769,-0.029710112,-0.0035212503,-0.015765121,0.011487816,-0.020469455,-0.0049423515,-0.0032219791,-0.00900264,0.011711833,-0.015821125,-0.013972994,-0.012026855,-0.021113502,0.005320378,-0.0045048203,-0.005736908,-0.011886845,-0.00913565,-0.014267014,0.018201293,-0.003629758,-0.025411807,-0.017977279,0.011130791,-0.008512605,0.0006142937,0.03206228,0.010276731,-0.027651966,0.019153362,0.0146590425,-0.028226007,-0.0001860601,0.008547608,0.010451743,-0.027511956,-0.0070495014,-0.047043346,0.028029993,-0.003108221,-0.034218434,-0.0155411055,-0.005019357,0.008799626,-0.008302591,-0.012593895,0.020133432,-0.016213153,0.0109067755,-0.014393023,-0.0029944628,-0.017235225,-0.0122788735,0.018915346,-0.011914847,-0.0036367585,-0.0050823614,0.015401095,-0.0016608681,0.012222869,0.011494817,-0.012383881,0.0009170652,-0.010381739,0.012754907,-0.012012854,-0.013055928,-0.0036892623,-0.022177577,0.0034389945,0.023045639,-0.0009030642,0.0013169687,-0.013195938,0.033014346,0.027245937,0.022107571,-0.003391741,-0.03265032,-0.0006265445,-0.01898535,-0.0036157572,-0.01054975,-0.005743908,-0.007707548,-0.007427528,-0.0017895022,0.024795763,0.006555966,-0.007287518,-0.03965082,0.0065594665,0.02009143,-0.0098357,-0.017963277,-0.0065209637,0.004655331,0.043935124,-0.012334877,-0.004455817,-0.0008903758,0.006723978,-0.00885563,-0.0032674824,0.010521748,0.018453313,-0.0038747755,0.0073365215,0.008316591,-0.0030067137,0.017557248,-0.00886963,-0.020469455,0.0094716735,0.0018008781,0.0029594605,0.032958344,0.013034927,0.0014263514,-0.009681689,-8.198239e-05,0.004697334,0.0047288365,-0.010857772,0.0087716235,-0.008687618,0.0048268433,0.028786046,0.014042999,-0.014379023,0.011949849,-0.0154711,-0.01869133,-0.0046203285,-0.009527678,0.015457099,0.022625608,-0.0073225205,-0.0014097253,-0.0067204777,-0.030186146,-0.02557982,0.02319965,-0.012754907,-0.037746683,-0.004910849,0.03335037,0.032706324,-0.0020756477,0.0013545963,0.009310662,-0.018299302,0.02420772,-0.011648828,-0.023185648,-0.036178574,0.020063426,0.025817836,0.001053575,-0.0026881911,-0.008631614,0.011774837,0.032958344,0.024697756,-0.009513676,0.006247944,0.029458094,0.00059154205,0.0013265944,-0.0050578597,-0.008211584,-0.018145291,-0.025565818,-0.018453313,0.0076935473,0.015121075,0.068660885,0.01587713,-0.008561608,0.01982541,-0.022317586,0.020455455,0.03419043,-0.004609828,-0.024109714,-0.012320876,-0.01222987,0.01026973,-0.014183008,0.0057404083,0.002458925,0.01729123,-0.0084426,0.0037872694,-0.01800528,0.01783727,0.008547608,-0.0031747257,0.023367662,-0.0027249437,-0.017599251,0.015135076,0.0060764323,0.00674848,0.002770447,-0.016213153,0.02574783,0.014162007,-0.024809765,-0.022331588,-0.008204583,0.0119428495,-0.005946923,-0.03500249,-0.0030347158,0.0028842052,-0.0068009836,-0.021757547,-0.017557248,0.003473997,-0.009814698,0.009051643,-0.010227728,-0.01954539,-0.015653113]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011617147,0.0045137913,-0.0021010665,-0.01473548,-0.00252128,0.024610493,-0.015379807,0.017522896,-0.011254713,-0.03445749,0.004709891,0.016010128,-0.016066156,0.013621915,-0.0029992724,-0.025128756,0.02811227,0.006387242,-0.011688934,-0.014217217,-0.0035788168,0.01764896,-0.0069930498,-0.038743667,0.0071856477,0.033841178,0.027944185,-0.015449842,0.022873612,0.009146643,-0.0060860896,0.015337786,-0.03767913,-0.024218293,0.0011704692,-4.0161012e-05,0.010127141,-0.00082904584,0.0040060338,0.0044297487,0.011156663,0.006425762,0.0013639424,-0.014763494,-0.007942031,-0.008348238,0.015589914,-0.03983622,-0.00799806,-0.013411808,0.010365262,0.024974678,-0.01914772,-0.012809502,-0.016234241,-0.0028749595,-0.004804439,0.009188664,0.0136779435,-0.014819522,0.021122722,0.0181252,-0.017704988,-0.0014374797,-0.021514922,0.0043387027,-0.0248206,-0.012284236,-0.014091153,0.0077529354,0.034569547,0.010351255,-0.010092123,-0.025759077,0.034681607,-0.007290701,-0.00352629,-0.025759077,-0.013874043,0.01638832,-0.0009804977,-0.023349853,-0.015071651,0.020562438,0.012445318,-0.016892575,0.003508781,0.015533885,-0.013593901,0.0037083824,-0.0039955284,-0.00074018823,0.020352332,0.015281757,0.007878999,-0.005826958,-0.008656394,0.026053226,0.0012212449,0.009832991,-0.006961534,-0.0037539057,-0.02103868,-0.009832991,-0.014707466,0.0028521977,0.013663936,0.003809934,0.0058619757,-0.01325773,-0.03616636,0.035550047,0.011793987,-0.03815537,2.4799698e-05,-0.009945048,0.007696907,-0.017733002,0.0038204393,-0.015786013,0.023686023,0.01439931,0.018097186,-0.008642387,0.011913047,-0.0066813915,-0.0063172067,-0.01168193,-0.017214738,-0.013390797,0.0011652164,0.010757461,0.005182631,0.019189741,-0.015211722,0.017466867,-0.01439931,0.01337679,-0.025436912,-0.030563515,0.0076899035,0.00516162,-0.019637968,0.017803038,-0.0021045683,0.01599612,0.010946557,0.026333367,0.017046653,0.012970584,0.0021308316,-0.03815537,0.02176705,0.029162804,0.016444348,0.0210807,-0.029330889,-0.009363754,-0.021206765,-0.008054089,-0.0073607364,0.013726968,0.0060195555,0.018111194,0.0106454035,0.010092123,0.014707466,-0.0053262035,0.012536364,0.004307186,-0.0113387555,0.03174011,-0.02893869,0.0005222026,-0.0069160108,0.019287791,0.021122722,-0.005602844,-0.017466867,-0.025604997,0.017242752,-0.0015749244,0.00500404,0.02491865,-0.019399848,-0.02379808,0.016920589,-0.012375282,0.005179129,0.001982006,0.018783536,0.016150199,-0.0016353301,0.005060069,-0.67010015,-0.021949142,0.0039535067,-0.02529684,0.015561899,0.017004631,-0.0019890096,-0.016318284,-0.03258054,0.012389289,-0.021220772,0.0067654345,0.02801422,-0.028966704,-0.0072066584,-0.026109254,-0.0030377922,-0.033140823,0.009629888,0.0028767104,-0.018615449,0.015912076,-0.019287791,-0.009195668,-0.0014978853,0.028658548,0.0016108177,-0.016808532,0.018755522,0.010162159,-0.009412779,0.03353302,0.0053402106,0.015603921,0.04359013,-0.021010665,-0.007003555,0.015603921,0.00018154529,0.050565667,-0.033084795,-0.011927054,0.004849962,0.0005686011,-0.0112617165,0.00384145,0.022355348,0.00252128,0.020044174,0.0106384,0.011934058,0.015659949,0.009608878,0.008509319,0.020156233,-0.020520417,0.023097726,-0.011492834,0.011485831,0.008292209,0.012690442,0.005070574,-0.017046653,-0.00652031,-0.0072486796,0.026165282,-0.021150736,0.013951082,-0.0047624176,-0.045747224,-0.0068739895,0.017018639,-0.021669,0.0052981894,-0.010946557,0.025829112,0.015351793,0.016318284,0.017676974,0.018867578,-0.00052351574,-0.030815642,0.0041496065,0.020394353,0.03392522,-0.0007025441,-0.03330891,-0.008908522,-0.0047519123,0.002832938,0.0077319248,0.019399848,-0.016584419,-0.019511905,0.0014488605,0.036418486,-0.009720935,0.01652839,-0.016080163,-0.015057644,-0.0022691519,-0.010750458,0.009818984,-0.007213662,-0.010288223,0.005371727,0.0003987649,0.027790107,0.019946124,-0.020422367,0.0102602085,0.019259777,-0.011836008,0.014497359,-0.012368279,-0.03364508,0.04081672,-0.014287253,0.00081503874,-0.0073887506,0.003494774,0.012676435,0.008005064,-0.018265272,0.007591854,0.033028767,-0.014343281,-0.03106777,-0.013993103,0.00831322,0.022649497,-0.018335307,0.01420321,-0.01229124,0.01764896,-0.0005970531,-0.00057954417,0.0021185754,0.0041776206,-0.022593468,-0.0045908303,0.011401787,0.0014943836,0.01798513,-0.025899148,-0.004125094,-0.0080120675,0.007984053,-0.0056238547,-0.008873505,-0.0108765215,-0.021220772,-0.012676435,-0.020296304,0.005238659,0.008467298,0.015505871,-0.031235857,-0.02564702,-0.027706064,0.010715439,0.025773084,-0.015673956,0.017620945,-0.0156179285,0.006863484,-0.0015591665,0.034429476,0.0074167647,-0.022411376,0.0146794515,-0.02787415,0.00967191,0.013173687,-0.0028767104,0.0024197283,0.0050075417,-0.01327874,-0.02141687,-0.01493158,0.0009034586,-0.00086625223,0.01177998,-0.00040336102,0.014469345,0.009034586,0.02448443,0.011037603,-0.01672449,0.03515785,-0.0063522244,0.011878029,-0.018167222,-0.010022087,-0.0005804196,-0.00797705,0.008481305,-0.01672449,0.002566803,0.015729984,0.016682468,0.019708004,0.0080891065,-0.007213662,0.0071121105,-0.018363321,-0.0012019852,-0.014056135,0.019119706,0.014035124,0.026389396,-0.04003232,-0.02137485,-0.0069160108,0.011850015,0.009811981,0.00020616715,0.0118149975,-0.021486908,0.015659949,-0.035269905,0.00086844084,0.012480335,-0.00033835927,-0.018685484,0.010666414,-0.0035350444,0.019848075,0.014266242,-0.014917573,0.00600905,0.026921665,-0.0005020674,0.031768125,0.020996658,-0.01808318,0.010407283,0.0059250076,0.0020853085,0.0024267319,-0.004923499,0.0070455763,-0.015169701,0.0057744314,0.03597026,-0.009216678,0.033953235,0.019315805,-0.027019717,-0.0014821274,-0.011730955,0.009412779,-0.0036278416,-0.009153646,0.009216678,0.0048569655,0.014217217,-0.006296196,-0.0039430014,0.02050641,0.0070560817,0.020114211,0.033224866,-0.01229124,0.028000213,-0.0047799265,-0.012543367,-0.032356426,-0.022761554,0.003118333,-0.013656933,-0.00046442324,0.005886488,-0.028056242,0.026109254,0.017074667,0.01715871,0.014791508,0.034205362,0.01619222,-0.034149334,-0.02685163,0.018937614,0.0053577195,-0.008964551,0.0049024886,-0.02200517,0.010743454,-0.0101831695,0.007430772,0.021500915,0.01725676,-0.0037889234,-0.004881478,-0.018531406,0.0038939766,0.031319898,-0.011632905,-0.0011056863,-0.006044068,0.007353733,0.019665983,-0.0050775777,-0.041713174,0.017172717,-0.031291883,0.031039756,-0.007119114,-0.017004631,-0.019217756,0.0065728365,-0.025198791,0.022327334,-0.018475378,0.014273246,0.0017272518,0.00819416,-0.017186724,0.030031245,0.018055165,0.005697392,-0.026291346,-0.024218293,0.0088594975,0.0638164,0.05263872,-0.0057919403,0.019525912,-0.0023566964,-0.007119114,-0.013846029,-0.005497791,0.0066813915,-0.0040235426,-0.010064109,-0.018979635,0.018307293,-0.010911539,0.0052981894,0.0078019607,0.018167222,-0.014427324,-0.022593468,-0.03955608,-0.0071261176,0.007542829,0.04115289,0.032076284,0.009055597,0.0063627297,0.028686563,0.014119167,-0.013439822,-0.018237257,0.01605215,0.015912076,0.00979097,0.0060195555,0.0028101765,0.037875228,0.0004937506,0.014147181,0.020548431,0.012004093,0.0154638495,0.008670402,0.0074587865,-0.005214147,-0.0148335295,-0.0070770923,-0.011359766,-0.0011284478,-0.0015687963,-0.013166684,-0.00028999095,-0.016360305,-0.043758214,-0.008019071,0.010946557,0.001038277,-0.017536903,-0.008453291,-0.0049375063,-0.00037228272,-0.026571488,-0.023854109,-0.0036418487,0.0034194859,0.018293286,-0.016444348,-0.006611356,0.004877976,-0.030339401,-0.008663398,-0.012347268,-0.035886217,-0.019708004,-0.0051721255,0.034177348,0.018363321,0.024470422,-0.0070735905,-0.013895053,0.006821463,-0.005165122,-0.0029379914,-0.011422798,-0.0028224327,0.017410839,-0.0074377754,0.0010636649,-0.0032986745,-0.0056728795,0.013860036,-0.0011503339,0.0080120675,-0.003872966,-0.020856587,-0.021697015,0.010330244,0.021640986,0.03319685,-0.009825988,-0.025436912,0.0072836974,-0.030255359,-0.021164743,-0.008950544,-0.0057008937,-0.0062926942,0.0043387027,-0.008075099,-0.010092123,0.0032181337,0.031824153,-0.012543367,0.011744962,0.0036278416,0.0056098476,0.030283373,0.0013289246,0.009510828,-0.018923607,-0.024176272,0.011275724,-0.024596486,0.0059600254,0.003855457,-0.033476993,0.012494342,0.017606938,0.0060860896,-0.033224866,0.015127679,-0.013481843,0.048212472,-0.016332291,-0.001841935,-0.016234241,-0.0003048735,-0.013103652,-0.003401977,-0.0123542715,-0.0034580054,0.0066638826,-0.019988146,-0.0104913255,-0.01000808,0.003508781,-0.03353302,-0.012494342,0.02428833,0.004758916,0.010624393,0.0027296357,-0.0075778468,-0.005648367,-0.0071926513,0.0005953022,-0.01967999,-0.0044472576,0.007857989,0.011394784,0.0269917,0.021136729,-0.007647882,0.01662644,0.01093255,-0.014805515,0.00019062802,0.00083561166,0.021122722,-0.013390797,0.03557806,-0.0035858203,-0.0077319248,-0.014322271,0.00715063,0.026725566,0.007451783,-0.017718995,-0.018643463,-0.029330889,-0.028714577,0.016612433,0.013075638,-0.009006572,-0.003795927,-0.021725029,0.002710376,0.0029047246,0.004643357,-0.001755266,-0.0106454035,0.0059565236,-0.007591854,0.023335846,-0.002235885,0.018153215,-0.017775023,-0.030619543,-0.02846245,0.010246201,0.03126387,-0.018601442,0.026347375,0.018069172,-0.008663398,0.0040130373,-0.0028697068,0.0024319845,0.008243185,-0.004671371,-0.013236719,0.016640447,-0.023111733,-0.025717055,-0.007935028,0.004065564,0.012396293,-0.011513845,0.013068634,0.0069335196,-0.02141687,0.020296304,-0.0036243398,0.04857666,0.02292964,0.023055704,0.02496067,0.0013665687,0.0038134358,0.0017167465,0.0038484535,0.013334769,0.019203749,0.0098610055,-0.010288223,-0.021949142,0.0044192434,0.017704988,-0.024736557,-0.017046653,-0.011282727,0.0020993156,0.0025860628,-0.002566803,-0.0081661455,0.011730955,-0.0034457492,-0.011016592,0.008390259,0.018055165,-0.011864022,-0.003228639,0.026599502,0.018307293,0.02724383,-0.0102602085,0.0031130803,0.0040410515,0.009384764,0.023419889,0.013502854,-0.02031031,0.029498974,-0.009111625,-0.005918004,0.024470422,-0.0053577195,0.015519878,-0.007038573,0.004324695,0.030591529,-0.014861544,0.012228208,-0.0065553277,0.006387242,0.006880993,-0.00736774,-0.0014182199,-0.00882448,-0.009804977,0.023531945,0.01262741,0.008145135,-0.031235857,-0.0031043258,-0.002153593,-0.01229124,-0.0011984834,0.006044068,-0.0011932307,-0.033561036,-0.027229823,-0.00821517,0.016178213,0.03669863,-0.0053787306,-0.023545953,0.012137162,0.017564917,-0.0321043,0.016374312,0.019105699,-0.012564378,-0.019133713,0.011723951,-0.018545413,-0.035942245,0.010778472,-0.01755091,-0.038519554,-0.02549294,0.0015617928,-0.0045242966,0.0022849098,-0.02196315,-0.0056903884,-0.005497791,0.0034264894,0.0035490515,-0.025689041,0.016696475,0.009636892,0.002818931,0.016080163,-0.013965089,0.018545413,-0.020212261,-0.01696261,-0.0023514437,-0.044318497,-0.026823616,-0.022411376,-0.008656394,-0.008544337,-0.0022481412,-0.009433789,-0.0071576335,-0.014413317,0.0071261176,0.0017911593,-0.00632421,-0.0048849797,0.009020579,0.0036173363,0.012501346,-0.021360843,-0.00819416,-0.002251643,0.022383362,-0.027509965,-0.014329274,-0.01493158,0.040760692,0.01706066,-0.015099665,-0.0065098046,-0.0062576765,-0.031375926,0.0022621483,0.004790432,0.00054671505,-0.0076268716,0.007528822,0.012039111,0.03630643,-0.003321436,-0.00657984,0.0028451942,0.010036094,-0.021010665,-0.020002153,0.0058794846,0.0033827173,-0.021010665,0.002566803,-0.002283159,-0.015589914,0.022411376,-0.005448766,-0.016990624,-0.017901087,0.008915526,0.03126387,0.030087274,0.023826094,0.021388857,-0.022761554,-0.013691951,0.02040836,-0.015043637,-0.014791508,-0.02326581,0.010442301,0.0014462342,0.012298243,-0.0024950164,-0.028994719,0.012522357,0.0040690657,-0.0053297053,0.003162105,0.02947096,0.03297274,0.01473548,-0.019259777,-0.004034048,0.025464926,-0.023307832,-0.0043422044,0.02220127,-0.030003231,0.00614562,-0.016234241,-0.019806053,-0.018573428,-0.016150199,-0.011758969,-0.0017561414,-0.0046188445,0.014168192,0.018965628,-0.023391875,0.02525482,0.009832991,0.0016204476,-0.018335307,-0.0045698197,0.007227669,-0.019525912,0.003479016,0.005844467,-0.019189741,-0.010694428,0.0066778897,0.017172717,0.018041158,0.010750458,0.23173364,-0.018601442,-0.013404804,0.012074129,0.018139208,0.0026105752,0.02346191,0.019161727,0.00013591275,0.010694428,0.009069604,0.020058181,0.0047624176,-0.007633875,0.02273354,-0.017438853,-0.022579461,-0.008397263,0.0045383037,0.01769098,0.013951082,-0.009083611,-0.0047028875,-0.022607476,0.042917784,-0.011072621,-0.009966059,0.0029257352,0.005963527,0.006863484,-0.007409761,-0.0030658063,0.021024672,0.001276398,-0.014427324,-0.0003987649,0.021795064,-0.008593362,0.012767481,0.0014961344,0.037062813,-0.02491865,-0.0017062412,-0.0121231545,0.012872535,0.022873612,-0.019876089,-0.02040836,0.028168298,0.015603921,-0.016570412,-0.0052001397,0.0026998706,0.029050747,0.008250188,-0.0098610055,-0.011569873,0.0025913154,0.012165176,-0.019792046,-0.024148257,0.0080891065,-0.008348238,0.022761554,-0.0014427324,-0.0014366043,-0.006884495,-0.010050102,0.018139208,-0.015533885,-0.015547892,-0.015323779,-0.007556836,-0.012788491,-0.02961103,-0.015715977,0.029078761,-0.00048499618,0.022719532,0.028966704,-0.020688502,-0.000853996,-0.0011196934,-0.014427324,-0.008999568,-0.02117875,0.03549402,-0.0061981464,-0.0064957975,-0.0068879966,-0.016136192,0.014175195,-0.011990086,0.009868009,-0.0008929533,0.0002210497,0.010449304,0.012599396,0.0054102466,0.0012632663,-0.025801098,0.07619868,0.007066587,-0.002992269,0.00036703006,0.010295226,0.002080056,0.023083718,0.0055958405,-0.011352763,0.0019942624,-0.018181229,0.0008364871,-0.021318821,-0.0122772325,0.0027594008,0.023517938,-0.006156125,0.015645942,0.0016510881,-0.03039543,-0.013075638,-0.00853033,0.01126872,0.0038134358,-0.0066638826,0.0070700888,-0.0018139208,-0.017466867,-0.0068564806,0.0047659194,-0.019609954,0.008887512,0.015589914,-0.010330244,-0.022565454,-0.017312787,-0.008908522,0.017775023,-0.005151115,0.0020030169,0.016304277,-0.005662374,-0.011247709,-0.013502854,-0.009924037,-0.012186186,0.008978558,0.0066008507,0.00029721338,-0.004895485,0.012753474,-0.009875013,-0.015743991,0.006040566,-0.0122772325,0.015786013,0.0023759562,0.0029344896,-0.0049690222,-0.023686023,0.004625848,0.009545846,-0.018615449,-0.014189202,-0.018489385,-0.18265271,0.008992565,0.02239737,-0.037847213,0.010939553,0.0011380777,0.028714577,-0.01231225,-0.044094384,0.015687963,0.03496175,-0.013019609,-0.030311387,-0.0025738066,-0.0053437124,-0.012956577,-0.00884549,-0.0027331375,0.0035227882,0.013782997,0.04773623,-0.020212261,-0.0026385894,0.0071296194,-0.017859066,-0.0030272866,0.004422745,0.023041697,0.0153658,-0.030927699,-0.009020579,-0.0034580054,0.017733002,-0.005602844,-0.00853033,-0.003809934,0.004349208,-0.021921128,-0.021136729,-0.0009113376,0.020534424,0.016836546,0.01493158,-0.0017193728,-0.015561899,0.002755899,0.023447903,-0.013173687,0.0054102466,-0.028826633,0.002424981,-0.007017562,0.011632905,-0.006474787,0.0020030169,0.0055538192,-0.0063207084,-0.019175734,0.004363215,-0.0046468587,0.002190362,-0.0053227018,0.0120181,0.018601442,0.0050635706,0.0062751854,0.00018646965,0.014721473,-0.040984806,0.009293717,-0.008740437,-0.005210645,-0.011345759,-0.0048534637,0.0020555435,0.035942245,-0.018335307,-0.009538842,0.003214632,-0.022229284,-0.008481305,0.018209243,-0.0072977045,-0.0017911593,-0.0041355994,-0.0045418055,-0.0005580958,0.037847213,-0.008026075,-0.013460833,0.020632474,-0.047568146,-0.0043842257,-0.014469345,-0.0013087894,0.018307293,0.014357288,-0.021332828,0.015323779,-0.004790432,0.013621915,0.00025387888,-0.0016834795,-0.00034142332,0.030507486,0.0031866175,0.0029555003,0.015057644,0.03372912,-0.006376737,-0.02675358,-0.021893114,0.00017169653,0.003978019,0.014329274,0.028070249,-0.007528822,0.009931041,0.009636892,-0.0067794416,0.06605753,0.0019102197,-0.013797004,0.014469345,-0.009118629,-0.022915633,-0.116651215,-0.046419565,-0.004520795,-0.002990518,-0.008376252,0.024358366,-0.008082103,0.0016038142,-0.028854648,0.031712096,-0.016906582,-0.030031245,0.02389613,0.0019067179,-0.00431419,-0.032608554,0.0031586033,-0.0065133064,-0.027846135,0.03330891,-0.012074129,-0.02141687,0.006345221,-0.020968644,0.0122001935,0.0044507594,-0.03372912,-0.008390259,0.003638347,-0.0070105586,0.010253205,-0.010694428,0.014553388,-0.00016042519,-0.003809934,-0.02346191,-0.004990033,-0.010372265,0.020352332,-0.017915094,0.0111846775,-0.003666361,-0.0008614373,-0.008894515,-0.03950005,-0.022019178,-0.0072346726,0.020632474,0.030031245,-0.021136729,-0.03678267,0.011962072,-0.019525912,0.0045102895,0.009566857,-0.0028381906,-0.0034264894,0.0047168946,0.0046048374,0.0128305135,-0.018769529,0.0072066584,-0.009461803,-0.0014357289,0.0108345,-0.029639045,-0.003508781,-0.015786013,0.011499838,-0.020534424,-0.004986531,-0.0031901193,-0.009006572,0.011702941,-0.015772006,-0.013979096,-0.012025104,-0.021136729,0.005350716,-0.0044962824,-0.00569389,-0.011871026,-0.009153646,-0.014287253,0.018153215,-0.0036348451,-0.025408898,-0.017943108,0.011163667,-0.008467298,0.0005891741,0.032020256,0.010253205,-0.027692057,0.019105699,0.0146794515,-0.028266348,-0.00020003904,0.008642387,0.010386272,-0.027495958,-0.0070735905,-0.047091905,0.028028227,-0.0031726104,-0.034177348,-0.015561899,-0.0050355564,0.008789462,-0.008306216,-0.012571381,0.02017024,-0.016220234,0.010967568,-0.014413317,-0.0030027742,-0.017284773,-0.012284236,0.018923607,-0.011920051,-0.003573564,-0.005070574,0.0153658,-0.0017141202,0.012249218,0.011457817,-0.0123542715,0.0009174657,-0.010379269,0.012788491,-0.012053118,-0.013061631,-0.003715386,-0.022173256,0.0034369947,0.023083718,-0.0009253447,0.0012702699,-0.013243723,0.033000752,0.027313866,0.02210322,-0.0033582046,-0.03258054,-0.0006469534,-0.01895162,-0.003652354,-0.010603382,-0.005679883,-0.007745932,-0.0074237683,-0.0018822055,0.024792586,0.0065728365,-0.0072836974,-0.03964012,0.0065308153,0.020072188,-0.009854002,-0.017971123,-0.006562331,0.004692382,0.043898284,-0.012333261,-0.0044927807,-0.0008929533,0.0067269146,-0.008887512,-0.0032829165,0.010512336,0.018447364,-0.0038939766,0.0073467293,0.008348238,-0.0030167813,0.017564917,-0.008894515,-0.02040836,0.0094548,0.0018752019,0.0029992724,0.03297274,0.012984592,0.0014401061,-0.009699924,-4.109117e-05,0.0047203964,0.004772923,-0.010904536,0.008761448,-0.008712423,0.00484646,0.028770605,0.014056135,-0.014308264,0.011962072,-0.0154638495,-0.018727507,-0.0046678693,-0.009566857,0.015477857,0.022593468,-0.007276694,-0.0014296008,-0.006751427,-0.03019933,-0.025562976,0.023195775,-0.012732463,-0.037735157,-0.0048884815,0.033364937,0.03277664,-0.0020677997,0.0013613161,0.009272707,-0.018307293,0.0242323,-0.011674927,-0.023251804,-0.036194373,0.020072188,0.02584312,0.0010645404,-0.0026893653,-0.008663398,0.011695937,0.032944724,0.024708543,-0.009496821,0.0062611783,0.02947096,0.0006119356,0.0012772734,-0.0050775777,-0.008208167,-0.018195236,-0.02559099,-0.01841935,0.007710914,0.015127679,0.068746895,0.015870055,-0.008593362,0.01982006,-0.022285312,0.02050641,0.034233376,-0.004608339,-0.024148257,-0.012326257,-0.012207197,0.0102602085,-0.014175195,0.0057569225,0.0024950164,0.017312787,-0.008418273,0.0037924252,-0.017999137,0.017859066,0.008523326,-0.0031393436,0.023391875,-0.0027156286,-0.017606938,0.015183708,0.0060160537,0.0067619327,0.0027891658,-0.016206227,0.025759077,0.014119167,-0.024862621,-0.022369355,-0.008285206,0.011948065,-0.00594952,-0.035073806,-0.003039543,0.002944995,-0.0068424735,-0.021753043,-0.017578924,0.0034737634,-0.009839995,0.008978558,-0.01020418,-0.019525912,-0.015659949]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.7708400761542952
0.7452171958570686
0.7730007210225499
0.7852775563970997
0.8116662956519292
0.7159634704199438
0.7537319415883357
0.7975528479794385
0.7500401242812123
0.7820088086691941
0.7367834571756869
0.7899285572545696
0.7887118716581342
0.7700069877306677
0.7824736207077105
0.7939679494103369
0.7059015220104341
0.7643016009049578
0.7048733241732588
0.7830618932350568
0.7393067844990963
0.776068802980281
0.7687631863560728
0.7761351553026348
0.7057829444111481
0.7662043790554548
0.7051830300946276
0.7498637895035727
0.7631747570236547
0.713251293249569
0.7397199888617173
0.7497025693426245
0.7203435836163561
0.7492303964255246
0.7113798364771222
0.7759940996907152
0.7037013447473073
0.7177813191345148
0.7448275601926904
0.7522802960348345
0.7093896505646679
0.7028956938847415
0.726928285373334
0.7113688140954534
0.7121776590848606
0.7667939195906375
0.6878569619244485
0.6984404559290533
0.7431663321816968
0.7228900254383411
0.7028994199598362
0.7171126893060339
0.7429704145850192
0.6992019147562746
0.7099652080169764
0.6845238934776771
0.7366612891294306
0.7161026035147153
0.6767760573062594
0.7245282551956507
0.7358998271839454
0.7293567456906083
0.7308150539731851
0.7050385326526148
0.7511993598036816
0.6892106158883563
0.7178218266684689
0.7151501244030163
0.7055315958290814
0.6971429470055449
0.7492285980540229
0.7988356270396365
0.6904388670220031
0.741247508309104
0.6944584680333131
0.714555398768558
0.7031073393022407
0.7156988882306707
0.7308905742059862
0.6901741680644288
0.6933364879269635
0.69390742861154
0.8113686654878856
0.7049470628854967
0.7360183099006358
0.7863406239932744
0.7621332271676396
0.7018482363502796
0.7808290712587769
0.6831086887575161
0.6924546702211378
0.754191872446787
0.755079679504802
0.7114207797824282
0.7713104155961384
0.7474167572430516
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011513369,0.0045003626,-0.0021346977,-0.0147679085,-0.002514394,0.024524527,-0.015327829,0.01758151,-0.011345393,-0.034435123,0.00473133,0.015985737,-0.016111718,0.013592075,-0.003000825,-0.02514044,0.027996035,0.0064145913,-0.011548365,-0.014228985,-0.0036114885,0.017735489,-0.007009507,-0.038802505,0.0071354895,0.033735223,0.027940042,-0.015383821,0.022844765,0.0091547035,-0.0060471436,0.015313831,-0.037654668,-0.024272563,0.0012274511,-0.00013768363,0.01016956,-0.0008941234,0.0040419274,0.0044653676,0.011135423,0.006516077,0.0013411851,-0.014739912,-0.008013865,-0.008223835,0.015551797,-0.03989435,-0.008076856,-0.013466093,0.010386529,0.024958465,-0.019107293,-0.012647209,-0.016265696,-0.0030235718,-0.004857312,0.009231692,0.013725056,-0.014921887,0.021234993,0.018113434,-0.017707491,-0.001433047,-0.021584943,0.0045178602,-0.024762493,-0.012332253,-0.0140680075,0.0076289196,0.03451911,0.010246549,-0.010134565,-0.025728356,0.034743078,-0.007208979,-0.0035712442,-0.025798347,-0.013928028,0.016307691,-0.00093611743,-0.023418684,-0.015131857,0.020507095,0.012465235,-0.016867612,0.003494255,0.015523802,-0.013487089,0.0037444697,-0.0039859354,-0.00085300417,0.020297125,0.015243841,0.0077479025,-0.0058511714,-0.0086297775,0.026064308,0.0011408384,0.0098826,-0.007173984,-0.0035974905,-0.021011025,-0.009868602,-0.0147679085,0.0029343343,0.013760052,0.0037094746,0.005865169,-0.013340111,-0.036254864,0.035554964,0.011709342,-0.0381306,-2.5166357e-05,-0.009924594,0.007670914,-0.017875468,0.0037549683,-0.015999734,0.023670647,0.014459952,0.018043445,-0.008601782,0.012108285,-0.0065405737,-0.006208121,-0.011590359,-0.01723156,-0.013389104,0.001179333,0.010680487,0.0051057767,0.019163286,-0.015145855,0.017413534,-0.014375964,0.013319113,-0.025448397,-0.030515678,0.0076849116,0.005182766,-0.019611223,0.017959457,-0.0020454603,0.01602773,0.010981445,0.026330272,0.016993593,0.01299716,0.0021346977,-0.038298577,0.021766918,0.02922786,0.01658765,0.021095013,-0.029479824,-0.00932268,-0.021234993,-0.008153846,-0.007334961,0.013746053,0.00600165,0.018267414,0.010722482,0.010050576,0.014641927,-0.0052737533,0.012479233,0.0043148887,-0.011268404,0.03171951,-0.028835917,0.00053411187,-0.0070235054,0.01941525,0.021234993,-0.0057111913,-0.017469525,-0.025546381,0.017273553,-0.0017628754,0.0050322874,0.024958465,-0.019373257,-0.023754636,0.01688161,-0.012248266,0.0051792664,0.0019054802,0.018771341,0.016111718,-0.001793496,0.004990293,-0.6701131,-0.021906897,0.003877451,-0.025252424,0.015495805,0.016979596,-0.0020787057,-0.016279694,-0.032615382,0.012381246,-0.021165002,0.006771541,0.028010033,-0.028891908,-0.00727197,-0.026120301,-0.0030305707,-0.033287287,0.009707625,0.0028765926,-0.01871535,0.015971739,-0.019233275,-0.0090357205,-0.0015170352,0.028639944,0.0016193957,-0.016811619,0.018799337,0.0101485625,-0.009378672,0.033623237,0.005399735,0.015593791,0.043589827,-0.02098303,-0.007009507,0.015579794,0.00017617818,0.050392862,-0.033035323,-0.011940309,0.0049552983,0.00056473253,-0.011170418,0.0037724657,0.022354834,0.002521393,0.020143148,0.010659491,0.0120732905,0.015733771,0.009581643,0.008412808,0.020073157,-0.0204791,0.02315272,-0.011401385,0.011520368,0.008307823,0.0126052145,0.0051722676,-0.017077582,-0.0064355885,-0.00720198,0.026232285,-0.021179,0.013879035,-0.004689336,-0.045857504,-0.0068835253,0.017133573,-0.021528952,0.005417233,-0.011072432,0.02598032,0.015341828,0.016503662,0.017749486,0.018953316,-0.00042956416,-0.030767642,0.0041924063,0.020423107,0.033847205,-0.00073489593,-0.033203296,-0.008846747,-0.0047278306,0.0026718716,0.0077409036,0.019345261,-0.016573653,-0.019541232,0.0015135356,0.03642284,-0.009875601,0.01658765,-0.016279694,-0.015089863,-0.0023569162,-0.010743478,0.009728623,-0.0072649713,-0.010400527,0.005231759,0.0004781198,0.02775807,0.020017166,-0.020381114,0.0102675455,0.019219277,-0.011870319,0.01454394,-0.01229026,-0.033679232,0.040874213,-0.014214987,0.00084119337,-0.0073979525,0.0034277646,0.012766192,0.0077199065,-0.018379398,0.007642918,0.033007324,-0.014298975,-0.031159587,-0.013963022,0.008342818,0.022732781,-0.01829541,0.014291976,-0.012318255,0.017707491,-0.0005817926,-0.0005520468,0.0020297125,0.0042588967,-0.022508813,-0.004542357,0.011359391,0.001588775,0.017973455,-0.025882334,-0.003975437,-0.008027863,0.008083855,-0.0055152187,-0.008881742,-0.010827467,-0.021165002,-0.012465235,-0.020395111,0.005308748,0.008461801,0.0154118175,-0.031243576,-0.025812345,-0.02767408,0.0106734885,0.025644368,-0.015649784,0.017595507,-0.015565796,0.006869527,-0.0016885109,0.034267146,0.007327962,-0.022424825,0.014795905,-0.027884051,0.009616638,0.01320013,-0.0027768568,0.0025091446,0.0051057767,-0.013228127,-0.021318981,-0.014865895,0.0008862495,-0.0007987619,0.011702343,-0.00043415726,0.0144739505,0.009112709,0.02458052,0.01086946,-0.016755627,0.035107028,-0.0063026072,0.011982303,-0.01815543,-0.010204555,-0.00053061236,-0.007873884,0.008489798,-0.016657641,0.0024531526,0.015691778,0.016657641,0.019723207,0.008034862,-0.007243974,0.0071249907,-0.0183654,-0.0011802078,-0.014110002,0.019149289,0.01418699,0.026260281,-0.040006336,-0.021262988,-0.006869527,0.011968305,0.009847606,0.00022549932,0.011800329,-0.021528952,0.015621788,-0.035330996,0.0010069824,0.01257022,-0.00024912096,-0.018743346,0.010708484,-0.0034925053,0.019863186,0.014277978,-0.014865895,0.0060611414,0.027002176,-0.00057698076,0.03163552,0.021067016,-0.018057443,0.010456519,0.0059561566,0.002111951,0.002456652,-0.0049867937,0.0069675134,-0.015131857,0.005697193,0.036030896,-0.009196698,0.033679232,0.019219277,-0.026988178,-0.001624645,-0.01186332,0.009441663,-0.0035309999,-0.009091713,0.0091757,0.004822317,0.014256981,-0.006201122,-0.0039334428,0.0204791,0.006981511,0.020003168,0.033343278,-0.012276261,0.027884051,-0.0047348295,-0.012367249,-0.03233542,-0.022732781,0.003205546,-0.0136550665,-0.00038778884,0.005945658,-0.028052026,0.026036313,0.017119575,0.01714757,0.014753911,0.03423915,0.016195707,-0.03412717,-0.026918188,0.018911323,0.005287751,-0.009000725,0.0048643113,-0.022046877,0.010722482,-0.010288543,0.0074539445,0.021528952,0.017371539,-0.0037689663,-0.004829316,-0.018463384,0.0039649387,0.03135556,-0.011604357,-0.0012117034,-0.0060471436,0.0074539445,0.019695211,-0.0051057767,-0.04174209,0.01709158,-0.03135556,0.031159587,-0.007075998,-0.0169376,-0.019331262,0.006572069,-0.025294418,0.022326838,-0.018477384,0.014200989,0.0017103828,0.008160844,-0.017245557,0.030067742,0.018169427,0.00571819,-0.026246283,-0.024258565,0.00889574,0.06366298,0.05268854,-0.0057951794,0.01955523,-0.002358666,-0.0070794974,-0.013760052,-0.005501221,0.006834532,-0.004017431,-0.010218553,-0.019079298,0.018337402,-0.010918453,0.0051512704,0.0077479025,0.018197423,-0.01440396,-0.022648793,-0.039698377,-0.007075998,0.0075309332,0.041266154,0.031971473,0.008909739,0.006376097,0.028639944,0.014047011,-0.0134240985,-0.018267414,0.016055726,0.015775766,0.009700626,0.005980653,0.0028975897,0.037822645,0.00053717394,0.014326971,0.020563088,0.012010299,0.01539782,0.00875576,0.0074049514,-0.0052352585,-0.014837898,-0.0070724986,-0.011324396,-0.0010865962,-0.0015730272,-0.0130111575,-0.00023031113,-0.016335687,-0.043869786,-0.008062858,0.0110864295,0.0010271046,-0.017679496,-0.008377814,-0.004906305,-0.0003792588,-0.02655424,-0.023768634,-0.0035747436,0.0035747436,0.018239416,-0.01653166,-0.006684053,0.0048538125,-0.03043169,-0.008650775,-0.0124302395,-0.035862923,-0.0197652,-0.00508478,0.034155164,0.018379398,0.024496531,-0.007065499,-0.013844039,0.006645559,-0.005070782,-0.0027996036,-0.011415383,-0.0028468468,0.017469525,-0.0074679423,0.0012265763,-0.0032527894,-0.0055887084,0.0137740495,-0.0012152029,0.007971871,-0.0038844498,-0.020703068,-0.021808911,0.010365532,0.02173892,0.033287287,-0.009903598,-0.025406402,0.0073979525,-0.030095737,-0.021095013,-0.009014723,-0.005641201,-0.0063516004,0.0043253875,-0.008034862,-0.010141564,0.003219544,0.03183149,-0.012500229,0.011961306,0.003607989,0.00550822,0.03029171,0.00141205,0.00946266,-0.019009307,-0.024258565,0.011303399,-0.024608515,0.0060121487,0.0038039612,-0.03353925,0.012598216,0.017665498,0.0061206333,-0.03325929,0.015187849,-0.013606073,0.048181176,-0.016209705,-0.0017471275,-0.016223703,-0.0002543702,-0.013158136,-0.0034505113,-0.012409243,-0.0032807854,0.006579068,-0.020059159,-0.010463518,-0.009952591,0.0035187516,-0.03353925,-0.012451236,0.024230568,0.0048188176,0.0106734885,0.002796104,-0.0074679423,-0.0057286886,-0.007229976,0.0005572961,-0.019611223,-0.004524859,0.007880884,0.011471376,0.027058167,0.021206997,-0.0077339048,0.016461669,0.010939451,-0.014781906,0.00016207079,0.0007887008,0.021109011,-0.01334711,0.035638954,-0.0034890058,-0.0076359184,-0.014417958,0.0070445025,0.026652226,0.007418949,-0.017693494,-0.018673355,-0.029395837,-0.028625946,0.016629646,0.0130111575,-0.008965731,-0.0037899632,-0.02175292,0.002661373,0.0028870911,0.004552855,-0.0016972596,-0.010659491,0.0060366453,-0.0075939246,0.023376688,-0.0022256847,0.01829541,-0.017707491,-0.030655658,-0.02852796,0.010218553,0.031159587,-0.01856137,0.02634427,0.017959457,-0.008643776,0.003989435,-0.002803103,0.0023674148,0.008314823,-0.0047523268,-0.013270121,0.01658765,-0.023040736,-0.025742354,-0.007845889,0.004059425,0.012556221,-0.011695344,0.013088146,0.006834532,-0.021318981,0.020311123,-0.0037934626,0.048685104,0.022830766,0.023110727,0.02507045,0.0013963023,0.0037654666,0.001666639,0.0038809504,0.013480091,0.01927527,0.009840607,-0.0102675455,-0.021822909,0.0043043904,0.017637502,-0.024692504,-0.017203564,-0.01122641,0.0019824693,0.002514394,-0.0025686363,-0.008307823,0.011849321,-0.0034907556,-0.010988444,0.008440805,0.018085439,-0.011947308,-0.0031897982,0.026652226,0.018281411,0.02732413,-0.010253548,0.003086563,0.0041679097,0.009434664,0.023572661,0.013522085,-0.020241134,0.029451828,-0.009203697,-0.005875668,0.024440538,-0.0054207323,0.015509804,-0.007229976,0.0042868927,0.030515678,-0.014753911,0.0121362815,-0.0065300753,0.00642509,0.0070235054,-0.007369956,-0.0014199239,-0.008727764,-0.009700626,0.023558663,0.012647209,0.008307823,-0.031019608,-0.003135556,-0.0020699569,-0.01228326,-0.0012694452,0.006113634,-0.0011023439,-0.033567246,-0.027226144,-0.008300824,0.016265696,0.03664681,-0.0054767244,-0.023642652,0.012052293,0.01751152,-0.032027464,0.016307691,0.018953316,-0.012598216,-0.019107293,0.011688344,-0.018575368,-0.0360029,0.010750477,-0.017539516,-0.038634527,-0.02535041,0.0016045228,-0.0045178602,0.0022746779,-0.022018882,-0.0058336738,-0.005620204,0.003382271,0.003473258,-0.02556038,0.016783623,0.009623637,0.002831099,0.015971739,-0.014207988,0.01856137,-0.020171143,-0.0169376,-0.002195939,-0.044233736,-0.026848197,-0.02238283,-0.008748761,-0.008552789,-0.0022064375,-0.009455661,-0.0071284906,-0.014417958,0.0072369752,0.0017873718,-0.0063551,-0.004962297,0.009007724,0.00367098,0.012437238,-0.021416968,-0.008160844,-0.0022484316,0.02252281,-0.027436115,-0.014312973,-0.014921887,0.040790223,0.017021589,-0.015117859,-0.0064740833,-0.0062816106,-0.03141155,0.0023411685,0.004794321,0.0005747936,-0.0076779127,0.0074819406,0.012038295,0.036254864,-0.0032580385,-0.006572069,0.0029325846,0.010050576,-0.02096903,-0.020031163,0.0059211613,0.003333278,-0.021123009,0.0026508747,-0.0021154503,-0.015551797,0.022494813,-0.005466226,-0.0169516,-0.017931461,0.008909739,0.03135556,0.029955758,0.02393661,0.021500954,-0.02280277,-0.013718057,0.02040911,-0.015173851,-0.014753911,-0.023376688,0.010386529,0.0015494055,0.012423241,-0.002484648,-0.029003892,0.012416242,0.004143413,-0.005382238,0.003191548,0.029619806,0.033007324,0.014753911,-0.019387254,-0.0040279296,0.02556038,-0.0233067,-0.0043428848,0.022172859,-0.029955758,0.0060541425,-0.0162377,-0.01983519,-0.018533375,-0.016013732,-0.011800329,-0.0017628754,-0.004636843,0.0141239995,0.019037304,-0.023320697,0.025154438,0.009840607,0.0015879001,-0.018267414,-0.0045178602,0.00720198,-0.01956923,0.003649983,0.005938659,-0.019149289,-0.010582501,0.006607064,0.017245557,0.01800145,0.010736479,0.23158321,-0.018659357,-0.013382105,0.012038295,0.018057443,0.002526642,0.023250706,0.019261273,0.00019564417,0.010680487,0.009126707,0.019961173,0.00473133,-0.0076149213,0.022732781,-0.01744153,-0.022536809,-0.008405809,0.004643842,0.017721491,0.013998018,-0.009161702,-0.0047628256,-0.0225928,0.042945918,-0.011079431,-0.009903598,0.0028398477,0.00600165,0.0069780117,-0.0075379326,-0.003070815,0.021053018,0.0012195773,-0.014305974,-0.00047418283,0.021724923,-0.008671772,0.012612213,0.0015004125,0.037094746,-0.024972463,-0.0016981345,-0.012108285,0.012815185,0.022886759,-0.019891184,-0.020381114,0.028192008,0.015551797,-0.01658765,-0.005280752,0.002768108,0.029031888,0.008328821,-0.009798612,-0.011618354,0.0024951466,0.012367249,-0.01983519,-0.024272563,0.008020864,-0.008419808,0.022690786,-0.001377055,-0.0015564045,-0.0068030367,-0.010127566,0.018127432,-0.015719773,-0.015481807,-0.01539782,-0.0075869253,-0.012871177,-0.029507821,-0.015775766,0.02908788,-0.00037204105,0.02280277,0.029003892,-0.020633077,-0.0008486298,-0.0010909705,-0.014445954,-0.009063716,-0.021276986,0.03552697,-0.0061556282,-0.0064635845,-0.0069010225,-0.016195707,0.014103003,-0.011975304,0.009966589,-0.0009492406,0.00019969048,0.010470517,0.0126052145,0.00543473,0.0012038295,-0.02598032,0.07637318,0.007048002,-0.003042819,0.00031626772,0.010176559,0.00211895,0.023054736,0.005550214,-0.011338394,0.001963222,-0.018057443,0.00084119337,-0.021374973,-0.012206271,0.0027978537,0.023628654,-0.006218619,0.015649784,0.0016430173,-0.030459685,-0.013046152,-0.008496797,0.011205413,0.0037794646,-0.0065650702,0.007020006,-0.0018897323,-0.017315548,-0.006971013,0.0047523268,-0.0197652,0.008811752,0.015551797,-0.010456519,-0.022578802,-0.017385539,-0.008930735,0.017889466,-0.005126774,0.0020454603,0.016153712,-0.005760184,-0.0112964,-0.013466093,-0.00995959,-0.0123112565,0.009091713,0.006701551,0.0003538874,-0.004878309,0.012787189,-0.009840607,-0.015831757,0.006127632,-0.012297259,0.015985737,0.002344668,0.002922086,-0.005035787,-0.023628654,0.0046403427,0.0095046535,-0.01864536,-0.014228985,-0.01850538,-0.18242216,0.008951732,0.022354834,-0.03771066,0.010897457,0.0010061075,0.028751928,-0.012367249,-0.044177745,0.015635785,0.034967046,-0.012906172,-0.030319706,-0.0026316273,-0.005350742,-0.012808186,-0.008797754,-0.002838098,0.0035572462,0.013739054,0.04773324,-0.020255132,-0.0025581378,0.0070689986,-0.017847473,-0.0029833275,0.0043883785,0.023026738,0.015313831,-0.030907623,-0.009000725,-0.003466259,0.017833475,-0.0057111913,-0.008503796,-0.0038844498,0.004426873,-0.021920895,-0.021151004,-0.00083550665,0.020297125,0.01679762,0.015019873,-0.0017515019,-0.015509804,0.0025248923,0.023432681,-0.0132491235,0.0054242318,-0.028835917,0.0024094088,-0.007037503,0.011695344,-0.0065650702,0.0019789697,0.0055117193,-0.0063585993,-0.019261273,0.0044373716,-0.004643842,0.0021941892,-0.005361241,0.012010299,0.018533375,0.0051652687,0.0062151197,9.0330956e-05,0.014935885,-0.04090221,0.009378672,-0.008811752,-0.00522476,-0.011240408,-0.0048678108,0.002139947,0.035862923,-0.018449387,-0.009476658,0.0033490257,-0.022186859,-0.008664773,0.018225418,-0.0074679423,-0.0017313798,-0.0042029046,-0.0045283586,-0.00045012374,0.037934627,-0.007971871,-0.013508087,0.02061908,-0.04745328,-0.004489864,-0.014501946,-0.0014741662,0.018337402,0.014249981,-0.021416968,0.015215845,-0.004766325,0.013613072,0.00029920763,-0.0016552656,-0.00029373963,0.030627662,0.0032387914,0.0029185866,0.015075865,0.03376322,-0.0063026072,-0.026736213,-0.021850904,0.00010339942,0.003908946,0.01440396,0.028136015,-0.0074889394,0.009945592,0.009805611,-0.006701551,0.06595866,0.0018984812,-0.013823043,0.014417958,-0.009056717,-0.022844765,-0.116463505,-0.046417426,-0.004531858,-0.003070815,-0.008349817,0.02428656,-0.008090854,0.001644767,-0.028919904,0.031747505,-0.0169516,-0.03015173,0.023908613,0.0018547373,-0.004293892,-0.03275536,0.003114559,-0.006582568,-0.027800063,0.03325929,-0.0121362815,-0.021430966,0.0064215907,-0.021011025,0.012353251,0.004318388,-0.033623237,-0.008293825,0.0036604817,-0.0069850106,0.010246549,-0.010561504,0.014571936,3.2479777e-05,-0.0037269723,-0.02351667,-0.004857312,-0.010372531,0.020367116,-0.017889466,0.011170418,-0.0037724657,-0.0007327087,-0.0088607455,-0.03947441,-0.022046877,-0.007180983,0.020773059,0.030123733,-0.021374973,-0.036982764,0.012038295,-0.01955523,0.0044373716,0.009525651,-0.0028888409,-0.0034347635,0.0047978205,0.0045283586,0.012794188,-0.01885533,0.0070689986,-0.009497655,-0.0015117859,0.01086946,-0.02973179,-0.00345926,-0.015733771,0.011450378,-0.020563088,-0.0050602835,-0.0032212937,-0.009049718,0.011835324,-0.015635785,-0.01398402,-0.0120033,-0.021109011,0.005406734,-0.0044793654,-0.005690194,-0.011751336,-0.009259689,-0.01433397,0.018309407,-0.003663981,-0.025392404,-0.017917462,0.011121425,-0.008447804,0.00060497684,0.03205546,0.010351534,-0.027548099,0.019107293,0.014585935,-0.028289994,-9.9954595e-05,0.008538791,0.010414525,-0.02746411,-0.007020006,-0.047145322,0.028066026,-0.0030830633,-0.03412717,-0.015621788,-0.005018289,0.008748761,-0.008167843,-0.012479233,0.020199139,-0.016279694,0.010778474,-0.014305974,-0.003100561,-0.01730155,-0.012227268,0.018841332,-0.011912313,-0.0036044896,-0.00508128,0.015285836,-0.0015607789,0.012206271,0.011499371,-0.012353251,0.00096761296,-0.010526509,0.012724198,-0.012108285,-0.0130111575,-0.0037199731,-0.022116868,0.0034750078,0.023110727,-0.0008088229,0.00127032,-0.013214128,0.03297933,0.02725414,0.022060875,-0.0034487615,-0.032615382,-0.0006684053,-0.018911323,-0.003642984,-0.010533508,-0.005763684,-0.0076219207,-0.0076079224,-0.0017313798,0.024804488,0.0065125776,-0.00720198,-0.039782368,0.0065650702,0.02018514,-0.009819609,-0.017973455,-0.0065055788,0.004699834,0.043869786,-0.012185275,-0.004531858,-0.0009387421,0.0067400453,-0.009042719,-0.0032300425,0.010484515,0.018477384,-0.0038144598,0.0074889394,0.008447804,-0.003070815,0.017609507,-0.009021723,-0.020507095,0.009483657,0.001786497,0.0030060743,0.03289534,0.012878176,0.0014216737,-0.0096796295,-6.7474815e-05,0.0047278306,0.00473133,-0.010736479,0.008678771,-0.008811752,0.0049028057,0.028751928,0.014033013,-0.014375964,0.011800329,-0.015481807,-0.018547373,-0.004580851,-0.009483657,0.0154118175,0.0225928,-0.007306965,-0.0014234234,-0.0068450305,-0.03029171,-0.025546381,0.023110727,-0.012675205,-0.037878636,-0.004815318,0.033287287,0.032783356,-0.0020577086,0.0014304224,0.009238692,-0.018267414,0.024272563,-0.011562362,-0.023180718,-0.03622687,0.020101152,0.025966322,0.0010865962,-0.0026526244,-0.008580784,0.011660349,0.032951333,0.024706502,-0.009490656,0.0062221186,0.029423833,0.0005345493,0.0012755693,-0.00508128,-0.008230834,-0.018127432,-0.025658365,-0.018309407,0.0077199065,0.015215845,0.068646275,0.015859755,-0.008657774,0.01991918,-0.022200856,0.020465102,0.034407128,-0.004636843,-0.024160579,-0.012262263,-0.012325254,0.010393528,-0.014137997,0.0058231754,0.0024619014,0.017287552,-0.008454802,0.0035397487,-0.01800145,0.017763484,0.008482799,-0.0031530533,0.023502672,-0.0027488607,-0.017693494,0.015215845,0.006152129,0.006820534,0.0027366125,-0.016153712,0.025756352,0.014207988,-0.024818486,-0.02224285,-0.008244832,0.011856321,-0.0060086492,-0.03493905,-0.0029850772,0.0028713434,-0.0067540435,-0.021808911,-0.017469525,0.0033840206,-0.0098546045,0.00897273,-0.010442521,-0.019527234,-0.015789764]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.7390438993128231
0.7034688077232469
0.7575022935077717
0.7170697935033027
0.7620237775013095
0.7551038582520161
0.702029779528635
0.7984785244326585
0.7420271435345909
0.7158142969571629
0.69015447622665
0.7078310102827019
0.7624698599449515
0.7128210485708508
0.7834635129459262
0.7104773002186665
0.7149598656100533
0.8019594623618095
0.7814540695621124
0.8051607434794458
0.7250028166152883
0.7116610867114227
0.7014605279018151
0.7467818865813173
0.6826957252395864
0.7273419153542122
0.7289934085848205
0.7241540709680373
0.704078648689104
0.7029650233329102
0.699776547210036
0.7178938495797688
0.7123102951227991
0.7616361324556999
0.7007701257814158
0.6785604063404755
0.749792254461876
0.7151815109451772
0.7196987063158655
0.7117564901477462
0.7321985584971055
0.681726201261039
0.7214087158786903
0.7060672170877768
0.7383778590035024
0.7045931155868921
0.7060703591559001
0.7250942906518373
0.705632010816697
0.7708149368727338
0.681831143848112
0.7155726080971828
0.7711041872076196
0.738997687789034
0.7412811078052394
0.7429940543862276
0.7614692128232242
0.7514540072004502
0.7373050023438827
0.728170938591483
0.7744146983498797
0.7658174185751951
0.7012306511487078
0.7079377644737277
0.7410533081081907
0.7357181420755532
0.7231471824556627
0.7089531743891528
0.7720101548661807
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011355565,0.004479188,-0.00216605,-0.014750853,-0.0025687916,0.024528721,-0.015283172,0.01759456,-0.011332802,-0.034432665,0.004773365,0.016039627,-0.016137686,0.013567142,-0.0030048033,-0.025089057,0.027960781,0.006366821,-0.011556936,-0.014260558,-0.0036421858,0.017748652,-0.0070392247,-0.038775273,0.007091756,0.03376026,0.027876731,-0.015409248,0.022819696,0.009140486,-0.0060726446,0.015311189,-0.037738647,-0.024248553,0.0012493748,-0.00014829212,0.0101490915,-0.0008961003,0.004027417,0.004479188,0.011129679,0.006545428,0.0013518113,-0.014750853,-0.007963779,-0.008222935,0.015507307,-0.039895944,-0.008033821,-0.013455075,0.010408247,0.024920957,-0.019121476,-0.012635583,-0.016235745,-0.0030118076,-0.004850411,0.00923154,0.013707226,-0.014904945,0.021222737,0.018140888,-0.017706627,-0.001409596,-0.021600964,0.0045282175,-0.024738846,-0.01231339,-0.014085454,0.007634582,0.034544732,0.010254154,-0.0101350825,-0.025705427,0.03474085,-0.007221334,-0.0035318697,-0.02576146,-0.0139103485,0.016333804,-0.0009017912,-0.023380032,-0.015087055,0.020466283,0.012467482,-0.01688013,0.0035021019,0.015521315,-0.013504105,0.0037017216,-0.003988894,-0.0008374401,0.020340208,0.015255155,0.007767662,-0.0057924762,-0.008636183,0.026055638,0.0011574447,0.009805885,-0.0071372837,-0.0036071648,-0.021040628,-0.00984791,-0.014736844,0.0029330102,0.013749252,0.0036982195,0.005873025,-0.013357016,-0.036169708,0.035525322,0.011711028,-0.038130883,-5.119088e-05,-0.009910949,0.007676607,-0.017846711,0.0037717638,-0.015941568,0.023688216,0.014442668,0.018084854,-0.008650191,0.012103264,-0.0065209134,-0.006216231,-0.011612969,-0.017272366,-0.013385033,0.0012143538,0.010709427,0.0051235748,0.0191635,-0.01512908,0.017440466,-0.014386634,0.013293979,-0.025439268,-0.030566344,0.007662599,0.005197119,-0.01962578,0.017930761,-0.0020574848,0.016039627,0.010954575,0.02629378,0.01696418,0.012999802,0.0021748052,-0.038214933,0.021755056,0.02919352,0.016543929,0.021068644,-0.029529722,-0.009350612,-0.021180712,-0.008124876,-0.0073754266,0.013742248,0.005985092,0.018224938,0.010716432,0.010037024,0.014638785,-0.0052846717,0.012495499,0.004286573,-0.011269764,0.031715035,-0.028801285,0.0004994873,-0.0069901953,0.019429661,0.02119472,-0.005676907,-0.01751051,-0.025523318,0.01724435,-0.0017326649,0.0050465288,0.025005007,-0.019331602,-0.023772268,0.01688013,-0.012271365,0.0051866127,0.0019226539,0.018785274,0.016137686,-0.001822844,0.0049694823,-0.6701622,-0.02189514,0.003852312,-0.025271166,0.015535324,0.016992198,-0.0020749953,-0.01626376,-0.03263959,0.01239744,-0.021152696,0.0067800693,0.028030822,-0.028913353,-0.007256355,-0.026125679,-0.0030485797,-0.033255957,0.009672805,0.002852462,-0.018673208,0.01591355,-0.01926156,-0.009049431,-0.001529543,0.028619176,0.0016468634,-0.01681009,0.018813292,0.010142087,-0.00936462,0.033648193,0.005400241,0.015633382,0.043594163,-0.021026619,-0.0069901953,0.015577349,0.00018331314,0.050458282,-0.033031825,-0.011949171,0.0048994403,0.00053275726,-0.011192718,0.003754253,0.02234341,0.0025337706,0.02014409,0.010653393,0.012061238,0.015759459,0.009595759,0.008419053,0.020088056,-0.020480292,0.023169905,-0.0114588775,0.0114728855,0.008299981,0.012614571,0.005242646,-0.017048232,-0.0064193527,-0.007200321,0.026237747,-0.021152696,0.01389634,-0.004678808,-0.04583551,-0.0068676216,0.017146291,-0.021572948,0.0053827306,-0.011059637,0.025985595,0.015325198,0.016459879,0.017734643,0.018953376,-0.00043601167,-0.03079048,0.0042095263,0.020382233,0.03387233,-0.0007411323,-0.033255957,-0.0088533135,-0.004710327,0.0026931162,0.0077186325,0.019359618,-0.016585954,-0.019569745,0.0014848912,0.036421858,-0.009875927,0.016557937,-0.016221736,-0.015087055,-0.0023253956,-0.010779469,0.009728839,-0.0072423466,-0.010387234,0.005263659,0.0004697194,0.027778672,0.020032022,-0.020382233,0.010289175,0.019219534,-0.011872125,0.014498701,-0.012278369,-0.03367621,0.040904548,-0.01424655,0.00084400654,-0.0073894346,0.0034075452,0.01279668,0.007732641,-0.01837903,0.0076555945,0.033031825,-0.01429558,-0.031182714,-0.013959378,0.008335003,0.022721637,-0.018266963,0.014281571,-0.012306386,0.017720636,-0.0005791601,-0.0005305684,0.0020364723,0.0042725643,-0.02251151,-0.0045317197,0.011304785,0.0015768213,0.017972786,-0.02592956,-0.004027417,-0.008005804,0.008068843,-0.0054983,-0.008874326,-0.010849511,-0.021180712,-0.012418453,-0.020382233,0.0052811694,0.00844707,0.015381231,-0.031182714,-0.025817495,-0.027680613,0.010660398,0.025635386,-0.015703425,0.01758055,-0.015563341,0.006836103,-0.00164949,0.034264565,0.0073193926,-0.022455476,0.014792878,-0.027834706,0.009644789,0.013188915,-0.0027876731,0.002505754,0.005085052,-0.013202924,-0.02127877,-0.014876928,0.0008580149,-0.0008102988,0.011690016,-0.000429883,0.01451271,0.009105464,0.024598762,0.010884533,-0.016754055,0.03510507,-0.0063107875,0.011928159,-0.018140888,-0.010240146,-0.0005323195,-0.007893737,0.008461078,-0.016641987,0.002444467,0.015675407,0.016655996,0.019681811,0.008068843,-0.0072493507,0.0071162707,-0.018407047,-0.001119797,-0.014106466,0.019107467,0.014190516,0.026251756,-0.040036026,-0.02127877,-0.0068851323,0.011956176,0.009819893,0.00022413452,0.011809087,-0.021502905,0.015591357,-0.035329204,0.0010068542,0.012600563,-0.00028979892,-0.018743249,0.010695419,-0.0034793383,0.019891938,0.014253554,-0.014876928,0.0060621384,0.026980191,-0.00057959784,0.031602968,0.021040628,-0.018056838,0.010436263,0.005953573,0.0021362822,0.0024637287,-0.0049729845,0.006986693,-0.015101063,0.0056593963,0.03597359,-0.009196519,0.03367621,0.019219534,-0.026980191,-0.0015750703,-0.011837104,0.009455675,-0.0035406249,-0.009098461,0.009140486,0.0048223943,0.014288575,-0.006163699,-0.0039293584,0.020480292,0.0069936975,0.020018013,0.03334001,-0.012264361,0.027918756,-0.0047348416,-0.01239744,-0.03235942,-0.022707628,0.00319917,-0.013630181,-0.00042244102,0.0059360624,-0.028002806,0.026041629,0.017146291,0.017160298,0.014750853,0.034180515,0.01619372,-0.034068447,-0.026938166,0.018939367,0.0053161904,-0.0089933975,0.0048924363,-0.02207725,0.01073044,-0.0103312,0.007466481,0.021516914,0.017370425,-0.0037612573,-0.004853913,-0.018491097,0.0039293584,0.03137883,-0.0115849525,-0.0012169804,-0.00604813,0.00743146,0.019639786,-0.0051095667,-0.041717038,0.01706224,-0.031350814,0.031126682,-0.007091756,-0.016922155,-0.01934561,0.0065174117,-0.02524315,0.022301385,-0.018449072,0.014162499,0.0017274118,0.008117872,-0.017258357,0.030118076,0.018154895,0.0056909155,-0.026279772,-0.02426256,0.008888334,0.06376627,0.05269963,-0.0057644597,0.019555736,-0.0023884333,-0.0070672412,-0.013749252,-0.0054527726,0.0068220943,-0.004027417,-0.0101911165,-0.019023417,0.018337006,-0.010898541,0.005162098,0.0077536535,0.018196922,-0.014400642,-0.022665603,-0.039643794,-0.007042727,0.0075575355,0.041268766,0.031995203,0.008909347,0.0064088465,0.028647194,0.0140224155,-0.013427058,-0.018266963,0.016039627,0.015787475,0.009700822,0.005995598,0.002926006,0.037850715,0.00051743555,0.014344609,0.020550333,0.012005205,0.015409248,0.008776267,0.00743146,-0.00529868,-0.014806886,-0.007091756,-0.011304785,-0.0010926558,-0.001547929,-0.013020814,-0.00023529747,-0.016319795,-0.0438183,-0.00809686,0.011073646,0.0010392487,-0.017664602,-0.008419053,-0.0049099466,-0.00035283677,-0.026489899,-0.023800284,-0.0035808992,0.0035598865,0.018224938,-0.016529921,-0.006713529,0.004808386,-0.030398244,-0.008699221,-0.012453474,-0.035833504,-0.019751854,-0.0050815498,0.03412448,0.018407047,0.024472687,-0.0070812497,-0.01381229,0.0066539934,-0.00509906,-0.0028279473,-0.011423856,-0.0028804787,0.017440466,-0.0074104476,0.0012336153,-0.0032464485,-0.005571844,0.013798282,-0.0011933412,0.007963779,-0.003887333,-0.020732442,-0.021797081,0.010387234,0.02172704,0.033283975,-0.009917952,-0.025425259,0.0073894346,-0.030090058,-0.021040628,-0.009021414,-0.00563138,-0.0063423063,0.0043321,-0.008061838,-0.0101771075,0.0032236846,0.031799085,-0.012488495,0.011977188,0.003614169,0.0055298186,0.03034221,0.0013833302,0.0094977,-0.01900941,-0.02427657,0.011283772,-0.024584755,0.0060621384,0.0038032825,-0.033564143,0.01257955,0.017622577,0.006100661,-0.033227943,0.01521313,-0.013595159,0.04818892,-0.016165702,-0.0017650593,-0.016249752,-0.00026090659,-0.013167903,-0.0034898445,-0.012411449,-0.0032464485,0.0065769474,-0.020046031,-0.010492297,-0.009938965,0.0034950976,-0.033564143,-0.012467482,0.024206528,0.004773365,0.010688415,0.0027789178,-0.0074524726,-0.0057679615,-0.007200321,0.00059010414,-0.019597761,-0.004479188,0.007872725,0.0114868935,0.027064243,0.021208728,-0.0076836115,0.016431862,0.010961578,-0.014736844,0.00018790965,0.0008304359,0.021068644,-0.013364021,0.035609372,-0.0034915954,-0.007662599,-0.014442668,0.0070812497,0.026672008,0.0074524726,-0.017692618,-0.01864519,-0.029417654,-0.0286612,0.016613971,0.012978789,-0.008979389,-0.0037402448,-0.021741048,0.002644087,0.002889234,0.0045492304,-0.0017274118,-0.010702423,0.0060411254,-0.0075785485,0.023408048,-0.0022606067,0.01829498,-0.017762661,-0.030650396,-0.028521117,0.010219133,0.031126682,-0.01854713,0.026321797,0.017930761,-0.008650191,0.0039713834,-0.0028419555,0.0023201425,0.008299981,-0.0047348416,-0.013293979,0.016557937,-0.023015814,-0.025747452,-0.007809687,0.0040729446,0.012551533,-0.011683011,0.013069844,0.006878128,-0.02136282,0.02031219,-0.0038067847,0.048665207,0.022847712,0.023099864,0.025075048,0.0013526868,0.003747249,0.0016407347,0.00391535,0.013490096,0.019303584,0.00984791,-0.0102051245,-0.0218251,0.004339104,0.017608568,-0.024682814,-0.017188316,-0.011178709,0.002029468,0.0024987496,-0.0025670407,-0.008306986,0.011865121,-0.0034495704,-0.010961578,0.008440065,0.018084854,-0.011907146,-0.0031869127,0.026643991,0.018210929,0.027302386,-0.010240146,0.00309936,0.0041394844,0.009392637,0.023534125,0.01354613,-0.02022814,0.029417654,-0.009217532,-0.005918552,0.024416653,-0.0053722244,0.015521315,-0.0072493507,0.0042795683,0.030538328,-0.014750853,0.012152294,-0.006569943,0.0064543737,0.007053233,-0.0073824306,-0.001463003,-0.008720233,-0.009721834,0.02356214,0.0126706045,0.008292977,-0.03104263,-0.0031553938,-0.0021117674,-0.012264361,-0.0012511258,0.006156695,-0.0011355565,-0.03359216,-0.027302386,-0.008306986,0.016235745,0.036617976,-0.005466781,-0.023618175,0.012110268,0.017552534,-0.032051235,0.01634781,0.0189954,-0.012614571,-0.01917751,0.011669003,-0.018603165,-0.035945572,0.010744449,-0.017552534,-0.03860717,-0.025383234,0.0016048382,-0.004535222,0.0022448474,-0.0219932,-0.005852012,-0.005603363,0.0034075452,0.0034863423,-0.025607368,0.016782071,0.009651792,0.0028402046,0.015997602,-0.014267563,0.018519115,-0.02014409,-0.016936164,-0.0021800583,-0.044266567,-0.026840108,-0.022385435,-0.008699221,-0.008538124,-0.002195818,-0.009455675,-0.0071022627,-0.014400642,0.007256355,0.0017703124,-0.0063773273,-0.0049659805,0.009049431,0.0036561943,0.012467482,-0.02144687,-0.008138885,-0.0022851215,0.022455476,-0.027470486,-0.014337605,-0.014932962,0.040820498,0.017048232,-0.01512908,-0.006503403,-0.006303783,-0.03140685,0.0023534123,0.004790875,0.00061155454,-0.007599561,0.007459477,0.012068243,0.036253758,-0.003302482,-0.0065664407,0.002922504,0.010016011,-0.020956578,-0.020046031,0.005960577,0.0033217436,-0.021096662,0.002652842,-0.0020925058,-0.015577349,0.022497501,-0.005456275,-0.016936164,-0.017902745,0.0088813305,0.0313228,0.029949974,0.023954377,0.021474889,-0.022791678,-0.013714231,0.020368224,-0.01521313,-0.014764861,-0.02339404,0.010401242,0.0015575598,0.012425457,-0.0024619775,-0.02902542,0.012432462,0.0041079656,-0.0053477096,0.0031869127,0.029585756,0.033003807,0.014708827,-0.019401643,-0.003992396,0.025551334,-0.023253957,-0.004335602,0.022147292,-0.029977992,0.006055134,-0.01626376,-0.019821897,-0.018505106,-0.016025618,-0.011795079,-0.0017685614,-0.0046612974,0.014148491,0.019023417,-0.023323998,0.0251591,0.009791877,0.0015671905,-0.018238947,-0.0045842514,0.0071688024,-0.019555736,0.0036001606,0.005953573,-0.01917751,-0.01059736,0.0066119684,0.01724435,0.017958779,0.010744449,0.23153095,-0.018673208,-0.013392038,0.012075247,0.018014811,0.0025477791,0.023281973,0.01926156,0.00020323135,0.010674407,0.009098461,0.019961981,0.0047278376,-0.007599561,0.022735644,-0.01742646,-0.02251151,-0.008370023,0.004643787,0.01767861,0.013966382,-0.009161498,-0.0047348416,-0.022581553,0.042949777,-0.011045629,-0.009875927,0.002820943,0.005985092,0.006941166,-0.0075225146,-0.0030485797,0.021068644,0.001202972,-0.014316592,-0.00043294733,0.021755056,-0.008678208,0.012621575,0.001531294,0.03703823,-0.025005007,-0.0017020215,-0.012103264,0.01279668,0.022861721,-0.019905947,-0.020424258,0.028170908,0.015535324,-0.016613971,-0.005288174,0.0027386437,0.029053437,0.008327998,-0.009840906,-0.011612969,0.002479488,0.012355415,-0.019807888,-0.024248553,0.008061838,-0.008454074,0.022665603,-0.0014069694,-0.0015654395,-0.0067870733,-0.010107066,0.018168904,-0.015703425,-0.015521315,-0.015409248,-0.007599561,-0.012831701,-0.029501706,-0.01574545,0.02910947,-0.00037647595,0.022805687,0.028969387,-0.020648392,-0.00082693377,-0.0010891537,-0.014400642,-0.009098461,-0.02129278,0.035525322,-0.0061496906,-0.0065139094,-0.006874626,-0.016137686,0.0140924575,-0.011991196,0.010002003,-0.00094819407,0.0002084845,0.010457276,0.0126285795,0.005470283,0.0011968433,-0.02592956,0.0763178,0.007053233,-0.0030520817,0.00030971714,0.0101490915,0.0021135185,0.023085855,0.0055578356,-0.011353814,0.0019646792,-0.01811287,0.00083787786,-0.021390839,-0.012236344,0.0027596562,0.023604166,-0.006191716,0.015633382,0.0016004605,-0.030454278,-0.013034823,-0.008489095,0.011199721,0.0037892743,-0.00659796,0.007056735,-0.0018876329,-0.017300382,-0.006986693,0.0047593564,-0.019751854,0.0088112885,0.015563341,-0.010457276,-0.02259556,-0.017370425,-0.008888334,0.017888736,-0.0051095667,0.0020452274,0.016165702,-0.0057889745,-0.011290777,-0.01341305,-0.009903944,-0.01231339,0.009049431,0.0067205336,0.00035524444,-0.0048924363,0.012775667,-0.009833902,-0.0158295,0.006146189,-0.012334403,0.015955577,0.0023271467,0.0029049935,-0.0049974993,-0.023618175,0.004647289,0.009483691,-0.018659199,-0.014218533,-0.018505106,-0.18266962,0.008979389,0.02234341,-0.037710633,0.010884533,0.0010059788,0.028773269,-0.012369423,-0.044182517,0.015619374,0.03490895,-0.01292976,-0.03025816,-0.0026773568,-0.005368722,-0.0128106885,-0.008818292,-0.0028454578,0.0035721438,0.01376326,0.047712635,-0.020256156,-0.0025670407,0.0070707435,-0.01786072,-0.0030188118,0.0044126483,0.023057839,0.015325198,-0.03087453,-0.008986393,-0.0034513213,0.017846711,-0.0057434468,-0.00848209,-0.0039188517,0.0044056443,-0.021937165,-0.021152696,-0.00081467646,0.020298183,0.016852114,0.015003004,-0.0017659349,-0.015521315,0.0025372729,0.023436066,-0.013244949,0.005463279,-0.028829303,0.0024024418,-0.007049731,0.011725036,-0.006538424,0.0020347212,0.005533321,-0.0063843317,-0.01926156,0.0044476693,-0.004622774,0.0021905648,-0.005375726,0.011984193,0.018533124,0.005200621,0.006216231,8.481653e-05,0.014904945,-0.040848516,0.009329599,-0.008776267,-0.0051866127,-0.011227738,-0.0048223943,0.00213278,0.035833504,-0.01847709,-0.009476688,0.0033269967,-0.0221613,-0.008629179,0.018266963,-0.0074454686,-0.0017554285,-0.0042130286,-0.0045492304,-0.00047365928,0.037934765,-0.007977788,-0.013483092,0.020620376,-0.047460485,-0.0044896947,-0.014484693,-0.0014288576,0.018337006,0.014239546,-0.02144687,0.015199122,-0.0047768666,0.013609167,0.00028235695,-0.0016477389,-0.0003101549,0.030566344,0.0032446973,0.0029452676,0.015101063,0.033732243,-0.0063318,-0.026714033,-0.02181109,0.00013078161,0.0039048435,0.014386634,0.028128881,-0.007508506,0.009910949,0.009791877,-0.0067275376,0.06595158,0.001891135,-0.013826298,0.014456676,-0.009063439,-0.022847712,-0.11643788,-0.04642386,-0.004500201,-0.0030485797,-0.008370023,0.02427657,-0.008089855,0.0016634983,-0.028885337,0.031771068,-0.016908148,-0.030062042,0.023856318,0.0018508608,-0.004251552,-0.03272364,0.0031203728,-0.0065524327,-0.027820697,0.033283975,-0.012117272,-0.02146088,0.006366821,-0.020970585,0.012278369,0.0043531125,-0.033648193,-0.008292977,0.003652692,-0.0070112078,0.010261158,-0.010583351,0.014540726,2.1888137e-07,-0.0037437468,-0.023506107,-0.004906445,-0.010352213,0.020368224,-0.017902745,0.011192718,-0.0037612573,-0.00071005116,-0.008860318,-0.03947569,-0.022021215,-0.0072423466,0.020788476,0.030118076,-0.021320796,-0.03692616,0.011984193,-0.019541727,0.004409146,0.009518713,-0.0028997404,-0.0034127983,0.0048364024,0.004507205,0.012775667,-0.018855317,0.007088254,-0.009476688,-0.0014866422,0.010849511,-0.029753856,-0.0034653298,-0.01574545,0.011416852,-0.020620376,-0.0050745457,-0.0032184315,-0.009084452,0.011795079,-0.015633382,-0.0139803905,-0.012012209,-0.021068644,0.00543176,-0.0044756862,-0.005641886,-0.011718033,-0.009252553,-0.014344609,0.018308988,-0.003684211,-0.025425259,-0.01794477,0.011094659,-0.008468082,0.0005975461,0.032023218,0.010345208,-0.027582554,0.019107467,0.01459676,-0.028324999,-9.428315e-05,0.008545129,0.010373225,-0.02744247,-0.007018212,-0.0471523,0.028100865,-0.0031221237,-0.034068447,-0.015633382,-0.0049694823,0.008734242,-0.008152893,-0.012495499,0.020200124,-0.016333804,0.010786474,-0.014281571,-0.0031238748,-0.017314391,-0.012236344,0.018883333,-0.011970184,-0.003617671,-0.0050710435,0.015241147,-0.0015575598,0.012187314,0.011507907,-0.012327398,0.0010042277,-0.010471284,0.012747651,-0.01213128,-0.01301381,-0.00371573,-0.022119274,0.0034618275,0.023141889,-0.0007862219,0.0012633832,-0.013244949,0.032947775,0.027246352,0.022119274,-0.0034635786,-0.03261157,-0.0006951672,-0.018953376,-0.0036351816,-0.010555334,-0.0057504512,-0.007634582,-0.0075925565,-0.0017274118,0.024766864,0.0065314197,-0.0072143297,-0.039783876,0.006545428,0.020186115,-0.009805885,-0.018000804,-0.0065209134,0.0047068247,0.043846313,-0.012187314,-0.004535222,-0.0009700822,0.0067345416,-0.009063439,-0.00323244,0.010513309,0.01846308,-0.0038312995,0.007473485,0.008454074,-0.003060837,0.017636584,-0.0089933975,-0.020522317,0.009434662,0.0018175908,0.0029785377,0.03289174,0.012901743,0.0013964631,-0.009693818,-9.121881e-05,0.004755854,0.0047523524,-0.010744449,0.008699221,-0.0088112885,0.004878428,0.028717235,0.01402942,-0.014386634,0.0118301,-0.015507307,-0.018575149,-0.0045982595,-0.009469683,0.015381231,0.022623578,-0.0073193926,-0.0013920855,-0.00688163,-0.03025816,-0.025551334,0.023155898,-0.0126706045,-0.0378227,-0.004755854,0.033311993,0.03277967,-0.0020557337,0.0014559989,0.009224536,-0.018252954,0.02427657,-0.011598961,-0.023183914,-0.036197726,0.020130081,0.025957579,0.0010742698,-0.00268261,-0.008587154,0.011612969,0.032919757,0.024654796,-0.009532721,0.006233741,0.029445672,0.00054063695,0.0012782671,-0.00509906,-0.008222935,-0.018140888,-0.025649393,-0.01829498,0.0076906155,0.015185113,0.06869723,0.015899543,-0.008657196,0.019891938,-0.022175308,0.020480292,0.034404647,-0.0046262764,-0.024122477,-0.012222336,-0.012320394,0.010352213,-0.014106466,0.0057924762,0.0024549733,0.017300382,-0.008412048,0.0035616376,-0.018042829,0.017748652,0.008468082,-0.0031028623,0.023506107,-0.002785922,-0.01767861,0.015185113,0.006111168,0.0067975796,0.002752652,-0.016207727,0.025733445,0.014183512,-0.024780873,-0.022231342,-0.008264961,0.011816092,-0.0059570754,-0.034964986,-0.0029487698,0.0028507109,-0.0067170314,-0.021783073,-0.017482493,0.003372524,-0.009854915,0.008958376,-0.010457276,-0.019513711,-0.0156614]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011513152,0.0045001977,-0.002143285,-0.01477886,-0.0025565326,0.024500689,-0.015311179,0.017608557,-0.011290769,-0.034488674,0.0047803656,0.0160116,-0.01609565,0.013581142,-0.003027565,-0.02510305,0.028016796,0.0063808253,-0.011584945,-0.014246541,-0.003628175,0.017706616,-0.0070427223,-0.03874723,0.0071232705,0.033788256,0.027834687,-0.015409238,0.022805672,0.009119467,-0.0060131047,0.015283163,-0.03768259,-0.024234528,0.0012204817,-0.00014862035,0.010135076,-0.0008855934,0.0040414226,0.004402139,0.011108659,0.0065349177,0.0013982132,-0.014736835,-0.0080058,-0.008250946,0.015507297,-0.0398679,-0.008061833,-0.013476079,0.010366214,0.024948956,-0.019107455,-0.012656587,-0.016277758,-0.0030345693,-0.0048714206,0.009217526,0.013679201,-0.014960969,0.021222724,0.01809885,-0.017678598,-0.0014174748,-0.021642976,0.0044896915,-0.024794865,-0.012376419,-0.01407844,0.0076415814,0.034488674,0.01027516,-0.010100055,-0.025691401,0.034740828,-0.007207321,-0.0035633862,-0.02578946,-0.013938356,0.016319783,-0.00091667456,-0.023422042,-0.015171095,0.020508295,0.012495491,-0.01688012,0.0035020995,0.015521305,-0.013483083,0.003729736,-0.0039923936,-0.0008238689,0.020354202,0.015283163,0.0077536483,-0.0058975355,-0.0086361775,0.026069628,0.0011399334,0.009819887,-0.007109262,-0.0036491877,-0.02106863,-0.009819887,-0.014736835,0.002917249,0.01377726,0.0037227317,0.005887029,-0.013371016,-0.0361977,0.035525296,0.011711021,-0.03813086,-3.7456048e-05,-0.009910942,0.0076836064,-0.0178467,0.0037052212,-0.015969574,0.023674192,0.014470675,0.018056825,-0.008671198,0.012082243,-0.006552428,-0.0062127244,-0.0116479825,-0.017216321,-0.01337802,0.0012336145,0.010695412,0.005074542,0.019191505,-0.015087045,0.017440455,-0.014358608,0.013335995,-0.025425242,-0.030538308,0.0076836064,0.0051936135,-0.019583741,0.0180148,-0.0020224624,0.016039615,0.010961572,0.026335789,0.017020203,0.0129997935,0.0021292765,-0.038270943,0.02178306,0.029221518,0.016585942,0.021096647,-0.029529704,-0.009350605,-0.02116669,-0.008159892,-0.0073333965,0.013735235,0.005957071,0.018238934,0.01070942,0.0100720385,0.014638776,-0.005319689,0.012481483,0.004283068,-0.011290769,0.031686995,-0.028829284,0.00049817364,-0.007000697,0.019373614,0.021222724,-0.005725933,-0.017510498,-0.025523301,0.017244337,-0.0017475476,0.0050465255,0.024948956,-0.019359605,-0.023758244,0.016838094,-0.01224334,0.005183107,0.0019401631,0.018729229,0.016123665,-0.0018175896,0.0049764835,-0.6701618,-0.021881118,0.0038453052,-0.025257142,0.015493289,0.016978178,-0.0020469772,-0.01626375,-0.03261155,0.012425449,-0.021180699,0.006759052,0.028002787,-0.028885316,-0.007291371,-0.026167687,-0.0030135566,-0.03322792,0.009686807,0.0028909831,-0.01871522,0.015955565,-0.019275555,-0.009049425,-0.0014665042,0.028591141,0.0016249742,-0.016810078,0.018771254,0.0101280715,-0.009406639,0.03364817,0.005319689,0.01564738,0.04365017,-0.020970572,-0.0070252116,0.015563331,0.00016853854,0.050402217,-0.033031803,-0.011907138,0.0049064416,0.00054720306,-0.011206718,0.0037717612,0.022371411,0.0025845494,0.02011606,0.010611362,0.012047222,0.015731432,0.009609761,0.008433056,0.020102052,-0.020494286,0.02316989,-0.011423849,0.011472878,0.008299976,0.012628571,0.005207622,-0.017020203,-0.0064578713,-0.007179304,0.026265746,-0.021138672,0.013868314,-0.004671801,-0.045891512,-0.0068921316,0.017132271,-0.021516899,0.0054037394,-0.011059631,0.025957562,0.015353205,0.016459867,0.017776657,0.018953362,-0.0004136855,-0.03079046,0.004178005,0.020410236,0.033872306,-0.0006991066,-0.03322792,-0.00887432,-0.0047033196,0.002670351,0.0076906104,0.019359605,-0.016557926,-0.019541714,0.001476135,0.036393818,-0.009896933,0.016571935,-0.016193708,-0.015101053,-0.0023744234,-0.010744441,0.009735837,-0.007249346,-0.01035921,0.005207622,0.00047322118,0.027778653,0.020003993,-0.02038222,0.010289168,0.019205514,-0.011823088,0.014526709,-0.012299374,-0.033732224,0.040876504,-0.01421152,0.00084400596,-0.0074104425,0.0033970366,0.012782663,0.0077606523,-0.01836501,0.0076065604,0.033003785,-0.014330591,-0.031182693,-0.013952364,0.008278963,0.022749638,-0.018238934,0.014288566,-0.012292369,0.017692607,-0.0005800352,-0.0005244394,0.0020382218,0.0042375405,-0.022525504,-0.0045877504,0.011304777,0.0015041517,0.017958766,-0.02588752,-0.004044925,-0.00804082,0.008110862,-0.005522811,-0.008881324,-0.010828491,-0.021194706,-0.012411441,-0.020354202,0.005305681,0.008447064,0.015409238,-0.031182693,-0.025761444,-0.027694603,0.010639378,0.025649376,-0.015675398,0.017580539,-0.015563331,0.0068431026,-0.0016512399,0.034208506,0.007361413,-0.022455461,0.014764852,-0.027834687,0.00957474,0.0131959105,-0.0027771648,0.002533769,0.0050360193,-0.0131959105,-0.021292765,-0.01486291,0.00089084654,-0.0008527612,0.011732033,-0.00044607994,0.014470675,0.00909145,0.024598747,0.010905538,-0.01669801,0.035077028,-0.0063177873,0.011963172,-0.018168893,-0.0101841055,-0.00050255127,-0.007858711,0.008489089,-0.01662797,0.002461976,0.015703414,0.01662797,0.019737832,0.008061833,-0.00725635,0.007116266,-0.018407036,-0.0010996592,-0.014099453,0.019121462,0.014190507,0.026293764,-0.04006402,-0.021278756,-0.0068851276,0.011963172,0.009833896,0.00021691128,0.011802075,-0.021488883,0.015633373,-0.035357196,0.00097445917,0.012572537,-0.00028279453,-0.018771254,0.010723429,-0.0034513192,0.019877916,0.014267554,-0.014848902,0.0060761427,0.02700819,-0.0005747821,0.031602945,0.021054622,-0.018042816,0.010415244,0.0058975355,0.002150289,0.0024777355,-0.0050009983,0.0069796843,-0.015115062,0.005697916,0.03600158,-0.009196513,0.033732224,0.01923353,-0.026994184,-0.0015908286,-0.011879122,0.009399635,-0.0035668884,-0.009168496,0.009154488,0.00478737,0.014218524,-0.006191712,-0.003911845,0.020508295,0.0069901906,0.020018,0.03333999,-0.012236335,0.027862703,-0.0047313366,-0.012383424,-0.03227535,-0.022749638,0.003206172,-0.013616163,-0.00041215334,0.0059430627,-0.028002787,0.026013596,0.017048221,0.017174296,0.014722826,0.034208506,0.016109658,-0.034068424,-0.02693815,0.018897329,0.005316187,-0.009000395,0.0048714206,-0.022049218,0.010723429,-0.010317185,0.0074804844,0.021516899,0.017370414,-0.0038172884,-0.0048854286,-0.018491086,0.003967879,0.031350795,-0.011570937,-0.0011880873,-0.006086649,0.007431455,0.019653782,-0.0051235715,-0.041745026,0.017076237,-0.031350795,0.031182693,-0.0071617933,-0.01696417,-0.019289564,0.006583947,-0.025257142,0.022371411,-0.018519102,0.01416249,0.0017204063,0.008096854,-0.01723033,0.030118056,0.018154884,0.005662895,-0.026223721,-0.024276555,0.008909341,0.06382226,0.052671578,-0.0057854685,0.019569732,-0.0023394024,-0.007063735,-0.013763251,-0.0054737814,0.0067730607,-0.004048427,-0.010177101,-0.019051421,0.018379018,-0.010856508,0.0051340777,0.007774661,0.018154884,-0.014400633,-0.022707613,-0.03964377,-0.007081245,0.0075155054,0.04126874,0.03199518,0.008944362,0.0064158463,0.028591141,0.014043419,-0.013406037,-0.018238934,0.016039615,0.015759448,0.009693812,0.006027113,0.0029119956,0.037934743,0.0005060534,0.014330591,0.020564329,0.011949164,0.015409238,0.008727232,0.0074384594,-0.005281166,-0.014764852,-0.007046224,-0.011290769,-0.0011154187,-0.0014953965,-0.013013802,-0.00020498227,-0.016291767,-0.043846287,-0.008117867,0.011038617,0.0010874019,-0.017636573,-0.008447064,-0.004888931,-0.0003576519,-0.02648988,-0.023828285,-0.0035598841,0.0035668884,0.018210918,-0.016487885,-0.0067030187,0.0048083826,-0.030426241,-0.0086641945,-0.012404436,-0.03583348,-0.01976585,-0.0050815465,0.034124456,0.018379018,0.024458664,-0.007070739,-0.013798272,0.006625972,-0.0050920527,-0.002784169,-0.011416844,-0.002850709,0.017454464,-0.007424451,0.0012257348,-0.0032534504,-0.005592853,0.013784263,-0.0012090999,0.007970778,-0.0038733222,-0.020676395,-0.02178306,0.010394231,0.021727026,0.033283953,-0.009938958,-0.025383217,0.0074034384,-0.03009004,-0.021110656,-0.009014404,-0.0056138653,-0.006324792,0.0043846285,-0.008068837,-0.010163093,0.003241193,0.03182708,-0.0125095,0.011921147,0.0036106645,0.0055017984,0.030286156,0.0013973376,0.009490689,-0.018981379,-0.024248537,0.011262752,-0.024598747,0.006020109,0.003796276,-0.03350809,0.012607559,0.017608557,0.0061041596,-0.033199903,0.015185104,-0.01359515,0.048216905,-0.016221724,-0.0017720624,-0.016235733,-0.00031168686,-0.0131398775,-0.003449568,-0.012397433,-0.0032622057,0.0065489262,-0.02003201,-0.010485286,-0.009980984,0.0034950953,-0.03356412,-0.012481483,0.024234528,0.0047698594,0.010667395,0.0027596543,-0.007459472,-0.005732937,-0.0072283335,0.000573031,-0.019625766,-0.0045527294,0.007872719,0.0114798825,0.027050216,0.021194706,-0.0077256314,0.016473876,0.010968575,-0.014722826,0.00019217771,0.0008011053,0.021054622,-0.01337802,0.03558133,-0.0034338087,-0.007662594,-0.014372616,0.007046224,0.026587939,0.007417447,-0.017692607,-0.018645179,-0.029417636,-0.028633166,0.016669994,0.012992789,-0.008965375,-0.0037577527,-0.021727026,0.0026826083,0.0028944851,0.004542223,-0.0017291616,-0.010632374,0.006044624,-0.007571539,0.023408033,-0.0021975674,0.018280959,-0.017734632,-0.030594341,-0.02850709,0.010233135,0.031154677,-0.018519102,0.026363805,0.017860707,-0.0086361775,0.0039713806,-0.0028419537,0.0023831788,0.00830698,-0.0047313366,-0.013258949,0.016571935,-0.023029806,-0.02571942,-0.007858711,0.0040344186,0.012530512,-0.011668996,0.013090848,0.0068501066,-0.021376815,0.020284161,-0.0037857695,0.04863716,0.022805672,0.02308584,0.02508904,0.0013456817,0.0037507485,0.001708149,0.0039223516,0.01346207,0.019303573,0.009868916,-0.010212122,-0.021811076,0.0043461053,0.017636573,-0.024696806,-0.017188305,-0.011108659,0.001975184,0.0025127565,-0.0025635369,-0.008320988,0.011921147,-0.0034408127,-0.01097558,0.008454069,0.018042816,-0.011907138,-0.0032236825,0.026643973,0.018266952,0.027260343,-0.0102681555,0.0030871008,0.004125473,0.009406639,0.023548117,0.013518104,-0.020214118,0.029445652,-0.00922453,-0.005918548,0.02438862,-0.0054072416,0.015493289,-0.007186308,0.004300578,0.030566325,-0.014764852,0.012131273,-0.0065139052,0.0064998968,0.007004199,-0.00738943,-0.0014463671,-0.0087342365,-0.009728832,0.023562126,0.012600554,0.008278963,-0.031070627,-0.0031203707,-0.0021047618,-0.012271357,-0.0012975279,0.006128674,-0.0011145432,-0.033536106,-0.027274352,-0.008320988,0.01616569,0.036645968,-0.0054702796,-0.023632167,0.012054226,0.017552523,-0.03207923,0.016291767,0.018981379,-0.012586545,-0.019121462,0.011668996,-0.018589145,-0.03594555,0.010779462,-0.017566532,-0.03863516,-0.025341192,0.0016398581,-0.004542223,0.00225185,-0.022007193,-0.0058625145,-0.0055788443,0.0033672687,0.0034863402,-0.025593344,0.016754044,0.009602757,0.0028314474,0.01599759,-0.01421152,0.018519102,-0.020172093,-0.016936153,-0.0022308375,-0.044266537,-0.026826082,-0.02239943,-0.008713224,-0.008545123,-0.00221858,-0.009406639,-0.0070847473,-0.014400633,0.0072703585,0.0017659337,-0.0063843275,-0.0049379603,0.009014404,0.0036106645,0.012474478,-0.021432849,-0.008138879,-0.0022273352,0.022427445,-0.027484477,-0.0143446,-0.014932952,0.040792454,0.017048221,-0.015143078,-0.006482386,-0.006261754,-0.031406827,0.002323643,0.004776864,0.00059273036,-0.0076485854,0.0074804844,0.012047222,0.036225718,-0.003237691,-0.006580445,0.0029189999,0.009994992,-0.020998588,-0.020003993,0.0059325565,0.0033147372,-0.021096647,0.002638832,-0.0021327785,-0.015549322,0.02246947,-0.005445765,-0.016950162,-0.017902732,0.008909341,0.031350795,0.029949956,0.023940353,0.021488883,-0.022777656,-0.01372823,0.020396227,-0.015143078,-0.014750843,-0.023351999,0.010401236,0.0015382972,0.012439458,-0.0024847395,-0.0290254,0.012411441,0.0040939543,-0.005340702,0.003197417,0.029613754,0.03297577,0.014736835,-0.01940163,-0.0039923936,0.025565326,-0.023295965,-0.0043110843,0.022189302,-0.030005988,0.0060761427,-0.016235733,-0.0198499,-0.018491086,-0.016053624,-0.011816083,-0.0017422945,-0.004650788,0.014141478,0.019037412,-0.023281958,0.025159083,0.009798874,0.0015671896,-0.018210918,-0.004538721,0.007221329,-0.019597748,0.0036351793,0.0059010377,-0.01916349,-0.010597353,0.00662247,0.017300371,0.017986784,0.010723429,0.23175494,-0.018673195,-0.013392028,0.012054226,0.01800079,0.0025285159,0.023323983,0.019261546,0.000187034,0.01070942,0.009077442,0.01993395,0.0047278344,-0.007599556,0.022749638,-0.017510498,-0.02255352,-0.008419047,0.0046612946,0.017720623,0.014008398,-0.009147484,-0.004759353,-0.022539513,0.042921733,-0.011073639,-0.009896933,0.0028349496,0.0060411217,0.0069201486,-0.0075435224,-0.0030678392,0.021054622,0.0012353656,-0.014274558,-0.00043316593,0.021685,-0.008671198,0.012684604,0.0015523056,0.037038203,-0.024948956,-0.0016687504,-0.01215929,0.012824688,0.022889722,-0.019905934,-0.020354202,0.028142871,0.015549322,-0.016585942,-0.005235639,0.0027631565,0.0290254,0.008299976,-0.009805879,-0.01162697,0.0024864906,0.012376419,-0.019779857,-0.024192503,0.008054829,-0.008405039,0.022721622,-0.0014052175,-0.0015628119,-0.0068150857,-0.010107059,0.018154884,-0.015675398,-0.015521305,-0.01539523,-0.0075785434,-0.012817685,-0.029501686,-0.015759448,0.029053418,-0.00040624355,0.022791663,0.028969368,-0.020620363,-0.00083306193,-0.0010523809,-0.014414642,-0.00909145,-0.021292765,0.03549728,-0.006114666,-0.006503399,-0.0069201486,-0.0161797,0.014092448,-0.011970176,0.0100019965,-0.0009481934,0.0001846263,0.010457269,0.012600554,0.0054037394,0.0011819586,-0.025957562,0.07626172,0.0070777433,-0.002994295,0.00035064772,0.01019111,0.0021310276,0.023015797,0.005557832,-0.011360811,0.0019839394,-0.018112859,0.00084969687,-0.021376815,-0.012250344,0.002780667,0.023576135,-0.0062092226,0.015605356,0.0016556175,-0.030426241,-0.013055827,-0.008496094,0.011199715,0.003799778,-0.00662247,0.0070427223,-0.0018736232,-0.017286364,-0.0069866884,0.004741843,-0.019793866,0.0088182865,0.015535314,-0.010499294,-0.022511495,-0.017384421,-0.008930353,0.017860707,-0.005141082,0.0020312178,0.016137674,-0.0057469453,-0.011283765,-0.013441058,-0.009952967,-0.012285365,0.009077442,0.006650487,0.00036859597,-0.004888931,0.012761651,-0.009819887,-0.015815482,0.006132176,-0.012341399,0.01592755,0.0023131368,0.0028769746,-0.00498699,-0.02361816,0.004647286,0.009490689,-0.018659186,-0.014190507,-0.018477077,-0.1826695,0.008951366,0.02239943,-0.03768259,0.010968575,0.0009972228,0.028745232,-0.012355407,-0.04415447,0.015619364,0.034908928,-0.012936756,-0.030314174,-0.0026143172,-0.005319689,-0.01281068,-0.0088182865,-0.002847207,0.0035126058,0.013735235,0.04765657,-0.020242136,-0.0025355201,0.0070882495,-0.0178467,-0.0029977972,0.00437062,0.023057824,0.015325188,-0.030902525,-0.008993392,-0.003447817,0.017818682,-0.0056874095,-0.008482085,-0.0039188494,0.004402139,-0.021909134,-0.021110656,-0.00081555144,0.020298168,0.016852103,0.015002994,-0.0017589295,-0.015507297,0.0025565326,0.023394024,-0.013202915,0.005445765,-0.028801266,0.0024392123,-0.007063735,0.011683004,-0.006506901,0.002039973,0.0055123046,-0.006377323,-0.01923353,0.004433658,-0.004650788,0.0021362808,-0.005417748,0.012005197,0.01854712,0.0051936135,0.006230235,0.00010145144,0.014904936,-0.040904522,0.009350605,-0.008804278,-0.0052671577,-0.011220727,-0.0048784246,0.002178306,0.0358615,-0.01844906,-0.009497694,0.0033585133,-0.022203311,-0.008622169,0.018238934,-0.007494493,-0.0017711868,-0.0042025195,-0.0045702397,-0.00047059462,0.037934743,-0.008026812,-0.013504095,0.02063437,-0.04748847,-0.0044546705,-0.014498692,-0.0014157237,0.01836501,0.014232532,-0.021362808,0.015185104,-0.004811885,0.013658188,0.00028235678,-0.0016617462,-0.00026506514,0.030594341,0.003237691,0.002959274,0.015073036,0.03376024,-0.006377323,-0.026742032,-0.0218531,7.644427e-05,0.0039258534,0.014400633,0.028114855,-0.0074734804,0.009903938,0.009798874,-0.006696014,0.06600757,0.0018543617,-0.013826289,0.014442658,-0.009077442,-0.022847697,-0.11643781,-0.04633978,-0.0045282147,-0.003057333,-0.008349005,0.024276555,-0.008075842,0.0016608707,-0.028885316,0.03174303,-0.016950162,-0.030118056,0.023926344,0.0018368512,-0.0042760633,-0.032695603,0.0030853497,-0.006587449,-0.027848694,0.03325594,-0.012124268,-0.02141884,0.0064263525,-0.020970572,0.012306377,0.0043110843,-0.03359214,-0.008327993,0.0036772045,-0.0070322156,0.0102401385,-0.010611362,0.014610759,-3.731925e-05,-0.003764757,-0.023478076,-0.0049099433,-0.01035921,0.020368211,-0.017888725,0.011171698,-0.0037402422,-0.00071486604,-0.008909341,-0.039475664,-0.022049218,-0.007242342,0.020760447,0.030146072,-0.02133479,-0.036954153,0.012026209,-0.019527707,0.0044196495,0.009518706,-0.002889232,-0.0034075428,0.0048013786,0.0045001977,0.012796672,-0.018869312,0.0070672366,-0.009448664,-0.0014735084,0.010849505,-0.029753838,-0.0035003484,-0.015759448,0.011437857,-0.020578336,-0.005074542,-0.0032131763,-0.009077442,0.011837096,-0.015619364,-0.013980381,-0.011998193,-0.02108264,0.0054597734,-0.0044301557,-0.005673401,-0.0117460415,-0.00922453,-0.014323587,0.018238934,-0.0036456855,-0.025411233,-0.017944759,0.011073639,-0.008426052,0.0005642758,0.0320232,0.010331194,-0.02755452,0.019135471,0.014568734,-0.028268946,-8.21899e-05,0.008580144,0.010429252,-0.02745646,-0.0070567303,-0.04715227,0.028058821,-0.003095856,-0.034096442,-0.015633373,-0.0049449643,0.0087202275,-0.008236938,-0.012467475,0.02020011,-0.016347801,0.010786466,-0.014295571,-0.0031081133,-0.017272355,-0.012257348,0.018925346,-0.011928151,-0.0036526897,-0.0050850483,0.015283163,-0.0015698161,0.01219431,0.011514903,-0.012404436,0.0009832145,-0.010485286,0.012719626,-0.012096251,-0.0130418185,-0.0037087235,-0.022147277,0.0034408127,0.023113856,-0.0008282465,0.0012922747,-0.013202915,0.033003785,0.027260343,0.022091243,-0.003447817,-0.03261155,-0.0006146185,-0.018911337,-0.003621171,-0.010520307,-0.0057819663,-0.007599556,-0.0076065604,-0.0017317882,0.02483689,0.006464876,-0.0071933125,-0.03972782,0.0066014575,0.020158084,-0.009812883,-0.017944759,-0.0065209093,0.0047313366,0.04390232,-0.012187306,-0.004507202,-0.0010112312,0.0067170267,-0.009084446,-0.0032184294,0.01049229,0.018519102,-0.0038207907,0.0074384594,0.008433056,-0.0030835986,0.017566532,-0.008993392,-0.020494286,0.009462673,0.0018070834,0.003027565,0.032919735,0.012922747,0.0013859558,-0.009679803,-7.797644e-05,0.0047383406,0.0047278344,-0.010730433,0.00865719,-0.008783266,0.0048399013,0.0286892,0.014050423,-0.01442865,0.011837096,-0.015465272,-0.01853311,-0.004545725,-0.009518706,0.01539523,0.022595545,-0.007319388,-0.0014122216,-0.006829094,-0.03025814,-0.02553731,0.023099849,-0.012719626,-0.037794657,-0.004794374,0.03333999,0.032723617,-0.0020504792,0.0014139727,0.009259551,-0.018266952,0.02422052,-0.011535916,-0.023113856,-0.036253735,0.02011606,0.025901528,0.0010996592,-0.0026633467,-0.008580144,0.011697012,0.032919735,0.024682797,-0.009511703,0.0062232306,0.029445652,0.0005327569,0.0012782663,-0.0050885505,-0.008264955,-0.018154884,-0.02563537,-0.018322984,0.0077116233,0.015185104,0.06864115,0.015899532,-0.008671198,0.0198499,-0.022189302,0.020480277,0.034348592,-0.0046753027,-0.024150478,-0.012278361,-0.012292369,0.010373219,-0.014106457,0.005799477,0.002460225,0.017286364,-0.008419047,0.0035423737,-0.018028809,0.017762648,0.008489089,-0.0031518897,0.023464067,-0.002784169,-0.017678598,0.015199112,0.0061111636,0.0068080816,0.0027614054,-0.0161797,0.025733428,0.014225529,-0.024780856,-0.022189302,-0.008236938,0.011858109,-0.006058632,-0.034908928,-0.00295227,0.0028121858,-0.0067380397,-0.021727026,-0.017538514,0.0033515093,-0.009882925,0.008979383,-0.010443261,-0.019457664,-0.015745439]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011570163,0.004481031,-0.0021407427,-0.01473139,-0.0025730922,0.024533646,-0.015277516,0.01760205,-0.011328607,-0.034447927,0.0047470927,0.01599168,-0.016103705,0.013590127,-0.00299844,-0.025107779,0.027950432,0.0063644648,-0.011580666,-0.014234276,-0.003658342,0.01772808,-0.007008613,-0.038788926,0.0071101366,0.03371976,0.027880417,-0.015417548,0.022783244,0.009109097,-0.0060388898,0.015291519,-0.037696674,-0.02423958,0.0012760437,-0.00016661648,0.01016634,-0.00090058224,0.004018925,0.004449524,0.0111115575,0.006504497,0.0013626886,-0.014745394,-0.00799584,-0.008268903,0.0155155705,-0.039909184,-0.008030849,-0.013436092,0.010397393,0.024953743,-0.019128403,-0.012623905,-0.016271744,-0.0029756848,-0.0048521166,0.009193116,0.01368815,-0.014899429,0.021200879,0.018106166,-0.017714078,-0.0014449576,-0.021578966,0.004505537,-0.024757698,-0.012322836,-0.01408024,0.007638758,0.03450394,0.010250359,-0.010117329,-0.025681911,0.03472799,-0.0072326646,-0.0035078074,-0.025737923,-0.013919204,0.016313754,-0.00088832946,-0.023371378,-0.015109478,0.020486714,0.012483873,-0.01685988,0.003511308,0.0155155705,-0.013520111,0.003763366,-0.0040224255,-0.0008520086,0.020346683,0.015263513,0.0077577853,-0.0058323424,-0.008618983,0.026074002,0.0011543906,0.009858269,-0.0071626483,-0.0036443388,-0.021018837,-0.009844266,-0.014745394,0.0029091695,0.013758167,0.0037143547,0.005891856,-0.013324066,-0.036184326,0.03551217,0.011699692,-0.03811677,-8.622102e-06,-0.009914282,0.0076527614,-0.017868113,0.0037388604,-0.015977677,0.02363744,0.014479333,0.018078161,-0.0086399885,0.0120777795,-0.0065185004,-0.006210429,-0.011608671,-0.017223964,-0.013408085,0.0011920243,0.010684459,0.005114677,0.019198418,-0.015081471,0.017377999,-0.01438131,0.013289059,-0.025457859,-0.030527025,0.0076877694,0.0051776916,-0.019604512,0.017910121,-0.002016464,0.0160757,0.010957521,0.026270045,0.01698591,0.012987989,0.0021494946,-0.0382288,0.021761008,0.029266736,0.01655181,0.021060847,-0.029518794,-0.009347151,-0.021214882,-0.0081008645,-0.0073796986,0.013779171,0.005961872,0.01820419,0.010712465,0.010054314,0.014619364,-0.005314223,0.012532884,0.0042814855,-0.0113146035,0.03167529,-0.028790627,0.00050630403,-0.0069701043,0.019366456,0.021200879,-0.0056888093,-0.017476022,-0.025513873,0.01720996,-0.001729398,0.0050586644,0.02498175,-0.019338451,-0.023749465,0.016845876,-0.012224813,0.0051601874,0.0019394463,0.018764319,0.016145715,-0.0018484254,0.0049466384,-0.6703623,-0.02190104,0.0038578878,-0.025219804,0.015487565,0.016957903,-0.0020532226,-0.01629975,-0.0325995,0.012406855,-0.021144867,0.0067670573,0.027992442,-0.028902652,-0.007260671,-0.026088003,-0.0030404497,-0.033215646,0.009676227,0.0028531565,-0.018680299,0.015921663,-0.019254431,-0.009025077,-0.0015193496,0.02863659,0.0016217482,-0.016803868,0.01882033,0.010131332,-0.009396163,0.033663746,0.0053807385,0.015613593,0.043606035,-0.020976828,-0.007012114,0.01559959,0.00020676633,0.0504116,-0.033047605,-0.011930746,0.004883624,0.0005456881,-0.011174572,0.0037738685,0.02237715,0.0025363336,0.020136634,0.010607441,0.012098785,0.015697613,0.009627216,0.00842994,0.020094624,-0.020500718,0.023175333,-0.011419628,0.011454636,0.008317914,0.012630907,0.0052126995,-0.017041922,-0.0064204778,-0.0071836533,0.026228037,-0.021172872,0.013828183,-0.0046910797,-0.04584655,-0.0068790833,0.017125942,-0.021522954,0.0054297494,-0.011083551,0.025975978,0.015333529,0.016495796,0.017784093,0.018932357,-0.00040565585,-0.030751077,0.004162458,0.020430703,0.0338878,-0.000736482,-0.03318764,-0.008878043,-0.0047015822,0.0026693642,0.0077577853,0.019338451,-0.01655181,-0.019520493,0.0015062216,0.036464393,-0.009872272,0.01655181,-0.016215732,-0.015123481,-0.002377047,-0.010747474,0.009725238,-0.0072676726,-0.010355383,0.0052652117,0.00046079356,0.027796397,0.020010605,-0.020388693,0.010299371,0.019198418,-0.011860729,0.014577355,-0.0123018315,-0.033691753,0.040861405,-0.014255281,0.00082837814,-0.0073796986,0.0034255383,0.012749935,0.0077787903,-0.018344222,0.007638758,0.033047605,-0.0143252965,-0.03119918,-0.013940209,0.008303911,0.02268522,-0.018260203,0.014283287,-0.012280826,0.01768607,-0.00054306246,-0.0005093672,0.002033968,0.0042639812,-0.022531185,-0.004558049,0.011300601,0.0015613594,0.017966134,-0.02589196,-0.004032928,-0.008016845,0.0081008645,-0.0054717595,-0.008871041,-0.010845496,-0.021172872,-0.012399854,-0.020360686,0.0052687125,0.008436942,0.015389542,-0.031171173,-0.02576593,-0.027684372,0.010684459,0.025625898,-0.015697613,0.01756004,-0.015571584,0.006861579,-0.0016567563,0.03419587,0.007365695,-0.02241916,0.014787403,-0.0278104,0.009571203,0.013163029,-0.0028444047,0.0025100778,0.005062165,-0.013212041,-0.021284899,-0.014899429,0.0008419438,-0.0008485078,0.011664685,-0.0004340999,0.014507338,0.009130102,0.024575656,0.010908511,-0.016719848,0.03512008,-0.0062944484,0.011972755,-0.018134173,-0.010222353,-0.0005470009,-0.007841805,0.008499956,-0.016649831,0.0024453127,0.01568361,0.016649831,0.019674528,0.008030849,-0.0072326646,0.007113637,-0.018386232,-0.0011027538,-0.014115249,0.019128403,0.01416426,0.026284048,-0.04002121,-0.021270895,-0.006896587,0.011958752,0.009816259,0.00019473232,0.01177671,-0.02146694,0.015613593,-0.03537214,0.0010344881,0.012567893,-0.00026365442,-0.018722309,0.010719467,-0.0034710488,0.019870574,0.014262282,-0.014829413,0.006108906,0.026956204,-0.00059951295,0.031619277,0.021060847,-0.018050155,0.010411396,0.005965373,0.0021599971,0.0024750696,-0.0049711443,0.006973605,-0.015095474,0.0056678043,0.035988282,-0.009214121,0.033691753,0.019226424,-0.027012216,-0.0015963673,-0.011902739,0.009417167,-0.003576073,-0.0091231,0.0091791125,0.004775099,0.014248279,-0.0061894245,-0.003927904,0.020458708,0.0069666035,0.020024609,0.03332767,-0.012231815,0.02789442,-0.004750593,-0.012378849,-0.03229143,-0.022713227,0.0032032372,-0.013597129,-0.00039909183,0.005944368,-0.028020449,0.026017988,0.017111938,0.017167952,0.014703384,0.034223877,0.016187726,-0.034083843,-0.026928198,0.01890435,0.005331727,-0.008997071,0.004869621,-0.022013066,0.010705464,-0.010320375,0.007498726,0.021536956,0.017349994,-0.003731859,-0.004831112,-0.018484253,0.003927904,0.03136722,-0.011573664,-0.0011876483,-0.006066896,0.0074147065,0.019632518,-0.005100674,-0.041729603,0.017083932,-0.03136722,0.031171173,-0.007113637,-0.0169439,-0.019338451,0.006522001,-0.025275817,0.022307133,-0.018442245,0.014143255,0.0016733852,0.0081008645,-0.017265974,0.030050917,0.01816218,0.0057168156,-0.026256043,-0.024253583,0.008892046,0.06374267,0.052680124,-0.0057693277,0.019562501,-0.0023385382,-0.0070366194,-0.013772169,-0.005461257,0.0067880624,-0.0040049218,-0.010173341,-0.019016376,0.018372228,-0.010908511,0.0051496853,0.0077577853,0.018190186,-0.014451326,-0.022629207,-0.039601114,-0.0070856307,0.0075337337,0.041253496,0.031955354,0.008927055,0.0063749673,0.028608585,0.014038231,-0.013422089,-0.0182462,0.01599168,0.015767628,0.009704233,0.0060108835,0.002881163,0.03789272,0.00051855686,0.014332298,0.020542728,0.012000762,0.015417548,0.0087520145,0.0074497145,-0.005279215,-0.01481541,-0.007075128,-0.0113146035,-0.0010931266,-0.0015088472,-0.013008994,-0.00022886517,-0.016313754,-0.04380208,-0.0081008645,0.01103454,0.0010782481,-0.017630057,-0.008436942,-0.004897627,-0.00034132856,-0.026494097,-0.023833485,-0.0035690714,0.003576073,0.018218193,-0.01655181,-0.0067040427,0.0048486157,-0.030386994,-0.008681998,-0.01242786,-0.035820242,-0.019786553,-0.005065666,0.03411185,0.018372228,0.02446363,-0.00708213,-0.013779171,0.0066060205,-0.005100674,-0.0028093965,-0.011433631,-0.0028479055,0.017462019,-0.007456716,0.0012541637,-0.0032399956,-0.0055977884,0.013744163,-0.0011999011,0.007974835,-0.0038508861,-0.020696763,-0.021789014,0.01038339,0.021718998,0.033271655,-0.00990728,-0.025429852,0.0073796986,-0.030106928,-0.02103284,-0.009039081,-0.0056257946,-0.006322455,0.0043725064,-0.008044851,-0.01016634,0.003206738,0.03181532,-0.012448865,0.011923744,0.0036268346,0.0055347737,0.030274967,0.0013784423,0.00947318,-0.018960364,-0.024253583,0.011286598,-0.024575656,0.006035389,0.0038263807,-0.03357973,0.0126169035,0.01760205,0.006070397,-0.033243652,0.015179493,-0.013604131,0.04814308,-0.016187726,-0.0017749085,-0.016243739,-0.00029581808,-0.013142024,-0.0034973049,-0.012392852,-0.003253999,0.0065290025,-0.020010605,-0.010495415,-0.0099422885,0.0034920536,-0.033551723,-0.012441863,0.024225576,0.004754094,0.010684459,0.0027236268,-0.0074777207,-0.0057448223,-0.0072116596,0.00059426174,-0.019618515,-0.0045300424,0.007855808,0.011496645,0.02706823,0.021214882,-0.0076877694,0.016411778,0.010971525,-0.014717387,0.00020654754,0.00082925335,0.02107485,-0.013401085,0.0356242,-0.003467548,-0.007638758,-0.014395313,0.007047122,0.026620127,0.007442713,-0.01768607,-0.018638289,-0.029406767,-0.028594581,0.016649831,0.012917973,-0.008962062,-0.003749363,-0.021704996,0.002676366,0.002898667,0.0045825546,-0.0017267724,-0.010642449,0.0060143843,-0.007582745,0.023413388,-0.0022387651,0.018260203,-0.017756086,-0.030667057,-0.028510561,0.010194346,0.031143168,-0.01855427,0.026298052,0.01789612,-0.008660994,0.0039524096,-0.0027971438,0.0023577926,0.00829691,-0.0047260877,-0.013261052,0.016537806,-0.023021298,-0.025737923,-0.007848807,0.0040504322,0.012518881,-0.0116506815,0.01307901,0.0068580783,-0.021354914,0.020304672,-0.0038403838,0.0486752,0.022825252,0.023133324,0.025093775,0.0013268053,0.003731859,0.0016585067,0.0039244033,0.013464099,0.019254431,0.009844266,-0.010222353,-0.021817021,0.004305991,0.017616054,-0.024673678,-0.017223964,-0.011174572,0.001990208,0.002524081,-0.0026010985,-0.008331917,0.011888736,-0.0034115352,-0.01099253,0.008422938,0.018078161,-0.011923744,-0.0032277429,0.026634129,0.0182462,0.027320288,-0.010215351,0.003089461,0.0041519557,0.009417167,0.023539416,0.01351311,-0.020178644,0.029434774,-0.009186114,-0.0059198625,0.024421621,-0.0053982423,0.015501567,-0.0071976567,0.004288487,0.030499019,-0.014801406,0.012133792,-0.00656051,0.0064589866,0.0070191156,-0.007351692,-0.0014160759,-0.00878002,-0.00969023,0.02355342,0.012630907,0.008303911,-0.031059148,-0.0031402227,-0.002119738,-0.012287828,-0.0013031749,0.0061054053,-0.0011351362,-0.033551723,-0.027264275,-0.008310913,0.016229736,0.036604423,-0.005457756,-0.02363744,0.012063776,0.017546037,-0.03206738,0.01629975,0.018974368,-0.0125958985,-0.0191144,0.011692691,-0.01859628,-0.03593227,0.010768478,-0.017532036,-0.038564876,-0.025359835,0.0016112458,-0.0045335433,0.0022282628,-0.021971056,-0.0058323424,-0.0055732825,0.003415036,0.0034763,-0.025583887,0.016761858,0.009620214,0.002837403,0.015977677,-0.014220273,0.018526264,-0.020150637,-0.0169439,-0.00221601,-0.04427819,-0.026844177,-0.022391153,-0.008660994,-0.008541966,-0.0022125093,-0.009459177,-0.007103135,-0.01438131,0.0072326646,0.0018081662,-0.006378468,-0.0049676434,0.009004072,0.0036093306,0.01246987,-0.021438934,-0.008114868,-0.0022772742,0.02241916,-0.027446317,-0.014353303,-0.014913432,0.040777385,0.017055925,-0.015137483,-0.0064659882,-0.0062979492,-0.03136722,0.0022930277,0.0047856015,0.0005925114,-0.0076247547,0.007491724,0.012014765,0.03624034,-0.0032732533,-0.006557009,0.0028951664,0.010033309,-0.020962825,-0.019996602,0.005912861,0.0033012598,-0.02111686,0.0026151019,-0.002098733,-0.015543577,0.022503179,-0.0054297494,-0.0169439,-0.017910121,0.008899048,0.031339213,0.029910883,0.023917504,0.021480944,-0.022797247,-0.013709155,0.02037469,-0.015193497,-0.014717387,-0.023357375,0.010432401,0.0015464809,0.012413857,-0.002441812,-0.028986672,0.012392852,0.004109946,-0.005373737,0.003162978,0.029602813,0.0330196,0.014745394,-0.019408466,-0.0039874176,0.025583887,-0.023315366,-0.0043480005,0.022153098,-0.029966896,0.0060738977,-0.016215732,-0.01981456,-0.018526264,-0.0160757,-0.011783712,-0.0017530285,-0.0046420684,0.014129252,0.019002372,-0.02328736,0.025177794,0.009774249,0.0015797386,-0.018232197,-0.004600059,0.0072186613,-0.019534497,0.0035988283,0.005912861,-0.019212421,-0.010600439,0.006627025,0.017265974,0.017980138,0.010719467,0.23166932,-0.018666295,-0.0133800795,0.012063776,0.018036151,0.0025748427,0.023259353,0.019254431,0.00020042113,0.01069146,0.00908109,0.019926585,0.0047610956,-0.0075897467,0.02272723,-0.017434012,-0.022559192,-0.008366926,0.0046210634,0.017714078,0.013989219,-0.009165109,-0.004754094,-0.022573195,0.042905875,-0.011041541,-0.009900278,0.0028304013,0.0060143843,0.0069280947,-0.007526732,-0.003059704,0.021060847,0.0012287828,-0.014311294,-0.00041200107,0.021704996,-0.008696001,0.012637909,0.0015088472,0.037052527,-0.024995752,-0.0016541306,-0.012133792,0.012805947,0.022853259,-0.01989858,-0.020402696,0.028132474,0.015529574,-0.016607823,-0.005275714,0.0027481325,0.029014677,0.008310913,-0.009781251,-0.011622675,0.0025048265,0.012329837,-0.01981456,-0.02423958,0.008051853,-0.008450945,0.022699224,-0.0013723158,-0.0015587338,-0.0067985645,-0.010110327,0.018190186,-0.015669607,-0.015473561,-0.015389542,-0.007582745,-0.012833954,-0.029490788,-0.015767628,0.02907069,-0.00039165263,0.022755237,0.028986672,-0.020626748,-0.0008165629,-0.0011272595,-0.014395313,-0.009109097,-0.021270895,0.03554018,-0.00612641,-0.0065114987,-0.006935096,-0.016173722,0.014101245,-0.0119657535,0.009984298,-0.0009040831,0.0001875119,0.010495415,0.0125958985,0.0053877397,0.0011911491,-0.025947971,0.07628956,0.007026117,-0.0030141936,0.00033739014,0.010187345,0.002119738,0.0230353,0.005580284,-0.011335609,0.0019762048,-0.018092163,0.00082619017,-0.021410927,-0.012217812,0.002802395,0.02359543,-0.0062209317,0.01559959,0.0016322506,-0.030471012,-0.013008994,-0.008534964,0.011216582,0.0037983742,-0.0065850154,0.0070541236,-0.0018589278,-0.01729398,-0.0069526,0.004743592,-0.019786553,0.00882203,0.015557581,-0.010432401,-0.022517182,-0.01733599,-0.00890605,0.01785411,-0.005114677,0.0020392193,0.016145715,-0.0057378206,-0.011293599,-0.013450095,-0.009935287,-0.012308833,0.0090670865,0.0066900398,0.0003640838,-0.0048766225,0.012770939,-0.009844266,-0.015823642,0.0060984036,-0.0123018315,0.015977677,0.002359543,0.0029021678,-0.004988648,-0.02359543,0.0046140617,0.009501186,-0.018638289,-0.014234276,-0.01851226,-0.18260202,0.008962062,0.02237715,-0.03772468,0.010943519,0.00099948,0.028706606,-0.012364846,-0.044166163,0.015585586,0.034924038,-0.01294598,-0.030274967,-0.0026641132,-0.0053387284,-0.012812949,-0.008829032,-0.0028601582,0.0035568185,0.013751165,0.047638964,-0.020220654,-0.0025835945,0.00708213,-0.01785411,-0.0030141936,0.0043725064,0.023077311,0.015319525,-0.030835096,-0.009018076,-0.003458796,0.017784093,-0.005727318,-0.008485953,-0.0038893952,0.0044075144,-0.02190104,-0.021144867,-0.0008078109,0.020318676,0.016845876,0.015011455,-0.0017617805,-0.015487565,0.002541585,0.023413388,-0.013212041,0.0054857624,-0.028790627,0.0024085543,-0.0070611252,0.011720697,-0.0065114987,0.002028717,0.00551727,-0.006416977,-0.019226424,0.0044425223,-0.0046210634,0.0021757507,-0.0053807385,0.011972755,0.01855427,0.0051461845,0.006238436,8.5550935e-05,0.014913432,-0.040861405,0.009326146,-0.008801025,-0.0052652117,-0.011258591,-0.0048521166,0.0021424931,0.035876255,-0.018484253,-0.009501186,0.0033467703,-0.022167102,-0.008625985,0.0182462,-0.0074497145,-0.0017477772,-0.0041869637,-0.0045265416,-0.00044700914,0.037948735,-0.007981837,-0.013506108,0.020612745,-0.047470924,-0.004488033,-0.014507338,-0.0014843416,0.018330218,0.014220273,-0.021396924,0.015193497,-0.0048031053,0.013632137,0.00028115846,-0.0016480043,-0.00027743884,0.030611046,0.0032434964,0.0029441775,0.015109478,0.033747766,-0.0062979492,-0.026760159,-0.021817021,0.000100374666,0.0039174017,0.014367307,0.02811847,-0.0074847224,0.009872272,0.009816259,-0.0067005423,0.06592717,0.001881683,-0.013814179,0.014451326,-0.0090670865,-0.022811249,-0.11628276,-0.046378672,-0.0044775303,-0.0030912114,-0.008352922,0.024267584,-0.008086861,0.0016663835,-0.028874645,0.031731304,-0.01690189,-0.030078921,0.023861492,0.0018274206,-0.004235975,-0.03271153,0.0030789585,-0.006592017,-0.0278104,0.033271655,-0.012105786,-0.021410927,0.0063994727,-0.020976828,0.012322836,0.004340999,-0.033607736,-0.008289908,0.0036793468,-0.007022616,0.010250359,-0.010586436,0.014577355,-4.311051e-06,-0.0037423612,-0.023511412,-0.0049081296,-0.0103693865,0.020360686,-0.017882116,0.01120958,-0.0037388604,-0.00070366194,-0.008892046,-0.039433077,-0.022041073,-0.007253669,0.020794787,0.030106928,-0.021312905,-0.036912493,0.011972755,-0.01950649,0.0044005127,0.009543196,-0.0028601582,-0.0034132856,0.004806606,0.004509038,0.012770939,-0.01882033,0.00708213,-0.009466179,-0.0014720887,0.010831493,-0.029742844,-0.0035008057,-0.015725618,0.011405624,-0.020542728,-0.0051076757,-0.0032189908,-0.00908109,0.011804717,-0.01559959,-0.013975216,-0.012014765,-0.02107485,0.005436751,-0.004414516,-0.0057133147,-0.0117627075,-0.009214121,-0.014318295,0.018260203,-0.0037423612,-0.025401846,-0.017952131,0.011097554,-0.008478952,0.00060520176,0.032011367,0.010313374,-0.027530337,0.019142406,0.0145493485,-0.02832852,-6.853921e-05,0.008506957,0.010425399,-0.027446317,-0.0070191156,-0.047162853,0.02806246,-0.0030947123,-0.034083843,-0.015655603,-0.0049396367,0.008787022,-0.008142874,-0.012476872,0.02020665,-0.01634176,0.010789483,-0.014353303,-0.0030947123,-0.01729398,-0.012245818,0.018890347,-0.011972755,-0.0036093306,-0.005076168,0.015277516,-0.0015674857,0.012217812,0.011503647,-0.012378849,0.0009758496,-0.010488414,0.0127079245,-0.012070778,-0.013022997,-0.0037038524,-0.022097085,0.0034833017,0.023133324,-0.00076273805,0.0012839205,-0.013177033,0.032963585,0.027208261,0.02206908,-0.003450044,-0.0325995,-0.0006817819,-0.018974368,-0.0036513403,-0.010537425,-0.0057553244,-0.0076457597,-0.0075757434,-0.0017258972,0.024785705,0.0065114987,-0.0071976567,-0.039769154,0.006543006,0.020150637,-0.009802256,-0.017938128,-0.0065114987,0.0046910797,0.043858092,-0.012133792,-0.0045475466,-0.00096359674,0.0066935406,-0.00908109,-0.003241746,0.01051642,0.01847025,-0.0038263807,0.0074777207,0.008450945,-0.0030667058,0.017588047,-0.008962062,-0.020472711,0.009459177,0.0018239197,0.002989688,0.03287957,0.012924975,0.0013985719,-0.00969023,-6.3397405e-05,0.004715585,0.00473659,-0.010698462,0.008688999,-0.008836034,0.00486612,0.028706606,0.014045232,-0.014395313,0.011783712,-0.015445555,-0.018582277,-0.004537044,-0.009508188,0.015389542,0.02264321,-0.0072886776,-0.0013880695,-0.0068545775,-0.030274967,-0.025569884,0.023091314,-0.012700923,-0.037780695,-0.004771598,0.033299662,0.03276754,-0.0020619745,0.0014300791,0.009214121,-0.018260203,0.024267584,-0.011587666,-0.023105318,-0.03624034,0.020150637,0.025947971,0.0010756225,-0.0026606123,-0.008569973,0.011699692,0.03299159,0.024645671,-0.00951519,0.0062244325,0.029434774,0.00051155523,0.0013119269,-0.005104175,-0.008233895,-0.018106166,-0.025625898,-0.018316215,0.0076877694,0.015179493,0.06867181,0.015893659,-0.0086399885,0.01985657,-0.022181105,0.020472711,0.034391914,-0.00464907,-0.024113549,-0.012245818,-0.01225282,0.0103693865,-0.014143255,0.005783331,0.002450564,0.017307984,-0.008450945,0.0035830745,-0.018050155,0.017742082,0.008478952,-0.003124469,0.023483405,-0.0027656364,-0.017714078,0.015179493,0.0061159073,0.006812568,0.0027393803,-0.016187726,0.02572392,0.014220273,-0.024799708,-0.022223115,-0.008226893,0.011804717,-0.0059828768,-0.034924038,-0.0029704336,0.0028479055,-0.0067320494,-0.021718998,-0.017476022,0.0033485207,-0.009921283,0.00894806,-0.010425399,-0.019548498,-0.015697613]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011401908,0.0044837585,-0.0021893762,-0.014756851,-0.0025603976,0.024543416,-0.01526088,0.017557012,-0.011298652,-0.03446999,0.0047147716,0.016016923,-0.016058926,0.013559782,-0.0030171738,-0.025117448,0.027987614,0.006384368,-0.0115296645,-0.01421782,-0.003608708,0.017711021,-0.0070319055,-0.038782235,0.007094909,0.03379795,0.027875608,-0.015414889,0.022793313,0.009156528,-0.0060448484,0.0153028825,-0.037746176,-0.024249397,0.0012381964,-0.00014350828,0.010129584,-0.0009091774,0.004039233,0.0044417563,0.011144643,0.006524376,0.0013720791,-0.01474285,-0.008050464,-0.008239475,0.015512895,-0.039846297,-0.008043463,-0.013433775,0.0103955995,0.024893435,-0.019139104,-0.012649729,-0.01629694,-0.0030206742,-0.0048652804,0.009212531,0.013657788,-0.0148968585,0.021197222,0.018075041,-0.017739022,-0.0014385829,-0.021603245,0.004494259,-0.024739426,-0.012334711,-0.014028809,0.0076024383,0.03452599,0.010283593,-0.010087581,-0.025705483,0.034722,-0.0072244164,-0.0035124526,-0.025775487,-0.013895801,0.01629694,-0.0008978018,-0.023395348,-0.015134873,0.020497182,0.01248872,-0.01684297,0.003505452,0.015540896,-0.013482777,0.0037417158,-0.0040042307,-0.0008085466,0.020315172,0.015232878,0.0077564474,-0.0058173356,-0.008610496,0.026041502,0.0011506913,0.00988457,-0.00710891,-0.0036192087,-0.021057215,-0.009849568,-0.014728849,0.0029366694,0.013755793,0.0037207145,0.0058873394,-0.01335677,-0.03620609,0.035506047,0.011697674,-0.0381382,-6.8308625e-05,-0.009919572,0.007665442,-0.017851029,0.003762717,-0.01596092,0.023675365,0.014462834,0.018089043,-0.008610496,0.012089697,-0.006555878,-0.0061848564,-0.011599669,-0.017248994,-0.013377772,0.0012530723,0.010668615,0.0051067946,0.019209107,-0.015106871,0.017459007,-0.014420832,0.013314768,-0.025425466,-0.03054976,0.007665442,0.0052012997,-0.01958713,0.017963035,-0.0020388674,0.016058926,0.011011635,0.026349518,0.017010981,0.012985749,0.002133373,-0.03830621,0.021743253,0.029289689,0.016548954,0.021057215,-0.029541703,-0.009338538,-0.021225223,-0.008190473,-0.0073294225,0.0137627935,0.0059783445,0.018257052,0.010724618,0.010024578,0.014644844,-0.0052993055,0.012495721,0.0042947475,-0.01128465,0.031725828,-0.028841663,0.0005136546,-0.006989903,0.019363116,0.021225223,-0.005691328,-0.01751501,-0.02549547,0.017262995,-0.0017308498,0.0050612916,0.024963439,-0.019377118,-0.023717368,0.016856972,-0.012229705,0.005169798,0.0019443621,0.01870508,0.01612893,-0.001837606,0.004977287,-0.67024666,-0.021883262,0.0038747233,-0.025299458,0.015526895,0.01702498,-0.002030117,-0.016254937,-0.032565877,0.012425716,-0.021141218,0.006783391,0.028057618,-0.028869664,-0.0072874203,-0.026125506,-0.0030049232,-0.03326592,0.009639556,0.0028771658,-0.018677076,0.015918918,-0.019265112,-0.009065523,-0.0014998364,0.02858965,0.0016529703,-0.016800968,0.018761082,0.010143585,-0.009401542,0.03362994,0.005362309,0.0156109,0.04354251,-0.02098721,-0.007010904,0.015554897,0.0001514931,0.050402906,-0.033013903,-0.0119076865,0.0048862817,0.0005232802,-0.011221647,0.0037767177,0.02237329,0.0025533973,0.02013316,0.010633613,0.0120336935,0.015722906,0.009583552,0.008449487,0.020063156,-0.02046918,0.023115333,-0.011424659,0.01144566,0.008281478,0.012607727,0.005187299,-0.017080985,-0.00641937,-0.0072244164,0.026251514,-0.021197222,0.013853799,-0.0046552685,-0.04581064,-0.0068568955,0.017136987,-0.021533241,0.005435813,-0.011032636,0.025957497,0.015358886,0.016492952,0.017795026,0.01891509,-0.00040624218,-0.030801777,0.0041862414,0.020385176,0.033881955,-0.00071097846,-0.033209916,-0.008883513,-0.004693771,0.0026636536,0.0077564474,0.019363116,-0.016492952,-0.019531125,0.0014788352,0.0364301,-0.009849568,0.016576955,-0.016226936,-0.015050868,-0.0024046386,-0.01075262,0.009723561,-0.007252418,-0.010381599,0.0052153007,0.00050359155,0.027791603,0.019993152,-0.020385176,0.010276592,0.019223109,-0.011830682,0.014518837,-0.012292709,-0.033741947,0.040854357,-0.014308825,0.00081423443,-0.007399427,0.0033916954,0.012789737,0.0077494467,-0.018341057,0.0076514413,0.033041906,-0.014280823,-0.031165797,-0.013958805,0.00831648,0.022737311,-0.018257052,0.014287824,-0.012285708,0.017655019,-0.00053553085,-0.00054384384,0.0020388674,0.004256245,-0.022555301,-0.0045572626,0.011312652,0.0015689655,0.017893031,-0.025915494,-0.004060234,-0.008008461,0.008113468,-0.0055408194,-0.008897513,-0.010843625,-0.021169221,-0.012453718,-0.020385176,0.005271304,0.008435487,0.015414889,-0.0312218,-0.025803488,-0.027665595,0.010668615,0.025607476,-0.015694905,0.01752901,-0.015540896,0.006884897,-0.0016713464,0.034273975,0.007357424,-0.022457294,0.014784852,-0.027819604,0.009583552,0.013174759,-0.0027896608,0.0025288959,0.0050857933,-0.013195761,-0.021309229,-0.014840855,0.0008798632,-0.0008623622,0.011690674,-0.00043686893,0.014490835,0.009093524,0.024585418,0.010885628,-0.016744966,0.035142027,-0.0062828623,0.011914687,-0.018145045,-0.0101785865,-0.0005451564,-0.007896455,0.008463488,-0.016646959,0.002479893,0.015694905,0.016646959,0.019699136,0.008064465,-0.007210416,0.007126411,-0.01841106,-0.0011349404,-0.014112813,0.019111102,0.014196819,0.026265515,-0.040014308,-0.021267226,-0.006853395,0.011956689,0.009849568,0.00022324725,0.011809681,-0.021533241,0.015596899,-0.035310037,0.0009433044,0.012558724,-0.0002830788,-0.018761082,0.010696617,-0.0034704502,0.019895148,0.014252822,-0.014840855,0.00607285,0.026965555,-0.00058715884,0.03158582,0.021071214,-0.018033039,0.0104096,0.0059608435,0.0021841258,0.0024658921,-0.004977287,0.0069584013,-0.015134873,0.0056878277,0.036010075,-0.00919153,0.03368594,0.019209107,-0.026979556,-0.0015882165,-0.011851683,0.009436544,-0.003556205,-0.009079523,0.009177529,0.004805777,0.014259822,-0.0061848564,-0.0038992248,0.02048318,0.006972402,0.020021154,0.03332192,-0.0122227045,0.027903609,-0.0047042714,-0.012404716,-0.03228586,-0.022695309,0.003155432,-0.013601785,-0.0003874286,0.0059748446,-0.028029617,0.0260275,0.017080985,0.017192991,0.01474285,0.034189973,0.01614293,-0.034077965,-0.026951553,0.01891509,0.005323807,-0.00900952,0.004924784,-0.022037271,0.01075262,-0.010304594,0.0074694306,0.02150524,0.017361,-0.003797719,-0.004872281,-0.018481066,0.003920226,0.031361807,-0.0115926685,-0.0012023193,-0.0060658497,0.0074484292,0.019657133,-0.0051452965,-0.041694403,0.017122988,-0.031333808,0.031165797,-0.0071579125,-0.016968979,-0.019307112,0.0065698787,-0.025299458,0.022331288,-0.018495066,0.014175817,0.0017194741,0.008127469,-0.017234994,0.030045733,0.01821505,0.005673827,-0.026251514,-0.024249397,0.008862511,0.06373168,0.052699037,-0.0057858336,0.019559128,-0.0023608862,-0.007059907,-0.013741792,-0.0054498143,0.006779891,-0.0040707346,-0.010171587,-0.019013096,0.01838306,-0.010878627,0.005120795,0.0077774483,0.01820105,-0.014434832,-0.022667307,-0.039678287,-0.0070494064,0.0075674364,0.041302383,0.031977843,0.008883513,0.0064438717,0.028645651,0.014000807,-0.013419773,-0.01822905,0.016044926,0.015736908,0.009695559,0.006006346,0.0029436697,0.037858184,0.00052853045,0.014301824,0.020511182,0.011998692,0.015414889,0.008708502,0.0074344287,-0.0052748043,-0.014812854,-0.007052907,-0.011333654,-0.0010964383,-0.0015217128,-0.013020751,-0.00020465243,-0.016282938,-0.04385053,-0.008078466,0.011046637,0.0010649364,-0.01768302,-0.008372483,-0.004963286,-0.00032923772,-0.026503528,-0.023801371,-0.003587707,0.003554455,0.01820105,-0.016562955,-0.006681885,0.0047882763,-0.03035375,-0.008638498,-0.012446717,-0.035814065,-0.019755138,-0.0050612916,0.034133967,0.018397061,0.024473412,-0.00710891,-0.013818797,0.006622382,-0.005096294,-0.002791411,-0.01143166,-0.002878916,0.017445005,-0.0074274284,0.001266198,-0.003260438,-0.005586322,0.013748793,-0.0012110699,0.007945458,-0.0038467217,-0.020735195,-0.021799257,0.010388599,0.021701252,0.03326592,-0.009891571,-0.025383463,0.0073644244,-0.030073734,-0.021113217,-0.009016519,-0.005586322,-0.006317864,0.0043507507,-0.008085466,-0.010150585,0.0032114352,0.031837836,-0.012509721,0.011900686,0.003591207,0.0055058175,0.030325748,0.0013519529,0.0094855465,-0.018985095,-0.024249397,0.011291651,-0.02461342,0.0060168467,0.0038292208,-0.03348993,0.012600726,0.017655019,0.0061113522,-0.033181913,0.015204877,-0.013601785,0.048162777,-0.016184933,-0.0017317248,-0.016198933,-0.00032508123,-0.013146758,-0.0034459487,-0.012404716,-0.003258688,0.0065838797,-0.020035155,-0.010507606,-0.009940573,0.0034704502,-0.033545934,-0.012474719,0.024249397,0.004770775,0.010689616,0.0027616592,-0.0074624303,-0.0057438314,-0.007252418,0.0005337808,-0.01960113,-0.0045502624,0.007854453,0.011487663,0.02706356,0.02118322,-0.0076934434,0.016436948,0.010969632,-0.014686847,0.00020443366,0.00078229513,0.021085216,-0.0133847715,0.035590053,-0.003431948,-0.007686443,-0.014364828,0.0070669074,0.026615534,0.007441429,-0.01769702,-0.018607073,-0.029345691,-0.02863165,0.016646959,0.012978748,-0.0089815175,-0.0037102138,-0.021729253,0.0026584032,0.0028894166,0.004525761,-0.0017115987,-0.010661615,0.006037848,-0.007581437,0.023423351,-0.0022173778,0.018257052,-0.017711021,-0.030605765,-0.028505644,0.01022759,0.031193798,-0.01855107,0.026335519,0.017935034,-0.008624497,0.004007731,-0.0028036616,0.002359136,0.008323479,-0.004735773,-0.013272765,0.016548954,-0.023017326,-0.025719482,-0.007847453,0.0040882356,0.012523722,-0.011704675,0.013062753,0.006853395,-0.02133723,0.02028717,-0.0037907185,0.048610803,0.022779314,0.023059329,0.025047444,0.0013519529,0.003766217,0.0016652211,0.0038992248,0.0134477755,0.019293113,0.0098635685,-0.010255591,-0.021799257,0.00432975,0.017613016,-0.024725426,-0.01716499,-0.011172644,0.0020318672,0.0024728926,-0.0025796487,-0.008337481,0.011900686,-0.0034441985,-0.010990634,0.0084144855,0.018061042,-0.0119076865,-0.0031991845,0.026601534,0.01822905,0.027273573,-0.010276592,0.0030556761,0.004123238,0.00937354,0.023549357,0.013489778,-0.020245166,0.029429697,-0.009212531,-0.0059013404,0.02443141,-0.0054183123,0.015484893,-0.007252418,0.0043122484,0.03054976,-0.014784852,0.012152701,-0.0065313764,0.006503375,0.0070669074,-0.0073784254,-0.0014700848,-0.008694502,-0.0096745575,0.023563359,0.012621728,0.008232474,-0.03102579,-0.0031659326,-0.0021176222,-0.012299709,-0.0012898244,0.0061323536,-0.0011034387,-0.033601936,-0.027273573,-0.00831648,0.016212935,0.03659811,-0.005477816,-0.023619361,0.012061696,0.01751501,-0.032033846,0.016268939,0.018999096,-0.012600726,-0.019111102,0.011690674,-0.018593073,-0.03592607,0.0107736215,-0.01752901,-0.038642228,-0.02532746,0.001594342,-0.0045397617,0.002271631,-0.02202327,-0.0058173356,-0.0055898223,0.0033969458,0.0034827008,-0.025593476,0.016758965,0.009618554,0.0028771658,0.016016923,-0.014210819,0.018509068,-0.020105159,-0.016884973,-0.0022436294,-0.04421455,-0.026811546,-0.02237329,-0.008722503,-0.008533492,-0.0022261282,-0.0094855465,-0.0071054096,-0.014406831,0.007210416,0.0018008539,-0.006384368,-0.004959786,0.00902352,0.0036297094,0.012460719,-0.021379232,-0.008127469,-0.0022593802,0.022443295,-0.027455583,-0.014336826,-0.01491086,0.040854357,0.01702498,-0.015134873,-0.0064648725,-0.006279362,-0.03138981,0.0022611304,0.004770775,0.00058453373,-0.00763744,0.007476431,0.012082697,0.03626209,-0.003260438,-0.0065978803,0.0029261687,0.009968575,-0.02097321,-0.020021154,0.0059433426,0.0033269417,-0.021099217,0.0026444024,-0.0020948707,-0.015540896,0.022513298,-0.0054393136,-0.016926976,-0.017921032,0.008925514,0.031333808,0.029961728,0.02392738,0.021491239,-0.022737311,-0.013713791,0.020357173,-0.015190876,-0.014700848,-0.023367347,0.010388599,0.0015602149,0.012446717,-0.0024501414,-0.029037675,0.012404716,0.004133738,-0.0053518084,0.0031676826,0.029569704,0.032985903,0.01474285,-0.019377118,-0.004025232,0.025593476,-0.023297343,-0.00432975,0.022191279,-0.029989729,0.0060273474,-0.016240936,-0.019839143,-0.018495066,-0.01611493,-0.011753677,-0.0017684769,-0.0046587684,0.014105814,0.019027097,-0.023353346,0.02513145,0.009779564,0.0016135931,-0.018243052,-0.004564263,0.007182414,-0.019517126,0.0036367096,0.005946843,-0.019195106,-0.010598611,0.0066188816,0.017276997,0.017977037,0.010724618,0.23162936,-0.018663077,-0.013391772,0.012026694,0.01801904,0.0025743984,0.023297343,0.019237109,0.0001696504,0.010731619,0.009093524,0.01993715,0.0047042714,-0.0076234397,0.02275131,-0.017459007,-0.022555301,-0.008372483,0.004627267,0.017711021,0.013979806,-0.009163529,-0.0047812755,-0.0225413,0.042926475,-0.011039636,-0.009877569,0.0028369136,0.006030848,0.0069233994,-0.007525434,-0.0030661768,0.021043213,0.0011935688,-0.014287824,-0.00043139988,0.021715252,-0.008701501,0.01265673,0.0015313383,0.037046134,-0.024991442,-0.0016975979,-0.012117699,0.012789737,0.02290532,-0.019881146,-0.020371174,0.028155623,0.015540896,-0.016590957,-0.0052923053,0.0027476584,0.029009672,0.008295478,-0.009842567,-0.011606669,0.0025253957,0.012341712,-0.019811142,-0.024221396,0.008050464,-0.008442487,0.02272331,-0.0014184568,-0.0015479643,-0.006779891,-0.010115583,0.018117044,-0.015680904,-0.015512895,-0.015386887,-0.0075884373,-0.012817739,-0.029513702,-0.015750907,0.029065676,-0.0003826158,0.022779314,0.02898167,-0.020595187,-0.00082998537,-0.0010894379,-0.014434832,-0.009107525,-0.021267226,0.03553405,-0.0061673555,-0.0064928746,-0.0068988977,-0.016184933,0.014105814,-0.01196369,0.009975575,-0.0009048022,0.00018616699,0.010493605,0.012607727,0.005446314,0.0011900687,-0.025929496,0.0763324,0.007024905,-0.0030276745,0.00032792517,0.0101785865,0.0020843702,0.023059329,0.0055443197,-0.011368656,0.0020178664,-0.018089043,0.000832173,-0.021393234,-0.0122227045,0.0027634094,0.023577359,-0.006188357,0.0156389,0.001614468,-0.030437754,-0.013048752,-0.00849849,0.011186645,0.0038222205,-0.006555878,0.0070669074,-0.001874358,-0.017332999,-0.006993403,0.0047147716,-0.019727137,0.008820509,0.015554897,-0.010500605,-0.022513298,-0.017389003,-0.008925514,0.01786503,-0.005120795,0.0020581186,0.016170932,-0.0057438314,-0.01127065,-0.013426774,-0.009933573,-0.01230671,0.009030521,0.0066608842,0.00038195951,-0.00485828,0.012810739,-0.009821566,-0.015806912,0.0061078523,-0.012299709,0.01593292,0.0022768814,0.0028806662,-0.0050192894,-0.023619361,0.004627267,0.0095485505,-0.018635074,-0.01422482,-0.018523067,-0.18257053,0.008946516,0.022331288,-0.037718173,0.01092063,0.0010019328,0.028701656,-0.012369713,-0.044186547,0.0156389,0.034946013,-0.012936746,-0.030297747,-0.0026234013,-0.005309806,-0.012824739,-0.008827509,-0.0028509144,0.0035369538,0.013741792,0.04771475,-0.020189164,-0.0025463968,0.0071019093,-0.01786503,-0.0030311747,0.004354251,0.023031328,0.015344885,-0.03088578,-0.008960516,-0.003484451,0.017795026,-0.005705329,-0.0084774885,-0.0039307266,0.0043997536,-0.021897262,-0.021085216,-0.00080679654,0.020259168,0.016828971,0.015022866,-0.0017369752,-0.015484893,0.002584899,0.023451352,-0.013237763,0.005509318,-0.028813662,0.0024483912,-0.0070844083,0.011690674,-0.006541877,0.0020721194,0.005502317,-0.0063738674,-0.019209107,0.0044172546,-0.0046167662,0.002185876,-0.005393811,0.01197769,0.01855107,0.0051977998,0.0061848564,7.596532e-05,0.014882858,-0.040882356,0.00935254,-0.008799507,-0.0052258014,-0.011228647,-0.00485828,0.0021421234,0.03589807,-0.018467065,-0.009478547,0.0033356922,-0.022149278,-0.008645498,0.01822905,-0.007476431,-0.001752726,-0.0042072427,-0.0045817643,-0.00047996518,0.037914187,-0.007952458,-0.013468777,0.020651191,-0.047462735,-0.0044977595,-0.014490835,-0.0014053311,0.018397061,0.014231821,-0.021379232,0.015232878,-0.004791776,0.013608784,0.00029270438,-0.001629344,-0.00028395388,0.030633766,0.0032359366,0.0029506702,0.015148873,0.033741947,-0.0063248645,-0.026741542,-0.02184126,9.166153e-05,0.0039622285,0.014364828,0.028127622,-0.0075044325,0.009905571,0.009821566,-0.006744889,0.066027805,0.0018831085,-0.013818797,0.014448833,-0.009065523,-0.022835316,-0.11671073,-0.046370674,-0.0044837585,-0.0030276745,-0.008344481,0.024263399,-0.008085466,0.0016363444,-0.028869664,0.031725828,-0.016926976,-0.030101735,0.023885377,0.0018446064,-0.004249245,-0.032733887,0.003101179,-0.0065768794,-0.027847605,0.03326592,-0.012089697,-0.021407234,0.006384368,-0.020959208,0.01231371,0.0043262495,-0.03362994,-0.00833048,0.0036542106,-0.0070179044,0.010255591,-0.010598611,0.014588841,1.4793822e-05,-0.0037417158,-0.023465352,-0.0048652804,-0.010381599,0.020371174,-0.017935034,0.011207646,-0.0037522162,-0.00070616574,-0.008890512,-0.039482277,-0.022037271,-0.007168413,0.020763198,0.030129736,-0.02132323,-0.036906127,0.012054695,-0.019489124,0.0044347555,0.00954155,-0.0028806662,-0.0034039463,0.0047812755,0.0045222607,0.012775737,-0.01890109,0.0070704077,-0.009422543,-0.0015234628,0.010822624,-0.029709714,-0.003451199,-0.015722906,0.011417658,-0.020567186,-0.0050857933,-0.0032359366,-0.009065523,0.01179568,-0.015582899,-0.014000807,-0.011984691,-0.021057215,0.0054323133,-0.004480258,-0.00571583,-0.011690674,-0.009219532,-0.014364828,0.018257052,-0.0037172143,-0.025397465,-0.017893031,0.011137642,-0.008456487,0.0005792834,0.032033846,0.010353597,-0.027497586,0.019139104,0.014546839,-0.028323634,-6.300363e-05,0.0085404925,0.010437602,-0.027455583,-0.007059907,-0.047154717,0.028029617,-0.0030906782,-0.034133967,-0.015666904,-0.0049877875,0.008736503,-0.008176471,-0.012481719,0.02013316,-0.016338943,0.010801623,-0.014308825,-0.0031309305,-0.017290996,-0.012243706,0.01890109,-0.0119076865,-0.0036507105,-0.0051032943,0.015288882,-0.0016030924,0.012215705,0.011487663,-0.012355712,0.0009791815,-0.010465603,0.012705732,-0.012103698,-0.013055753,-0.0037067137,-0.022121275,0.0034757005,0.023087332,-0.00081642205,0.0012653229,-0.013188761,0.032985903,0.02724557,0.022037271,-0.0034634497,-0.03262188,-0.0006742264,-0.01888709,-0.0036017078,-0.010535607,-0.005757832,-0.0076724426,-0.0075674364,-0.0017194741,0.02479543,0.0064963745,-0.007182414,-0.039762292,0.0065803793,0.020189164,-0.009807565,-0.017963035,-0.006499875,0.004770775,0.04385053,-0.0121457,-0.0045397617,-0.00097568124,0.006730888,-0.009072523,-0.0031851837,0.010507606,0.018467065,-0.00381872,0.0074274284,0.008456487,-0.0030644266,0.017599015,-0.008967517,-0.02045518,0.009408543,0.0017991037,0.0030066734,0.032873895,0.012852741,0.0014114564,-0.009681558,-6.808987e-05,0.004767275,0.0047287727,-0.010731619,0.008708502,-0.008834509,0.0048652804,0.028757658,0.014014808,-0.014420832,0.0118446825,-0.015526895,-0.018523067,-0.0045537627,-0.009492547,0.015358886,0.022597304,-0.007336423,-0.0013642036,-0.006832394,-0.030269746,-0.025579475,0.023171335,-0.012684732,-0.03783018,-0.004770775,0.03332192,0.03278989,-0.00208262,0.0014482085,0.009254534,-0.018271053,0.024249397,-0.011585668,-0.023115333,-0.03620609,0.02013316,0.025971498,0.0010360597,-0.0026811545,-0.008582495,0.011683674,0.032901898,0.024655422,-0.009513549,0.006209358,0.029401695,0.0005136546,0.0013257015,-0.0050507914,-0.008253476,-0.018103044,-0.025649479,-0.018327057,0.007728446,0.015190876,0.06865996,0.01593292,-0.0086805,0.019867146,-0.022177279,0.020511182,0.03432998,-0.004630767,-0.024123391,-0.012278708,-0.01231371,0.010388599,-0.014126815,0.005824336,0.0024431408,0.017290996,-0.008449487,0.0035474545,-0.01804704,0.017753024,0.008449487,-0.0031449313,0.023451352,-0.0027721599,-0.01769702,0.015204877,0.0061148526,0.0067903916,0.0028019114,-0.016184933,0.025733484,0.014189818,-0.02479543,-0.022233281,-0.0082254745,0.011872685,-0.006002846,-0.034918014,-0.0030171738,0.0028316632,-0.006730888,-0.021771256,-0.017543012,0.0033636938,-0.009870569,0.008911514,-0.010423601,-0.019489124,-0.015722906]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.7255161948119574
0.6966888690638526
0.7253142815069079
0.7074607879069607
0.7003910299179055
0.7162695700928983
0.7457069865333786
0.7100585600654548
0.7729744615210281
0.7388962875861903
0.705078727319994
0.6962016517191757
0.7434357694804137
0.720806713224736
0.7546254722350607
0.7722200399919807
0.7442001421444842
0.7770265140688307
0.7224644696796612
0.7101735227595746
0.7104588369154011
0.7230767443178184
0.7001891142709649
0.711536518575466
0.7063409546875835
0.7150682503597076
0.7604980705901343
0.7248014902694085
0.7847726470791787
0.7380085543555411
0.6944979845181342
0.6725366130311066
0.752029693502798
0.7255306515554433
0.712968164593991
0.7627529260761097
0.7526542490734892
0.6751663088980246
0.7465500015351965
0.6690724273354989
0.7067892692418197
0.6986501661607651
0.7092084508336994
0.6980573095059585
0.7723009620472
0.7073511143368103
0.733135058929573
0.7082930926126564
0.7120877562712375
0.700538734426191
0.6976833032664894
0.7325247156588237
{"object":"list","data":[{"object":"embedding","index":0,"embedding":[-0.0011964173,0.004544287,-0.0020814862,-0.01476281,-0.0025362647,0.024502067,-0.01533653,0.01761742,-0.011348473,-0.034423236,0.0047052084,0.01599421,-0.016106157,0.013622366,-0.003022528,-0.02513176,0.027972376,0.0064193737,-0.01162134,-0.014224072,-0.0036242348,0.017673392,-0.007049067,-0.03876112,0.0071645104,0.033751562,0.027902411,-0.015364517,0.022822885,0.009137549,-0.006048554,0.015280558,-0.03769764,-0.024194216,0.0012104105,-0.00013796406,0.010166049,-0.0008929401,0.004026539,0.004418348,0.011124582,0.006552309,0.0013617118,-0.014748817,-0.007969119,-0.008248983,0.015560421,-0.03990856,-0.008011098,-0.0134544475,0.010375947,0.024963843,-0.019072711,-0.012649839,-0.01630206,-0.003010284,-0.004869628,0.009200519,0.0136923315,-0.014930728,0.021213667,0.018135168,-0.017729364,-0.0014666606,-0.021591485,0.0045058057,-0.024753945,-0.012355982,-0.014077144,0.0076612686,0.03447921,0.010243012,-0.0101100765,-0.025719473,0.034731086,-0.0072064903,-0.003589252,-0.02574746,-0.0139302155,0.01630206,-0.0009462891,-0.023396606,-0.0151266325,0.020528002,0.012502911,-0.016875781,0.003496547,0.015490456,-0.01351042,0.0037501736,-0.003988058,-0.00085445883,0.020304112,0.015238578,0.007794204,-0.0058526495,-0.008654784,0.026041318,0.0011465666,0.009851202,-0.0071260296,-0.003627733,-0.02100377,-0.009844205,-0.014734823,0.002928074,0.013783287,0.003732682,0.0058631445,-0.013356495,-0.036214363,0.035514705,0.011712296,-0.038145423,5.411427e-06,-0.009928165,0.0076612686,-0.017897284,0.0037186889,-0.015980218,0.023648482,0.014440967,0.018023223,-0.008619802,0.012055129,-0.0065593054,-0.0061849877,-0.01160035,-0.017197624,-0.013391478,0.0011526886,0.0106977895,0.005090021,0.01915667,-0.0151266325,0.017379535,-0.014357008,0.013258543,-0.025467597,-0.030505143,0.0077032484,0.0051774783,-0.019604452,0.017939262,-0.0020587472,0.01603619,0.010956664,0.02632118,0.017043699,0.012999669,0.002125215,-0.03831334,0.021773396,0.029301729,0.016539944,0.02108773,-0.029497635,-0.009340451,-0.021227662,-0.00815103,-0.0073394254,0.013741308,0.00597509,0.018247113,0.010732773,0.009998131,0.0146508645,-0.0053069154,0.012530897,0.004299406,-0.011264514,0.03168057,-0.028825961,0.0004989445,-0.006975603,0.019366568,0.021255648,-0.0057092193,-0.017477488,-0.025551556,0.017309569,-0.001753521,0.0050130584,0.024893876,-0.019338582,-0.023732442,0.016861787,-0.012251033,0.0052019665,0.0019170663,0.018750867,0.016120149,-0.0018226124,0.004995567,-0.6703295,-0.021857355,0.0038796104,-0.025243705,0.015434483,0.016973734,-0.0020972285,-0.016246088,-0.032576133,0.012362978,-0.021171689,0.006790193,0.028014356,-0.028881934,-0.007297446,-0.026125276,-0.0030330229,-0.03330378,0.00971127,0.0028598572,-0.018694894,0.015966224,-0.019268615,-0.009060587,-0.001505142,0.028658042,0.0016275824,-0.016777828,0.018778855,0.01012407,-0.009375433,0.0336676,0.005397871,0.015616395,0.043546792,-0.020989778,-0.0070420704,0.015588408,0.00019852832,0.050403453,-0.033051904,-0.011936187,0.0049046115,0.00055098167,-0.011173558,0.003753672,0.022347117,0.0025939867,0.020108206,0.01065581,0.012055129,0.015714347,0.009641305,0.0084169,0.02008022,-0.020500015,0.023144728,-0.011390452,0.011495401,0.008269972,0.01262885,0.0052124616,-0.017043699,-0.0064508584,-0.0071715075,0.026251215,-0.021157695,0.01386025,-0.004691215,-0.045813687,-0.006888145,0.017141651,-0.021535512,0.0054223593,-0.011054616,0.025999337,0.015350523,0.016455986,0.017743358,0.018946772,-0.00040011763,-0.030757021,0.004169969,0.020374076,0.033863507,-0.00074032694,-0.03316385,-0.008850689,-0.004736693,0.0026831932,0.007724238,0.019338582,-0.016595917,-0.019534485,0.0014771556,0.036438253,-0.009893182,0.016553938,-0.016204108,-0.015098646,-0.002385838,-0.010760759,0.009739256,-0.0072624628,-0.010396936,0.0052124616,0.00046439882,0.027748486,0.020024247,-0.020374076,0.010257005,0.019226637,-0.011880214,0.01453892,-0.012293013,-0.0336676,0.040888086,-0.014238066,0.00087457406,-0.0073534185,0.0033880998,0.012775778,0.007759221,-0.018331071,0.007640279,0.03299593,-0.014280045,-0.031204803,-0.013958202,0.008325945,0.022752918,-0.01831708,0.014308032,-0.012327996,0.017715372,-0.00060914084,-0.0005426732,0.0020727406,0.0042189453,-0.022515034,-0.0045163003,0.011341476,0.0015217589,0.017953256,-0.02592937,-0.0039985524,-0.008053078,0.008081065,-0.005478332,-0.008885672,-0.0108167315,-0.021199675,-0.012425948,-0.020360084,0.0052929223,0.008486867,0.01542049,-0.03123279,-0.02578944,-0.02767852,0.010662807,0.025649508,-0.015686361,0.01757544,-0.015588408,0.0068951417,-0.0016476975,0.03425532,0.0073394254,-0.02240309,0.014790797,-0.027874425,0.009571338,0.013153594,-0.0027846438,0.0024890378,0.0050550383,-0.0132165635,-0.021297628,-0.014846769,0.00089162827,-0.0008194759,0.011670317,-0.00046090054,0.0145249255,0.00909557,0.02460002,0.010872705,-0.016749842,0.035122894,-0.0062899366,0.011964173,-0.018163154,-0.010180042,-0.00052868004,-0.007857174,0.008472874,-0.016665883,0.0024400617,0.015742334,0.016679876,0.019758377,0.008053078,-0.0072344765,0.0070560635,-0.018373052,-0.0011491904,-0.014070148,0.019128684,0.0141750965,0.026265208,-0.039964534,-0.021283634,-0.0068636574,0.012013149,0.009830212,0.00018431648,0.011803252,-0.021493532,0.015616395,-0.035346784,0.0009803976,0.012558883,-0.0002411638,-0.018736875,0.010725777,-0.003494798,0.019842336,0.0142870415,-0.014832776,0.006104527,0.026992854,-0.00059864594,0.031624597,0.021031756,-0.018065201,0.010417926,0.0059541003,0.0021444557,0.0024855395,-0.0049500894,0.006947616,-0.015112639,0.0057022227,0.036018457,-0.009207516,0.03369559,0.019226637,-0.027048826,-0.0016004705,-0.011915197,0.009431407,-0.003556018,-0.009123556,0.00915854,0.0048136557,0.014308032,-0.0061744926,-0.003932085,0.020486023,0.0069721043,0.019996261,0.03335975,-0.01230001,0.027846439,-0.004747188,-0.012390966,-0.03229627,-0.022780905,0.0031974427,-0.013608372,-0.00036907024,0.005905124,-0.028014356,0.025999337,0.017113665,0.017141651,0.014748817,0.03425532,0.016190115,-0.034115385,-0.026908895,0.018904792,0.005310414,-0.009011611,0.0048731267,-0.022053258,0.0106977895,-0.010291987,0.0074443743,0.021549504,0.017365543,-0.0037746616,-0.004827649,-0.018484997,0.0039495765,0.031372722,-0.01160035,-0.0011911698,-0.0060415575,0.007388402,0.019674418,-0.005121506,-0.041727677,0.017071685,-0.031400707,0.03114883,-0.007122531,-0.016917761,-0.01928261,0.0065593054,-0.0252577,0.022389095,-0.01849899,0.014182093,0.0017045449,0.008158027,-0.017253596,0.030113334,0.018163154,0.005695226,-0.026251215,-0.02420821,0.008906662,0.063641004,0.05267035,-0.0058036735,0.019562472,-0.0023526042,-0.007038572,-0.01377629,-0.005488827,0.0067831962,-0.004030037,-0.010159052,-0.019086704,0.01835906,-0.010900691,0.0051459935,0.0077522243,0.01819114,-0.014371001,-0.02262698,-0.0396287,-0.00706306,0.007521337,0.04125191,0.031960435,0.008927652,0.0063808924,0.028630055,0.014021171,-0.013391478,-0.01823312,0.016050182,0.01577032,0.00969028,0.0059925816,0.0028755995,0.037837572,0.0005330529,0.014343015,0.020569982,0.012048132,0.015378511,0.008759733,0.0074373777,-0.0052509424,-0.01480479,-0.007098043,-0.011264514,-0.0011351971,-0.0015549926,-0.013034652,-0.0002457553,-0.01634404,-0.043826655,-0.008067071,0.011026629,0.0010477398,-0.017589433,-0.008444887,-0.0048626317,-0.00037716006,-0.0264891,-0.023802407,-0.0035525197,0.0035857537,0.018219126,-0.016525952,-0.006681746,0.0048801233,-0.030421184,-0.008626798,-0.012418952,-0.035878524,-0.019744383,-0.005104014,0.034171358,0.018373052,0.024502067,-0.0070700566,-0.0138112735,0.006625773,-0.005104014,-0.0027846438,-0.011397449,-0.0028406165,0.017477488,-0.0074723605,0.0012611358,-0.0032569137,-0.0056042704,0.013727315,-0.001250641,0.007969119,-0.0038586208,-0.020709913,-0.021787388,0.010403933,0.02174541,0.033275794,-0.009956151,-0.025383638,0.0074373777,-0.030057361,-0.02108773,-0.009011611,-0.0056497483,-0.006328418,0.0043658735,-0.008011098,-0.010152056,0.0032184324,0.031820502,-0.012488917,0.011957176,0.0035962486,0.005527308,0.030309238,0.0013905728,0.009459393,-0.019002745,-0.024250189,0.011306494,-0.024572033,0.006010073,0.0038376309,-0.033583645,0.01262885,0.017603427,0.00611852,-0.033275794,0.015154619,-0.013587383,0.048192527,-0.016218102,-0.001736904,-0.016232094,-0.00026434002,-0.01316059,-0.0034405743,-0.012418952,-0.0032883985,0.006576797,-0.020010255,-0.010487892,-0.009963147,0.0034808049,-0.033527672,-0.012488917,0.024250189,0.0048206523,0.010669803,0.0027461625,-0.0074233846,-0.005712718,-0.0072204834,0.00056235114,-0.019632438,-0.004512802,0.007878163,0.011474412,0.027034834,0.021171689,-0.007710245,0.016455986,0.010977654,-0.014748817,0.00021514522,0.00079717423,0.02108773,-0.013370488,0.03559866,-0.0034650625,-0.007654272,-0.014371001,0.007035074,0.026601044,0.0074233846,-0.017687386,-0.018666908,-0.029385688,-0.028616063,0.016679876,0.012999669,-0.008962635,-0.0037711633,-0.02170343,0.002691939,0.0028423658,0.004582768,-0.0017237854,-0.010683796,0.006048554,-0.007549323,0.023382612,-0.0022284146,0.018261107,-0.017701378,-0.030617088,-0.02856009,0.010236015,0.031092856,-0.018512983,0.026349166,0.017939262,-0.008647788,0.003960071,-0.0027933896,0.0023928345,0.008283965,-0.004747188,-0.013265539,0.016595917,-0.023018789,-0.025719473,-0.00782219,0.004047529,0.012537894,-0.011656323,0.013076631,0.0068461658,-0.021325614,0.020290118,-0.0037816581,0.04864031,0.022836877,0.02310275,0.025061794,0.0013477186,0.003753672,0.0016678127,0.0038831087,0.013475437,0.01928261,0.009837209,-0.010270998,-0.021829369,0.0043308907,0.017603427,-0.024725957,-0.017155645,-0.011173558,0.001994029,0.0025047802,-0.0025590037,-0.008283965,0.011908201,-0.0034633132,-0.010998643,0.0084308935,0.018065201,-0.011908201,-0.003200941,0.026671011,0.018261107,0.027258724,-0.010264001,0.0030907446,0.0041594743,0.009438403,0.02350855,0.013496427,-0.020206159,0.02944166,-0.009214512,-0.0059261136,0.024376128,-0.0054223593,0.015518442,-0.0072064903,0.0043029045,0.030505143,-0.014748817,0.012139088,-0.006531319,0.006475346,0.007007087,-0.0073953983,-0.0014299286,-0.008738744,-0.009676287,0.02355053,0.012642843,0.008290962,-0.03106487,-0.0031484666,-0.0020535,-0.01227902,-0.0012348986,0.006094032,-0.001151814,-0.033583645,-0.027230738,-0.008283965,0.016232094,0.036578186,-0.005432854,-0.023620496,0.012048132,0.017519467,-0.032044392,0.01630206,0.018946772,-0.012572876,-0.01915667,0.011670317,-0.018596943,-0.035962485,0.010781749,-0.017547455,-0.03862119,-0.02535565,0.0016083417,-0.004519799,0.0022406587,-0.021997286,-0.0058771376,-0.0056147655,0.0033968457,0.0035000453,-0.025579542,0.016777828,0.009648301,0.0028178776,0.015952231,-0.014203083,0.018484997,-0.020136192,-0.016931754,-0.002221418,-0.044218466,-0.026824936,-0.02240309,-0.008731747,-0.008535842,-0.0022126723,-0.009403421,-0.007094545,-0.0144129805,0.00722748,0.0017928769,-0.006373896,-0.004929099,0.008990621,0.0036032451,0.012432945,-0.021395579,-0.008123044,-0.0022354112,0.022445068,-0.027468622,-0.014343015,-0.0148887485,0.040832113,0.017057693,-0.015140626,-0.0064543565,-0.0062759435,-0.031372722,0.00234036,0.0047786725,0.000572846,-0.007654272,0.0074933507,0.012083115,0.036242347,-0.0032621613,-0.0065558073,0.0029368196,0.010026117,-0.02100377,-0.019996261,0.0059575983,0.0033443712,-0.02108773,0.0026009833,-0.002112971,-0.015560421,0.022487048,-0.005443349,-0.016917761,-0.017897284,0.008941645,0.031372722,0.02991743,0.023914352,0.021493532,-0.022766912,-0.013755301,0.02038807,-0.015140626,-0.014748817,-0.023396606,0.010375947,0.0015611147,0.012411955,-0.0025135258,-0.028993879,0.012390966,0.0041139964,-0.005383878,0.003178202,0.029665552,0.032967944,0.014748817,-0.019394554,-0.0039635696,0.025551556,-0.023270667,-0.0043168976,0.022179198,-0.029945416,0.006080039,-0.016204108,-0.019870322,-0.01854097,-0.01603619,-0.011838234,-0.0017578938,-0.004631744,0.01410513,0.019058717,-0.023298653,0.02517374,0.009830212,0.0015952231,-0.018261107,-0.004512802,0.0072064903,-0.019534485,0.00363473,0.0059226155,-0.01915667,-0.010571851,0.0066292714,0.017253596,0.017953256,0.01071878,0.23150325,-0.018680902,-0.013370488,0.012055129,0.018065201,0.0025327664,0.023256673,0.019226637,0.00015971909,0.01071878,0.009109563,0.01995428,0.0047611813,-0.007591303,0.022752918,-0.017435508,-0.022529028,-0.008395911,0.0046282457,0.017715372,0.014000181,-0.009214512,-0.0047541847,-0.022529028,0.042903107,-0.011082603,-0.009935161,0.0028248741,0.00597509,0.0069825994,-0.007500347,-0.003068006,0.021059744,0.0012139088,-0.014301035,-0.00046352425,0.021773396,-0.008689768,0.012649839,0.001523508,0.03708194,-0.025019815,-0.0016363281,-0.012174071,0.012810761,0.022878857,-0.019898308,-0.02038807,0.028154287,0.015560421,-0.01656793,-0.005254441,0.0027619048,0.029021865,0.008325945,-0.009823216,-0.011628336,0.0025082785,0.012355982,-0.019828344,-0.024236197,0.008046081,-0.0084169,0.022682952,-0.0013949457,-0.0015856028,-0.0067866948,-0.010145059,0.018135168,-0.015686361,-0.015490456,-0.015392504,-0.0075843064,-0.012817757,-0.029497635,-0.015756326,0.029105825,-0.000380877,0.022766912,0.028993879,-0.020639949,-0.00085052324,-0.0010932175,-0.01445496,-0.009088574,-0.021255648,0.03554269,-0.006129015,-0.006475346,-0.0069406196,-0.01616213,0.01412612,-0.011957176,0.009970144,-0.00096552976,0.00019185968,0.010473899,0.0126148565,0.0053908746,0.0012042884,-0.025971351,0.076346815,0.0070805517,-0.003083748,0.00037497364,0.010187038,0.0021427064,0.023032783,0.0055692876,-0.011327483,0.0019660424,-0.018079195,0.00083390635,-0.021381587,-0.012244036,0.0028126303,0.023606503,-0.0061744926,0.01564438,0.0016345789,-0.03044917,-0.013041648,-0.008535842,0.011236527,0.003767665,-0.00661178,0.0070210807,-0.0018890799,-0.017365543,-0.006916132,0.004768178,-0.019786363,0.008836696,0.015588408,-0.010445912,-0.02254302,-0.017337557,-0.008955638,0.017911276,-0.0051110107,0.0020604965,0.016148135,-0.0057756873,-0.01127151,-0.013461444,-0.009928165,-0.012320999,0.009102567,0.006706234,0.00038896682,-0.004929099,0.012803764,-0.009830212,-0.015784312,0.00613951,-0.012314003,0.015966224,0.0023228687,0.002870352,-0.0050375466,-0.023606503,0.004666727,0.009480382,-0.018652916,-0.014217076,-0.01849899,-0.18235919,0.008920656,0.022389095,-0.037725627,0.0109426705,0.0009777738,0.028769989,-0.012334992,-0.044190478,0.015602401,0.03492699,-0.012943696,-0.030253265,-0.0026184747,-0.0053384,-0.01283175,-0.008801714,-0.0028790978,0.0035455232,0.013727315,0.04771676,-0.02024814,-0.0025694985,0.0070840498,-0.017869297,-0.0030330229,0.00437287,0.023074761,0.015294551,-0.030896952,-0.008990621,-0.0034458218,0.017855303,-0.0056987246,-0.008535842,-0.003886607,0.0044113514,-0.021899335,-0.021157695,-0.0007914895,0.020304112,0.016805815,0.015014688,-0.0017351549,-0.015518442,0.0025485088,0.023424592,-0.01318158,0.0054258574,-0.028825961,0.0023998313,-0.0070455684,0.011677313,-0.006520824,0.001995778,0.005516813,-0.0063808924,-0.019212643,0.0044708224,-0.004666727,0.0021532013,-0.0053803795,0.01197117,0.01854097,0.0051739803,0.0061849877,6.613966e-05,0.014916735,-0.040916074,0.009368437,-0.008780723,-0.005282427,-0.011264514,-0.0048591336,0.0021339606,0.03585054,-0.018484997,-0.009501372,0.0033758557,-0.022151211,-0.008619802,0.018205134,-0.007451371,-0.0017430261,-0.00420845,-0.0045302934,-0.00047358184,0.03792153,-0.007948129,-0.013503423,0.020597968,-0.047436897,-0.0044848155,-0.014510932,-0.0014789047,0.01831708,0.014252059,-0.021395579,0.015196599,-0.0047751744,0.013650352,0.00028270605,-0.0016459484,-0.00027089933,0.030589102,0.0032271782,0.0029385688,0.015084653,0.033723574,-0.00628294,-0.026782956,-0.02184336,7.1715076e-05,0.0039040986,0.014371001,0.028140295,-0.0074373777,0.009900179,0.00979523,-0.0067132306,0.06599186,0.0018995749,-0.01386025,0.014440967,-0.009074581,-0.022836877,-0.1164233,-0.0464014,-0.0045163003,-0.0030750025,-0.008353932,0.024264183,-0.008102054,0.0016844296,-0.028937906,0.03173654,-0.016917761,-0.03014132,0.023914352,0.0018610936,-0.0043064025,-0.032744054,0.0030959921,-0.0066187764,-0.02781845,0.033275794,-0.012132091,-0.021423565,0.006412377,-0.02100377,0.0123769725,0.0043168976,-0.033639617,-0.0083119515,0.0036662144,-0.007017582,0.010264001,-0.0105858445,0.014608885,6.2791682e-06,-0.0037361803,-0.02350855,-0.00486613,-0.01038994,0.020360084,-0.017855303,0.011194548,-0.003732682,-0.00073901506,-0.008878676,-0.039488766,-0.022039266,-0.0071855006,0.020807866,0.03014132,-0.021339606,-0.03694201,0.012006152,-0.019534485,0.004418348,0.009522363,-0.0028616064,-0.003424832,0.004817154,0.0045407885,0.012803764,-0.01884882,0.0071015414,-0.009466389,-0.0014727827,0.010851715,-0.029777497,-0.0034510691,-0.015742334,0.011446426,-0.020541996,-0.005062035,-0.0032534155,-0.009046594,0.011803252,-0.015616395,-0.013993185,-0.012041136,-0.021101722,0.0054223593,-0.0044358396,-0.005716216,-0.011810248,-0.009235502,-0.014308032,0.01823312,-0.003648723,-0.025411624,-0.01792527,0.011103592,-0.008444887,0.0005977714,0.032044392,0.01032697,-0.027496608,0.01915667,0.014566906,-0.028280227,-7.1879054e-05,0.008528846,0.010452909,-0.02745463,-0.007003589,-0.04710106,0.028056337,-0.003104738,-0.034087397,-0.01564438,-0.0049500894,0.008724751,-0.008179016,-0.012488917,0.020164179,-0.016316054,0.010767756,-0.014315028,-0.0030977414,-0.01726759,-0.012272024,0.018876806,-0.011922194,-0.0036312314,-0.005065533,0.015308544,-0.0015497452,0.01221605,0.011495401,-0.0123769725,0.0009795229,-0.010508882,0.012705812,-0.012097108,-0.013006666,-0.0036837058,-0.022109233,0.003473808,0.023060769,-0.00079367595,0.0012969933,-0.013195573,0.032939956,0.027202751,0.022081247,-0.0034440726,-0.03260412,-0.0006594288,-0.018932778,-0.003648723,-0.010543865,-0.005751199,-0.007640279,-0.007570313,-0.0017622667,0.024851896,0.006520824,-0.007241473,-0.039740644,0.0065837936,0.020192165,-0.009823216,-0.017981242,-0.006552309,0.0047227,0.043882627,-0.012181068,-0.0045372904,-0.0009873941,0.006709732,-0.009081577,-0.0032674086,0.0104599055,0.018512983,-0.003827136,0.007500347,0.0084308935,-0.0030959921,0.017589433,-0.009004614,-0.02047203,0.009487379,0.0017911276,0.0030277753,0.032939956,0.012964685,0.0013792033,-0.009655298,-6.5593056e-05,0.0047296965,0.0047157034,-0.010711783,0.008696765,-0.008780723,0.00488712,0.028714016,0.014021171,-0.014384994,0.011845231,-0.015476462,-0.01854097,-0.0045512835,-0.009515366,0.015406497,0.022612987,-0.007283453,-0.0014360506,-0.006839169,-0.030253265,-0.025551556,0.023144728,-0.012684822,-0.037837572,-0.0048206523,0.03330378,0.032800026,-0.0020692423,0.0014106879,0.009263488,-0.01823312,0.024250189,-0.011572364,-0.023130735,-0.036214363,0.020136192,0.02592937,0.0011010887,-0.002621973,-0.008577823,0.011670317,0.03299593,0.024683978,-0.0095083695,0.0062199705,0.02944166,0.00055054436,0.0012899968,-0.0051005157,-0.008262976,-0.018107181,-0.025677495,-0.018345065,0.0077032484,0.015224585,0.06862258,0.015896259,-0.008689768,0.019870322,-0.022221178,0.020458037,0.034339275,-0.0046597305,-0.02412425,-0.012251033,-0.012307006,0.010396936,-0.014133117,0.005786182,0.0024418107,0.01726759,-0.008409904,0.0035647638,-0.018023223,0.017771345,0.008493863,-0.0031694563,0.023480564,-0.0027584066,-0.017729364,0.015196599,0.0061465064,0.0068356707,0.002763654,-0.016204108,0.025761453,0.014210079,-0.024809917,-0.02223517,-0.008241986,0.011824241,-0.0059960796,-0.034954976,-0.0029683043,0.0028301217,-0.006744715,-0.021759402,-0.017505474,0.0033828525,-0.009872192,0.008948642,-0.010424923,-0.019520493,-0.01572834]}],"model":"text-embedding-ada-002-v2","usage":{"prompt_tokens":10,"total_tokens":10}}
0.6856131791879715
0.7232717429780893
0.7034477786362874
0.7155060851302657
0.7012027369424765
0.7033031672076767
0.7540654916667395
0.7022460098336684
[{"sentences":["Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications.","BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding.","The solid lines present the existing knowledge facts.","The red dotted lines present the facts extracted from the sentence in red.","The green dotdash lines present the facts extracted from the sentence in green."],"sections":[{"title":"Introduction","number":"1"}],"section_type":"main"},{"sentences":["The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations.","As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010).","Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings."],"sections":[{"title":"Related Work","number":"2"}],"section_type":"main"},{"sentences":["Though both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information.","As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE.","The right part is the aggregator for the mutual integration of the input of tokens and entities.","Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding."],"sections":[{"title":"Related Work","number":"2"}],"section_type":"main"}]
0.7307917398413589
0.7345022940738816
0.6991534483080044
0.7238195904065257
0.7411886438452175
0.7332570052600058
0.7119904784326141
0.7262430019318409
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.","formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.","formatted":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Though both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information. As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE. The right part is the aggregator for the mutual integration of the input of tokens and entities. Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding.","formatted":"Though both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information. As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE. The right part is the aggregator for the mutual integration of the input of tokens and entities. Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding."}]},"question":"How does the model extend previous work and models?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.","formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.","formatted":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Though both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information. As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE. The right part is the aggregator for the mutual integration of the input of tokens and entities. Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding.","formatted":"Though both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information. As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE. The right part is the aggregator for the mutual integration of the input of tokens and entities. Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding."}]},"formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.\n\nThe early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.\n\nThough both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information. As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE. The right part is the aggregator for the mutual integration of the input of tokens and entities. Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.","formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.","formatted":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Though both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information. As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE. The right part is the aggregator for the mutual integration of the input of tokens and entities. Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding.","formatted":"Though both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information. As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE. The right part is the aggregator for the mutual integration of the input of tokens and entities. Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding."}]},"formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.\n\nThe early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.\n\nThough both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information. As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE. The right part is the aggregator for the mutual integration of the input of tokens and entities. Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.","formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.","formatted":"The early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Though both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information. As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE. The right part is the aggregator for the mutual integration of the input of tokens and entities. Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding.","formatted":"Though both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information. As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE. The right part is the aggregator for the mutual integration of the input of tokens and entities. Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding."}]},"formatted":"Pre-trained language representation models, including feature-based (Mikolov et al., 2013;Pennington et al., 2014;Peters et al., 2017Peters et al., , 2018 and fine-tuning (Dai and Le, 2015;Howard and Ruder, 2018;Radford et al., 2018;Devlin et al., 2019) approaches, can capture rich language information from text and then benefit many NLP applications. BERT (Devlin et al., 2019), as one of the most recently proposed models, obtains the stateof-the-art results on various NLP applications by simple fine-tuning, including named entity recognition (Sang and De Meulder, 2003), question Figure 1 : An example of incorporating extra knowledge information for language understanding. The solid lines present the existing knowledge facts. The red dotted lines present the facts extracted from the sentence in red. The green dotdash lines present the facts extracted from the sentence in green.\n\nThe early work (Collobert and Weston, 2008;Mikolov et al., 2013;Pennington et al., 2014) focuses on adopting feature-based approaches to transform words into distributed representations. As these pre-trained word representations capture syntactic and semantic information in textual corpora, they are often used as input embeddings and initialization parameters for various NLP models, and offer significant improvements over random initialization parameters (Turian et al., 2010). Since these word-level models often suffer from the word polysemy, Peters et al. (2018) further adopt the sequence-level model (ELMo) to capture complex word features across different linguistic contexts and use ELMo to generate context-aware word embeddings.\n\nThough both feature-based and fine-tuning language representation models have achieved great success, they ignore the incorporation of knowledge information. As demonstrated in recent work, injecting extra knowledge information can significantly enhance original models, such as reading comprehension (Mihaylov and Frank, 2018;Zhong et al., 2018), machine translation (Zaremoodi et al., 2018) The left part is the architecture of ERNIE. The right part is the aggregator for the mutual integration of the input of tokens and entities. Information fusion layer takes two kinds of input: one is the token embedding, and the other one is the concatenation of the token embedding and entity embedding."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
[{"sentences":["The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames).","These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details.","Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues.","Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules.","The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details)."],"sections":[{"title":"The AlphaFold network","number":null}],"section_type":"main"},{"sentences":["We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details).","We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d ."],"sections":[{"title":"Training regimen","number":null}],"section_type":"main"},{"sentences":["Further information on research design is available in the Nature Research Reporting Summary linked to this paper."],"sections":[{"title":"Reporting summary","number":null}],"section_type":"back"}]
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames). These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details. Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues. Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules. The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details).","formatted":"The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames). These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details. Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues. Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules. The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details)."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .","formatted":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Further information on research design is available in the Nature Research Reporting Summary linked to this paper.","formatted":"Further information on research design is available in the Nature Research Reporting Summary linked to this paper."}]},"question":"How does the model extend previous work and models?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames). These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details. Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues. Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules. The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details).","formatted":"The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames). These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details. Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues. Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules. The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details)."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .","formatted":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Further information on research design is available in the Nature Research Reporting Summary linked to this paper.","formatted":"Further information on research design is available in the Nature Research Reporting Summary linked to this paper."}]},"formatted":"The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames). These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details. Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues. Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules. The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details).\n\nWe train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .\n\nFurther information on research design is available in the Nature Research Reporting Summary linked to this paper."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames). These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details. Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues. Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules. The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details).","formatted":"The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames). These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details. Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues. Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules. The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details)."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .","formatted":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Further information on research design is available in the Nature Research Reporting Summary linked to this paper.","formatted":"Further information on research design is available in the Nature Research Reporting Summary linked to this paper."}]},"formatted":"The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames). These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details. Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues. Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules. The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details).\n\nWe train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .\n\nFurther information on research design is available in the Nature Research Reporting Summary linked to this paper."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames). These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details. Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues. Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules. The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details).","formatted":"The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames). These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details. Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues. Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules. The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details)."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .","formatted":"We train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"Further information on research design is available in the Nature Research Reporting Summary linked to this paper.","formatted":"Further information on research design is available in the Nature Research Reporting Summary linked to this paper."}]},"formatted":"The trunk of the network is followed by the structure module that introduces an explicit 3D structure in the form of a rotation and translation for each residue of the protein (global rigid body frames). These representations are initialized in a trivial state with all rotations set to the identity and all positions set to the origin, but rapidly develop and refine a highly accurate protein structure with precise atomic details. Key innovations in this section of the network include breaking the chain structure to allow simultaneous local refinement of all parts of the structure, a novel equivariant transformer to allow the network to implicitly reason about the unrepresented side-chain atoms and a loss term that places substantial weight on the orientational correctness of the residues. Both within the structure module and throughout the whole network, we reinforce the notion of iterative refinement by repeatedly applying the final loss to outputs and then feeding the outputs recursively into the same modules. The iterative refinement using the whole network (which we term 'recycling' and is related to approaches in computer vision 28, 29 ) contributes markedly to accuracy with minor extra training time (see Supplementary Methods 1.8 for details).\n\nWe train five different models using different random seeds, some with templates and some without, to encourage diversity in the predictions (see Supplementary Table 5 and Supplementary Methods 1.12.1 for details). We also fine-tuned these models after CASP14 to add a pTM prediction objective (Supplementary Methods 1.9.7) and use the obtained models for Fig. 2d .\n\nFurther information on research design is available in the Nature Research Reporting Summary linked to this paper."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
0.7110290464883279
0.7511939622825277
0.7246070849441726
[{"sentences":["Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization."],"sections":[{"title":"Introduction","number":"1"}],"section_type":"main"},{"sentences":["Contemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) ."],"sections":[{"title":"Introduction","number":"1"}],"section_type":"main"},{"sentences":["In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary.","To do this with the same template, for each example we randomly selected 4 out of the 5 summaries.","This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."],"sections":[{"title":"F Human Evaluation Details","number":null}],"section_type":"main"}]
{"context":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization.","formatted":"Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Contemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) .","formatted":"Contemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task.","formatted":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."}]},"question":"How does the model extend previous work and models?","answer_model":"chatgpt","top_n":3,"relevance_method":"vector","relevance_model":null}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization.","formatted":"Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Contemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) .","formatted":"Contemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task.","formatted":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."}]},"formatted":"Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization.\n\nContemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) .\n\nIn experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","verbose":false,"default":"","max_tokens":256}
{"self":{"class_name":"OpenAIChatCompletionAgent","model":"gpt-3.5-turbo","temperature":0.0,"top_p":1.0},"prompt":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization.","formatted":"Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Contemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) .","formatted":"Contemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task.","formatted":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."}]},"formatted":"Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization.\n\nContemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) .\n\nIn experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]},"stop":"\"","max_tokens":256}
{"messages":[{"role":"user","content":{"__fstring__":["Background text: \"",{"source":"context","value":{"__fstring__":[{"source":"list((str(p) for p in relevant_paragraphs))[0]","value":"Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization.","formatted":"Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[1]","value":"Contemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) .","formatted":"Contemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) ."},{"source":"F(\"\\n\\n\")","value":{"__fstring__":["\n\n"]},"formatted":"\n\n"},{"source":"list((str(p) for p in relevant_paragraphs))[2]","value":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task.","formatted":"In experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."}]},"formatted":"Recent work leveraging such pre-training for Transformerbased sequence-to-sequence models (Dong et al., 2019; Song et al., 2019; Rothe et al., 2019; Lewis et al., 2019; Raffel et al., 2019) has extended the success to text generation, including abstractive summarization.\n\nContemporaneously, the adoption of Transformer models (Vaswani et al., 2017) pre-trained using self-supervised objectives on large text corpora (Radford et al., 2018a; Devlin et al., 2019) have improved performance on many NLP tasks (Wang et al., 2018; Rajpurkar et al., 2016) .\n\nIn experiment 2, we evaluated 4 models (PEGASUS LARGE pre-trained on HugeNews fine-tuned using different amounts of supervision, 10, 100, 1000, and all examples) alongside the human summary. To do this with the same template, for each example we randomly selected 4 out of the 5 summaries. This resulted in fewer ratings per model, but did not increase the work (and cost) of the task."},"\"\n\nAnswer the following question about the background text above:\n\nQuestion: \"",{"source":"question","value":"How does the model extend previous work and models?","formatted":"How does the model extend previous work and models?"},"\"\nAnswer:"]}}],"stop":"\"","top_p":1.0,"temperature":0.0,"model":"gpt-3.5-turbo","max_tokens":256,"logit_bias":null,"n":1,"cache_id":0}
{"id":"chatcmpl-7lg5JjMVqLxncNMJJNRK3lcgx7BUc","object":"chat.completion","created":1691597545,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model extends previous work and models by incorporating extra knowledge information into pre-trained language representation models. This is done to enhance the original models and improve their performance in various NLP applications. The incorporation of knowledge information has been shown to significantly enhance models in tasks such as reading comprehension and machine translation."},"finish_reason":"stop"}],"usage":{"prompt_tokens":543,"completion_tokens":59,"total_tokens":602}}
"The model extends previous work and models by incorporating extra knowledge information into pre-trained language representation models. This is done to enhance the original models and improve their performance in various NLP applications. The incorporation of knowledge information has been shown to significantly enhance models in tasks such as reading comprehension and machine translation."
["2019_Zhang.pdf","The model extends previous work and models by incorporating extra knowledge information into pre-trained language representation models. This is done to enhance the original models and improve their performance in various NLP applications. The incorporation of knowledge information has been shown to significantly enhance models in tasks such as reading comprehension and machine translation."]
{"id":"chatcmpl-7lg5JiJwl8caZMeQXYh5LNrFOpUOY","object":"chat.completion","created":1691597545,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model extends previous work and models by leveraging improvements proposed in various models such as PaLM and incorporating them into the transformer architecture. It builds upon the advancements made in feed forward models, recurrent neural networks (RNNs), LSTMs, and transformer networks to capture long-range dependencies."},"finish_reason":"stop"}],"usage":{"prompt_tokens":383,"completion_tokens":58,"total_tokens":441}}
"The model extends previous work and models by leveraging improvements proposed in various models such as PaLM and incorporating them into the transformer architecture. It builds upon the advancements made in feed forward models, recurrent neural networks (RNNs), LSTMs, and transformer networks to capture long-range dependencies."
["2023_Touvron.pdf","The model extends previous work and models by leveraging improvements proposed in various models such as PaLM and incorporating them into the transformer architecture. It builds upon the advancements made in feed forward models, recurrent neural networks (RNNs), LSTMs, and transformer networks to capture long-range dependencies."]
{"id":"chatcmpl-7lg5KICEyEnTxCmxXsa8IymGb5O8o","object":"chat.completion","created":1691597546,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model extends previous work and models by leveraging pre-training for Transformer-based sequence-to-sequence models and applying it to text generation tasks, specifically abstractive summarization. Additionally, the adoption of Transformer models pre-trained using self-supervised objectives on large text corpora has improved performance on various NLP tasks."},"finish_reason":"stop"}],"usage":{"prompt_tokens":285,"completion_tokens":62,"total_tokens":347}}
"The model extends previous work and models by leveraging pre-training for Transformer-based sequence-to-sequence models and applying it to text generation tasks, specifically abstractive summarization. Additionally, the adoption of Transformer models pre-trained using self-supervised objectives on large text corpora has improved performance on various NLP tasks."
["2020_Zhang.pdf","The model extends previous work and models by leveraging pre-training for Transformer-based sequence-to-sequence models and applying it to text generation tasks, specifically abstractive summarization. Additionally, the adoption of Transformer models pre-trained using self-supervised objectives on large text corpora has improved performance on various NLP tasks."]
{"id":"chatcmpl-7lg5J7EoYQ0gMSGnQVsHc03qVSL4q","object":"chat.completion","created":1691597545,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model extends previous work and models by introducing a structure module that incorporates an explicit 3D structure in the form of rotation and translation for each residue of the protein. This allows for the development and refinement of a highly accurate protein structure with precise atomic details. The model also includes key innovations such as breaking the chain structure for simultaneous local refinement, using a novel equivariant transformer to reason about unrepresented side-chain atoms, and placing substantial weight on the orientational correctness of the residues. Additionally, the model incorporates iterative refinement by repeatedly applying the final loss to outputs and feeding them recursively into the same modules. This iterative refinement, referred to as "},"finish_reason":"stop"}],"usage":{"prompt_tokens":360,"completion_tokens":129,"total_tokens":489}}
"The model extends previous work and models by introducing a structure module that incorporates an explicit 3D structure in the form of rotation and translation for each residue of the protein. This allows for the development and refinement of a highly accurate protein structure with precise atomic details. The model also includes key innovations such as breaking the chain structure for simultaneous local refinement, using a novel equivariant transformer to reason about unrepresented side-chain atoms, and placing substantial weight on the orientational correctness of the residues. Additionally, the model incorporates iterative refinement by repeatedly applying the final loss to outputs and feeding them recursively into the same modules. This iterative refinement, referred to as"
["2021_Jumper.pdf","The model extends previous work and models by introducing a structure module that incorporates an explicit 3D structure in the form of rotation and translation for each residue of the protein. This allows for the development and refinement of a highly accurate protein structure with precise atomic details. The model also includes key innovations such as breaking the chain structure for simultaneous local refinement, using a novel equivariant transformer to reason about unrepresented side-chain atoms, and placing substantial weight on the orientational correctness of the residues. Additionally, the model incorporates iterative refinement by repeatedly applying the final loss to outputs and feeding them recursively into the same modules. This iterative refinement, referred to as"]
{"id":"chatcmpl-7lg5JgmrMzFL0OkyEmeWw8llAh2o2","object":"chat.completion","created":1691597545,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model extends previous work and models by using the Transformer architecture and demonstrating that language modeling benefits from the ability to learn longer-term dependency. It differs from previous efforts that focused on relieving the vanishing gradient problem in LSTM models by modifying the internal architecture of RNNs. Additionally, the model incorporates a line of work that directly feeds a representation of the wider context into the network as an additional input, ranging from manually defined context representations to document-level topics learned from data. The model also takes into account recent advances in language modeling, such as novel architectures for better context encoding, improved regularization and optimization algorithms, faster Softmax computation, and enriched output distribution family."},"finish_reason":"stop"}],"usage":{"prompt_tokens":414,"completion_tokens":133,"total_tokens":547}}
"The model extends previous work and models by using the Transformer architecture and demonstrating that language modeling benefits from the ability to learn longer-term dependency. It differs from previous efforts that focused on relieving the vanishing gradient problem in LSTM models by modifying the internal architecture of RNNs. Additionally, the model incorporates a line of work that directly feeds a representation of the wider context into the network as an additional input, ranging from manually defined context representations to document-level topics learned from data. The model also takes into account recent advances in language modeling, such as novel architectures for better context encoding, improved regularization and optimization algorithms, faster Softmax computation, and enriched output distribution family."
["2019_Dai.pdf","The model extends previous work and models by using the Transformer architecture and demonstrating that language modeling benefits from the ability to learn longer-term dependency. It differs from previous efforts that focused on relieving the vanishing gradient problem in LSTM models by modifying the internal architecture of RNNs. Additionally, the model incorporates a line of work that directly feeds a representation of the wider context into the network as an additional input, ranging from manually defined context representations to document-level topics learned from data. The model also takes into account recent advances in language modeling, such as novel architectures for better context encoding, improved regularization and optimization algorithms, faster Softmax computation, and enriched output distribution family."]
{"id":"chatcmpl-7lg5JNtzTP6QP5DVFq3NsXIalskZO","object":"chat.completion","created":1691597545,"model":"gpt-3.5-turbo-0613","choices":[{"index":0,"message":{"role":"assistant","content":"The model extends previous work and models in two main ways. First, it is textually grounded, making it suitable for downstream grounded text generation tasks that rely on external knowledge. Second, it is designed for open-ended goal-directed dialogue and is evaluated on a variety of tasks, including traditional task-oriented dialogue and scenarios that involve informing the user. Additionally, the model disentangles intrinsic and extrinsic evaluation, capturing utility and humanness respectively, and advocates for greater use of extrinsic evaluation in dialog pretraining research. The model, GODEL, is shown to be competitive with state-of-the-art pre-trained models and outperforms them in few-shot fine-tuning setups for goal-directed datasets."},"finish_reason":"stop"}],"usage":{"prompt_tokens":1109,"completion_tokens":140,"total_tokens":1249}}
"The model extends previous work and models in two main ways. First, it is textually grounded, making it suitable for downstream grounded text generation tasks that rely on external knowledge. Second, it is designed for open-ended goal-directed dialogue and is evaluated on a variety of tasks, including traditional task-oriented dialogue and scenarios that involve informing the user. Additionally, the model disentangles intrinsic and extrinsic evaluation, capturing utility and humanness respectively, and advocates for greater use of extrinsic evaluation in dialog pretraining research. The model, GODEL, is shown to be competitive with state-of-the-art pre-trained models and outperforms them in few-shot fine-tuning setups for goal-directed datasets."
["2022_Peng.pdf","The model extends previous work and models in two main ways. First, it is textually grounded, making it suitable for downstream grounded text generation tasks that rely on external knowledge. Second, it is designed for open-ended goal-directed dialogue and is evaluated on a variety of tasks, including traditional task-oriented dialogue and scenarios that involve informing the user. Additionally, the model disentangles intrinsic and extrinsic evaluation, capturing utility and humanness respectively, and advocates for greater use of extrinsic evaluation in dialog pretraining research. The model, GODEL, is shown to be competitive with state-of-the-art pre-trained models and outperforms them in few-shot fine-tuning setups for goal-directed datasets."]
[["2023_Touvron.pdf","The model extends previous work and models by leveraging improvements proposed in various models such as PaLM and incorporating them into the transformer architecture. It builds upon the advancements made in feed forward models, recurrent neural networks (RNNs), LSTMs, and transformer networks to capture long-range dependencies."],["2019_Dai.pdf","The model extends previous work and models by using the Transformer architecture and demonstrating that language modeling benefits from the ability to learn longer-term dependency. It differs from previous efforts that focused on relieving the vanishing gradient problem in LSTM models by modifying the internal architecture of RNNs. Additionally, the model incorporates a line of work that directly feeds a representation of the wider context into the network as an additional input, ranging from manually defined context representations to document-level topics learned from data. The model also takes into account recent advances in language modeling, such as novel architectures for better context encoding, improved regularization and optimization algorithms, faster Softmax computation, and enriched output distribution family."],["2022_Peng.pdf","The model extends previous work and models in two main ways. First, it is textually grounded, making it suitable for downstream grounded text generation tasks that rely on external knowledge. Second, it is designed for open-ended goal-directed dialogue and is evaluated on a variety of tasks, including traditional task-oriented dialogue and scenarios that involve informing the user. Additionally, the model disentangles intrinsic and extrinsic evaluation, capturing utility and humanness respectively, and advocates for greater use of extrinsic evaluation in dialog pretraining research. The model, GODEL, is shown to be competitive with state-of-the-art pre-trained models and outperforms them in few-shot fine-tuning setups for goal-directed datasets."],["2019_Zhang.pdf","The model extends previous work and models by incorporating extra knowledge information into pre-trained language representation models. This is done to enhance the original models and improve their performance in various NLP applications. The incorporation of knowledge information has been shown to significantly enhance models in tasks such as reading comprehension and machine translation."],["2021_Jumper.pdf","The model extends previous work and models by introducing a structure module that incorporates an explicit 3D structure in the form of rotation and translation for each residue of the protein. This allows for the development and refinement of a highly accurate protein structure with precise atomic details. The model also includes key innovations such as breaking the chain structure for simultaneous local refinement, using a novel equivariant transformer to reason about unrepresented side-chain atoms, and placing substantial weight on the orientational correctness of the residues. Additionally, the model incorporates iterative refinement by repeatedly applying the final loss to outputs and feeding them recursively into the same modules. This iterative refinement, referred to as"],["2020_Zhang.pdf","The model extends previous work and models by leveraging pre-training for Transformer-based sequence-to-sequence models and applying it to text generation tasks, specifically abstractive summarization. Additionally, the adoption of Transformer models pre-trained using self-supervised objectives on large text corpora has improved performance on various NLP tasks."]]
